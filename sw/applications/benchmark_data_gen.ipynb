{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2022 ETH Zurich and University of Bologna.\n",
    "# Licensed under the Apache License, Version 2.0, see LICENSE for details.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import pathlib\n",
    "import hjson\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "global verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_cstr(a):\n",
    "    out = '{'\n",
    "    if isinstance(a, np.ndarray):\n",
    "        a = a.flat\n",
    "    if isinstance(a, torch.Tensor):\n",
    "        a = a.numpy().flat\n",
    "    for el in a:\n",
    "        out += '{}, '.format(el)\n",
    "    out = out[:-2] + '}'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_data(name='mnist', **kwargs):\n",
    "    \n",
    "    # constants\n",
    "    IN_CH = kwargs['IN_CH']\n",
    "    OUT_CH = kwargs['OUT_CH']\n",
    "    DATASET_SIZE = kwargs['DATASET_SIZE']\n",
    "    \n",
    "    # data\n",
    "    MAT_INPUT = kwargs['INPUT']\n",
    "    MAT_LABELS = kwargs['LABELS']\n",
    "\n",
    "    # network init parameters from golden model\n",
    "    MAT_WEIGHTS = kwargs['WEIGHTS']\n",
    "    MAT_BIASES = kwargs['BIASES'] \n",
    "    \n",
    "    layer_str = ''\n",
    "    layer_str += '#include \"network.h\"\\n\\n'\n",
    "    layer_str += f'network_benchmark_t {name}_t = {{\\n'\n",
    "    layer_str += f'\\t.IN_CH = {IN_CH},\\n'\n",
    "    layer_str += f'\\t.OUT_CH = {OUT_CH},\\n'\n",
    "    layer_str += f'\\t.dtype = FP{kwargs[\"prec\"]}\\n'\n",
    "    layer_str += '};\\n\\n\\n'\n",
    "\n",
    "    ctypes = {\n",
    "        '64': 'double',\n",
    "        '32': 'float',\n",
    "        '16': '__fp16',\n",
    "        'B16': '__bf16',\n",
    "        '8': 'char'\n",
    "    }\n",
    "\n",
    "    dtype = ctypes[str(kwargs['prec'])]\n",
    "\n",
    "    # network initialization\n",
    "    layer_str += f'static {dtype} {name}_weights_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHTS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_biases_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIASES) + ';\\n\\n\\n'\n",
    "\n",
    "\n",
    "    # input data\n",
    "    layer_str += f'static {dtype} {name}_images_dram [{DATASET_SIZE*IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    layer_str += f'static uint32_t {name}_labels_dram [{DATASET_SIZE}][{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "\n",
    "    return layer_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_header_file(layer_type: str, **kwargs):\n",
    "\n",
    "    file_path = '/scratch/msc22f11/msc22f11/snitch/sw/applications/data/'\n",
    "    emit_str = \"// Copyright 2022 ETH Zurich and University of Bologna.\\n\" + \\\n",
    "               \"// Licensed under the Apache License, Version 2.0, see LICENSE for details.\\n\" + \\\n",
    "               \"// SPDX-License-Identifier: Apache-2.0\\n\\n\"\n",
    "\n",
    "    if(layer_type == 'mnist'):\n",
    "        file = file_path + 'data_fp32_benchmark.h'\n",
    "        emit_str += emit_mnist_data(**kwargs)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(emit_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(input, weights, bias, **kwargs):\n",
    "    out = torch.mul(input, weights)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset using DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "mnist_dataset = MNIST(PATH_DATASETS, train=True, transform=transform, download=True)\n",
    "\n",
    "# set seeds for reproducability \n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "mnist_dl = DataLoader(mnist_dataset, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_im, first_label = next(iter(mnist_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n",
      "torch.Size([16, 784])\n",
      "torch.Size([16])\n",
      "torch.Size([1, 16])\n",
      "tensor([7])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "# get input channels\n",
    "IN_CH = 1 * 28 * 28 # 3 channels, 32x32 pixels\n",
    "OUT_CH = 16 # 16 classes\n",
    "r1 = 0\n",
    "r2 = 0.5\n",
    "\n",
    "# get random input data with shape (IN_CH, 1)\n",
    "input = first_im.to(torch.float32).view(first_im.to(torch.float64).size(0), -1) #torch.randn(IN_CH)\n",
    "print(input.shape)\n",
    "\n",
    "# get random weights with shape (OUT_CH, IN_CH)\n",
    "weights = torch.FloatTensor(OUT_CH, IN_CH).uniform_(r1, r2).to(torch.float32) #torch.randn(OUT_CH, IN_CH).to(torch.float64)\n",
    "print(weights.shape)\n",
    "\n",
    "# get random bias with shape (OUT_CH, 1)\n",
    "bias = torch.FloatTensor(OUT_CH).uniform_(r1, r2).to(torch.float32)#torch.randn(OUT_CH).to(torch.float64)\n",
    "print(bias.shape)\n",
    "\n",
    "# calculate the activations of the linear layer\n",
    "activations = input @ weights.t() + bias\n",
    "print(activations.shape)\n",
    "# get a random integer between 0 and 16\n",
    "label = torch.randint(0, 16, (1,))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26.3321, 26.9016, 27.8120, 30.3491, 27.2808, 25.2449, 28.9580, 26.0793,\n",
      "         28.7988, 27.2119, 25.8306, 28.1869, 27.7081, 24.9478, 27.7745, 29.6327]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(activations)\n",
    "# print data type of the activations\n",
    "print(activations.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.349098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(activations.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0073, 0.0129, 0.0321, 0.4055, 0.0189, 0.0025, 0.1009, 0.0057, 0.0860,\n",
      "         0.0176, 0.0044, 0.0467, 0.0289, 0.0018, 0.0309, 0.1981]])\n",
      "torch.Size([1, 16])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# apply softmax to the activations\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "ff_out = softmax(activations)\n",
    "print(ff_out)\n",
    "print(ff_out.shape)\n",
    "print(ff_out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0073,  0.0129,  0.0321,  0.4055,  0.0189,  0.0025,  0.1009, -0.9943,\n",
      "          0.0860,  0.0176,  0.0044,  0.0467,  0.0289,  0.0018,  0.0309,  0.1981]])\n",
      "torch.Size([1, 16])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# transform softmax activations to list\n",
    "ff_out_l = ff_out.tolist()[0]\n",
    "# if index matches label, subtract 1 from value at index\n",
    "ff_out_l[label] = ff_out_l[label] - 1\n",
    "# print the bias gradient \n",
    "bias_gradients = torch.FloatTensor(ff_out_l).reshape(1, -1)\n",
    "print(bias_gradients)\n",
    "print(bias_gradients.shape)\n",
    "print(bias_gradients.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0.7881,    1.3928,    3.4617,   43.7660,    2.0351,    0.2657,\n",
      "          10.8887, -107.3291,    9.2861,    1.8996,    0.4773,    5.0363,\n",
      "           3.1202,    0.1974,    3.3343,   21.3798])\n",
      "torch.Size([16])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# compute the weight gradient matrix\n",
    "weight_gradients = torch.mul(input.t(), bias_gradients).t()\n",
    "# compute the checksum for every column of the weight gradient matrix\n",
    "weight_gradients_checksum = torch.sum(weight_gradients, dim=1)\n",
    "print(weight_gradients_checksum)\n",
    "print(weight_gradients_checksum.shape)\n",
    "print(weight_gradients_checksum.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_update =  tensor([[ 0.3965,  0.4461,  0.3087,  0.2464,  0.1215,  0.0852, -0.0012,  0.7076,\n",
      "          0.1823,  0.0991,  0.1623,  0.1462,  0.4767,  0.2312,  0.4372,  0.1750]])\n",
      "torch.Size([1, 16])\n",
      "torch.float32\n",
      "\n",
      "weight_update_checksum =  tensor([188.4179, 197.7575, 191.1750, 176.6682, 190.4993, 195.2947, 197.8444,\n",
      "        248.8347, 197.1029, 191.0635, 198.1736, 196.9793, 192.9529, 189.7249,\n",
      "        194.1348, 181.0583])\n",
      "torch.Size([16])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# compute the training step\n",
    "bias_update = bias - torch.mul(bias_gradients, 0.5)\n",
    "print(\"bias_update = \", bias_update)\n",
    "print(bias_update.shape)\n",
    "print(bias_update.dtype)\n",
    "weight_update = weights - torch.mul(weight_gradients, 0.5)\n",
    "weight_update_checksum = torch.sum(weight_update, dim=1)\n",
    "print(\"\\nweight_update_checksum = \", weight_update_checksum)\n",
    "print(weight_update_checksum.shape)\n",
    "print(weight_update_checksum.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 3.0625 KB\n",
      "Weights size: 49.0 KB\n",
      "Bias size: 0.0625 KB\n",
      "Output size: 0.0625 KB\n",
      "\n",
      "Total size: 52.125 KB\n"
     ]
    }
   ],
   "source": [
    "# calculate the memory requirements\n",
    "if(activations.dtype == torch.float64):\n",
    "    print(f'Input size: {IN_CH * 64 / 8 / 1024} KB')\n",
    "    print(f'Weights size: {OUT_CH * IN_CH * 64 / 8 / 1024} KB')\n",
    "    print(f'Bias size: {OUT_CH * 64 / 8 / 1024} KB')\n",
    "    print(f'Output size: {OUT_CH * 64 / 8 / 1024} KB')\n",
    "    print(f'\\nTotal size: {(IN_CH + OUT_CH * IN_CH + OUT_CH) * 64 / 8 / 1024} KB')\n",
    "elif(activations.dtype == torch.float32):\n",
    "    print(f'Input size: {IN_CH * 32 / 8 / 1024} KB')\n",
    "    print(f'Weights size: {OUT_CH * IN_CH * 32 / 8 / 1024} KB')\n",
    "    print(f'Bias size: {OUT_CH * 32 / 8 / 1024} KB')\n",
    "    print(f'Output size: {OUT_CH * 32 / 8 / 1024} KB')\n",
    "    print(f'\\nTotal size: {(IN_CH + OUT_CH * IN_CH + OUT_CH) * 32 / 8 / 1024} KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "            'IN_CH': IN_CH,\n",
    "            'OUT_CH': OUT_CH,\n",
    "            'DATASET_SIZE': 1,\n",
    "            'INPUT': input,\n",
    "            'WEIGHTS': weights.detach(),\n",
    "            'BIASES': bias.detach(),\n",
    "            'LABELS': label,\n",
    "            'prec': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mnist_header_file('mnist', **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('msc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ecad0643b88c81fa0e19ea49e906f3e8e46360fe82f2ddcb2e85abcf6121e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
