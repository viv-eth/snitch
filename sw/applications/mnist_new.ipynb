{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2022 ETH Zurich and University of Bologna.\n",
    "# Licensed under the Apache License, Version 2.0, see LICENSE for details.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import pathlib\n",
    "import hjson\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "global verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_cstr(a):\n",
    "    out = '{'\n",
    "    if isinstance(a, np.ndarray):\n",
    "        a = a.flat\n",
    "    if isinstance(a, torch.Tensor):\n",
    "        a = a.numpy().flat\n",
    "    for el in a:\n",
    "        out += '{}, '.format(el)\n",
    "    out = out[:-2] + '}'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check what is missing for CNN\n",
    "def emit_mnist_data(name='mnist_cnn', **kwargs):\n",
    "    \n",
    "    # constants\n",
    "    IN_CH1 = kwargs['IN_CH1']\n",
    "    IN_CH2 = kwargs['IN_CH2']\n",
    "    OUT_CH = kwargs['OUT_CH']\n",
    "    DATASET_SIZE = kwargs['DATASET_SIZE']\n",
    "    \n",
    "    # data\n",
    "    MAT_INPUT = kwargs['INPUT']\n",
    "    MAT_LABELS = kwargs['LABELS']\n",
    "\n",
    "    # network init parameters from golden model\n",
    "    MAT_WEIGHTS = kwargs['WEIGHTS']\n",
    "    MAT_BIASES = kwargs['BIASES']\n",
    "    MAT_WEIGHT_GRADS = kwargs['WEIGHT GRADIENTS']\n",
    "    MAT_BIAS_GRADS = kwargs['BIAS GRADIENTS'] \n",
    "\n",
    "    IN_CH = IN_CH1*IN_CH2\n",
    "    \n",
    "    layer_str = ''\n",
    "    layer_str += '#include \"network.h\"\\n\\n'\n",
    "    layer_str += f'network_t {name}_t = {{\\n'\n",
    "    layer_str += f'\\t.IN_CH1 = {IN_CH1},\\n'\n",
    "    layer_str += f'\\t.IN_CH2 = {IN_CH2},\\n'\n",
    "    layer_str += f'\\t.OUT_CH = {OUT_CH},\\n'\n",
    "    layer_str += f'\\t.dtype = FP{kwargs[\"prec\"]}\\n'\n",
    "    layer_str += '};\\n\\n\\n'\n",
    "\n",
    "    ctypes = {\n",
    "        '64': 'double',\n",
    "        '32': 'float',\n",
    "        '16': '__fp16',\n",
    "        'B16': '__bf16',\n",
    "        '8': 'char'\n",
    "    }\n",
    "\n",
    "    dtype = ctypes[str(kwargs['prec'])]\n",
    "\n",
    "    # network initialization\n",
    "    layer_str += f'static {dtype} {name}_weights_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHTS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_biases_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIASES) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_weight_grads_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHT_GRADS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_bias_grads_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIAS_GRADS) + ';\\n\\n\\n'\n",
    "\n",
    "\n",
    "    # input data\n",
    "    layer_str += f'static {dtype} {name}_images_dram [{DATASET_SIZE*IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    layer_str += f'static uint32_t {name}_labels_dram [{DATASET_SIZE}][{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static {dtype} {name}_images_dram [{IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static uint32_t {name}_labels_dram[{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "\n",
    "    return layer_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset using DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "mnist_dataset = MNIST(PATH_DATASETS, train=True, transform=transform, download=True)\n",
    "\n",
    "# set seeds for reproducability \n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "mnist_dl = DataLoader(mnist_dataset, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: .\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = CNN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we iterate through a smaller subset of the dataset \n",
    "to retrieve the image data with their\n",
    "respective labels\n",
    "\"\"\"\n",
    "\n",
    "data_iterator = iter(mnist_dl)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    s_image, s_label = data_iterator.next()\n",
    "    np_s_image = s_image.numpy().flatten()\n",
    "    np_s_label = s_label.numpy().flatten()\n",
    "    if(i==0):\n",
    "        s_images = np.array(np_s_image.tolist())\n",
    "        s_labels = np.array(np_s_label.tolist())\n",
    "    else:\n",
    "        s_images = np.append(s_images, np_s_image)\n",
    "        s_labels = np.append(s_labels, np_s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_im, first_label = next(iter(mnist_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0137,  0.1058, -0.0069,  0.0514, -0.0232,  0.0712,  0.0820,  0.0368,\n",
       "          0.0433,  0.0888]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "weights_conv1 = net.conv1[0].weight\n",
    "biases_conv1 = net.conv1[0].bias\n",
    "weights_conv2 = net.conv2[0].weight\n",
    "biases_conv2 = net.conv2[0].bias\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(1):\n",
    "    net.zero_grad\n",
    "    output = net(first_im)[0]\n",
    "    loss = criterion(output, first_label)\n",
    "    loss.backward()\n",
    "    weight_grads_conv1 = net.conv1[0].weight.grad\n",
    "    bias_grads_conv1 = net.conv1[0].bias.grad\n",
    "    weight_grads_conv2 = net.conv2[0].weight.grad\n",
    "    bias_grads_conv2 = net.conv2[0].bias.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             416\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 14, 14]          12,832\n",
      "              ReLU-5           [-1, 32, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 32, 7, 7]               0\n",
      "            Linear-7                   [-1, 10]          15,690\n",
      "================================================================\n",
      "Total params: 28,938\n",
      "Trainable params: 28,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.32\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "summary(net, (1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f2d020fb0ab3aa1fc34292ba06ea4aad36f6d83100c7410d044bd1aea761e0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('msc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
