{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2022 ETH Zurich and University of Bologna.\n",
    "# Licensed under the Apache License, Version 2.0, see LICENSE for details.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import pathlib\n",
    "import hjson\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "global verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_cstr(a):\n",
    "    out = '{'\n",
    "    if isinstance(a, np.ndarray):\n",
    "        a = a.flat\n",
    "    if isinstance(a, torch.Tensor):\n",
    "        a = a.numpy().flat\n",
    "    for el in a:\n",
    "        out += '{}, '.format(el)\n",
    "    out = out[:-2] + '}'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_data(name='mini_mnist', **kwargs):\n",
    "    \n",
    "    # constants\n",
    "    IN_CH1 = kwargs['IN_CH1']\n",
    "    IN_CH2 = kwargs['IN_CH2']\n",
    "    OUT_CH = kwargs['OUT_CH']\n",
    "    DATASET_SIZE = kwargs['DATASET_SIZE']\n",
    "    \n",
    "    # data\n",
    "    MAT_INPUT = kwargs['INPUT']\n",
    "    MAT_LABELS = kwargs['LABELS']\n",
    "\n",
    "    # network init parameters from golden model\n",
    "    MAT_WEIGHTS = kwargs['WEIGHTS']\n",
    "    MAT_BIASES = kwargs['BIASES']\n",
    "    MAT_WEIGHT_GRADS = kwargs['WEIGHT GRADIENTS']\n",
    "    MAT_BIAS_GRADS = kwargs['BIAS GRADIENTS'] \n",
    "\n",
    "    IN_CH = IN_CH1*IN_CH2\n",
    "    \n",
    "    layer_str = ''\n",
    "    layer_str += '#include \"network.h\"\\n\\n'\n",
    "    layer_str += f'network_t {name}_t = {{\\n'\n",
    "    layer_str += f'\\t.IN_CH1 = {IN_CH1},\\n'\n",
    "    layer_str += f'\\t.IN_CH2 = {IN_CH2},\\n'\n",
    "    layer_str += f'\\t.OUT_CH = {OUT_CH},\\n'\n",
    "    layer_str += f'\\t.dtype = FP{kwargs[\"prec\"]}\\n'\n",
    "    layer_str += '};\\n\\n\\n'\n",
    "\n",
    "    ctypes = {\n",
    "        '64': 'double',\n",
    "        '32': 'float',\n",
    "        '16': '__fp16',\n",
    "        'B16': '__bf16',\n",
    "        '8': 'char'\n",
    "    }\n",
    "\n",
    "    dtype = ctypes[str(kwargs['prec'])]\n",
    "\n",
    "    # network initialization\n",
    "    layer_str += f'static {dtype} {name}_weights_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHTS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_biases_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIASES) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_weight_grads_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHT_GRADS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_bias_grads_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIAS_GRADS) + ';\\n\\n\\n'\n",
    "\n",
    "\n",
    "    # input data\n",
    "    layer_str += f'static {dtype} {name}_images_dram [{DATASET_SIZE*IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    layer_str += f'static uint32_t {name}_labels_dram [{DATASET_SIZE}][{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static {dtype} {name}_images_dram [{IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static uint32_t {name}_labels_dram[{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "\n",
    "    return layer_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_header_file(layer_type: str, **kwargs):\n",
    "\n",
    "    file_path = '/scratch/msc22f11/msc22f11/snitch/sw/applications/data/'\n",
    "    emit_str = \"// Copyright 2022 ETH Zurich and University of Bologna.\\n\" + \\\n",
    "               \"// Licensed under the Apache License, Version 2.0, see LICENSE for details.\\n\" + \\\n",
    "               \"// SPDX-License-Identifier: Apache-2.0\\n\\n\"\n",
    "\n",
    "    if(layer_type == 'mini_mnist'):\n",
    "        file = file_path + 'data_fp16_mnist.h'\n",
    "        emit_str += emit_mnist_data(**kwargs)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(emit_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset using DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "mnist_dataset = MNIST(PATH_DATASETS, train=True, transform=transform, download=True)\n",
    "\n",
    "# set seeds for reproducability \n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "mnist_dl = DataLoader(mnist_dataset, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scratch/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/scratch/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#ch0000006?line=14'>15</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(np_label\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     <a href='vscode-notebook-cell:/scratch/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/scratch/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#ch0000006?line=16'>17</a>\u001b[0m     images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mappend(images, np_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/scratch/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#ch0000006?line=17'>18</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(labels, np_label)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/scratch/msc22f11/.conda/envs/msc/lib/python3.9/site-packages/numpy/lib/function_base.py:4817\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///scratch/msc22f11/.conda/envs/msc/lib/python3.9/site-packages/numpy/lib/function_base.py?line=4814'>4815</a>\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[1;32m   <a href='file:///scratch/msc22f11/.conda/envs/msc/lib/python3.9/site-packages/numpy/lib/function_base.py?line=4815'>4816</a>\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> <a href='file:///scratch/msc22f11/.conda/envs/msc/lib/python3.9/site-packages/numpy/lib/function_base.py?line=4816'>4817</a>\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we iterate through the dataset \n",
    "to retrieve the image data with their\n",
    "respective labels\n",
    "\"\"\"\n",
    "\n",
    "data_iterator = iter(mnist_dl)\n",
    "\n",
    "for i in range(0, len(mnist_dl)):\n",
    "    image, label = data_iterator.next()\n",
    "    np_image = image.numpy().flatten()\n",
    "    np_label = label.numpy().flatten()\n",
    "    if(i==0):\n",
    "        images = np.array(np_image.tolist())\n",
    "        labels = np.array(np_label.tolist())\n",
    "    else:\n",
    "        images = np.append(images, np_image)\n",
    "        labels = np.append(labels, np_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we iterate through a smaller subset of the dataset \n",
    "to retrieve the image data with their\n",
    "respective labels\n",
    "\"\"\"\n",
    "\n",
    "data_iterator = iter(mnist_dl)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    s_image, s_label = data_iterator.next()\n",
    "    np_s_image = s_image.numpy().flatten()\n",
    "    np_s_label = s_label.numpy().flatten()\n",
    "    if(i==0):\n",
    "        s_images = np.array(np_s_image.tolist())\n",
    "        s_labels = np.array(np_s_label.tolist())\n",
    "    else:\n",
    "        s_images = np.append(s_images, np_s_image)\n",
    "        s_labels = np.append(s_labels, np_s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch = 28*28\n",
    "out_ch = 10\n",
    "\n",
    "class LinLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinLayer, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.lin = nn.Linear(in_ch, out_ch, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        torch.manual_seed(42)\n",
    "        out = self.lin(x.view(x.size(0), -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_im, first_label = next(iter(mnist_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.0\n",
      "acc =  0.390625\n",
      "acc =  0.390625\n",
      "acc =  0.390625\n",
      "acc =  0.390625\n",
      "acc =  0.390625\n",
      "acc =  0.78125\n",
      "acc =  1.171875\n",
      "acc =  1.171875\n",
      "acc =  1.171875\n",
      "acc =  1.171875\n",
      "acc =  1.171875\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.5625\n",
      "acc =  1.953125\n",
      "acc =  1.953125\n",
      "acc =  1.953125\n",
      "acc =  1.953125\n",
      "acc =  2.34375\n",
      "acc =  2.34375\n",
      "acc =  2.34375\n",
      "acc =  2.34375\n",
      "acc =  2.34375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  2.734375\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.125\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.515625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  3.90625\n",
      "acc =  4.296875\n",
      "acc =  4.296875\n",
      "acc =  4.296875\n",
      "acc =  4.296875\n",
      "acc =  4.296875\n",
      "acc =  4.6875\n",
      "acc =  4.6875\n",
      "acc =  4.6875\n",
      "acc =  4.6875\n",
      "acc =  4.6875\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.078125\n",
      "acc =  5.46875\n",
      "acc =  5.859375\n",
      "acc =  5.859375\n",
      "acc =  5.859375\n",
      "acc =  5.859375\n",
      "acc =  6.25\n",
      "acc =  6.25\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  6.640625\n",
      "acc =  7.03125\n",
      "acc =  7.421875\n",
      "acc =  7.421875\n",
      "acc =  7.421875\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  7.8125\n",
      "acc =  8.203125\n",
      "acc =  8.59375\n",
      "acc =  8.59375\n",
      "acc =  8.59375\n",
      "acc =  8.59375\n",
      "acc =  8.984375\n",
      "acc =  8.984375\n",
      "acc =  8.984375\n",
      "acc =  8.984375\n",
      "acc =  9.375\n",
      "acc =  9.375\n",
      "acc =  9.765625\n",
      "acc =  9.765625\n",
      "acc =  9.765625\n",
      "acc =  9.765625\n",
      "acc =  9.765625\n",
      "acc =  10.15625\n",
      "acc =  10.15625\n",
      "acc =  10.15625\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.546875\n",
      "acc =  10.9375\n",
      "acc =  10.9375\n",
      "acc =  11.328125\n",
      "acc =  11.328125\n",
      "acc =  11.328125\n",
      "acc =  11.328125\n",
      "acc =  11.328125\n",
      "acc =  11.328125\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  11.71875\n",
      "acc =  12.109375\n",
      "acc =  12.5\n",
      "acc =  12.890625\n",
      "acc =  12.890625\n",
      "acc =  12.890625\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.28125\n",
      "acc =  13.671875\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.0625\n",
      "acc =  14.453125\n",
      "acc =  14.84375\n",
      "acc =  14.84375\n",
      "acc =  14.84375\n",
      "acc =  14.84375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.234375\n",
      "acc =  15.625\n",
      "acc =  15.625\n",
      "acc =  15.625\n",
      "acc =  15.625\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "net = LinLayer()\n",
    "weights = net.lin.weight\n",
    "biases = net.lin.bias\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "it = iter(mnist_dl) \n",
    "correct = 0\n",
    "\n",
    "for i in range(256):\n",
    "    net.zero_grad\n",
    "    image, label = next(it)\n",
    "    # print(label[0].numpy())\n",
    "    l = label[0].numpy()\n",
    "    output = net(image.to(torch.float32))\n",
    "    pred = torch.argmax(output).numpy()\n",
    "    if(l == pred):\n",
    "        correct += 1\n",
    "    print(\"acc = \", (correct/256) * 100)\n",
    "    # print(torch.argmax(output).numpy())\n",
    "    # loss = criterion(output.to(torch.float32), first_label)\n",
    "    # loss.backward()\n",
    "    # weight_grads = net.lin.weight.grad\n",
    "    # bias_grads = net.lin.bias.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1598, -0.0484,  0.0685,  0.4418,  0.0252, -0.2573,  0.2446, -0.1718,\n",
       "          0.2287,  0.0333]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_grads.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0801,  0.0895,  0.1006,  0.1462,  0.0964, -0.9273,  0.1200,  0.0791,\n",
       "         0.1181,  0.0972])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s_images.astype(np.float16)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "            'IN_CH1': 28,\n",
    "            'IN_CH2': 28,\n",
    "            'OUT_CH': 10,\n",
    "            'DATASET_SIZE': 5,\n",
    "            'INPUT': s_images.astype(np.float16),\n",
    "            'LABELS': s_labels,\n",
    "            'WEIGHTS': weights.detach(),\n",
    "            'BIASES': biases.detach(),\n",
    "            'WEIGHT GRADIENTS': weight_grads,\n",
    "            'BIAS GRADIENTS': bias_grads,\n",
    "            'prec': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mnist_header_file('mini_mnist', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0273, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1598, -0.0484,  0.0685,  0.4418,  0.0252, -0.2573,  0.2446, -0.1718,\n",
      "          0.2287,  0.0333]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0801, 0.0895, 0.1006, 0.1462, 0.0964, 0.0727, 0.1200, 0.0791, 0.1181,\n",
       "         0.0972]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)\n",
    "sm = nn.Softmax(dim=1)\n",
    "sm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4418, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 152,  153,  154, ..., 7737, 7738, 7739]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(weight_grads.flatten() != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0057)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_grads.flatten()[153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0801,  0.0895,  0.1006,  0.1462,  0.0964, -0.9273,  0.1200,  0.0791,\n",
       "         0.1181,  0.0972])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycparser as pyc\n",
    "from pyclibrary import CParser\n",
    "\n",
    "\n",
    "parser = CParser('/home/msc22f11/snitch/sw/applications/data/data_full_mnist.h')\n",
    "\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.defs['variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02730494923889637,\n",
       " 0.029643140733242035,\n",
       " -0.008366874419152737,\n",
       " 0.032807547599077225,\n",
       " -0.007825127802789211,\n",
       " 0.007206810638308525,\n",
       " -0.01738768070936203,\n",
       " 0.020974380895495415,\n",
       " 0.03148367628455162,\n",
       " -0.026201006025075912,\n",
       " 0.03104272112250328,\n",
       " 0.006684260908514261,\n",
       " 0.02638603188097477,\n",
       " 0.004836806561797857,\n",
       " 0.017221003770828247,\n",
       " -0.005042536184191704,\n",
       " 0.027531638741493225,\n",
       " 0.005278890021145344,\n",
       " -0.016672855243086815,\n",
       " 0.009103511460125446,\n",
       " -0.01645488105714321,\n",
       " -0.004188316408544779,\n",
       " -0.014505655504763126,\n",
       " 0.023691821843385696,\n",
       " -0.028191793709993362,\n",
       " -0.016464656218886375,\n",
       " -0.01008481252938509,\n",
       " -0.021474016830325127,\n",
       " 0.0033708258997648954,\n",
       " -0.03527425602078438,\n",
       " 0.032253898680210114,\n",
       " -0.03033815324306488,\n",
       " 0.027572408318519592,\n",
       " 0.005943541415035725,\n",
       " -0.011596591211855412,\n",
       " 0.022069642320275307,\n",
       " 0.005566099192947149,\n",
       " 0.028855836018919945,\n",
       " 0.0039042746648192406,\n",
       " -0.011263328604400158,\n",
       " 0.009595845825970173,\n",
       " -0.009684979915618896,\n",
       " 0.015030627138912678,\n",
       " 0.0318865068256855,\n",
       " 0.020644985139369965,\n",
       " -0.015613305382430553,\n",
       " 0.020616596564650536,\n",
       " 0.006390222813934088,\n",
       " 0.018136966973543167,\n",
       " -0.02176803909242153,\n",
       " -0.035353876650333405,\n",
       " -0.013798590749502182,\n",
       " -0.027393674477934837,\n",
       " 0.02930496074259281,\n",
       " 0.010286834090948105,\n",
       " 0.014793341048061848,\n",
       " 0.011295042000710964,\n",
       " -0.0006212847656570375,\n",
       " 0.02795029617846012,\n",
       " -0.0253754872828722,\n",
       " 0.002248704433441162,\n",
       " -0.024376435205340385,\n",
       " 0.01101257186383009,\n",
       " -0.012299368157982826,\n",
       " 0.010943438857793808,\n",
       " -0.007440767250955105,\n",
       " 0.02962113916873932,\n",
       " -0.021167926490306854,\n",
       " -0.021299930289387703,\n",
       " -0.021301215514540672,\n",
       " 0.032122958451509476,\n",
       " 0.011901826597750187,\n",
       " 0.034366097301244736,\n",
       " -0.029474154114723206,\n",
       " -0.03542415052652359,\n",
       " -0.027941564098000526,\n",
       " -0.024024611338973045,\n",
       " 0.014465720392763615,\n",
       " 0.012788424268364906,\n",
       " 0.02967587299644947,\n",
       " -0.018443763256072998,\n",
       " -0.02434685081243515,\n",
       " 0.018949219956994057,\n",
       " -0.014435875229537487,\n",
       " 0.021675851196050644,\n",
       " -0.008475023321807384,\n",
       " 0.02043021284043789,\n",
       " -0.02774885855615139,\n",
       " -0.018023205921053886,\n",
       " 0.010888445191085339,\n",
       " 0.007550269830971956,\n",
       " -0.009105670265853405,\n",
       " 0.021288195624947548,\n",
       " 0.024278901517391205,\n",
       " -0.025899048894643784,\n",
       " -0.019066721200942993,\n",
       " 0.032702215015888214,\n",
       " -0.012051161378622055,\n",
       " -0.012661299668252468,\n",
       " -0.034556951373815536,\n",
       " -0.020452508702874184,\n",
       " 0.008921559900045395,\n",
       " -0.0047140419483184814,\n",
       " -0.025924500077962875,\n",
       " 0.0008377390913665295,\n",
       " -0.024395769461989403,\n",
       " -0.030299881473183632,\n",
       " -0.01966652274131775,\n",
       " -0.03125757724046707,\n",
       " -0.022740645334124565,\n",
       " 0.03570031747221947,\n",
       " 0.006745534483343363,\n",
       " 0.011005704291164875,\n",
       " -0.03331015631556511,\n",
       " -0.023456208407878876,\n",
       " -0.011887708678841591,\n",
       " 0.0055846828036010265,\n",
       " -0.03142576292157173,\n",
       " -0.015388322994112968,\n",
       " -0.021381022408604622,\n",
       " 9.897351992549375e-05,\n",
       " -0.013289401307702065,\n",
       " -0.0024748488795012236,\n",
       " -0.024201061576604843,\n",
       " -0.02451411448419094,\n",
       " -0.02083577960729599,\n",
       " -0.012224908918142319,\n",
       " -0.02818860486149788,\n",
       " 0.02994535304605961,\n",
       " -0.0070880018174648285,\n",
       " 0.030728455632925034,\n",
       " 0.011127931997179985,\n",
       " -0.03024275042116642,\n",
       " 0.024715544655919075,\n",
       " -0.009826600551605225,\n",
       " -0.013690216466784477,\n",
       " -0.029645375907421112,\n",
       " -0.035505738109350204,\n",
       " 0.010218237526714802,\n",
       " -0.007801567204296589,\n",
       " 0.013904397375881672,\n",
       " -0.029309410601854324,\n",
       " 0.026515327394008636,\n",
       " -0.026216205209493637,\n",
       " -0.006166905630379915,\n",
       " 0.007459632121026516,\n",
       " 0.018437564373016357,\n",
       " 0.028832513839006424,\n",
       " 0.03253426030278206,\n",
       " -0.028318649157881737,\n",
       " 0.00898811686784029,\n",
       " -0.01536164153367281,\n",
       " -0.003913743421435356,\n",
       " -0.026731790974736214,\n",
       " 0.03253066539764404,\n",
       " -0.02621251903474331,\n",
       " 0.019087545573711395,\n",
       " 0.012551414780318737,\n",
       " 0.01160557009279728,\n",
       " -0.019308794289827347,\n",
       " 0.032462555915117264,\n",
       " 0.007848229259252548,\n",
       " 0.00459428783506155,\n",
       " -0.03147338703274727,\n",
       " 0.014992446638643742,\n",
       " -0.005357878748327494,\n",
       " -0.016361583024263382,\n",
       " 0.030676664784550667,\n",
       " 0.007962456904351711,\n",
       " -0.019759872928261757,\n",
       " -0.018076390027999878,\n",
       " -0.0017055614152923226,\n",
       " 0.019941475242376328,\n",
       " -0.009126207791268826,\n",
       " -0.02037767507135868,\n",
       " -0.01223010290414095,\n",
       " -0.026681246235966682,\n",
       " 0.012736874632537365,\n",
       " 0.027644295245409012,\n",
       " -0.033622872084379196,\n",
       " 0.008294668048620224,\n",
       " 0.018449706956744194,\n",
       " 0.0064760493114590645,\n",
       " -0.012718738056719303,\n",
       " 0.0186407919973135,\n",
       " 0.018768329173326492,\n",
       " 0.013354544527828693,\n",
       " -0.006275764666497707,\n",
       " -0.009457188658416271,\n",
       " 0.003820747369900346,\n",
       " -0.006309075281023979,\n",
       " -0.010642895475029945,\n",
       " 0.02282881923019886,\n",
       " 0.030692841857671738,\n",
       " -0.0035356199368834496,\n",
       " -0.007996316999197006,\n",
       " 0.0005211532115936279,\n",
       " -0.002132437191903591,\n",
       " 0.008586117997765541,\n",
       " 0.010008344426751137,\n",
       " -0.03243774175643921,\n",
       " -0.013179919682443142,\n",
       " 0.030076052993535995,\n",
       " 0.013912678696215153,\n",
       " -0.001776341930963099,\n",
       " -0.021532349288463593,\n",
       " -0.021850181743502617,\n",
       " -0.03199167549610138,\n",
       " -0.011641515418887138,\n",
       " 0.012060863897204399,\n",
       " 0.022772202268242836,\n",
       " 0.016489190980792046,\n",
       " -0.031569432467222214,\n",
       " -0.0214772317558527,\n",
       " -0.005636309273540974,\n",
       " 0.03454820066690445,\n",
       " 0.005166339222341776,\n",
       " -0.009248955175280571,\n",
       " 0.014775545336306095,\n",
       " -0.013602913357317448,\n",
       " -0.023116273805499077,\n",
       " 0.026067402213811874,\n",
       " -0.0162393506616354,\n",
       " -0.007159527391195297,\n",
       " -0.03552872687578201,\n",
       " 0.023902524262666702,\n",
       " 0.027058381587266922,\n",
       " 0.013016006909310818,\n",
       " -0.024902651086449623,\n",
       " -0.03524785488843918,\n",
       " -0.029006393626332283,\n",
       " 0.026632152497768402,\n",
       " 0.017146635800600052,\n",
       " 0.03005373105406761,\n",
       " 0.018709639087319374,\n",
       " 0.009039006195962429,\n",
       " -0.0003497387806419283,\n",
       " -0.02716093137860298,\n",
       " -0.03059900738298893,\n",
       " -0.03340531140565872,\n",
       " 0.014620070345699787,\n",
       " -0.017534572631120682,\n",
       " -0.007187592331320047,\n",
       " -0.02055376023054123,\n",
       " -0.006507984362542629,\n",
       " -0.025136960670351982,\n",
       " -0.023336274549365044,\n",
       " 0.0118468152359128,\n",
       " -0.010614157654345036,\n",
       " 0.022047972306609154,\n",
       " -0.011457456275820732,\n",
       " -0.02619883045554161,\n",
       " -0.0063013904727995396,\n",
       " -0.01731240749359131,\n",
       " -0.010926485992968082,\n",
       " -0.03399984538555145,\n",
       " 0.01998182013630867,\n",
       " -0.024864448234438896,\n",
       " 0.01795063354074955,\n",
       " 0.01620658114552498,\n",
       " 0.02551545575261116,\n",
       " -0.027394717559218407,\n",
       " 0.02568560093641281,\n",
       " -0.016883987933397293,\n",
       " 0.013252471573650837,\n",
       " 0.03353981301188469,\n",
       " -0.0050368523225188255,\n",
       " -0.0002761951764114201,\n",
       " -0.008222520351409912,\n",
       " -0.02982087805867195,\n",
       " 0.017139388248324394,\n",
       " -0.03545420989394188,\n",
       " 0.022171426564455032,\n",
       " 0.026722325012087822,\n",
       " 0.03377522900700569,\n",
       " -0.00842426996678114,\n",
       " -0.029344355687499046,\n",
       " 0.008029652759432793,\n",
       " 0.019729547202587128,\n",
       " -0.035546742379665375,\n",
       " -0.00810655951499939,\n",
       " -0.02140912599861622,\n",
       " -0.003123705042526126,\n",
       " -0.017579054459929466,\n",
       " -0.014598842710256577,\n",
       " -0.011337817646563053,\n",
       " -0.033939432352781296,\n",
       " 0.029303841292858124,\n",
       " 0.029940402135252953,\n",
       " -0.005602466408163309,\n",
       " -0.0040672169998288155,\n",
       " -0.014575712382793427,\n",
       " -0.032252244651317596,\n",
       " -0.0347551591694355,\n",
       " 0.013273516669869423,\n",
       " -0.019608791917562485,\n",
       " -0.022959893569350243,\n",
       " -0.0027865427546203136,\n",
       " -0.011893255636096,\n",
       " -0.011554313823580742,\n",
       " 0.0011475427309051156,\n",
       " -0.0075754439458251,\n",
       " -0.012296873144805431,\n",
       " -0.01710021123290062,\n",
       " -0.029065266251564026,\n",
       " 0.029946686699986458,\n",
       " -0.01429239846765995,\n",
       " 0.009463553316891193,\n",
       " -0.01239163987338543,\n",
       " 0.0029021885711699724,\n",
       " 0.03329644724726677,\n",
       " 0.016454381868243217,\n",
       " -0.030949989333748817,\n",
       " 0.01417510025203228,\n",
       " 0.033901531249284744,\n",
       " 0.009395834058523178,\n",
       " 0.023943740874528885,\n",
       " 0.035210270434617996,\n",
       " -0.005472464486956596,\n",
       " 0.007412659469991922,\n",
       " -0.02482268400490284,\n",
       " -0.007359896786510944,\n",
       " 0.026449421420693398,\n",
       " 0.01830878108739853,\n",
       " -0.022599609568715096,\n",
       " -0.028638752177357674,\n",
       " -0.024405846372246742,\n",
       " -0.035245634615421295,\n",
       " -0.02755853720009327,\n",
       " -0.008832050487399101,\n",
       " 0.02410275675356388,\n",
       " 0.005977937486022711,\n",
       " -0.027164481580257416,\n",
       " -0.028650855645537376,\n",
       " 0.01776697486639023,\n",
       " -0.026565762236714363,\n",
       " -0.004397409502416849,\n",
       " 0.017132360488176346,\n",
       " -0.016529003158211708,\n",
       " -0.003894282504916191,\n",
       " -0.003108731471002102,\n",
       " -0.008449405431747437,\n",
       " -0.018108291551470757,\n",
       " -0.031837087124586105,\n",
       " -0.02886989340186119,\n",
       " -0.019123632460832596,\n",
       " 0.03449420630931854,\n",
       " -0.017250526696443558,\n",
       " -0.023983143270015717,\n",
       " 0.008656936697661877,\n",
       " 0.00984322652220726,\n",
       " 0.019568204879760742,\n",
       " 0.027147158980369568,\n",
       " 0.019888363778591156,\n",
       " -0.03541075065732002,\n",
       " 0.003167450660839677,\n",
       " 0.021634038537740707,\n",
       " -0.0033009096514433622,\n",
       " -0.021045686677098274,\n",
       " 0.03404785320162773,\n",
       " -0.01335813757032156,\n",
       " -0.020333733409643173,\n",
       " -0.03219839558005333,\n",
       " 0.0015952971298247576,\n",
       " 0.015826184302568436,\n",
       " 0.007905815728008747,\n",
       " 0.007062491029500961,\n",
       " -0.02708526700735092,\n",
       " -0.03335311636328697,\n",
       " 0.0006289056618697941,\n",
       " 0.03256550431251526,\n",
       " 0.020604334771633148,\n",
       " -0.020794082432985306,\n",
       " -0.004636019468307495,\n",
       " -0.026327986270189285,\n",
       " -0.017229408025741577,\n",
       " 0.006467798259109259,\n",
       " 0.019447803497314453,\n",
       " 0.029584618285298347,\n",
       " -0.032789506018161774,\n",
       " 0.023879116401076317,\n",
       " -0.025189004838466644,\n",
       " 0.013373831287026405,\n",
       " 0.030223047360777855,\n",
       " 0.0005015134811401367,\n",
       " 0.03249318152666092,\n",
       " -0.03043041191995144,\n",
       " -0.013641400262713432,\n",
       " 0.020830461755394936,\n",
       " -0.007780995219945908,\n",
       " -0.007310722954571247,\n",
       " -0.014885418117046356,\n",
       " 0.024618078023195267,\n",
       " 0.017517972737550735,\n",
       " 0.011444645933806896,\n",
       " -0.020070131868124008,\n",
       " -0.028991058468818665,\n",
       " 0.0038628792390227318,\n",
       " 0.01058138720691204,\n",
       " -0.01648971065878868,\n",
       " -0.009992774575948715,\n",
       " 0.024120276793837547,\n",
       " 0.0028449895326048136,\n",
       " 0.0016113690799102187,\n",
       " -0.008789305575191975,\n",
       " -0.032342489808797836,\n",
       " -0.03358062356710434,\n",
       " -0.01707196794450283,\n",
       " -0.018154336139559746,\n",
       " 0.011126914992928505,\n",
       " -0.010396813042461872,\n",
       " -0.013972219079732895,\n",
       " 0.034051068127155304,\n",
       " 0.012440103106200695,\n",
       " 0.025460798293352127,\n",
       " -0.017289740964770317,\n",
       " -0.014588100835680962,\n",
       " 0.013126445934176445,\n",
       " -0.023795541375875473,\n",
       " -0.02334657497704029,\n",
       " -0.0017249883385375142,\n",
       " -0.013062882237136364,\n",
       " -0.026773501187562943,\n",
       " 0.021184248849749565,\n",
       " 0.028720103204250336,\n",
       " 0.005793691147118807,\n",
       " -0.006218331400305033,\n",
       " -0.03308118134737015,\n",
       " -0.013008526526391506,\n",
       " 0.009092343971133232,\n",
       " 0.016840390861034393,\n",
       " -0.00451491167768836,\n",
       " -0.01411974523216486,\n",
       " 0.019900931045413017,\n",
       " -0.028442848473787308,\n",
       " 0.022572072222828865,\n",
       " -0.013855529949069023,\n",
       " 0.0005466214497573674,\n",
       " -0.0070577096194028854,\n",
       " 0.004329962655901909,\n",
       " -0.010792801156640053,\n",
       " 0.025968821719288826,\n",
       " -0.000928470108192414,\n",
       " 0.02787855453789234,\n",
       " 0.03433858975768089,\n",
       " -0.017399678006768227,\n",
       " -0.02605389803647995,\n",
       " 0.028653644025325775,\n",
       " 0.02798621356487274,\n",
       " -0.027269547805190086,\n",
       " -0.0027608319651335478,\n",
       " -0.035218797624111176,\n",
       " -0.029235683381557465,\n",
       " 0.006897947750985622,\n",
       " 0.009501236490905285,\n",
       " 0.0075707524083554745,\n",
       " -0.009720168076455593,\n",
       " 0.03294920548796654,\n",
       " 0.005106355529278517,\n",
       " -0.021074457094073296,\n",
       " -0.0020219215657562017,\n",
       " 0.008576614782214165,\n",
       " 0.012506881728768349,\n",
       " -0.02525288797914982,\n",
       " 0.013385343365371227,\n",
       " -0.018245775252580643,\n",
       " -0.029676442965865135,\n",
       " -0.019507408142089844,\n",
       " 0.034443192183971405,\n",
       " 0.030530637130141258,\n",
       " 0.031981587409973145,\n",
       " 0.020964687690138817,\n",
       " 0.026980342343449593,\n",
       " -0.004780347924679518,\n",
       " -0.01965099573135376,\n",
       " 0.017844878137111664,\n",
       " -0.018506526947021484,\n",
       " -0.024102352559566498,\n",
       " -0.011404787190258503,\n",
       " 0.007494973484426737,\n",
       " 0.018385594710707664,\n",
       " -0.013871751725673676,\n",
       " -0.021020226180553436,\n",
       " 0.004817609675228596,\n",
       " -0.021051187068223953,\n",
       " -0.023252194747328758,\n",
       " 0.018616139888763428,\n",
       " -0.005999450571835041,\n",
       " 0.03263517841696739,\n",
       " 0.03474223613739014,\n",
       " 0.01068234071135521,\n",
       " 0.012291346676647663,\n",
       " 0.008224419318139553,\n",
       " 0.0005593172390945256,\n",
       " -0.002597587648779154,\n",
       " 0.0004908613045699894,\n",
       " 0.013336599804461002,\n",
       " 0.03320610150694847,\n",
       " -0.009255682118237019,\n",
       " -0.015096993185579777,\n",
       " -0.008648744784295559,\n",
       " -0.017254438251256943,\n",
       " 0.006072810851037502,\n",
       " 0.02665887214243412,\n",
       " 0.027927765622735023,\n",
       " 0.01639734022319317,\n",
       " -0.026283269748091698,\n",
       " -0.019168028607964516,\n",
       " -0.007846836932003498,\n",
       " -0.006583005655556917,\n",
       " 0.002937419107183814,\n",
       " -0.03278469666838646,\n",
       " 0.011115883477032185,\n",
       " -0.027245434001088142,\n",
       " -0.0225980244576931,\n",
       " -0.029692234471440315,\n",
       " 0.03111856058239937,\n",
       " -0.033819280564785004,\n",
       " 0.02694167196750641,\n",
       " -0.0012006036704406142,\n",
       " -0.004153528716415167,\n",
       " 0.022338518872857094,\n",
       " -0.0033009862527251244,\n",
       " 0.022398361936211586,\n",
       " 0.02582196332514286,\n",
       " -0.03100750409066677,\n",
       " 0.013742285780608654,\n",
       " 0.006742107216268778,\n",
       " 0.007678990252315998,\n",
       " 0.005213980562984943,\n",
       " 0.009768962860107422,\n",
       " -0.01718095876276493,\n",
       " -0.004569326527416706,\n",
       " 0.03393285721540451,\n",
       " 0.023994626477360725,\n",
       " -0.0013417304726317525,\n",
       " -0.03359039127826691,\n",
       " 0.001565277692861855,\n",
       " -0.024320485070347786,\n",
       " 0.029042556881904602,\n",
       " -0.021681692451238632,\n",
       " -0.00257862894795835,\n",
       " -0.007926523685455322,\n",
       " 0.006355494726449251,\n",
       " 0.03360813111066818,\n",
       " 0.0033935438841581345,\n",
       " 0.02068443037569523,\n",
       " 0.027722202241420746,\n",
       " 0.02883254364132881,\n",
       " -0.01233398076146841,\n",
       " -0.007987737655639648,\n",
       " 0.01721206307411194,\n",
       " -0.009745274670422077,\n",
       " 0.016723714768886566,\n",
       " -0.0078024184331297874,\n",
       " -0.02422329969704151,\n",
       " 0.014537262730300426,\n",
       " 0.005475644953548908,\n",
       " 0.01592315547168255,\n",
       " 0.03548164665699005,\n",
       " 0.024383319541811943,\n",
       " 0.03385647013783455,\n",
       " 0.0019115295726805925,\n",
       " -0.0307218786329031,\n",
       " -0.02505454607307911,\n",
       " -0.02218477800488472,\n",
       " -0.031473156064748764,\n",
       " -0.017901698127388954,\n",
       " -0.032877422869205475,\n",
       " -0.032950546592473984,\n",
       " -0.02134123630821705,\n",
       " -0.03520835563540459,\n",
       " -0.021921874955296516,\n",
       " 0.013618167489767075,\n",
       " 0.02978760190308094,\n",
       " -0.010623672977089882,\n",
       " -0.010388527996838093,\n",
       " 0.019069761037826538,\n",
       " -0.0176203902810812,\n",
       " -0.0168868787586689,\n",
       " 0.0220046266913414,\n",
       " -0.031117917969822884,\n",
       " 0.00436695571988821,\n",
       " 0.0315493568778038,\n",
       " 0.006124517880380154,\n",
       " 0.009712278842926025,\n",
       " -0.020799685269594193,\n",
       " -0.0004927346017211676,\n",
       " 0.0019637304358184338,\n",
       " 0.00876551028341055,\n",
       " 0.013876643031835556,\n",
       " 0.031033137813210487,\n",
       " -0.02726069651544094,\n",
       " 0.0010705463355407119,\n",
       " -0.017844153568148613,\n",
       " -0.028252283111214638,\n",
       " -0.0028599160723388195,\n",
       " -0.03143703192472458,\n",
       " 0.024924973025918007,\n",
       " 0.004136243369430304,\n",
       " -0.01924850419163704,\n",
       " 0.018663538619875908,\n",
       " -0.03380100056529045,\n",
       " -0.013814258389174938,\n",
       " -0.006957812234759331,\n",
       " -0.03034822642803192,\n",
       " -0.022710299119353294,\n",
       " -0.0058292364701628685,\n",
       " 0.02709873765707016,\n",
       " 0.03448765352368355,\n",
       " 0.02272365801036358,\n",
       " -0.021325858309864998,\n",
       " -0.023365043103694916,\n",
       " 0.031167615205049515,\n",
       " 0.012632766738533974,\n",
       " 0.0009488463983871043,\n",
       " 0.004833289887756109,\n",
       " -0.02870345674455166,\n",
       " -0.011924480088055134,\n",
       " 0.03437922149896622,\n",
       " -0.00880829431116581,\n",
       " -0.001791575225070119,\n",
       " -0.02965468354523182,\n",
       " -0.019978826865553856,\n",
       " -0.0007292713853530586,\n",
       " -0.02218426577746868,\n",
       " -0.004428914748132229,\n",
       " 0.014534257352352142,\n",
       " -0.03493490442633629,\n",
       " 0.010607575066387653,\n",
       " -0.02361457794904709,\n",
       " -0.017430394887924194,\n",
       " 0.013711061328649521,\n",
       " 0.028397152200341225,\n",
       " -0.009761023335158825,\n",
       " -0.014663182199001312,\n",
       " -0.0322941392660141,\n",
       " -0.01841634511947632,\n",
       " -0.03127275034785271,\n",
       " -0.008173947222530842,\n",
       " 0.00728769414126873,\n",
       " -0.033459849655628204,\n",
       " 0.031182626262307167,\n",
       " 0.022406818345189095,\n",
       " -0.034962352365255356,\n",
       " -0.017058322206139565,\n",
       " 0.011648399755358696,\n",
       " -0.00733784306794405,\n",
       " -0.0038920175284147263,\n",
       " -0.01612555980682373,\n",
       " 0.028686413541436195,\n",
       " -0.019964223727583885,\n",
       " 0.029617030173540115,\n",
       " 0.0023043667897582054,\n",
       " 0.0071793501265347,\n",
       " 0.027861852198839188,\n",
       " -0.00588448578491807,\n",
       " -0.02033369056880474,\n",
       " -0.005776222329586744,\n",
       " 0.02896619401872158,\n",
       " -0.0264995489269495,\n",
       " 0.008106444962322712,\n",
       " -0.03509969636797905,\n",
       " 0.0187250766903162,\n",
       " 0.013195277191698551,\n",
       " 0.001514009083621204,\n",
       " 0.01532832719385624,\n",
       " 4.0169274143408984e-05,\n",
       " 0.01976260170340538,\n",
       " -0.02827216126024723,\n",
       " -0.005244732368737459,\n",
       " 0.015843380242586136,\n",
       " 0.03556488826870918,\n",
       " 0.018192552030086517,\n",
       " -0.025970514863729477,\n",
       " 0.027467746287584305,\n",
       " -0.007964223623275757,\n",
       " -0.007625516504049301,\n",
       " -0.03246106207370758,\n",
       " -0.005621940363198519,\n",
       " 0.02526167221367359,\n",
       " 0.004980172496289015,\n",
       " -0.020801927894353867,\n",
       " 0.01099328976124525,\n",
       " -0.011451585218310356,\n",
       " 0.032606929540634155,\n",
       " -0.030998380854725838,\n",
       " -0.01128126960247755,\n",
       " -0.03448477014899254,\n",
       " -0.014065364375710487,\n",
       " 0.011258845217525959,\n",
       " 0.03437909483909607,\n",
       " 0.005998083855956793,\n",
       " 0.035012803971767426,\n",
       " 0.006987576372921467,\n",
       " 0.020626286044716835,\n",
       " 0.02863079495728016,\n",
       " 0.02985440567135811,\n",
       " -0.019990134984254837,\n",
       " 0.03283535689115524,\n",
       " 0.021634481847286224,\n",
       " -0.016699250787496567,\n",
       " -0.0170429777354002,\n",
       " -0.029955223202705383,\n",
       " 0.00896918773651123,\n",
       " -0.028948189690709114,\n",
       " 0.01508659590035677,\n",
       " 0.011278489604592323,\n",
       " -0.03102865070104599,\n",
       " 0.009732174687087536,\n",
       " -0.002904662163928151,\n",
       " 0.016314920037984848,\n",
       " 0.020492486655712128,\n",
       " -0.035505183041095734,\n",
       " 0.032753534615039825,\n",
       " 0.02995150163769722,\n",
       " 0.014210131019353867,\n",
       " -0.032641466706991196,\n",
       " -0.01275788526982069,\n",
       " -0.010350316762924194,\n",
       " -0.00917849875986576,\n",
       " 0.020140111446380615,\n",
       " 0.012984664179384708,\n",
       " 0.028292112052440643,\n",
       " -0.013375828042626381,\n",
       " 0.012019277550280094,\n",
       " 0.012706969864666462,\n",
       " -0.029735388234257698,\n",
       " -0.034643568098545074,\n",
       " -0.01853175275027752,\n",
       " 0.024448132142424583,\n",
       " -0.03362356126308441,\n",
       " -0.03108692355453968,\n",
       " 0.020007163286209106,\n",
       " 0.01926889270544052,\n",
       " 0.029371168464422226,\n",
       " -0.026962097734212875,\n",
       " -0.0261392779648304,\n",
       " 0.018320953473448753,\n",
       " 0.03105822391808033,\n",
       " 0.021369244903326035,\n",
       " 0.005594717804342508,\n",
       " 0.011770525947213173,\n",
       " 0.033897385001182556,\n",
       " -0.023043012246489525,\n",
       " -0.016214707866311073,\n",
       " 0.02498096413910389,\n",
       " -0.024437131360173225,\n",
       " -0.01969330757856369,\n",
       " 0.026071110740303993,\n",
       " 0.011268646456301212,\n",
       " 0.011538216844201088,\n",
       " -0.015137158334255219,\n",
       " -0.0004928751150146127,\n",
       " 0.03268688544631004,\n",
       " -0.021436432376503944,\n",
       " 0.00028079323237761855,\n",
       " 0.01698569767177105,\n",
       " -0.024655582383275032,\n",
       " 0.034684889018535614,\n",
       " -0.017843235284090042,\n",
       " -0.0085762869566679,\n",
       " -0.009663224220275879,\n",
       " -0.023273533210158348,\n",
       " -0.035045165568590164,\n",
       " 0.02013755775988102,\n",
       " 0.0094883618876338,\n",
       " -0.03345002979040146,\n",
       " -0.022986672818660736,\n",
       " 0.03529886156320572,\n",
       " 0.01365125272423029,\n",
       " 0.014330166392028332,\n",
       " -0.021367790177464485,\n",
       " -0.015657003968954086,\n",
       " -0.005391219165176153,\n",
       " -0.006531426217406988,\n",
       " -0.0244731567800045,\n",
       " 0.002942319493740797,\n",
       " 0.0035495716147124767,\n",
       " -0.004522179253399372,\n",
       " 0.004951136652380228,\n",
       " -0.014155380427837372,\n",
       " 0.009294710122048855,\n",
       " 0.013469301164150238,\n",
       " -0.018812108784914017,\n",
       " -0.03541354089975357,\n",
       " 0.018694086000323296,\n",
       " 0.008519168943166733,\n",
       " -0.018163856118917465,\n",
       " 0.034417927265167236,\n",
       " -0.01615171507000923,\n",
       " 0.024133814498782158,\n",
       " 0.018118876963853836,\n",
       " -0.02994314767420292,\n",
       " 0.023033620789647102,\n",
       " -0.03283832222223282,\n",
       " -0.01978623867034912,\n",
       " -0.005954104010015726,\n",
       " -0.02407309040427208,\n",
       " 0.03488963842391968,\n",
       " -0.007163559086620808,\n",
       " 0.014185348525643349,\n",
       " -0.03188971430063248,\n",
       " 0.020559515804052353,\n",
       " -0.011099419556558132,\n",
       " -0.027166832238435745,\n",
       " 0.005222248379141092,\n",
       " 0.01730220764875412,\n",
       " 0.03090704046189785,\n",
       " -0.021814024075865746,\n",
       " -0.017575154080986977,\n",
       " 0.006866531912237406,\n",
       " 0.00968790054321289,\n",
       " 0.0137311527505517,\n",
       " 0.019602686166763306,\n",
       " -0.00809834711253643,\n",
       " 0.019841773435473442,\n",
       " 0.026331843808293343,\n",
       " -0.009329340420663357,\n",
       " 0.025409188121557236,\n",
       " 0.01744926907122135,\n",
       " 0.0315018855035305,\n",
       " -0.02029549703001976,\n",
       " -0.01763603650033474,\n",
       " -0.010326390154659748,\n",
       " 0.0018116534920409322,\n",
       " 0.021435679867863655,\n",
       " -0.020387953147292137,\n",
       " 0.017880499362945557,\n",
       " -0.012799335643649101,\n",
       " 0.021575333550572395,\n",
       " -0.0016956159379333258,\n",
       " -0.03128882125020027,\n",
       " -0.019651640206575394,\n",
       " -0.02584828808903694,\n",
       " 0.017712946981191635,\n",
       " -0.023948151618242264,\n",
       " -0.0029756512958556414,\n",
       " 0.007705565541982651,\n",
       " -0.01958552561700344,\n",
       " 0.010302501730620861,\n",
       " -0.03487226366996765,\n",
       " -0.025553874671459198,\n",
       " -0.032361552119255066,\n",
       " -0.010802763514220715,\n",
       " -0.013010622002184391,\n",
       " 0.005114048719406128,\n",
       " -0.006604088470339775,\n",
       " 0.016788644716143608,\n",
       " 0.0327426940202713,\n",
       " 0.01281396858394146,\n",
       " -0.014070268720388412,\n",
       " -0.03344234451651573,\n",
       " 0.012935783714056015,\n",
       " -0.017694925889372826,\n",
       " 0.018174154683947563,\n",
       " 0.023874463513493538,\n",
       " 0.01377573236823082,\n",
       " 0.033511098474264145,\n",
       " 0.03392130136489868,\n",
       " 0.0075621395371854305,\n",
       " -0.026022741571068764,\n",
       " 0.03190862014889717,\n",
       " -0.016946278512477875,\n",
       " -0.016869772225618362,\n",
       " 0.029884953051805496,\n",
       " 0.027671799063682556,\n",
       " 0.010791119188070297,\n",
       " 0.002238708082586527,\n",
       " -0.030041640624403954,\n",
       " -0.0037072899285703897,\n",
       " 0.034254513680934906,\n",
       " 0.009094958193600178,\n",
       " 0.0030577864963561296,\n",
       " -0.0074161081574857235,\n",
       " -0.01245651114732027,\n",
       " 0.021286526694893837,\n",
       " 0.002202447038143873,\n",
       " 0.023234793916344643,\n",
       " -0.006321379449218512,\n",
       " 0.015603900887072086,\n",
       " 0.014741783030331135,\n",
       " 0.005695147439837456,\n",
       " 0.022441895678639412,\n",
       " 0.02238021232187748,\n",
       " 0.03310440480709076,\n",
       " 0.027456285431981087,\n",
       " -0.0091320239007473,\n",
       " -0.030236437916755676,\n",
       " 0.006529195234179497,\n",
       " -0.0003117237938567996,\n",
       " -0.009315192699432373,\n",
       " -0.0059805260971188545,\n",
       " 0.0016797441057860851,\n",
       " 0.02605821006000042,\n",
       " 0.011133615858852863,\n",
       " -0.012681940570473671,\n",
       " -0.01468660682439804,\n",
       " -0.008843976072967052,\n",
       " -0.013803678564727306,\n",
       " 0.03211510181427002,\n",
       " 0.018915904685854912,\n",
       " 0.03224913403391838,\n",
       " 0.00011405775148887187,\n",
       " 0.007202532142400742,\n",
       " 0.012384453788399696,\n",
       " -0.033805470913648605,\n",
       " 0.0031891637481749058,\n",
       " -0.002388928784057498,\n",
       " -0.02002335898578167,\n",
       " -0.02771240659058094,\n",
       " 0.0316169448196888,\n",
       " 0.029038073495030403,\n",
       " 0.016552453860640526,\n",
       " 0.034080348908901215,\n",
       " -0.014493138529360294,\n",
       " -0.006168668158352375,\n",
       " 0.013522093184292316,\n",
       " -0.005900949705392122,\n",
       " -0.00700838677585125,\n",
       " -0.029520053416490555,\n",
       " 0.009595045819878578,\n",
       " -0.021583115682005882,\n",
       " 0.001298793824389577,\n",
       " 0.034820556640625,\n",
       " -0.010993404313921928,\n",
       " -0.011256848461925983,\n",
       " 0.02154688909649849,\n",
       " -0.013130473904311657,\n",
       " -0.003067050827667117,\n",
       " 0.033347804099321365,\n",
       " -0.014641920104622841,\n",
       " -0.025550367310643196,\n",
       " -0.019987277686595917,\n",
       " -0.009901630692183971,\n",
       " -0.01694638468325138,\n",
       " -0.01853327825665474,\n",
       " 0.01442658994346857,\n",
       " 0.006069204770028591,\n",
       " -0.011430771090090275,\n",
       " -0.027746835723519325,\n",
       " -0.011244995519518852,\n",
       " -0.015072827227413654,\n",
       " -0.011622105725109577,\n",
       " -0.032218679785728455,\n",
       " 0.0076938956044614315,\n",
       " -0.02624012902379036,\n",
       " -0.027814257889986038,\n",
       " -0.029179757460951805,\n",
       " 0.014906560070812702,\n",
       " -0.021500954404473305,\n",
       " -0.014741102233529091,\n",
       " 0.02799431048333645,\n",
       " 0.018963009119033813,\n",
       " 0.020478257909417152,\n",
       " -0.033910948783159256,\n",
       " -0.025610707700252533,\n",
       " -0.013482537120580673,\n",
       " 0.029503487050533295,\n",
       " 0.003653586143627763,\n",
       " -0.026710612699389458,\n",
       " 0.00022363664174918085,\n",
       " -0.027738245204091072,\n",
       " -0.007824975065886974,\n",
       " -0.009820538572967052,\n",
       " 0.03091648779809475,\n",
       " 0.01106202695518732,\n",
       " -0.006227540317922831,\n",
       " 0.006033169571310282,\n",
       " -0.010309483855962753,\n",
       " 0.014032156206667423,\n",
       " 0.014127280563116074,\n",
       " 0.009590933099389076,\n",
       " -0.01392060611397028,\n",
       " 0.03046967089176178,\n",
       " -0.005156069993972778,\n",
       " -0.013904167339205742,\n",
       " 0.022368360310792923,\n",
       " 0.0291091687977314,\n",
       " 0.03554142266511917,\n",
       " 0.010580655187368393,\n",
       " -0.012174781411886215,\n",
       " 0.018139000982046127,\n",
       " 0.030641233548521996,\n",
       " -0.03502979129552841,\n",
       " -0.004424533806741238,\n",
       " -0.02435591071844101,\n",
       " 0.006655706092715263,\n",
       " 0.014770887792110443,\n",
       " -0.0073781399987638,\n",
       " -0.0029877552296966314,\n",
       " 0.016075385734438896,\n",
       " -0.006002490408718586,\n",
       " -0.029992125928401947,\n",
       " 0.028576286509633064,\n",
       " -0.017975518479943275,\n",
       " -0.00392351858317852,\n",
       " 0.003368799341842532,\n",
       " -0.002146316459402442,\n",
       " -0.03359593078494072,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.defs['variables']['mini_mnist_weights_dram'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine FP8 from F32\n",
    "\n",
    "Special values:\n",
    "1. exponent and fractional part all zeros --> zero\n",
    "1. exponent all ones and fractional all zeros --> INF\n",
    "1. exponent all ones and fractional non-zero --> NaN\n",
    "\n",
    "FP8 format:  | 5 bit exponent | 2 bit mantissa | <br/>\n",
    "FP8ALT format: | 4 bit exponent | 3 bit mantissa | <br/>\n",
    "\n",
    "Example below is for FP8 format. TODO: Discuss with GIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary equivalent of -0.009314311668276787: 10111100000110001001101100001110\n",
      "\n",
      "Sign     ( 1 bit ) = 1\n",
      "Exponent ( 8 bits) = 01111000\n",
      "Mantissa (23 bits) = 00110001001101100001110\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def floatToBinary32(value):\n",
    "    return ''.join(f'{c:0>8b}' for c in struct.pack('!f', value))\n",
    "\n",
    "# float to binary\n",
    "fl0 = biases.detach().numpy()[0]\n",
    "binstr = floatToBinary32(fl0)\n",
    "print(f'Binary equivalent of {fl0}: {binstr}')\n",
    "\n",
    "print(f'\\nSign     ( 1 bit ) = {binstr[0]}\\nExponent ( 8 bits) = {binstr[1:9]}\\nMantissa (23 bits) = {binstr[9:]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate exponent bias of an FP32\n",
    "exp_bias_fp32 = 2 ** (8 - 1) - 1\n",
    "exp_bias_fp32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate unbiased exponent\n",
    "exponent_fp32 = int('01111000', 2) - exp_bias_fp32\n",
    "exponent_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate exponent bias of an FP8\n",
    "exp_bias_fp8 = 2 ** (5 - 1) - 1\n",
    "exp_bias_fp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the new exponent in the new FP format\n",
    "# minimum exponent: E_min = b'00001 - b'01111 = -14 \n",
    "# maximum exponent: E_max = b'01111 - b'00000 = 15\n",
    "exp_8 = exponent_fp32 + exp_bias_fp8\n",
    "exp_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the binary representation of the new exponent\n",
    "exp_8_bin = \"{0:b}\".format(exp_8)\n",
    "exp_8_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: check this with GIM\n",
    "# determine the new mantissa in the new FP format\n",
    "man_8_bin = binstr[9:11]\n",
    "man_8_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1100000'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 sign it + 5 exponent bits + 2 mantissa bits\n",
    "fp_8 = binstr[0] + exp_8_bin + man_8_bin\n",
    "fp_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f2d020fb0ab3aa1fc34292ba06ea4aad36f6d83100c7410d044bd1aea761e0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('msc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
