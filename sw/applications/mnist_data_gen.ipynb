{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2022 ETH Zurich and University of Bologna.\n",
    "# Licensed under the Apache License, Version 2.0, see LICENSE for details.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import pathlib\n",
    "import hjson\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "global verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_cstr(a):\n",
    "    out = '{'\n",
    "    if isinstance(a, np.ndarray):\n",
    "        a = a.flat\n",
    "    if isinstance(a, torch.Tensor):\n",
    "        a = a.numpy().flat\n",
    "    for el in a:\n",
    "        out += '{}, '.format(el)\n",
    "    out = out[:-2] + '}'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_data(name='mnist', **kwargs):\n",
    "    \n",
    "    # constants\n",
    "    IN_CH1 = kwargs['IN_CH1']\n",
    "    IN_CH2 = kwargs['IN_CH2']\n",
    "    OUT_CH = kwargs['OUT_CH']\n",
    "    DATASET_SIZE = kwargs['DATASET_SIZE']\n",
    "    \n",
    "    # data\n",
    "    MAT_INPUT = kwargs['INPUT']\n",
    "    MAT_LABELS = kwargs['LABELS']\n",
    "\n",
    "    # network init parameters from golden model\n",
    "    MAT_WEIGHTS = kwargs['WEIGHTS']\n",
    "    MAT_BIASES = kwargs['BIASES']\n",
    "    MAT_WEIGHT_GRADS = kwargs['WEIGHT GRADIENTS']\n",
    "    MAT_BIAS_GRADS = kwargs['BIAS GRADIENTS'] \n",
    "\n",
    "    IN_CH = IN_CH1*IN_CH2\n",
    "    \n",
    "    layer_str = ''\n",
    "    layer_str += '#include \"network.h\"\\n\\n'\n",
    "    layer_str += f'network_fp64_t {name}_t = {{\\n'\n",
    "    layer_str += f'\\t.IN_CH1 = {IN_CH1},\\n'\n",
    "    layer_str += f'\\t.IN_CH2 = {IN_CH2},\\n'\n",
    "    layer_str += f'\\t.OUT_CH = {OUT_CH},\\n'\n",
    "    layer_str += f'\\t.dtype = FP{kwargs[\"prec\"]}\\n'\n",
    "    layer_str += '};\\n\\n\\n'\n",
    "\n",
    "    ctypes = {\n",
    "        '64': 'double',\n",
    "        '32': 'float',\n",
    "        '16': '__fp16',\n",
    "        'B16': '__bf16',\n",
    "        '8': 'char'\n",
    "    }\n",
    "\n",
    "    dtype = ctypes[str(kwargs['prec'])]\n",
    "\n",
    "    # network initialization\n",
    "    layer_str += f'static {dtype} {name}_weights_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHTS) + ';\\n\\n\\n'\n",
    "    layer_str += f'static {dtype} {name}_biases_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIASES) + ';\\n\\n\\n'\n",
    "    # layer_str += f'static {dtype} {name}_weight_grads_dram [{OUT_CH}][{IN_CH}] = ' + array_to_cstr(MAT_WEIGHT_GRADS) + ';\\n\\n\\n'\n",
    "    # layer_str += f'static {dtype} {name}_bias_grads_dram [{OUT_CH}][{1}] = ' + array_to_cstr(MAT_BIAS_GRADS) + ';\\n\\n\\n'\n",
    "\n",
    "\n",
    "    # input data\n",
    "    layer_str += f'static {dtype} {name}_images_dram [{DATASET_SIZE*IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    layer_str += f'static uint32_t {name}_labels_dram [{DATASET_SIZE}][{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static {dtype} {name}_images_dram [{IN_CH}][{1}] = ' + array_to_cstr(MAT_INPUT) + ';\\n\\n\\n'\n",
    "    #layer_str += f'static uint32_t {name}_labels_dram[{1}] = ' + array_to_cstr(MAT_LABELS) + ';\\n\\n\\n'\n",
    "\n",
    "    return layer_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emit_mnist_header_file(layer_type: str, **kwargs):\n",
    "\n",
    "    file_path = '/scratch/msc22f11/msc22f11/snitch/sw/applications/data/'\n",
    "    emit_str = \"// Copyright 2022 ETH Zurich and University of Bologna.\\n\" + \\\n",
    "               \"// Licensed under the Apache License, Version 2.0, see LICENSE for details.\\n\" + \\\n",
    "               \"// SPDX-License-Identifier: Apache-2.0\\n\\n\"\n",
    "\n",
    "    if(layer_type == 'mnist'):\n",
    "        file = file_path + 'data_fp64_mnist.h'\n",
    "        emit_str += emit_mnist_data(**kwargs)\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(emit_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset using DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "mnist_dataset = MNIST(PATH_DATASETS, train=True, transform=transform, download=True)\n",
    "\n",
    "# set seeds for reproducability \n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "mnist_dl = DataLoader(mnist_dataset, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/usr/scratch/badile31/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/usr/scratch/badile31/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(np_label\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     <a href='vscode-notebook-cell:/usr/scratch/badile31/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/usr/scratch/badile31/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mappend(images, np_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/usr/scratch/badile31/msc22f11/msc22f11/snitch/sw/applications/mnist_data_gen.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(labels, np_label)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/scratch/badile31/msc22f11/.conda/envs/msc/lib/python3.9/site-packages/numpy/lib/function_base.py:4817\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[1;32m   4816\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 4817\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we iterate through the dataset \n",
    "to retrieve the image data with their\n",
    "respective labels\n",
    "\"\"\"\n",
    "\n",
    "data_iterator = iter(mnist_dl)\n",
    "\n",
    "for i in range(0, len(mnist_dl)):\n",
    "    image, label = data_iterator.next()\n",
    "    np_image = image.numpy().flatten()\n",
    "    np_label = label.numpy().flatten()\n",
    "    if(i==0):\n",
    "        images = np.array(np_image.tolist())\n",
    "        labels = np.array(np_label.tolist())\n",
    "    else:\n",
    "        images = np.append(images, np_image)\n",
    "        labels = np.append(labels, np_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we iterate through a smaller subset of the dataset \n",
    "to retrieve the image data with their\n",
    "respective labels\n",
    "\"\"\"\n",
    "\n",
    "data_iterator = iter(mnist_dl)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    s_image, s_label = data_iterator.next()\n",
    "    np_s_image = s_image.numpy().flatten()\n",
    "    np_s_label = s_label.numpy().flatten()\n",
    "    if(i==0):\n",
    "        s_images = np.array(np_s_image.tolist())\n",
    "        s_labels = np.array(np_s_label.tolist())\n",
    "    else:\n",
    "        s_images = np.append(s_images, np_s_image)\n",
    "        s_labels = np.append(s_labels, np_s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch = 28*28\n",
    "out_ch = 10\n",
    "\n",
    "class LinLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinLayer, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.lin = nn.Linear(in_ch, out_ch, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        torch.manual_seed(42)\n",
    "        out = self.lin(x.view(x.size(0), -1))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_im, first_label = next(iter(mnist_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image[0][0] = 0.000000 \n",
      "image[0][1] = 0.000000 \n",
      "image[0][2] = 0.000000 \n",
      "image[0][3] = 0.000000 \n",
      "image[0][4] = 0.000000 \n",
      "image[0][5] = 0.000000 \n",
      "image[0][6] = 0.000000 \n",
      "image[0][7] = 0.000000 \n",
      "image[0][8] = 0.000000 \n",
      "image[0][9] = 0.000000 \n",
      "image[0][10] = 0.000000 \n",
      "image[0][11] = 0.000000 \n",
      "image[0][12] = 0.000000 \n",
      "image[0][13] = 0.000000 \n",
      "image[0][14] = 0.000000 \n",
      "image[0][15] = 0.000000 \n",
      "image[0][16] = 0.000000 \n",
      "image[0][17] = 0.000000 \n",
      "image[0][18] = 0.000000 \n",
      "image[0][19] = 0.000000 \n",
      "image[0][20] = 0.000000 \n",
      "image[0][21] = 0.000000 \n",
      "image[0][22] = 0.000000 \n",
      "image[0][23] = 0.000000 \n",
      "image[0][24] = 0.000000 \n",
      "image[0][25] = 0.000000 \n",
      "image[0][26] = 0.000000 \n",
      "image[0][27] = 0.000000 \n",
      "image[0][28] = 0.000000 \n",
      "image[0][29] = 0.000000 \n",
      "image[0][30] = 0.000000 \n",
      "image[0][31] = 0.000000 \n",
      "image[0][32] = 0.000000 \n",
      "image[0][33] = 0.000000 \n",
      "image[0][34] = 0.000000 \n",
      "image[0][35] = 0.000000 \n",
      "image[0][36] = 0.000000 \n",
      "image[0][37] = 0.000000 \n",
      "image[0][38] = 0.000000 \n",
      "image[0][39] = 0.000000 \n",
      "image[0][40] = 0.000000 \n",
      "image[0][41] = 0.000000 \n",
      "image[0][42] = 0.000000 \n",
      "image[0][43] = 0.000000 \n",
      "image[0][44] = 0.000000 \n",
      "image[0][45] = 0.000000 \n",
      "image[0][46] = 0.000000 \n",
      "image[0][47] = 0.000000 \n",
      "image[0][48] = 0.000000 \n",
      "image[0][49] = 0.000000 \n",
      "image[0][50] = 0.000000 \n",
      "image[0][51] = 0.000000 \n",
      "image[0][52] = 0.000000 \n",
      "image[0][53] = 0.000000 \n",
      "image[0][54] = 0.000000 \n",
      "image[0][55] = 0.000000 \n",
      "image[0][56] = 0.000000 \n",
      "image[0][57] = 0.000000 \n",
      "image[0][58] = 0.000000 \n",
      "image[0][59] = 0.000000 \n",
      "image[0][60] = 0.000000 \n",
      "image[0][61] = 0.000000 \n",
      "image[0][62] = 0.000000 \n",
      "image[0][63] = 0.000000 \n",
      "image[0][64] = 0.000000 \n",
      "image[0][65] = 0.000000 \n",
      "image[0][66] = 0.000000 \n",
      "image[0][67] = 0.000000 \n",
      "image[0][68] = 0.000000 \n",
      "image[0][69] = 0.000000 \n",
      "image[0][70] = 0.000000 \n",
      "image[0][71] = 0.000000 \n",
      "image[0][72] = 0.000000 \n",
      "image[0][73] = 0.000000 \n",
      "image[0][74] = 0.000000 \n",
      "image[0][75] = 0.000000 \n",
      "image[0][76] = 0.000000 \n",
      "image[0][77] = 0.000000 \n",
      "image[0][78] = 0.000000 \n",
      "image[0][79] = 0.000000 \n",
      "image[0][80] = 0.000000 \n",
      "image[0][81] = 0.000000 \n",
      "image[0][82] = 0.000000 \n",
      "image[0][83] = 0.000000 \n",
      "image[0][84] = 0.000000 \n",
      "image[0][85] = 0.000000 \n",
      "image[0][86] = 0.000000 \n",
      "image[0][87] = 0.000000 \n",
      "image[0][88] = 0.000000 \n",
      "image[0][89] = 0.000000 \n",
      "image[0][90] = 0.000000 \n",
      "image[0][91] = 0.000000 \n",
      "image[0][92] = 0.000000 \n",
      "image[0][93] = 0.000000 \n",
      "image[0][94] = 0.000000 \n",
      "image[0][95] = 0.000000 \n",
      "image[0][96] = 0.000000 \n",
      "image[0][97] = 0.000000 \n",
      "image[0][98] = 0.000000 \n",
      "image[0][99] = 0.000000 \n",
      "image[0][100] = 0.000000 \n",
      "image[0][101] = 0.000000 \n",
      "image[0][102] = 0.000000 \n",
      "image[0][103] = 0.000000 \n",
      "image[0][104] = 0.000000 \n",
      "image[0][105] = 0.000000 \n",
      "image[0][106] = 0.000000 \n",
      "image[0][107] = 0.000000 \n",
      "image[0][108] = 0.000000 \n",
      "image[0][109] = 0.000000 \n",
      "image[0][110] = 0.000000 \n",
      "image[0][111] = 0.000000 \n",
      "image[0][112] = 0.000000 \n",
      "image[0][113] = 0.000000 \n",
      "image[0][114] = 0.000000 \n",
      "image[0][115] = 0.000000 \n",
      "image[0][116] = 0.000000 \n",
      "image[0][117] = 0.000000 \n",
      "image[0][118] = 0.000000 \n",
      "image[0][119] = 0.000000 \n",
      "image[0][120] = 0.000000 \n",
      "image[0][121] = 0.000000 \n",
      "image[0][122] = 0.000000 \n",
      "image[0][123] = 0.000000 \n",
      "image[0][124] = 0.000000 \n",
      "image[0][125] = 0.000000 \n",
      "image[0][126] = 0.000000 \n",
      "image[0][127] = 0.000000 \n",
      "image[0][128] = 0.000000 \n",
      "image[0][129] = 0.000000 \n",
      "image[0][130] = 0.000000 \n",
      "image[0][131] = 0.000000 \n",
      "image[0][132] = 0.000000 \n",
      "image[0][133] = 0.000000 \n",
      "image[0][134] = 0.000000 \n",
      "image[0][135] = 0.000000 \n",
      "image[0][136] = 0.000000 \n",
      "image[0][137] = 0.000000 \n",
      "image[0][138] = 0.000000 \n",
      "image[0][139] = 0.000000 \n",
      "image[0][140] = 0.000000 \n",
      "image[0][141] = 0.000000 \n",
      "image[0][142] = 0.000000 \n",
      "image[0][143] = 0.000000 \n",
      "image[0][144] = 0.000000 \n",
      "image[0][145] = 0.000000 \n",
      "image[0][146] = 0.000000 \n",
      "image[0][147] = 0.000000 \n",
      "image[0][148] = 0.000000 \n",
      "image[0][149] = 0.000000 \n",
      "image[0][150] = 0.000000 \n",
      "image[0][151] = 0.000000 \n",
      "image[0][152] = 0.011765 \n",
      "image[0][153] = 0.070588 \n",
      "image[0][154] = 0.070588 \n",
      "image[0][155] = 0.070588 \n",
      "image[0][156] = 0.494118 \n",
      "image[0][157] = 0.533333 \n",
      "image[0][158] = 0.686275 \n",
      "image[0][159] = 0.101961 \n",
      "image[0][160] = 0.650980 \n",
      "image[0][161] = 1.000000 \n",
      "image[0][162] = 0.968627 \n",
      "image[0][163] = 0.498039 \n",
      "image[0][164] = 0.000000 \n",
      "image[0][165] = 0.000000 \n",
      "image[0][166] = 0.000000 \n",
      "image[0][167] = 0.000000 \n",
      "image[0][168] = 0.000000 \n",
      "image[0][169] = 0.000000 \n",
      "image[0][170] = 0.000000 \n",
      "image[0][171] = 0.000000 \n",
      "image[0][172] = 0.000000 \n",
      "image[0][173] = 0.000000 \n",
      "image[0][174] = 0.000000 \n",
      "image[0][175] = 0.000000 \n",
      "image[0][176] = 0.117647 \n",
      "image[0][177] = 0.141176 \n",
      "image[0][178] = 0.368627 \n",
      "image[0][179] = 0.603922 \n",
      "image[0][180] = 0.666667 \n",
      "image[0][181] = 0.992157 \n",
      "image[0][182] = 0.992157 \n",
      "image[0][183] = 0.992157 \n",
      "image[0][184] = 0.992157 \n",
      "image[0][185] = 0.992157 \n",
      "image[0][186] = 0.882353 \n",
      "image[0][187] = 0.674510 \n",
      "image[0][188] = 0.992157 \n",
      "image[0][189] = 0.949020 \n",
      "image[0][190] = 0.764706 \n",
      "image[0][191] = 0.250980 \n",
      "image[0][192] = 0.000000 \n",
      "image[0][193] = 0.000000 \n",
      "image[0][194] = 0.000000 \n",
      "image[0][195] = 0.000000 \n",
      "image[0][196] = 0.000000 \n",
      "image[0][197] = 0.000000 \n",
      "image[0][198] = 0.000000 \n",
      "image[0][199] = 0.000000 \n",
      "image[0][200] = 0.000000 \n",
      "image[0][201] = 0.000000 \n",
      "image[0][202] = 0.000000 \n",
      "image[0][203] = 0.192157 \n",
      "image[0][204] = 0.933333 \n",
      "image[0][205] = 0.992157 \n",
      "image[0][206] = 0.992157 \n",
      "image[0][207] = 0.992157 \n",
      "image[0][208] = 0.992157 \n",
      "image[0][209] = 0.992157 \n",
      "image[0][210] = 0.992157 \n",
      "image[0][211] = 0.992157 \n",
      "image[0][212] = 0.992157 \n",
      "image[0][213] = 0.984314 \n",
      "image[0][214] = 0.364706 \n",
      "image[0][215] = 0.321569 \n",
      "image[0][216] = 0.321569 \n",
      "image[0][217] = 0.219608 \n",
      "image[0][218] = 0.152941 \n",
      "image[0][219] = 0.000000 \n",
      "image[0][220] = 0.000000 \n",
      "image[0][221] = 0.000000 \n",
      "image[0][222] = 0.000000 \n",
      "image[0][223] = 0.000000 \n",
      "image[0][224] = 0.000000 \n",
      "image[0][225] = 0.000000 \n",
      "image[0][226] = 0.000000 \n",
      "image[0][227] = 0.000000 \n",
      "image[0][228] = 0.000000 \n",
      "image[0][229] = 0.000000 \n",
      "image[0][230] = 0.000000 \n",
      "image[0][231] = 0.070588 \n",
      "image[0][232] = 0.858824 \n",
      "image[0][233] = 0.992157 \n",
      "image[0][234] = 0.992157 \n",
      "image[0][235] = 0.992157 \n",
      "image[0][236] = 0.992157 \n",
      "image[0][237] = 0.992157 \n",
      "image[0][238] = 0.776471 \n",
      "image[0][239] = 0.713726 \n",
      "image[0][240] = 0.968627 \n",
      "image[0][241] = 0.945098 \n",
      "image[0][242] = 0.000000 \n",
      "image[0][243] = 0.000000 \n",
      "image[0][244] = 0.000000 \n",
      "image[0][245] = 0.000000 \n",
      "image[0][246] = 0.000000 \n",
      "image[0][247] = 0.000000 \n",
      "image[0][248] = 0.000000 \n",
      "image[0][249] = 0.000000 \n",
      "image[0][250] = 0.000000 \n",
      "image[0][251] = 0.000000 \n",
      "image[0][252] = 0.000000 \n",
      "image[0][253] = 0.000000 \n",
      "image[0][254] = 0.000000 \n",
      "image[0][255] = 0.000000 \n",
      "image[0][256] = 0.000000 \n",
      "image[0][257] = 0.000000 \n",
      "image[0][258] = 0.000000 \n",
      "image[0][259] = 0.000000 \n",
      "image[0][260] = 0.313726 \n",
      "image[0][261] = 0.611765 \n",
      "image[0][262] = 0.419608 \n",
      "image[0][263] = 0.992157 \n",
      "image[0][264] = 0.992157 \n",
      "image[0][265] = 0.803922 \n",
      "image[0][266] = 0.043137 \n",
      "image[0][267] = 0.000000 \n",
      "image[0][268] = 0.168627 \n",
      "image[0][269] = 0.603922 \n",
      "image[0][270] = 0.000000 \n",
      "image[0][271] = 0.000000 \n",
      "image[0][272] = 0.000000 \n",
      "image[0][273] = 0.000000 \n",
      "image[0][274] = 0.000000 \n",
      "image[0][275] = 0.000000 \n",
      "image[0][276] = 0.000000 \n",
      "image[0][277] = 0.000000 \n",
      "image[0][278] = 0.000000 \n",
      "image[0][279] = 0.000000 \n",
      "image[0][280] = 0.000000 \n",
      "image[0][281] = 0.000000 \n",
      "image[0][282] = 0.000000 \n",
      "image[0][283] = 0.000000 \n",
      "image[0][284] = 0.000000 \n",
      "image[0][285] = 0.000000 \n",
      "image[0][286] = 0.000000 \n",
      "image[0][287] = 0.000000 \n",
      "image[0][288] = 0.000000 \n",
      "image[0][289] = 0.054902 \n",
      "image[0][290] = 0.003922 \n",
      "image[0][291] = 0.603922 \n",
      "image[0][292] = 0.992157 \n",
      "image[0][293] = 0.352941 \n",
      "image[0][294] = 0.000000 \n",
      "image[0][295] = 0.000000 \n",
      "image[0][296] = 0.000000 \n",
      "image[0][297] = 0.000000 \n",
      "image[0][298] = 0.000000 \n",
      "image[0][299] = 0.000000 \n",
      "image[0][300] = 0.000000 \n",
      "image[0][301] = 0.000000 \n",
      "image[0][302] = 0.000000 \n",
      "image[0][303] = 0.000000 \n",
      "image[0][304] = 0.000000 \n",
      "image[0][305] = 0.000000 \n",
      "image[0][306] = 0.000000 \n",
      "image[0][307] = 0.000000 \n",
      "image[0][308] = 0.000000 \n",
      "image[0][309] = 0.000000 \n",
      "image[0][310] = 0.000000 \n",
      "image[0][311] = 0.000000 \n",
      "image[0][312] = 0.000000 \n",
      "image[0][313] = 0.000000 \n",
      "image[0][314] = 0.000000 \n",
      "image[0][315] = 0.000000 \n",
      "image[0][316] = 0.000000 \n",
      "image[0][317] = 0.000000 \n",
      "image[0][318] = 0.000000 \n",
      "image[0][319] = 0.545098 \n",
      "image[0][320] = 0.992157 \n",
      "image[0][321] = 0.745098 \n",
      "image[0][322] = 0.007843 \n",
      "image[0][323] = 0.000000 \n",
      "image[0][324] = 0.000000 \n",
      "image[0][325] = 0.000000 \n",
      "image[0][326] = 0.000000 \n",
      "image[0][327] = 0.000000 \n",
      "image[0][328] = 0.000000 \n",
      "image[0][329] = 0.000000 \n",
      "image[0][330] = 0.000000 \n",
      "image[0][331] = 0.000000 \n",
      "image[0][332] = 0.000000 \n",
      "image[0][333] = 0.000000 \n",
      "image[0][334] = 0.000000 \n",
      "image[0][335] = 0.000000 \n",
      "image[0][336] = 0.000000 \n",
      "image[0][337] = 0.000000 \n",
      "image[0][338] = 0.000000 \n",
      "image[0][339] = 0.000000 \n",
      "image[0][340] = 0.000000 \n",
      "image[0][341] = 0.000000 \n",
      "image[0][342] = 0.000000 \n",
      "image[0][343] = 0.000000 \n",
      "image[0][344] = 0.000000 \n",
      "image[0][345] = 0.000000 \n",
      "image[0][346] = 0.000000 \n",
      "image[0][347] = 0.043137 \n",
      "image[0][348] = 0.745098 \n",
      "image[0][349] = 0.992157 \n",
      "image[0][350] = 0.274510 \n",
      "image[0][351] = 0.000000 \n",
      "image[0][352] = 0.000000 \n",
      "image[0][353] = 0.000000 \n",
      "image[0][354] = 0.000000 \n",
      "image[0][355] = 0.000000 \n",
      "image[0][356] = 0.000000 \n",
      "image[0][357] = 0.000000 \n",
      "image[0][358] = 0.000000 \n",
      "image[0][359] = 0.000000 \n",
      "image[0][360] = 0.000000 \n",
      "image[0][361] = 0.000000 \n",
      "image[0][362] = 0.000000 \n",
      "image[0][363] = 0.000000 \n",
      "image[0][364] = 0.000000 \n",
      "image[0][365] = 0.000000 \n",
      "image[0][366] = 0.000000 \n",
      "image[0][367] = 0.000000 \n",
      "image[0][368] = 0.000000 \n",
      "image[0][369] = 0.000000 \n",
      "image[0][370] = 0.000000 \n",
      "image[0][371] = 0.000000 \n",
      "image[0][372] = 0.000000 \n",
      "image[0][373] = 0.000000 \n",
      "image[0][374] = 0.000000 \n",
      "image[0][375] = 0.000000 \n",
      "image[0][376] = 0.137255 \n",
      "image[0][377] = 0.945098 \n",
      "image[0][378] = 0.882353 \n",
      "image[0][379] = 0.627451 \n",
      "image[0][380] = 0.423529 \n",
      "image[0][381] = 0.003922 \n",
      "image[0][382] = 0.000000 \n",
      "image[0][383] = 0.000000 \n",
      "image[0][384] = 0.000000 \n",
      "image[0][385] = 0.000000 \n",
      "image[0][386] = 0.000000 \n",
      "image[0][387] = 0.000000 \n",
      "image[0][388] = 0.000000 \n",
      "image[0][389] = 0.000000 \n",
      "image[0][390] = 0.000000 \n",
      "image[0][391] = 0.000000 \n",
      "image[0][392] = 0.000000 \n",
      "image[0][393] = 0.000000 \n",
      "image[0][394] = 0.000000 \n",
      "image[0][395] = 0.000000 \n",
      "image[0][396] = 0.000000 \n",
      "image[0][397] = 0.000000 \n",
      "image[0][398] = 0.000000 \n",
      "image[0][399] = 0.000000 \n",
      "image[0][400] = 0.000000 \n",
      "image[0][401] = 0.000000 \n",
      "image[0][402] = 0.000000 \n",
      "image[0][403] = 0.000000 \n",
      "image[0][404] = 0.000000 \n",
      "image[0][405] = 0.317647 \n",
      "image[0][406] = 0.941176 \n",
      "image[0][407] = 0.992157 \n",
      "image[0][408] = 0.992157 \n",
      "image[0][409] = 0.466667 \n",
      "image[0][410] = 0.098039 \n",
      "image[0][411] = 0.000000 \n",
      "image[0][412] = 0.000000 \n",
      "image[0][413] = 0.000000 \n",
      "image[0][414] = 0.000000 \n",
      "image[0][415] = 0.000000 \n",
      "image[0][416] = 0.000000 \n",
      "image[0][417] = 0.000000 \n",
      "image[0][418] = 0.000000 \n",
      "image[0][419] = 0.000000 \n",
      "image[0][420] = 0.000000 \n",
      "image[0][421] = 0.000000 \n",
      "image[0][422] = 0.000000 \n",
      "image[0][423] = 0.000000 \n",
      "image[0][424] = 0.000000 \n",
      "image[0][425] = 0.000000 \n",
      "image[0][426] = 0.000000 \n",
      "image[0][427] = 0.000000 \n",
      "image[0][428] = 0.000000 \n",
      "image[0][429] = 0.000000 \n",
      "image[0][430] = 0.000000 \n",
      "image[0][431] = 0.000000 \n",
      "image[0][432] = 0.000000 \n",
      "image[0][433] = 0.000000 \n",
      "image[0][434] = 0.176471 \n",
      "image[0][435] = 0.729412 \n",
      "image[0][436] = 0.992157 \n",
      "image[0][437] = 0.992157 \n",
      "image[0][438] = 0.588235 \n",
      "image[0][439] = 0.105882 \n",
      "image[0][440] = 0.000000 \n",
      "image[0][441] = 0.000000 \n",
      "image[0][442] = 0.000000 \n",
      "image[0][443] = 0.000000 \n",
      "image[0][444] = 0.000000 \n",
      "image[0][445] = 0.000000 \n",
      "image[0][446] = 0.000000 \n",
      "image[0][447] = 0.000000 \n",
      "image[0][448] = 0.000000 \n",
      "image[0][449] = 0.000000 \n",
      "image[0][450] = 0.000000 \n",
      "image[0][451] = 0.000000 \n",
      "image[0][452] = 0.000000 \n",
      "image[0][453] = 0.000000 \n",
      "image[0][454] = 0.000000 \n",
      "image[0][455] = 0.000000 \n",
      "image[0][456] = 0.000000 \n",
      "image[0][457] = 0.000000 \n",
      "image[0][458] = 0.000000 \n",
      "image[0][459] = 0.000000 \n",
      "image[0][460] = 0.000000 \n",
      "image[0][461] = 0.000000 \n",
      "image[0][462] = 0.000000 \n",
      "image[0][463] = 0.062745 \n",
      "image[0][464] = 0.364706 \n",
      "image[0][465] = 0.988235 \n",
      "image[0][466] = 0.992157 \n",
      "image[0][467] = 0.733333 \n",
      "image[0][468] = 0.000000 \n",
      "image[0][469] = 0.000000 \n",
      "image[0][470] = 0.000000 \n",
      "image[0][471] = 0.000000 \n",
      "image[0][472] = 0.000000 \n",
      "image[0][473] = 0.000000 \n",
      "image[0][474] = 0.000000 \n",
      "image[0][475] = 0.000000 \n",
      "image[0][476] = 0.000000 \n",
      "image[0][477] = 0.000000 \n",
      "image[0][478] = 0.000000 \n",
      "image[0][479] = 0.000000 \n",
      "image[0][480] = 0.000000 \n",
      "image[0][481] = 0.000000 \n",
      "image[0][482] = 0.000000 \n",
      "image[0][483] = 0.000000 \n",
      "image[0][484] = 0.000000 \n",
      "image[0][485] = 0.000000 \n",
      "image[0][486] = 0.000000 \n",
      "image[0][487] = 0.000000 \n",
      "image[0][488] = 0.000000 \n",
      "image[0][489] = 0.000000 \n",
      "image[0][490] = 0.000000 \n",
      "image[0][491] = 0.000000 \n",
      "image[0][492] = 0.000000 \n",
      "image[0][493] = 0.976471 \n",
      "image[0][494] = 0.992157 \n",
      "image[0][495] = 0.976471 \n",
      "image[0][496] = 0.250980 \n",
      "image[0][497] = 0.000000 \n",
      "image[0][498] = 0.000000 \n",
      "image[0][499] = 0.000000 \n",
      "image[0][500] = 0.000000 \n",
      "image[0][501] = 0.000000 \n",
      "image[0][502] = 0.000000 \n",
      "image[0][503] = 0.000000 \n",
      "image[0][504] = 0.000000 \n",
      "image[0][505] = 0.000000 \n",
      "image[0][506] = 0.000000 \n",
      "image[0][507] = 0.000000 \n",
      "image[0][508] = 0.000000 \n",
      "image[0][509] = 0.000000 \n",
      "image[0][510] = 0.000000 \n",
      "image[0][511] = 0.000000 \n",
      "image[0][512] = 0.000000 \n",
      "image[0][513] = 0.000000 \n",
      "image[0][514] = 0.000000 \n",
      "image[0][515] = 0.000000 \n",
      "image[0][516] = 0.000000 \n",
      "image[0][517] = 0.000000 \n",
      "image[0][518] = 0.180392 \n",
      "image[0][519] = 0.509804 \n",
      "image[0][520] = 0.717647 \n",
      "image[0][521] = 0.992157 \n",
      "image[0][522] = 0.992157 \n",
      "image[0][523] = 0.811765 \n",
      "image[0][524] = 0.007843 \n",
      "image[0][525] = 0.000000 \n",
      "image[0][526] = 0.000000 \n",
      "image[0][527] = 0.000000 \n",
      "image[0][528] = 0.000000 \n",
      "image[0][529] = 0.000000 \n",
      "image[0][530] = 0.000000 \n",
      "image[0][531] = 0.000000 \n",
      "image[0][532] = 0.000000 \n",
      "image[0][533] = 0.000000 \n",
      "image[0][534] = 0.000000 \n",
      "image[0][535] = 0.000000 \n",
      "image[0][536] = 0.000000 \n",
      "image[0][537] = 0.000000 \n",
      "image[0][538] = 0.000000 \n",
      "image[0][539] = 0.000000 \n",
      "image[0][540] = 0.000000 \n",
      "image[0][541] = 0.000000 \n",
      "image[0][542] = 0.000000 \n",
      "image[0][543] = 0.000000 \n",
      "image[0][544] = 0.152941 \n",
      "image[0][545] = 0.580392 \n",
      "image[0][546] = 0.898039 \n",
      "image[0][547] = 0.992157 \n",
      "image[0][548] = 0.992157 \n",
      "image[0][549] = 0.992157 \n",
      "image[0][550] = 0.980392 \n",
      "image[0][551] = 0.713726 \n",
      "image[0][552] = 0.000000 \n",
      "image[0][553] = 0.000000 \n",
      "image[0][554] = 0.000000 \n",
      "image[0][555] = 0.000000 \n",
      "image[0][556] = 0.000000 \n",
      "image[0][557] = 0.000000 \n",
      "image[0][558] = 0.000000 \n",
      "image[0][559] = 0.000000 \n",
      "image[0][560] = 0.000000 \n",
      "image[0][561] = 0.000000 \n",
      "image[0][562] = 0.000000 \n",
      "image[0][563] = 0.000000 \n",
      "image[0][564] = 0.000000 \n",
      "image[0][565] = 0.000000 \n",
      "image[0][566] = 0.000000 \n",
      "image[0][567] = 0.000000 \n",
      "image[0][568] = 0.000000 \n",
      "image[0][569] = 0.000000 \n",
      "image[0][570] = 0.094118 \n",
      "image[0][571] = 0.447059 \n",
      "image[0][572] = 0.866667 \n",
      "image[0][573] = 0.992157 \n",
      "image[0][574] = 0.992157 \n",
      "image[0][575] = 0.992157 \n",
      "image[0][576] = 0.992157 \n",
      "image[0][577] = 0.788235 \n",
      "image[0][578] = 0.305882 \n",
      "image[0][579] = 0.000000 \n",
      "image[0][580] = 0.000000 \n",
      "image[0][581] = 0.000000 \n",
      "image[0][582] = 0.000000 \n",
      "image[0][583] = 0.000000 \n",
      "image[0][584] = 0.000000 \n",
      "image[0][585] = 0.000000 \n",
      "image[0][586] = 0.000000 \n",
      "image[0][587] = 0.000000 \n",
      "image[0][588] = 0.000000 \n",
      "image[0][589] = 0.000000 \n",
      "image[0][590] = 0.000000 \n",
      "image[0][591] = 0.000000 \n",
      "image[0][592] = 0.000000 \n",
      "image[0][593] = 0.000000 \n",
      "image[0][594] = 0.000000 \n",
      "image[0][595] = 0.000000 \n",
      "image[0][596] = 0.090196 \n",
      "image[0][597] = 0.258824 \n",
      "image[0][598] = 0.835294 \n",
      "image[0][599] = 0.992157 \n",
      "image[0][600] = 0.992157 \n",
      "image[0][601] = 0.992157 \n",
      "image[0][602] = 0.992157 \n",
      "image[0][603] = 0.776471 \n",
      "image[0][604] = 0.317647 \n",
      "image[0][605] = 0.007843 \n",
      "image[0][606] = 0.000000 \n",
      "image[0][607] = 0.000000 \n",
      "image[0][608] = 0.000000 \n",
      "image[0][609] = 0.000000 \n",
      "image[0][610] = 0.000000 \n",
      "image[0][611] = 0.000000 \n",
      "image[0][612] = 0.000000 \n",
      "image[0][613] = 0.000000 \n",
      "image[0][614] = 0.000000 \n",
      "image[0][615] = 0.000000 \n",
      "image[0][616] = 0.000000 \n",
      "image[0][617] = 0.000000 \n",
      "image[0][618] = 0.000000 \n",
      "image[0][619] = 0.000000 \n",
      "image[0][620] = 0.000000 \n",
      "image[0][621] = 0.000000 \n",
      "image[0][622] = 0.070588 \n",
      "image[0][623] = 0.670588 \n",
      "image[0][624] = 0.858824 \n",
      "image[0][625] = 0.992157 \n",
      "image[0][626] = 0.992157 \n",
      "image[0][627] = 0.992157 \n",
      "image[0][628] = 0.992157 \n",
      "image[0][629] = 0.764706 \n",
      "image[0][630] = 0.313726 \n",
      "image[0][631] = 0.035294 \n",
      "image[0][632] = 0.000000 \n",
      "image[0][633] = 0.000000 \n",
      "image[0][634] = 0.000000 \n",
      "image[0][635] = 0.000000 \n",
      "image[0][636] = 0.000000 \n",
      "image[0][637] = 0.000000 \n",
      "image[0][638] = 0.000000 \n",
      "image[0][639] = 0.000000 \n",
      "image[0][640] = 0.000000 \n",
      "image[0][641] = 0.000000 \n",
      "image[0][642] = 0.000000 \n",
      "image[0][643] = 0.000000 \n",
      "image[0][644] = 0.000000 \n",
      "image[0][645] = 0.000000 \n",
      "image[0][646] = 0.000000 \n",
      "image[0][647] = 0.000000 \n",
      "image[0][648] = 0.215686 \n",
      "image[0][649] = 0.674510 \n",
      "image[0][650] = 0.886275 \n",
      "image[0][651] = 0.992157 \n",
      "image[0][652] = 0.992157 \n",
      "image[0][653] = 0.992157 \n",
      "image[0][654] = 0.992157 \n",
      "image[0][655] = 0.956863 \n",
      "image[0][656] = 0.521569 \n",
      "image[0][657] = 0.043137 \n",
      "image[0][658] = 0.000000 \n",
      "image[0][659] = 0.000000 \n",
      "image[0][660] = 0.000000 \n",
      "image[0][661] = 0.000000 \n",
      "image[0][662] = 0.000000 \n",
      "image[0][663] = 0.000000 \n",
      "image[0][664] = 0.000000 \n",
      "image[0][665] = 0.000000 \n",
      "image[0][666] = 0.000000 \n",
      "image[0][667] = 0.000000 \n",
      "image[0][668] = 0.000000 \n",
      "image[0][669] = 0.000000 \n",
      "image[0][670] = 0.000000 \n",
      "image[0][671] = 0.000000 \n",
      "image[0][672] = 0.000000 \n",
      "image[0][673] = 0.000000 \n",
      "image[0][674] = 0.000000 \n",
      "image[0][675] = 0.000000 \n",
      "image[0][676] = 0.533333 \n",
      "image[0][677] = 0.992157 \n",
      "image[0][678] = 0.992157 \n",
      "image[0][679] = 0.992157 \n",
      "image[0][680] = 0.831373 \n",
      "image[0][681] = 0.529412 \n",
      "image[0][682] = 0.517647 \n",
      "image[0][683] = 0.062745 \n",
      "image[0][684] = 0.000000 \n",
      "image[0][685] = 0.000000 \n",
      "image[0][686] = 0.000000 \n",
      "image[0][687] = 0.000000 \n",
      "image[0][688] = 0.000000 \n",
      "image[0][689] = 0.000000 \n",
      "image[0][690] = 0.000000 \n",
      "image[0][691] = 0.000000 \n",
      "image[0][692] = 0.000000 \n",
      "image[0][693] = 0.000000 \n",
      "image[0][694] = 0.000000 \n",
      "image[0][695] = 0.000000 \n",
      "image[0][696] = 0.000000 \n",
      "image[0][697] = 0.000000 \n",
      "image[0][698] = 0.000000 \n",
      "image[0][699] = 0.000000 \n",
      "image[0][700] = 0.000000 \n",
      "image[0][701] = 0.000000 \n",
      "image[0][702] = 0.000000 \n",
      "image[0][703] = 0.000000 \n",
      "image[0][704] = 0.000000 \n",
      "image[0][705] = 0.000000 \n",
      "image[0][706] = 0.000000 \n",
      "image[0][707] = 0.000000 \n",
      "image[0][708] = 0.000000 \n",
      "image[0][709] = 0.000000 \n",
      "image[0][710] = 0.000000 \n",
      "image[0][711] = 0.000000 \n",
      "image[0][712] = 0.000000 \n",
      "image[0][713] = 0.000000 \n",
      "image[0][714] = 0.000000 \n",
      "image[0][715] = 0.000000 \n",
      "image[0][716] = 0.000000 \n",
      "image[0][717] = 0.000000 \n",
      "image[0][718] = 0.000000 \n",
      "image[0][719] = 0.000000 \n",
      "image[0][720] = 0.000000 \n",
      "image[0][721] = 0.000000 \n",
      "image[0][722] = 0.000000 \n",
      "image[0][723] = 0.000000 \n",
      "image[0][724] = 0.000000 \n",
      "image[0][725] = 0.000000 \n",
      "image[0][726] = 0.000000 \n",
      "image[0][727] = 0.000000 \n",
      "image[0][728] = 0.000000 \n",
      "image[0][729] = 0.000000 \n",
      "image[0][730] = 0.000000 \n",
      "image[0][731] = 0.000000 \n",
      "image[0][732] = 0.000000 \n",
      "image[0][733] = 0.000000 \n",
      "image[0][734] = 0.000000 \n",
      "image[0][735] = 0.000000 \n",
      "image[0][736] = 0.000000 \n",
      "image[0][737] = 0.000000 \n",
      "image[0][738] = 0.000000 \n",
      "image[0][739] = 0.000000 \n",
      "image[0][740] = 0.000000 \n",
      "image[0][741] = 0.000000 \n",
      "image[0][742] = 0.000000 \n",
      "image[0][743] = 0.000000 \n",
      "image[0][744] = 0.000000 \n",
      "image[0][745] = 0.000000 \n",
      "image[0][746] = 0.000000 \n",
      "image[0][747] = 0.000000 \n",
      "image[0][748] = 0.000000 \n",
      "image[0][749] = 0.000000 \n",
      "image[0][750] = 0.000000 \n",
      "image[0][751] = 0.000000 \n",
      "image[0][752] = 0.000000 \n",
      "image[0][753] = 0.000000 \n",
      "image[0][754] = 0.000000 \n",
      "image[0][755] = 0.000000 \n",
      "image[0][756] = 0.000000 \n",
      "image[0][757] = 0.000000 \n",
      "image[0][758] = 0.000000 \n",
      "image[0][759] = 0.000000 \n",
      "image[0][760] = 0.000000 \n",
      "image[0][761] = 0.000000 \n",
      "image[0][762] = 0.000000 \n",
      "image[0][763] = 0.000000 \n",
      "image[0][764] = 0.000000 \n",
      "image[0][765] = 0.000000 \n",
      "image[0][766] = 0.000000 \n",
      "image[0][767] = 0.000000 \n",
      "image[0][768] = 0.000000 \n",
      "image[0][769] = 0.000000 \n",
      "image[0][770] = 0.000000 \n",
      "image[0][771] = 0.000000 \n",
      "image[0][772] = 0.000000 \n",
      "image[0][773] = 0.000000 \n",
      "image[0][774] = 0.000000 \n",
      "image[0][775] = 0.000000 \n",
      "image[0][776] = 0.000000 \n",
      "image[0][777] = 0.000000 \n",
      "image[0][778] = 0.000000 \n",
      "image[0][779] = 0.000000 \n",
      "image[0][780] = 0.000000 \n",
      "image[0][781] = 0.000000 \n",
      "image[0][782] = 0.000000 \n",
      "image[0][783] = 0.000000 \n",
      "image[1][0] = 0.000000 \n",
      "image[1][1] = 0.000000 \n",
      "image[1][2] = 0.000000 \n",
      "image[1][3] = 0.000000 \n",
      "image[1][4] = 0.000000 \n",
      "image[1][5] = 0.000000 \n",
      "image[1][6] = 0.000000 \n",
      "image[1][7] = 0.000000 \n",
      "image[1][8] = 0.000000 \n",
      "image[1][9] = 0.000000 \n",
      "image[1][10] = 0.000000 \n",
      "image[1][11] = 0.000000 \n",
      "image[1][12] = 0.000000 \n",
      "image[1][13] = 0.000000 \n",
      "image[1][14] = 0.000000 \n",
      "image[1][15] = 0.000000 \n",
      "image[1][16] = 0.000000 \n",
      "image[1][17] = 0.000000 \n",
      "image[1][18] = 0.000000 \n",
      "image[1][19] = 0.000000 \n",
      "image[1][20] = 0.000000 \n",
      "image[1][21] = 0.000000 \n",
      "image[1][22] = 0.000000 \n",
      "image[1][23] = 0.000000 \n",
      "image[1][24] = 0.000000 \n",
      "image[1][25] = 0.000000 \n",
      "image[1][26] = 0.000000 \n",
      "image[1][27] = 0.000000 \n",
      "image[1][28] = 0.000000 \n",
      "image[1][29] = 0.000000 \n",
      "image[1][30] = 0.000000 \n",
      "image[1][31] = 0.000000 \n",
      "image[1][32] = 0.000000 \n",
      "image[1][33] = 0.000000 \n",
      "image[1][34] = 0.000000 \n",
      "image[1][35] = 0.000000 \n",
      "image[1][36] = 0.000000 \n",
      "image[1][37] = 0.000000 \n",
      "image[1][38] = 0.000000 \n",
      "image[1][39] = 0.000000 \n",
      "image[1][40] = 0.000000 \n",
      "image[1][41] = 0.000000 \n",
      "image[1][42] = 0.000000 \n",
      "image[1][43] = 0.000000 \n",
      "image[1][44] = 0.000000 \n",
      "image[1][45] = 0.000000 \n",
      "image[1][46] = 0.000000 \n",
      "image[1][47] = 0.000000 \n",
      "image[1][48] = 0.000000 \n",
      "image[1][49] = 0.000000 \n",
      "image[1][50] = 0.000000 \n",
      "image[1][51] = 0.000000 \n",
      "image[1][52] = 0.000000 \n",
      "image[1][53] = 0.000000 \n",
      "image[1][54] = 0.000000 \n",
      "image[1][55] = 0.000000 \n",
      "image[1][56] = 0.000000 \n",
      "image[1][57] = 0.000000 \n",
      "image[1][58] = 0.000000 \n",
      "image[1][59] = 0.000000 \n",
      "image[1][60] = 0.000000 \n",
      "image[1][61] = 0.000000 \n",
      "image[1][62] = 0.000000 \n",
      "image[1][63] = 0.000000 \n",
      "image[1][64] = 0.000000 \n",
      "image[1][65] = 0.000000 \n",
      "image[1][66] = 0.000000 \n",
      "image[1][67] = 0.000000 \n",
      "image[1][68] = 0.000000 \n",
      "image[1][69] = 0.000000 \n",
      "image[1][70] = 0.000000 \n",
      "image[1][71] = 0.000000 \n",
      "image[1][72] = 0.000000 \n",
      "image[1][73] = 0.000000 \n",
      "image[1][74] = 0.000000 \n",
      "image[1][75] = 0.000000 \n",
      "image[1][76] = 0.000000 \n",
      "image[1][77] = 0.000000 \n",
      "image[1][78] = 0.000000 \n",
      "image[1][79] = 0.000000 \n",
      "image[1][80] = 0.000000 \n",
      "image[1][81] = 0.000000 \n",
      "image[1][82] = 0.000000 \n",
      "image[1][83] = 0.000000 \n",
      "image[1][84] = 0.000000 \n",
      "image[1][85] = 0.000000 \n",
      "image[1][86] = 0.000000 \n",
      "image[1][87] = 0.000000 \n",
      "image[1][88] = 0.000000 \n",
      "image[1][89] = 0.000000 \n",
      "image[1][90] = 0.000000 \n",
      "image[1][91] = 0.000000 \n",
      "image[1][92] = 0.000000 \n",
      "image[1][93] = 0.000000 \n",
      "image[1][94] = 0.000000 \n",
      "image[1][95] = 0.000000 \n",
      "image[1][96] = 0.000000 \n",
      "image[1][97] = 0.000000 \n",
      "image[1][98] = 0.000000 \n",
      "image[1][99] = 0.000000 \n",
      "image[1][100] = 0.000000 \n",
      "image[1][101] = 0.000000 \n",
      "image[1][102] = 0.000000 \n",
      "image[1][103] = 0.000000 \n",
      "image[1][104] = 0.000000 \n",
      "image[1][105] = 0.000000 \n",
      "image[1][106] = 0.000000 \n",
      "image[1][107] = 0.000000 \n",
      "image[1][108] = 0.000000 \n",
      "image[1][109] = 0.000000 \n",
      "image[1][110] = 0.000000 \n",
      "image[1][111] = 0.000000 \n",
      "image[1][112] = 0.000000 \n",
      "image[1][113] = 0.000000 \n",
      "image[1][114] = 0.000000 \n",
      "image[1][115] = 0.000000 \n",
      "image[1][116] = 0.000000 \n",
      "image[1][117] = 0.000000 \n",
      "image[1][118] = 0.000000 \n",
      "image[1][119] = 0.000000 \n",
      "image[1][120] = 0.000000 \n",
      "image[1][121] = 0.000000 \n",
      "image[1][122] = 0.000000 \n",
      "image[1][123] = 0.000000 \n",
      "image[1][124] = 0.000000 \n",
      "image[1][125] = 0.000000 \n",
      "image[1][126] = 0.000000 \n",
      "image[1][127] = 0.200000 \n",
      "image[1][128] = 0.623529 \n",
      "image[1][129] = 0.992157 \n",
      "image[1][130] = 0.623529 \n",
      "image[1][131] = 0.196078 \n",
      "image[1][132] = 0.000000 \n",
      "image[1][133] = 0.000000 \n",
      "image[1][134] = 0.000000 \n",
      "image[1][135] = 0.000000 \n",
      "image[1][136] = 0.000000 \n",
      "image[1][137] = 0.000000 \n",
      "image[1][138] = 0.000000 \n",
      "image[1][139] = 0.000000 \n",
      "image[1][140] = 0.000000 \n",
      "image[1][141] = 0.000000 \n",
      "image[1][142] = 0.000000 \n",
      "image[1][143] = 0.000000 \n",
      "image[1][144] = 0.000000 \n",
      "image[1][145] = 0.000000 \n",
      "image[1][146] = 0.000000 \n",
      "image[1][147] = 0.000000 \n",
      "image[1][148] = 0.000000 \n",
      "image[1][149] = 0.000000 \n",
      "image[1][150] = 0.000000 \n",
      "image[1][151] = 0.000000 \n",
      "image[1][152] = 0.000000 \n",
      "image[1][153] = 0.000000 \n",
      "image[1][154] = 0.188235 \n",
      "image[1][155] = 0.933333 \n",
      "image[1][156] = 0.988235 \n",
      "image[1][157] = 0.988235 \n",
      "image[1][158] = 0.988235 \n",
      "image[1][159] = 0.929412 \n",
      "image[1][160] = 0.000000 \n",
      "image[1][161] = 0.000000 \n",
      "image[1][162] = 0.000000 \n",
      "image[1][163] = 0.000000 \n",
      "image[1][164] = 0.000000 \n",
      "image[1][165] = 0.000000 \n",
      "image[1][166] = 0.000000 \n",
      "image[1][167] = 0.000000 \n",
      "image[1][168] = 0.000000 \n",
      "image[1][169] = 0.000000 \n",
      "image[1][170] = 0.000000 \n",
      "image[1][171] = 0.000000 \n",
      "image[1][172] = 0.000000 \n",
      "image[1][173] = 0.000000 \n",
      "image[1][174] = 0.000000 \n",
      "image[1][175] = 0.000000 \n",
      "image[1][176] = 0.000000 \n",
      "image[1][177] = 0.000000 \n",
      "image[1][178] = 0.000000 \n",
      "image[1][179] = 0.000000 \n",
      "image[1][180] = 0.000000 \n",
      "image[1][181] = 0.211765 \n",
      "image[1][182] = 0.890196 \n",
      "image[1][183] = 0.992157 \n",
      "image[1][184] = 0.988235 \n",
      "image[1][185] = 0.937255 \n",
      "image[1][186] = 0.913725 \n",
      "image[1][187] = 0.988235 \n",
      "image[1][188] = 0.223529 \n",
      "image[1][189] = 0.023529 \n",
      "image[1][190] = 0.000000 \n",
      "image[1][191] = 0.000000 \n",
      "image[1][192] = 0.000000 \n",
      "image[1][193] = 0.000000 \n",
      "image[1][194] = 0.000000 \n",
      "image[1][195] = 0.000000 \n",
      "image[1][196] = 0.000000 \n",
      "image[1][197] = 0.000000 \n",
      "image[1][198] = 0.000000 \n",
      "image[1][199] = 0.000000 \n",
      "image[1][200] = 0.000000 \n",
      "image[1][201] = 0.000000 \n",
      "image[1][202] = 0.000000 \n",
      "image[1][203] = 0.000000 \n",
      "image[1][204] = 0.000000 \n",
      "image[1][205] = 0.000000 \n",
      "image[1][206] = 0.000000 \n",
      "image[1][207] = 0.039216 \n",
      "image[1][208] = 0.235294 \n",
      "image[1][209] = 0.878431 \n",
      "image[1][210] = 0.988235 \n",
      "image[1][211] = 0.992157 \n",
      "image[1][212] = 0.988235 \n",
      "image[1][213] = 0.792157 \n",
      "image[1][214] = 0.329412 \n",
      "image[1][215] = 0.988235 \n",
      "image[1][216] = 0.992157 \n",
      "image[1][217] = 0.478431 \n",
      "image[1][218] = 0.000000 \n",
      "image[1][219] = 0.000000 \n",
      "image[1][220] = 0.000000 \n",
      "image[1][221] = 0.000000 \n",
      "image[1][222] = 0.000000 \n",
      "image[1][223] = 0.000000 \n",
      "image[1][224] = 0.000000 \n",
      "image[1][225] = 0.000000 \n",
      "image[1][226] = 0.000000 \n",
      "image[1][227] = 0.000000 \n",
      "image[1][228] = 0.000000 \n",
      "image[1][229] = 0.000000 \n",
      "image[1][230] = 0.000000 \n",
      "image[1][231] = 0.000000 \n",
      "image[1][232] = 0.000000 \n",
      "image[1][233] = 0.000000 \n",
      "image[1][234] = 0.000000 \n",
      "image[1][235] = 0.639216 \n",
      "image[1][236] = 0.988235 \n",
      "image[1][237] = 0.988235 \n",
      "image[1][238] = 0.988235 \n",
      "image[1][239] = 0.992157 \n",
      "image[1][240] = 0.988235 \n",
      "image[1][241] = 0.988235 \n",
      "image[1][242] = 0.376471 \n",
      "image[1][243] = 0.741176 \n",
      "image[1][244] = 0.992157 \n",
      "image[1][245] = 0.654902 \n",
      "image[1][246] = 0.000000 \n",
      "image[1][247] = 0.000000 \n",
      "image[1][248] = 0.000000 \n",
      "image[1][249] = 0.000000 \n",
      "image[1][250] = 0.000000 \n",
      "image[1][251] = 0.000000 \n",
      "image[1][252] = 0.000000 \n",
      "image[1][253] = 0.000000 \n",
      "image[1][254] = 0.000000 \n",
      "image[1][255] = 0.000000 \n",
      "image[1][256] = 0.000000 \n",
      "image[1][257] = 0.000000 \n",
      "image[1][258] = 0.000000 \n",
      "image[1][259] = 0.000000 \n",
      "image[1][260] = 0.000000 \n",
      "image[1][261] = 0.000000 \n",
      "image[1][262] = 0.200000 \n",
      "image[1][263] = 0.933333 \n",
      "image[1][264] = 0.992157 \n",
      "image[1][265] = 0.992157 \n",
      "image[1][266] = 0.745098 \n",
      "image[1][267] = 0.447059 \n",
      "image[1][268] = 0.992157 \n",
      "image[1][269] = 0.894118 \n",
      "image[1][270] = 0.184314 \n",
      "image[1][271] = 0.309804 \n",
      "image[1][272] = 1.000000 \n",
      "image[1][273] = 0.658824 \n",
      "image[1][274] = 0.000000 \n",
      "image[1][275] = 0.000000 \n",
      "image[1][276] = 0.000000 \n",
      "image[1][277] = 0.000000 \n",
      "image[1][278] = 0.000000 \n",
      "image[1][279] = 0.000000 \n",
      "image[1][280] = 0.000000 \n",
      "image[1][281] = 0.000000 \n",
      "image[1][282] = 0.000000 \n",
      "image[1][283] = 0.000000 \n",
      "image[1][284] = 0.000000 \n",
      "image[1][285] = 0.000000 \n",
      "image[1][286] = 0.000000 \n",
      "image[1][287] = 0.000000 \n",
      "image[1][288] = 0.000000 \n",
      "image[1][289] = 0.188235 \n",
      "image[1][290] = 0.933333 \n",
      "image[1][291] = 0.988235 \n",
      "image[1][292] = 0.988235 \n",
      "image[1][293] = 0.701961 \n",
      "image[1][294] = 0.047059 \n",
      "image[1][295] = 0.294118 \n",
      "image[1][296] = 0.474510 \n",
      "image[1][297] = 0.082353 \n",
      "image[1][298] = 0.000000 \n",
      "image[1][299] = 0.000000 \n",
      "image[1][300] = 0.992157 \n",
      "image[1][301] = 0.952941 \n",
      "image[1][302] = 0.196078 \n",
      "image[1][303] = 0.000000 \n",
      "image[1][304] = 0.000000 \n",
      "image[1][305] = 0.000000 \n",
      "image[1][306] = 0.000000 \n",
      "image[1][307] = 0.000000 \n",
      "image[1][308] = 0.000000 \n",
      "image[1][309] = 0.000000 \n",
      "image[1][310] = 0.000000 \n",
      "image[1][311] = 0.000000 \n",
      "image[1][312] = 0.000000 \n",
      "image[1][313] = 0.000000 \n",
      "image[1][314] = 0.000000 \n",
      "image[1][315] = 0.000000 \n",
      "image[1][316] = 0.149020 \n",
      "image[1][317] = 0.647059 \n",
      "image[1][318] = 0.992157 \n",
      "image[1][319] = 0.913725 \n",
      "image[1][320] = 0.815686 \n",
      "image[1][321] = 0.329412 \n",
      "image[1][322] = 0.000000 \n",
      "image[1][323] = 0.000000 \n",
      "image[1][324] = 0.000000 \n",
      "image[1][325] = 0.000000 \n",
      "image[1][326] = 0.000000 \n",
      "image[1][327] = 0.000000 \n",
      "image[1][328] = 0.992157 \n",
      "image[1][329] = 0.988235 \n",
      "image[1][330] = 0.647059 \n",
      "image[1][331] = 0.000000 \n",
      "image[1][332] = 0.000000 \n",
      "image[1][333] = 0.000000 \n",
      "image[1][334] = 0.000000 \n",
      "image[1][335] = 0.000000 \n",
      "image[1][336] = 0.000000 \n",
      "image[1][337] = 0.000000 \n",
      "image[1][338] = 0.000000 \n",
      "image[1][339] = 0.000000 \n",
      "image[1][340] = 0.000000 \n",
      "image[1][341] = 0.000000 \n",
      "image[1][342] = 0.000000 \n",
      "image[1][343] = 0.027451 \n",
      "image[1][344] = 0.698039 \n",
      "image[1][345] = 0.988235 \n",
      "image[1][346] = 0.941176 \n",
      "image[1][347] = 0.278431 \n",
      "image[1][348] = 0.074510 \n",
      "image[1][349] = 0.109804 \n",
      "image[1][350] = 0.000000 \n",
      "image[1][351] = 0.000000 \n",
      "image[1][352] = 0.000000 \n",
      "image[1][353] = 0.000000 \n",
      "image[1][354] = 0.000000 \n",
      "image[1][355] = 0.000000 \n",
      "image[1][356] = 0.992157 \n",
      "image[1][357] = 0.988235 \n",
      "image[1][358] = 0.764706 \n",
      "image[1][359] = 0.000000 \n",
      "image[1][360] = 0.000000 \n",
      "image[1][361] = 0.000000 \n",
      "image[1][362] = 0.000000 \n",
      "image[1][363] = 0.000000 \n",
      "image[1][364] = 0.000000 \n",
      "image[1][365] = 0.000000 \n",
      "image[1][366] = 0.000000 \n",
      "image[1][367] = 0.000000 \n",
      "image[1][368] = 0.000000 \n",
      "image[1][369] = 0.000000 \n",
      "image[1][370] = 0.000000 \n",
      "image[1][371] = 0.223529 \n",
      "image[1][372] = 0.988235 \n",
      "image[1][373] = 0.988235 \n",
      "image[1][374] = 0.247059 \n",
      "image[1][375] = 0.000000 \n",
      "image[1][376] = 0.000000 \n",
      "image[1][377] = 0.000000 \n",
      "image[1][378] = 0.000000 \n",
      "image[1][379] = 0.000000 \n",
      "image[1][380] = 0.000000 \n",
      "image[1][381] = 0.000000 \n",
      "image[1][382] = 0.000000 \n",
      "image[1][383] = 0.000000 \n",
      "image[1][384] = 0.992157 \n",
      "image[1][385] = 0.988235 \n",
      "image[1][386] = 0.764706 \n",
      "image[1][387] = 0.000000 \n",
      "image[1][388] = 0.000000 \n",
      "image[1][389] = 0.000000 \n",
      "image[1][390] = 0.000000 \n",
      "image[1][391] = 0.000000 \n",
      "image[1][392] = 0.000000 \n",
      "image[1][393] = 0.000000 \n",
      "image[1][394] = 0.000000 \n",
      "image[1][395] = 0.000000 \n",
      "image[1][396] = 0.000000 \n",
      "image[1][397] = 0.000000 \n",
      "image[1][398] = 0.000000 \n",
      "image[1][399] = 0.776471 \n",
      "image[1][400] = 0.992157 \n",
      "image[1][401] = 0.745098 \n",
      "image[1][402] = 0.000000 \n",
      "image[1][403] = 0.000000 \n",
      "image[1][404] = 0.000000 \n",
      "image[1][405] = 0.000000 \n",
      "image[1][406] = 0.000000 \n",
      "image[1][407] = 0.000000 \n",
      "image[1][408] = 0.000000 \n",
      "image[1][409] = 0.000000 \n",
      "image[1][410] = 0.000000 \n",
      "image[1][411] = 0.000000 \n",
      "image[1][412] = 1.000000 \n",
      "image[1][413] = 0.992157 \n",
      "image[1][414] = 0.768627 \n",
      "image[1][415] = 0.000000 \n",
      "image[1][416] = 0.000000 \n",
      "image[1][417] = 0.000000 \n",
      "image[1][418] = 0.000000 \n",
      "image[1][419] = 0.000000 \n",
      "image[1][420] = 0.000000 \n",
      "image[1][421] = 0.000000 \n",
      "image[1][422] = 0.000000 \n",
      "image[1][423] = 0.000000 \n",
      "image[1][424] = 0.000000 \n",
      "image[1][425] = 0.000000 \n",
      "image[1][426] = 0.298039 \n",
      "image[1][427] = 0.964706 \n",
      "image[1][428] = 0.988235 \n",
      "image[1][429] = 0.439216 \n",
      "image[1][430] = 0.000000 \n",
      "image[1][431] = 0.000000 \n",
      "image[1][432] = 0.000000 \n",
      "image[1][433] = 0.000000 \n",
      "image[1][434] = 0.000000 \n",
      "image[1][435] = 0.000000 \n",
      "image[1][436] = 0.000000 \n",
      "image[1][437] = 0.000000 \n",
      "image[1][438] = 0.000000 \n",
      "image[1][439] = 0.000000 \n",
      "image[1][440] = 0.992157 \n",
      "image[1][441] = 0.988235 \n",
      "image[1][442] = 0.580392 \n",
      "image[1][443] = 0.000000 \n",
      "image[1][444] = 0.000000 \n",
      "image[1][445] = 0.000000 \n",
      "image[1][446] = 0.000000 \n",
      "image[1][447] = 0.000000 \n",
      "image[1][448] = 0.000000 \n",
      "image[1][449] = 0.000000 \n",
      "image[1][450] = 0.000000 \n",
      "image[1][451] = 0.000000 \n",
      "image[1][452] = 0.000000 \n",
      "image[1][453] = 0.000000 \n",
      "image[1][454] = 0.333333 \n",
      "image[1][455] = 0.988235 \n",
      "image[1][456] = 0.901961 \n",
      "image[1][457] = 0.098039 \n",
      "image[1][458] = 0.000000 \n",
      "image[1][459] = 0.000000 \n",
      "image[1][460] = 0.000000 \n",
      "image[1][461] = 0.000000 \n",
      "image[1][462] = 0.000000 \n",
      "image[1][463] = 0.000000 \n",
      "image[1][464] = 0.000000 \n",
      "image[1][465] = 0.000000 \n",
      "image[1][466] = 0.027451 \n",
      "image[1][467] = 0.529412 \n",
      "image[1][468] = 0.992157 \n",
      "image[1][469] = 0.729412 \n",
      "image[1][470] = 0.047059 \n",
      "image[1][471] = 0.000000 \n",
      "image[1][472] = 0.000000 \n",
      "image[1][473] = 0.000000 \n",
      "image[1][474] = 0.000000 \n",
      "image[1][475] = 0.000000 \n",
      "image[1][476] = 0.000000 \n",
      "image[1][477] = 0.000000 \n",
      "image[1][478] = 0.000000 \n",
      "image[1][479] = 0.000000 \n",
      "image[1][480] = 0.000000 \n",
      "image[1][481] = 0.000000 \n",
      "image[1][482] = 0.333333 \n",
      "image[1][483] = 0.988235 \n",
      "image[1][484] = 0.874510 \n",
      "image[1][485] = 0.000000 \n",
      "image[1][486] = 0.000000 \n",
      "image[1][487] = 0.000000 \n",
      "image[1][488] = 0.000000 \n",
      "image[1][489] = 0.000000 \n",
      "image[1][490] = 0.000000 \n",
      "image[1][491] = 0.000000 \n",
      "image[1][492] = 0.000000 \n",
      "image[1][493] = 0.027451 \n",
      "image[1][494] = 0.513726 \n",
      "image[1][495] = 0.988235 \n",
      "image[1][496] = 0.882353 \n",
      "image[1][497] = 0.278431 \n",
      "image[1][498] = 0.000000 \n",
      "image[1][499] = 0.000000 \n",
      "image[1][500] = 0.000000 \n",
      "image[1][501] = 0.000000 \n",
      "image[1][502] = 0.000000 \n",
      "image[1][503] = 0.000000 \n",
      "image[1][504] = 0.000000 \n",
      "image[1][505] = 0.000000 \n",
      "image[1][506] = 0.000000 \n",
      "image[1][507] = 0.000000 \n",
      "image[1][508] = 0.000000 \n",
      "image[1][509] = 0.000000 \n",
      "image[1][510] = 0.333333 \n",
      "image[1][511] = 0.988235 \n",
      "image[1][512] = 0.568627 \n",
      "image[1][513] = 0.000000 \n",
      "image[1][514] = 0.000000 \n",
      "image[1][515] = 0.000000 \n",
      "image[1][516] = 0.000000 \n",
      "image[1][517] = 0.000000 \n",
      "image[1][518] = 0.000000 \n",
      "image[1][519] = 0.000000 \n",
      "image[1][520] = 0.188235 \n",
      "image[1][521] = 0.647059 \n",
      "image[1][522] = 0.988235 \n",
      "image[1][523] = 0.678431 \n",
      "image[1][524] = 0.000000 \n",
      "image[1][525] = 0.000000 \n",
      "image[1][526] = 0.000000 \n",
      "image[1][527] = 0.000000 \n",
      "image[1][528] = 0.000000 \n",
      "image[1][529] = 0.000000 \n",
      "image[1][530] = 0.000000 \n",
      "image[1][531] = 0.000000 \n",
      "image[1][532] = 0.000000 \n",
      "image[1][533] = 0.000000 \n",
      "image[1][534] = 0.000000 \n",
      "image[1][535] = 0.000000 \n",
      "image[1][536] = 0.000000 \n",
      "image[1][537] = 0.000000 \n",
      "image[1][538] = 0.337255 \n",
      "image[1][539] = 0.992157 \n",
      "image[1][540] = 0.882353 \n",
      "image[1][541] = 0.000000 \n",
      "image[1][542] = 0.000000 \n",
      "image[1][543] = 0.000000 \n",
      "image[1][544] = 0.000000 \n",
      "image[1][545] = 0.000000 \n",
      "image[1][546] = 0.000000 \n",
      "image[1][547] = 0.447059 \n",
      "image[1][548] = 0.933333 \n",
      "image[1][549] = 0.992157 \n",
      "image[1][550] = 0.635294 \n",
      "image[1][551] = 0.000000 \n",
      "image[1][552] = 0.000000 \n",
      "image[1][553] = 0.000000 \n",
      "image[1][554] = 0.000000 \n",
      "image[1][555] = 0.000000 \n",
      "image[1][556] = 0.000000 \n",
      "image[1][557] = 0.000000 \n",
      "image[1][558] = 0.000000 \n",
      "image[1][559] = 0.000000 \n",
      "image[1][560] = 0.000000 \n",
      "image[1][561] = 0.000000 \n",
      "image[1][562] = 0.000000 \n",
      "image[1][563] = 0.000000 \n",
      "image[1][564] = 0.000000 \n",
      "image[1][565] = 0.000000 \n",
      "image[1][566] = 0.333333 \n",
      "image[1][567] = 0.988235 \n",
      "image[1][568] = 0.976471 \n",
      "image[1][569] = 0.572549 \n",
      "image[1][570] = 0.188235 \n",
      "image[1][571] = 0.113725 \n",
      "image[1][572] = 0.333333 \n",
      "image[1][573] = 0.698039 \n",
      "image[1][574] = 0.882353 \n",
      "image[1][575] = 0.992157 \n",
      "image[1][576] = 0.874510 \n",
      "image[1][577] = 0.654902 \n",
      "image[1][578] = 0.219608 \n",
      "image[1][579] = 0.000000 \n",
      "image[1][580] = 0.000000 \n",
      "image[1][581] = 0.000000 \n",
      "image[1][582] = 0.000000 \n",
      "image[1][583] = 0.000000 \n",
      "image[1][584] = 0.000000 \n",
      "image[1][585] = 0.000000 \n",
      "image[1][586] = 0.000000 \n",
      "image[1][587] = 0.000000 \n",
      "image[1][588] = 0.000000 \n",
      "image[1][589] = 0.000000 \n",
      "image[1][590] = 0.000000 \n",
      "image[1][591] = 0.000000 \n",
      "image[1][592] = 0.000000 \n",
      "image[1][593] = 0.000000 \n",
      "image[1][594] = 0.333333 \n",
      "image[1][595] = 0.988235 \n",
      "image[1][596] = 0.988235 \n",
      "image[1][597] = 0.988235 \n",
      "image[1][598] = 0.898039 \n",
      "image[1][599] = 0.843137 \n",
      "image[1][600] = 0.988235 \n",
      "image[1][601] = 0.988235 \n",
      "image[1][602] = 0.988235 \n",
      "image[1][603] = 0.768627 \n",
      "image[1][604] = 0.509804 \n",
      "image[1][605] = 0.000000 \n",
      "image[1][606] = 0.000000 \n",
      "image[1][607] = 0.000000 \n",
      "image[1][608] = 0.000000 \n",
      "image[1][609] = 0.000000 \n",
      "image[1][610] = 0.000000 \n",
      "image[1][611] = 0.000000 \n",
      "image[1][612] = 0.000000 \n",
      "image[1][613] = 0.000000 \n",
      "image[1][614] = 0.000000 \n",
      "image[1][615] = 0.000000 \n",
      "image[1][616] = 0.000000 \n",
      "image[1][617] = 0.000000 \n",
      "image[1][618] = 0.000000 \n",
      "image[1][619] = 0.000000 \n",
      "image[1][620] = 0.000000 \n",
      "image[1][621] = 0.000000 \n",
      "image[1][622] = 0.109804 \n",
      "image[1][623] = 0.780392 \n",
      "image[1][624] = 0.988235 \n",
      "image[1][625] = 0.988235 \n",
      "image[1][626] = 0.992157 \n",
      "image[1][627] = 0.988235 \n",
      "image[1][628] = 0.988235 \n",
      "image[1][629] = 0.913725 \n",
      "image[1][630] = 0.568627 \n",
      "image[1][631] = 0.000000 \n",
      "image[1][632] = 0.000000 \n",
      "image[1][633] = 0.000000 \n",
      "image[1][634] = 0.000000 \n",
      "image[1][635] = 0.000000 \n",
      "image[1][636] = 0.000000 \n",
      "image[1][637] = 0.000000 \n",
      "image[1][638] = 0.000000 \n",
      "image[1][639] = 0.000000 \n",
      "image[1][640] = 0.000000 \n",
      "image[1][641] = 0.000000 \n",
      "image[1][642] = 0.000000 \n",
      "image[1][643] = 0.000000 \n",
      "image[1][644] = 0.000000 \n",
      "image[1][645] = 0.000000 \n",
      "image[1][646] = 0.000000 \n",
      "image[1][647] = 0.000000 \n",
      "image[1][648] = 0.000000 \n",
      "image[1][649] = 0.000000 \n",
      "image[1][650] = 0.000000 \n",
      "image[1][651] = 0.098039 \n",
      "image[1][652] = 0.501961 \n",
      "image[1][653] = 0.988235 \n",
      "image[1][654] = 0.992157 \n",
      "image[1][655] = 0.988235 \n",
      "image[1][656] = 0.552941 \n",
      "image[1][657] = 0.145098 \n",
      "image[1][658] = 0.000000 \n",
      "image[1][659] = 0.000000 \n",
      "image[1][660] = 0.000000 \n",
      "image[1][661] = 0.000000 \n",
      "image[1][662] = 0.000000 \n",
      "image[1][663] = 0.000000 \n",
      "image[1][664] = 0.000000 \n",
      "image[1][665] = 0.000000 \n",
      "image[1][666] = 0.000000 \n",
      "image[1][667] = 0.000000 \n",
      "image[1][668] = 0.000000 \n",
      "image[1][669] = 0.000000 \n",
      "image[1][670] = 0.000000 \n",
      "image[1][671] = 0.000000 \n",
      "image[1][672] = 0.000000 \n",
      "image[1][673] = 0.000000 \n",
      "image[1][674] = 0.000000 \n",
      "image[1][675] = 0.000000 \n",
      "image[1][676] = 0.000000 \n",
      "image[1][677] = 0.000000 \n",
      "image[1][678] = 0.000000 \n",
      "image[1][679] = 0.000000 \n",
      "image[1][680] = 0.000000 \n",
      "image[1][681] = 0.000000 \n",
      "image[1][682] = 0.000000 \n",
      "image[1][683] = 0.000000 \n",
      "image[1][684] = 0.000000 \n",
      "image[1][685] = 0.000000 \n",
      "image[1][686] = 0.000000 \n",
      "image[1][687] = 0.000000 \n",
      "image[1][688] = 0.000000 \n",
      "image[1][689] = 0.000000 \n",
      "image[1][690] = 0.000000 \n",
      "image[1][691] = 0.000000 \n",
      "image[1][692] = 0.000000 \n",
      "image[1][693] = 0.000000 \n",
      "image[1][694] = 0.000000 \n",
      "image[1][695] = 0.000000 \n",
      "image[1][696] = 0.000000 \n",
      "image[1][697] = 0.000000 \n",
      "image[1][698] = 0.000000 \n",
      "image[1][699] = 0.000000 \n",
      "image[1][700] = 0.000000 \n",
      "image[1][701] = 0.000000 \n",
      "image[1][702] = 0.000000 \n",
      "image[1][703] = 0.000000 \n",
      "image[1][704] = 0.000000 \n",
      "image[1][705] = 0.000000 \n",
      "image[1][706] = 0.000000 \n",
      "image[1][707] = 0.000000 \n",
      "image[1][708] = 0.000000 \n",
      "image[1][709] = 0.000000 \n",
      "image[1][710] = 0.000000 \n",
      "image[1][711] = 0.000000 \n",
      "image[1][712] = 0.000000 \n",
      "image[1][713] = 0.000000 \n",
      "image[1][714] = 0.000000 \n",
      "image[1][715] = 0.000000 \n",
      "image[1][716] = 0.000000 \n",
      "image[1][717] = 0.000000 \n",
      "image[1][718] = 0.000000 \n",
      "image[1][719] = 0.000000 \n",
      "image[1][720] = 0.000000 \n",
      "image[1][721] = 0.000000 \n",
      "image[1][722] = 0.000000 \n",
      "image[1][723] = 0.000000 \n",
      "image[1][724] = 0.000000 \n",
      "image[1][725] = 0.000000 \n",
      "image[1][726] = 0.000000 \n",
      "image[1][727] = 0.000000 \n",
      "image[1][728] = 0.000000 \n",
      "image[1][729] = 0.000000 \n",
      "image[1][730] = 0.000000 \n",
      "image[1][731] = 0.000000 \n",
      "image[1][732] = 0.000000 \n",
      "image[1][733] = 0.000000 \n",
      "image[1][734] = 0.000000 \n",
      "image[1][735] = 0.000000 \n",
      "image[1][736] = 0.000000 \n",
      "image[1][737] = 0.000000 \n",
      "image[1][738] = 0.000000 \n",
      "image[1][739] = 0.000000 \n",
      "image[1][740] = 0.000000 \n",
      "image[1][741] = 0.000000 \n",
      "image[1][742] = 0.000000 \n",
      "image[1][743] = 0.000000 \n",
      "image[1][744] = 0.000000 \n",
      "image[1][745] = 0.000000 \n",
      "image[1][746] = 0.000000 \n",
      "image[1][747] = 0.000000 \n",
      "image[1][748] = 0.000000 \n",
      "image[1][749] = 0.000000 \n",
      "image[1][750] = 0.000000 \n",
      "image[1][751] = 0.000000 \n",
      "image[1][752] = 0.000000 \n",
      "image[1][753] = 0.000000 \n",
      "image[1][754] = 0.000000 \n",
      "image[1][755] = 0.000000 \n",
      "image[1][756] = 0.000000 \n",
      "image[1][757] = 0.000000 \n",
      "image[1][758] = 0.000000 \n",
      "image[1][759] = 0.000000 \n",
      "image[1][760] = 0.000000 \n",
      "image[1][761] = 0.000000 \n",
      "image[1][762] = 0.000000 \n",
      "image[1][763] = 0.000000 \n",
      "image[1][764] = 0.000000 \n",
      "image[1][765] = 0.000000 \n",
      "image[1][766] = 0.000000 \n",
      "image[1][767] = 0.000000 \n",
      "image[1][768] = 0.000000 \n",
      "image[1][769] = 0.000000 \n",
      "image[1][770] = 0.000000 \n",
      "image[1][771] = 0.000000 \n",
      "image[1][772] = 0.000000 \n",
      "image[1][773] = 0.000000 \n",
      "image[1][774] = 0.000000 \n",
      "image[1][775] = 0.000000 \n",
      "image[1][776] = 0.000000 \n",
      "image[1][777] = 0.000000 \n",
      "image[1][778] = 0.000000 \n",
      "image[1][779] = 0.000000 \n",
      "image[1][780] = 0.000000 \n",
      "image[1][781] = 0.000000 \n",
      "image[1][782] = 0.000000 \n",
      "image[1][783] = 0.000000 \n",
      "image[2][0] = 0.000000 \n",
      "image[2][1] = 0.000000 \n",
      "image[2][2] = 0.000000 \n",
      "image[2][3] = 0.000000 \n",
      "image[2][4] = 0.000000 \n",
      "image[2][5] = 0.000000 \n",
      "image[2][6] = 0.000000 \n",
      "image[2][7] = 0.000000 \n",
      "image[2][8] = 0.000000 \n",
      "image[2][9] = 0.000000 \n",
      "image[2][10] = 0.000000 \n",
      "image[2][11] = 0.000000 \n",
      "image[2][12] = 0.000000 \n",
      "image[2][13] = 0.000000 \n",
      "image[2][14] = 0.000000 \n",
      "image[2][15] = 0.000000 \n",
      "image[2][16] = 0.000000 \n",
      "image[2][17] = 0.000000 \n",
      "image[2][18] = 0.000000 \n",
      "image[2][19] = 0.000000 \n",
      "image[2][20] = 0.000000 \n",
      "image[2][21] = 0.000000 \n",
      "image[2][22] = 0.000000 \n",
      "image[2][23] = 0.000000 \n",
      "image[2][24] = 0.000000 \n",
      "image[2][25] = 0.000000 \n",
      "image[2][26] = 0.000000 \n",
      "image[2][27] = 0.000000 \n",
      "image[2][28] = 0.000000 \n",
      "image[2][29] = 0.000000 \n",
      "image[2][30] = 0.000000 \n",
      "image[2][31] = 0.000000 \n",
      "image[2][32] = 0.000000 \n",
      "image[2][33] = 0.000000 \n",
      "image[2][34] = 0.000000 \n",
      "image[2][35] = 0.000000 \n",
      "image[2][36] = 0.000000 \n",
      "image[2][37] = 0.000000 \n",
      "image[2][38] = 0.000000 \n",
      "image[2][39] = 0.000000 \n",
      "image[2][40] = 0.000000 \n",
      "image[2][41] = 0.000000 \n",
      "image[2][42] = 0.000000 \n",
      "image[2][43] = 0.000000 \n",
      "image[2][44] = 0.000000 \n",
      "image[2][45] = 0.000000 \n",
      "image[2][46] = 0.000000 \n",
      "image[2][47] = 0.000000 \n",
      "image[2][48] = 0.000000 \n",
      "image[2][49] = 0.000000 \n",
      "image[2][50] = 0.000000 \n",
      "image[2][51] = 0.000000 \n",
      "image[2][52] = 0.000000 \n",
      "image[2][53] = 0.000000 \n",
      "image[2][54] = 0.000000 \n",
      "image[2][55] = 0.000000 \n",
      "image[2][56] = 0.000000 \n",
      "image[2][57] = 0.000000 \n",
      "image[2][58] = 0.000000 \n",
      "image[2][59] = 0.000000 \n",
      "image[2][60] = 0.000000 \n",
      "image[2][61] = 0.000000 \n",
      "image[2][62] = 0.000000 \n",
      "image[2][63] = 0.000000 \n",
      "image[2][64] = 0.000000 \n",
      "image[2][65] = 0.000000 \n",
      "image[2][66] = 0.000000 \n",
      "image[2][67] = 0.000000 \n",
      "image[2][68] = 0.000000 \n",
      "image[2][69] = 0.000000 \n",
      "image[2][70] = 0.000000 \n",
      "image[2][71] = 0.000000 \n",
      "image[2][72] = 0.000000 \n",
      "image[2][73] = 0.000000 \n",
      "image[2][74] = 0.000000 \n",
      "image[2][75] = 0.000000 \n",
      "image[2][76] = 0.000000 \n",
      "image[2][77] = 0.000000 \n",
      "image[2][78] = 0.000000 \n",
      "image[2][79] = 0.000000 \n",
      "image[2][80] = 0.000000 \n",
      "image[2][81] = 0.000000 \n",
      "image[2][82] = 0.000000 \n",
      "image[2][83] = 0.000000 \n",
      "image[2][84] = 0.000000 \n",
      "image[2][85] = 0.000000 \n",
      "image[2][86] = 0.000000 \n",
      "image[2][87] = 0.000000 \n",
      "image[2][88] = 0.000000 \n",
      "image[2][89] = 0.000000 \n",
      "image[2][90] = 0.000000 \n",
      "image[2][91] = 0.000000 \n",
      "image[2][92] = 0.000000 \n",
      "image[2][93] = 0.000000 \n",
      "image[2][94] = 0.000000 \n",
      "image[2][95] = 0.000000 \n",
      "image[2][96] = 0.000000 \n",
      "image[2][97] = 0.000000 \n",
      "image[2][98] = 0.000000 \n",
      "image[2][99] = 0.000000 \n",
      "image[2][100] = 0.000000 \n",
      "image[2][101] = 0.000000 \n",
      "image[2][102] = 0.000000 \n",
      "image[2][103] = 0.000000 \n",
      "image[2][104] = 0.000000 \n",
      "image[2][105] = 0.000000 \n",
      "image[2][106] = 0.000000 \n",
      "image[2][107] = 0.000000 \n",
      "image[2][108] = 0.000000 \n",
      "image[2][109] = 0.000000 \n",
      "image[2][110] = 0.000000 \n",
      "image[2][111] = 0.000000 \n",
      "image[2][112] = 0.000000 \n",
      "image[2][113] = 0.000000 \n",
      "image[2][114] = 0.000000 \n",
      "image[2][115] = 0.000000 \n",
      "image[2][116] = 0.000000 \n",
      "image[2][117] = 0.000000 \n",
      "image[2][118] = 0.000000 \n",
      "image[2][119] = 0.000000 \n",
      "image[2][120] = 0.000000 \n",
      "image[2][121] = 0.000000 \n",
      "image[2][122] = 0.000000 \n",
      "image[2][123] = 0.000000 \n",
      "image[2][124] = 0.000000 \n",
      "image[2][125] = 0.000000 \n",
      "image[2][126] = 0.000000 \n",
      "image[2][127] = 0.000000 \n",
      "image[2][128] = 0.000000 \n",
      "image[2][129] = 0.000000 \n",
      "image[2][130] = 0.000000 \n",
      "image[2][131] = 0.000000 \n",
      "image[2][132] = 0.000000 \n",
      "image[2][133] = 0.000000 \n",
      "image[2][134] = 0.000000 \n",
      "image[2][135] = 0.000000 \n",
      "image[2][136] = 0.000000 \n",
      "image[2][137] = 0.000000 \n",
      "image[2][138] = 0.000000 \n",
      "image[2][139] = 0.000000 \n",
      "image[2][140] = 0.000000 \n",
      "image[2][141] = 0.000000 \n",
      "image[2][142] = 0.000000 \n",
      "image[2][143] = 0.000000 \n",
      "image[2][144] = 0.000000 \n",
      "image[2][145] = 0.000000 \n",
      "image[2][146] = 0.000000 \n",
      "image[2][147] = 0.000000 \n",
      "image[2][148] = 0.000000 \n",
      "image[2][149] = 0.000000 \n",
      "image[2][150] = 0.000000 \n",
      "image[2][151] = 0.000000 \n",
      "image[2][152] = 0.000000 \n",
      "image[2][153] = 0.000000 \n",
      "image[2][154] = 0.000000 \n",
      "image[2][155] = 0.000000 \n",
      "image[2][156] = 0.000000 \n",
      "image[2][157] = 0.000000 \n",
      "image[2][158] = 0.000000 \n",
      "image[2][159] = 0.000000 \n",
      "image[2][160] = 0.262745 \n",
      "image[2][161] = 0.909804 \n",
      "image[2][162] = 0.152941 \n",
      "image[2][163] = 0.000000 \n",
      "image[2][164] = 0.000000 \n",
      "image[2][165] = 0.000000 \n",
      "image[2][166] = 0.000000 \n",
      "image[2][167] = 0.000000 \n",
      "image[2][168] = 0.000000 \n",
      "image[2][169] = 0.000000 \n",
      "image[2][170] = 0.000000 \n",
      "image[2][171] = 0.000000 \n",
      "image[2][172] = 0.243137 \n",
      "image[2][173] = 0.317647 \n",
      "image[2][174] = 0.000000 \n",
      "image[2][175] = 0.000000 \n",
      "image[2][176] = 0.000000 \n",
      "image[2][177] = 0.000000 \n",
      "image[2][178] = 0.000000 \n",
      "image[2][179] = 0.000000 \n",
      "image[2][180] = 0.000000 \n",
      "image[2][181] = 0.000000 \n",
      "image[2][182] = 0.000000 \n",
      "image[2][183] = 0.000000 \n",
      "image[2][184] = 0.000000 \n",
      "image[2][185] = 0.000000 \n",
      "image[2][186] = 0.000000 \n",
      "image[2][187] = 0.000000 \n",
      "image[2][188] = 0.470588 \n",
      "image[2][189] = 0.705882 \n",
      "image[2][190] = 0.152941 \n",
      "image[2][191] = 0.000000 \n",
      "image[2][192] = 0.000000 \n",
      "image[2][193] = 0.000000 \n",
      "image[2][194] = 0.000000 \n",
      "image[2][195] = 0.000000 \n",
      "image[2][196] = 0.000000 \n",
      "image[2][197] = 0.000000 \n",
      "image[2][198] = 0.000000 \n",
      "image[2][199] = 0.000000 \n",
      "image[2][200] = 0.494118 \n",
      "image[2][201] = 0.639216 \n",
      "image[2][202] = 0.000000 \n",
      "image[2][203] = 0.000000 \n",
      "image[2][204] = 0.000000 \n",
      "image[2][205] = 0.000000 \n",
      "image[2][206] = 0.000000 \n",
      "image[2][207] = 0.000000 \n",
      "image[2][208] = 0.000000 \n",
      "image[2][209] = 0.000000 \n",
      "image[2][210] = 0.000000 \n",
      "image[2][211] = 0.000000 \n",
      "image[2][212] = 0.000000 \n",
      "image[2][213] = 0.000000 \n",
      "image[2][214] = 0.000000 \n",
      "image[2][215] = 0.007843 \n",
      "image[2][216] = 0.600000 \n",
      "image[2][217] = 0.823529 \n",
      "image[2][218] = 0.156863 \n",
      "image[2][219] = 0.000000 \n",
      "image[2][220] = 0.000000 \n",
      "image[2][221] = 0.000000 \n",
      "image[2][222] = 0.000000 \n",
      "image[2][223] = 0.000000 \n",
      "image[2][224] = 0.000000 \n",
      "image[2][225] = 0.000000 \n",
      "image[2][226] = 0.000000 \n",
      "image[2][227] = 0.000000 \n",
      "image[2][228] = 0.862745 \n",
      "image[2][229] = 0.639216 \n",
      "image[2][230] = 0.000000 \n",
      "image[2][231] = 0.000000 \n",
      "image[2][232] = 0.000000 \n",
      "image[2][233] = 0.000000 \n",
      "image[2][234] = 0.000000 \n",
      "image[2][235] = 0.000000 \n",
      "image[2][236] = 0.000000 \n",
      "image[2][237] = 0.000000 \n",
      "image[2][238] = 0.000000 \n",
      "image[2][239] = 0.000000 \n",
      "image[2][240] = 0.000000 \n",
      "image[2][241] = 0.000000 \n",
      "image[2][242] = 0.000000 \n",
      "image[2][243] = 0.105882 \n",
      "image[2][244] = 0.996078 \n",
      "image[2][245] = 0.635294 \n",
      "image[2][246] = 0.000000 \n",
      "image[2][247] = 0.000000 \n",
      "image[2][248] = 0.000000 \n",
      "image[2][249] = 0.000000 \n",
      "image[2][250] = 0.000000 \n",
      "image[2][251] = 0.000000 \n",
      "image[2][252] = 0.000000 \n",
      "image[2][253] = 0.000000 \n",
      "image[2][254] = 0.000000 \n",
      "image[2][255] = 0.000000 \n",
      "image[2][256] = 0.870588 \n",
      "image[2][257] = 0.639216 \n",
      "image[2][258] = 0.000000 \n",
      "image[2][259] = 0.000000 \n",
      "image[2][260] = 0.000000 \n",
      "image[2][261] = 0.000000 \n",
      "image[2][262] = 0.000000 \n",
      "image[2][263] = 0.000000 \n",
      "image[2][264] = 0.000000 \n",
      "image[2][265] = 0.000000 \n",
      "image[2][266] = 0.000000 \n",
      "image[2][267] = 0.000000 \n",
      "image[2][268] = 0.000000 \n",
      "image[2][269] = 0.000000 \n",
      "image[2][270] = 0.000000 \n",
      "image[2][271] = 0.717647 \n",
      "image[2][272] = 0.996078 \n",
      "image[2][273] = 0.490196 \n",
      "image[2][274] = 0.000000 \n",
      "image[2][275] = 0.000000 \n",
      "image[2][276] = 0.000000 \n",
      "image[2][277] = 0.000000 \n",
      "image[2][278] = 0.000000 \n",
      "image[2][279] = 0.000000 \n",
      "image[2][280] = 0.000000 \n",
      "image[2][281] = 0.000000 \n",
      "image[2][282] = 0.000000 \n",
      "image[2][283] = 0.180392 \n",
      "image[2][284] = 0.960784 \n",
      "image[2][285] = 0.639216 \n",
      "image[2][286] = 0.000000 \n",
      "image[2][287] = 0.000000 \n",
      "image[2][288] = 0.000000 \n",
      "image[2][289] = 0.000000 \n",
      "image[2][290] = 0.000000 \n",
      "image[2][291] = 0.000000 \n",
      "image[2][292] = 0.000000 \n",
      "image[2][293] = 0.000000 \n",
      "image[2][294] = 0.000000 \n",
      "image[2][295] = 0.000000 \n",
      "image[2][296] = 0.000000 \n",
      "image[2][297] = 0.000000 \n",
      "image[2][298] = 0.000000 \n",
      "image[2][299] = 0.776471 \n",
      "image[2][300] = 0.996078 \n",
      "image[2][301] = 0.219608 \n",
      "image[2][302] = 0.000000 \n",
      "image[2][303] = 0.000000 \n",
      "image[2][304] = 0.000000 \n",
      "image[2][305] = 0.000000 \n",
      "image[2][306] = 0.000000 \n",
      "image[2][307] = 0.000000 \n",
      "image[2][308] = 0.000000 \n",
      "image[2][309] = 0.000000 \n",
      "image[2][310] = 0.000000 \n",
      "image[2][311] = 0.470588 \n",
      "image[2][312] = 0.996078 \n",
      "image[2][313] = 0.639216 \n",
      "image[2][314] = 0.000000 \n",
      "image[2][315] = 0.000000 \n",
      "image[2][316] = 0.000000 \n",
      "image[2][317] = 0.000000 \n",
      "image[2][318] = 0.000000 \n",
      "image[2][319] = 0.000000 \n",
      "image[2][320] = 0.000000 \n",
      "image[2][321] = 0.000000 \n",
      "image[2][322] = 0.000000 \n",
      "image[2][323] = 0.000000 \n",
      "image[2][324] = 0.000000 \n",
      "image[2][325] = 0.000000 \n",
      "image[2][326] = 0.090196 \n",
      "image[2][327] = 0.905882 \n",
      "image[2][328] = 0.996078 \n",
      "image[2][329] = 0.113725 \n",
      "image[2][330] = 0.000000 \n",
      "image[2][331] = 0.000000 \n",
      "image[2][332] = 0.000000 \n",
      "image[2][333] = 0.000000 \n",
      "image[2][334] = 0.000000 \n",
      "image[2][335] = 0.000000 \n",
      "image[2][336] = 0.000000 \n",
      "image[2][337] = 0.000000 \n",
      "image[2][338] = 0.000000 \n",
      "image[2][339] = 0.623529 \n",
      "image[2][340] = 0.996078 \n",
      "image[2][341] = 0.470588 \n",
      "image[2][342] = 0.000000 \n",
      "image[2][343] = 0.000000 \n",
      "image[2][344] = 0.000000 \n",
      "image[2][345] = 0.000000 \n",
      "image[2][346] = 0.000000 \n",
      "image[2][347] = 0.000000 \n",
      "image[2][348] = 0.000000 \n",
      "image[2][349] = 0.000000 \n",
      "image[2][350] = 0.000000 \n",
      "image[2][351] = 0.000000 \n",
      "image[2][352] = 0.000000 \n",
      "image[2][353] = 0.000000 \n",
      "image[2][354] = 0.639216 \n",
      "image[2][355] = 0.996078 \n",
      "image[2][356] = 0.847059 \n",
      "image[2][357] = 0.062745 \n",
      "image[2][358] = 0.000000 \n",
      "image[2][359] = 0.000000 \n",
      "image[2][360] = 0.000000 \n",
      "image[2][361] = 0.000000 \n",
      "image[2][362] = 0.000000 \n",
      "image[2][363] = 0.000000 \n",
      "image[2][364] = 0.000000 \n",
      "image[2][365] = 0.000000 \n",
      "image[2][366] = 0.000000 \n",
      "image[2][367] = 0.623529 \n",
      "image[2][368] = 0.996078 \n",
      "image[2][369] = 0.262745 \n",
      "image[2][370] = 0.000000 \n",
      "image[2][371] = 0.000000 \n",
      "image[2][372] = 0.000000 \n",
      "image[2][373] = 0.000000 \n",
      "image[2][374] = 0.000000 \n",
      "image[2][375] = 0.000000 \n",
      "image[2][376] = 0.000000 \n",
      "image[2][377] = 0.000000 \n",
      "image[2][378] = 0.000000 \n",
      "image[2][379] = 0.054902 \n",
      "image[2][380] = 0.337255 \n",
      "image[2][381] = 0.698039 \n",
      "image[2][382] = 0.972549 \n",
      "image[2][383] = 0.996078 \n",
      "image[2][384] = 0.356863 \n",
      "image[2][385] = 0.000000 \n",
      "image[2][386] = 0.000000 \n",
      "image[2][387] = 0.000000 \n",
      "image[2][388] = 0.000000 \n",
      "image[2][389] = 0.000000 \n",
      "image[2][390] = 0.000000 \n",
      "image[2][391] = 0.000000 \n",
      "image[2][392] = 0.000000 \n",
      "image[2][393] = 0.000000 \n",
      "image[2][394] = 0.000000 \n",
      "image[2][395] = 0.623529 \n",
      "image[2][396] = 0.996078 \n",
      "image[2][397] = 0.333333 \n",
      "image[2][398] = 0.000000 \n",
      "image[2][399] = 0.000000 \n",
      "image[2][400] = 0.000000 \n",
      "image[2][401] = 0.184314 \n",
      "image[2][402] = 0.192157 \n",
      "image[2][403] = 0.454902 \n",
      "image[2][404] = 0.564706 \n",
      "image[2][405] = 0.588235 \n",
      "image[2][406] = 0.945098 \n",
      "image[2][407] = 0.952941 \n",
      "image[2][408] = 0.917647 \n",
      "image[2][409] = 0.701961 \n",
      "image[2][410] = 0.945098 \n",
      "image[2][411] = 0.988235 \n",
      "image[2][412] = 0.156863 \n",
      "image[2][413] = 0.000000 \n",
      "image[2][414] = 0.000000 \n",
      "image[2][415] = 0.000000 \n",
      "image[2][416] = 0.000000 \n",
      "image[2][417] = 0.000000 \n",
      "image[2][418] = 0.000000 \n",
      "image[2][419] = 0.000000 \n",
      "image[2][420] = 0.000000 \n",
      "image[2][421] = 0.000000 \n",
      "image[2][422] = 0.000000 \n",
      "image[2][423] = 0.588235 \n",
      "image[2][424] = 0.992157 \n",
      "image[2][425] = 0.929412 \n",
      "image[2][426] = 0.811765 \n",
      "image[2][427] = 0.811765 \n",
      "image[2][428] = 0.811765 \n",
      "image[2][429] = 0.992157 \n",
      "image[2][430] = 0.996078 \n",
      "image[2][431] = 0.980392 \n",
      "image[2][432] = 0.941176 \n",
      "image[2][433] = 0.776471 \n",
      "image[2][434] = 0.560784 \n",
      "image[2][435] = 0.356863 \n",
      "image[2][436] = 0.109804 \n",
      "image[2][437] = 0.019608 \n",
      "image[2][438] = 0.913725 \n",
      "image[2][439] = 0.980392 \n",
      "image[2][440] = 0.000000 \n",
      "image[2][441] = 0.000000 \n",
      "image[2][442] = 0.000000 \n",
      "image[2][443] = 0.000000 \n",
      "image[2][444] = 0.000000 \n",
      "image[2][445] = 0.000000 \n",
      "image[2][446] = 0.000000 \n",
      "image[2][447] = 0.000000 \n",
      "image[2][448] = 0.000000 \n",
      "image[2][449] = 0.000000 \n",
      "image[2][450] = 0.000000 \n",
      "image[2][451] = 0.000000 \n",
      "image[2][452] = 0.466667 \n",
      "image[2][453] = 0.694118 \n",
      "image[2][454] = 0.694118 \n",
      "image[2][455] = 0.694118 \n",
      "image[2][456] = 0.694118 \n",
      "image[2][457] = 0.694118 \n",
      "image[2][458] = 0.384314 \n",
      "image[2][459] = 0.219608 \n",
      "image[2][460] = 0.000000 \n",
      "image[2][461] = 0.000000 \n",
      "image[2][462] = 0.000000 \n",
      "image[2][463] = 0.000000 \n",
      "image[2][464] = 0.000000 \n",
      "image[2][465] = 0.400000 \n",
      "image[2][466] = 0.996078 \n",
      "image[2][467] = 0.862745 \n",
      "image[2][468] = 0.000000 \n",
      "image[2][469] = 0.000000 \n",
      "image[2][470] = 0.000000 \n",
      "image[2][471] = 0.000000 \n",
      "image[2][472] = 0.000000 \n",
      "image[2][473] = 0.000000 \n",
      "image[2][474] = 0.000000 \n",
      "image[2][475] = 0.000000 \n",
      "image[2][476] = 0.000000 \n",
      "image[2][477] = 0.000000 \n",
      "image[2][478] = 0.000000 \n",
      "image[2][479] = 0.000000 \n",
      "image[2][480] = 0.000000 \n",
      "image[2][481] = 0.000000 \n",
      "image[2][482] = 0.000000 \n",
      "image[2][483] = 0.000000 \n",
      "image[2][484] = 0.000000 \n",
      "image[2][485] = 0.000000 \n",
      "image[2][486] = 0.000000 \n",
      "image[2][487] = 0.000000 \n",
      "image[2][488] = 0.000000 \n",
      "image[2][489] = 0.000000 \n",
      "image[2][490] = 0.000000 \n",
      "image[2][491] = 0.000000 \n",
      "image[2][492] = 0.000000 \n",
      "image[2][493] = 0.662745 \n",
      "image[2][494] = 0.996078 \n",
      "image[2][495] = 0.537255 \n",
      "image[2][496] = 0.000000 \n",
      "image[2][497] = 0.000000 \n",
      "image[2][498] = 0.000000 \n",
      "image[2][499] = 0.000000 \n",
      "image[2][500] = 0.000000 \n",
      "image[2][501] = 0.000000 \n",
      "image[2][502] = 0.000000 \n",
      "image[2][503] = 0.000000 \n",
      "image[2][504] = 0.000000 \n",
      "image[2][505] = 0.000000 \n",
      "image[2][506] = 0.000000 \n",
      "image[2][507] = 0.000000 \n",
      "image[2][508] = 0.000000 \n",
      "image[2][509] = 0.000000 \n",
      "image[2][510] = 0.000000 \n",
      "image[2][511] = 0.000000 \n",
      "image[2][512] = 0.000000 \n",
      "image[2][513] = 0.000000 \n",
      "image[2][514] = 0.000000 \n",
      "image[2][515] = 0.000000 \n",
      "image[2][516] = 0.000000 \n",
      "image[2][517] = 0.000000 \n",
      "image[2][518] = 0.000000 \n",
      "image[2][519] = 0.000000 \n",
      "image[2][520] = 0.000000 \n",
      "image[2][521] = 0.662745 \n",
      "image[2][522] = 0.996078 \n",
      "image[2][523] = 0.223529 \n",
      "image[2][524] = 0.000000 \n",
      "image[2][525] = 0.000000 \n",
      "image[2][526] = 0.000000 \n",
      "image[2][527] = 0.000000 \n",
      "image[2][528] = 0.000000 \n",
      "image[2][529] = 0.000000 \n",
      "image[2][530] = 0.000000 \n",
      "image[2][531] = 0.000000 \n",
      "image[2][532] = 0.000000 \n",
      "image[2][533] = 0.000000 \n",
      "image[2][534] = 0.000000 \n",
      "image[2][535] = 0.000000 \n",
      "image[2][536] = 0.000000 \n",
      "image[2][537] = 0.000000 \n",
      "image[2][538] = 0.000000 \n",
      "image[2][539] = 0.000000 \n",
      "image[2][540] = 0.000000 \n",
      "image[2][541] = 0.000000 \n",
      "image[2][542] = 0.000000 \n",
      "image[2][543] = 0.000000 \n",
      "image[2][544] = 0.000000 \n",
      "image[2][545] = 0.000000 \n",
      "image[2][546] = 0.000000 \n",
      "image[2][547] = 0.000000 \n",
      "image[2][548] = 0.000000 \n",
      "image[2][549] = 0.662745 \n",
      "image[2][550] = 0.996078 \n",
      "image[2][551] = 0.223529 \n",
      "image[2][552] = 0.000000 \n",
      "image[2][553] = 0.000000 \n",
      "image[2][554] = 0.000000 \n",
      "image[2][555] = 0.000000 \n",
      "image[2][556] = 0.000000 \n",
      "image[2][557] = 0.000000 \n",
      "image[2][558] = 0.000000 \n",
      "image[2][559] = 0.000000 \n",
      "image[2][560] = 0.000000 \n",
      "image[2][561] = 0.000000 \n",
      "image[2][562] = 0.000000 \n",
      "image[2][563] = 0.000000 \n",
      "image[2][564] = 0.000000 \n",
      "image[2][565] = 0.000000 \n",
      "image[2][566] = 0.000000 \n",
      "image[2][567] = 0.000000 \n",
      "image[2][568] = 0.000000 \n",
      "image[2][569] = 0.000000 \n",
      "image[2][570] = 0.000000 \n",
      "image[2][571] = 0.000000 \n",
      "image[2][572] = 0.000000 \n",
      "image[2][573] = 0.000000 \n",
      "image[2][574] = 0.000000 \n",
      "image[2][575] = 0.000000 \n",
      "image[2][576] = 0.000000 \n",
      "image[2][577] = 0.662745 \n",
      "image[2][578] = 1.000000 \n",
      "image[2][579] = 0.368627 \n",
      "image[2][580] = 0.000000 \n",
      "image[2][581] = 0.000000 \n",
      "image[2][582] = 0.000000 \n",
      "image[2][583] = 0.000000 \n",
      "image[2][584] = 0.000000 \n",
      "image[2][585] = 0.000000 \n",
      "image[2][586] = 0.000000 \n",
      "image[2][587] = 0.000000 \n",
      "image[2][588] = 0.000000 \n",
      "image[2][589] = 0.000000 \n",
      "image[2][590] = 0.000000 \n",
      "image[2][591] = 0.000000 \n",
      "image[2][592] = 0.000000 \n",
      "image[2][593] = 0.000000 \n",
      "image[2][594] = 0.000000 \n",
      "image[2][595] = 0.000000 \n",
      "image[2][596] = 0.000000 \n",
      "image[2][597] = 0.000000 \n",
      "image[2][598] = 0.000000 \n",
      "image[2][599] = 0.000000 \n",
      "image[2][600] = 0.000000 \n",
      "image[2][601] = 0.000000 \n",
      "image[2][602] = 0.000000 \n",
      "image[2][603] = 0.000000 \n",
      "image[2][604] = 0.000000 \n",
      "image[2][605] = 0.662745 \n",
      "image[2][606] = 0.996078 \n",
      "image[2][607] = 0.376471 \n",
      "image[2][608] = 0.000000 \n",
      "image[2][609] = 0.000000 \n",
      "image[2][610] = 0.000000 \n",
      "image[2][611] = 0.000000 \n",
      "image[2][612] = 0.000000 \n",
      "image[2][613] = 0.000000 \n",
      "image[2][614] = 0.000000 \n",
      "image[2][615] = 0.000000 \n",
      "image[2][616] = 0.000000 \n",
      "image[2][617] = 0.000000 \n",
      "image[2][618] = 0.000000 \n",
      "image[2][619] = 0.000000 \n",
      "image[2][620] = 0.000000 \n",
      "image[2][621] = 0.000000 \n",
      "image[2][622] = 0.000000 \n",
      "image[2][623] = 0.000000 \n",
      "image[2][624] = 0.000000 \n",
      "image[2][625] = 0.000000 \n",
      "image[2][626] = 0.000000 \n",
      "image[2][627] = 0.000000 \n",
      "image[2][628] = 0.000000 \n",
      "image[2][629] = 0.000000 \n",
      "image[2][630] = 0.000000 \n",
      "image[2][631] = 0.000000 \n",
      "image[2][632] = 0.000000 \n",
      "image[2][633] = 0.662745 \n",
      "image[2][634] = 0.996078 \n",
      "image[2][635] = 0.600000 \n",
      "image[2][636] = 0.000000 \n",
      "image[2][637] = 0.000000 \n",
      "image[2][638] = 0.000000 \n",
      "image[2][639] = 0.000000 \n",
      "image[2][640] = 0.000000 \n",
      "image[2][641] = 0.000000 \n",
      "image[2][642] = 0.000000 \n",
      "image[2][643] = 0.000000 \n",
      "image[2][644] = 0.000000 \n",
      "image[2][645] = 0.000000 \n",
      "image[2][646] = 0.000000 \n",
      "image[2][647] = 0.000000 \n",
      "image[2][648] = 0.000000 \n",
      "image[2][649] = 0.000000 \n",
      "image[2][650] = 0.000000 \n",
      "image[2][651] = 0.000000 \n",
      "image[2][652] = 0.000000 \n",
      "image[2][653] = 0.000000 \n",
      "image[2][654] = 0.000000 \n",
      "image[2][655] = 0.000000 \n",
      "image[2][656] = 0.000000 \n",
      "image[2][657] = 0.000000 \n",
      "image[2][658] = 0.000000 \n",
      "image[2][659] = 0.000000 \n",
      "image[2][660] = 0.000000 \n",
      "image[2][661] = 0.662745 \n",
      "image[2][662] = 1.000000 \n",
      "image[2][663] = 0.600000 \n",
      "image[2][664] = 0.000000 \n",
      "image[2][665] = 0.000000 \n",
      "image[2][666] = 0.000000 \n",
      "image[2][667] = 0.000000 \n",
      "image[2][668] = 0.000000 \n",
      "image[2][669] = 0.000000 \n",
      "image[2][670] = 0.000000 \n",
      "image[2][671] = 0.000000 \n",
      "image[2][672] = 0.000000 \n",
      "image[2][673] = 0.000000 \n",
      "image[2][674] = 0.000000 \n",
      "image[2][675] = 0.000000 \n",
      "image[2][676] = 0.000000 \n",
      "image[2][677] = 0.000000 \n",
      "image[2][678] = 0.000000 \n",
      "image[2][679] = 0.000000 \n",
      "image[2][680] = 0.000000 \n",
      "image[2][681] = 0.000000 \n",
      "image[2][682] = 0.000000 \n",
      "image[2][683] = 0.000000 \n",
      "image[2][684] = 0.000000 \n",
      "image[2][685] = 0.000000 \n",
      "image[2][686] = 0.000000 \n",
      "image[2][687] = 0.000000 \n",
      "image[2][688] = 0.000000 \n",
      "image[2][689] = 0.376471 \n",
      "image[2][690] = 0.996078 \n",
      "image[2][691] = 0.600000 \n",
      "image[2][692] = 0.000000 \n",
      "image[2][693] = 0.000000 \n",
      "image[2][694] = 0.000000 \n",
      "image[2][695] = 0.000000 \n",
      "image[2][696] = 0.000000 \n",
      "image[2][697] = 0.000000 \n",
      "image[2][698] = 0.000000 \n",
      "image[2][699] = 0.000000 \n",
      "image[2][700] = 0.000000 \n",
      "image[2][701] = 0.000000 \n",
      "image[2][702] = 0.000000 \n",
      "image[2][703] = 0.000000 \n",
      "image[2][704] = 0.000000 \n",
      "image[2][705] = 0.000000 \n",
      "image[2][706] = 0.000000 \n",
      "image[2][707] = 0.000000 \n",
      "image[2][708] = 0.000000 \n",
      "image[2][709] = 0.000000 \n",
      "image[2][710] = 0.000000 \n",
      "image[2][711] = 0.000000 \n",
      "image[2][712] = 0.000000 \n",
      "image[2][713] = 0.000000 \n",
      "image[2][714] = 0.000000 \n",
      "image[2][715] = 0.000000 \n",
      "image[2][716] = 0.000000 \n",
      "image[2][717] = 0.000000 \n",
      "image[2][718] = 0.000000 \n",
      "image[2][719] = 0.000000 \n",
      "image[2][720] = 0.000000 \n",
      "image[2][721] = 0.000000 \n",
      "image[2][722] = 0.000000 \n",
      "image[2][723] = 0.000000 \n",
      "image[2][724] = 0.000000 \n",
      "image[2][725] = 0.000000 \n",
      "image[2][726] = 0.000000 \n",
      "image[2][727] = 0.000000 \n",
      "image[2][728] = 0.000000 \n",
      "image[2][729] = 0.000000 \n",
      "image[2][730] = 0.000000 \n",
      "image[2][731] = 0.000000 \n",
      "image[2][732] = 0.000000 \n",
      "image[2][733] = 0.000000 \n",
      "image[2][734] = 0.000000 \n",
      "image[2][735] = 0.000000 \n",
      "image[2][736] = 0.000000 \n",
      "image[2][737] = 0.000000 \n",
      "image[2][738] = 0.000000 \n",
      "image[2][739] = 0.000000 \n",
      "image[2][740] = 0.000000 \n",
      "image[2][741] = 0.000000 \n",
      "image[2][742] = 0.000000 \n",
      "image[2][743] = 0.000000 \n",
      "image[2][744] = 0.000000 \n",
      "image[2][745] = 0.000000 \n",
      "image[2][746] = 0.000000 \n",
      "image[2][747] = 0.000000 \n",
      "image[2][748] = 0.000000 \n",
      "image[2][749] = 0.000000 \n",
      "image[2][750] = 0.000000 \n",
      "image[2][751] = 0.000000 \n",
      "image[2][752] = 0.000000 \n",
      "image[2][753] = 0.000000 \n",
      "image[2][754] = 0.000000 \n",
      "image[2][755] = 0.000000 \n",
      "image[2][756] = 0.000000 \n",
      "image[2][757] = 0.000000 \n",
      "image[2][758] = 0.000000 \n",
      "image[2][759] = 0.000000 \n",
      "image[2][760] = 0.000000 \n",
      "image[2][761] = 0.000000 \n",
      "image[2][762] = 0.000000 \n",
      "image[2][763] = 0.000000 \n",
      "image[2][764] = 0.000000 \n",
      "image[2][765] = 0.000000 \n",
      "image[2][766] = 0.000000 \n",
      "image[2][767] = 0.000000 \n",
      "image[2][768] = 0.000000 \n",
      "image[2][769] = 0.000000 \n",
      "image[2][770] = 0.000000 \n",
      "image[2][771] = 0.000000 \n",
      "image[2][772] = 0.000000 \n",
      "image[2][773] = 0.000000 \n",
      "image[2][774] = 0.000000 \n",
      "image[2][775] = 0.000000 \n",
      "image[2][776] = 0.000000 \n",
      "image[2][777] = 0.000000 \n",
      "image[2][778] = 0.000000 \n",
      "image[2][779] = 0.000000 \n",
      "image[2][780] = 0.000000 \n",
      "image[2][781] = 0.000000 \n",
      "image[2][782] = 0.000000 \n",
      "image[2][783] = 0.000000 \n",
      "image[3][0] = 0.000000 \n",
      "image[3][1] = 0.000000 \n",
      "image[3][2] = 0.000000 \n",
      "image[3][3] = 0.000000 \n",
      "image[3][4] = 0.000000 \n",
      "image[3][5] = 0.000000 \n",
      "image[3][6] = 0.000000 \n",
      "image[3][7] = 0.000000 \n",
      "image[3][8] = 0.000000 \n",
      "image[3][9] = 0.000000 \n",
      "image[3][10] = 0.000000 \n",
      "image[3][11] = 0.000000 \n",
      "image[3][12] = 0.000000 \n",
      "image[3][13] = 0.000000 \n",
      "image[3][14] = 0.000000 \n",
      "image[3][15] = 0.000000 \n",
      "image[3][16] = 0.000000 \n",
      "image[3][17] = 0.000000 \n",
      "image[3][18] = 0.000000 \n",
      "image[3][19] = 0.000000 \n",
      "image[3][20] = 0.000000 \n",
      "image[3][21] = 0.000000 \n",
      "image[3][22] = 0.000000 \n",
      "image[3][23] = 0.000000 \n",
      "image[3][24] = 0.000000 \n",
      "image[3][25] = 0.000000 \n",
      "image[3][26] = 0.000000 \n",
      "image[3][27] = 0.000000 \n",
      "image[3][28] = 0.000000 \n",
      "image[3][29] = 0.000000 \n",
      "image[3][30] = 0.000000 \n",
      "image[3][31] = 0.000000 \n",
      "image[3][32] = 0.000000 \n",
      "image[3][33] = 0.000000 \n",
      "image[3][34] = 0.000000 \n",
      "image[3][35] = 0.000000 \n",
      "image[3][36] = 0.000000 \n",
      "image[3][37] = 0.000000 \n",
      "image[3][38] = 0.000000 \n",
      "image[3][39] = 0.000000 \n",
      "image[3][40] = 0.000000 \n",
      "image[3][41] = 0.000000 \n",
      "image[3][42] = 0.000000 \n",
      "image[3][43] = 0.000000 \n",
      "image[3][44] = 0.000000 \n",
      "image[3][45] = 0.000000 \n",
      "image[3][46] = 0.000000 \n",
      "image[3][47] = 0.000000 \n",
      "image[3][48] = 0.000000 \n",
      "image[3][49] = 0.000000 \n",
      "image[3][50] = 0.000000 \n",
      "image[3][51] = 0.000000 \n",
      "image[3][52] = 0.000000 \n",
      "image[3][53] = 0.000000 \n",
      "image[3][54] = 0.000000 \n",
      "image[3][55] = 0.000000 \n",
      "image[3][56] = 0.000000 \n",
      "image[3][57] = 0.000000 \n",
      "image[3][58] = 0.000000 \n",
      "image[3][59] = 0.000000 \n",
      "image[3][60] = 0.000000 \n",
      "image[3][61] = 0.000000 \n",
      "image[3][62] = 0.000000 \n",
      "image[3][63] = 0.000000 \n",
      "image[3][64] = 0.000000 \n",
      "image[3][65] = 0.000000 \n",
      "image[3][66] = 0.000000 \n",
      "image[3][67] = 0.000000 \n",
      "image[3][68] = 0.000000 \n",
      "image[3][69] = 0.000000 \n",
      "image[3][70] = 0.000000 \n",
      "image[3][71] = 0.000000 \n",
      "image[3][72] = 0.000000 \n",
      "image[3][73] = 0.000000 \n",
      "image[3][74] = 0.000000 \n",
      "image[3][75] = 0.000000 \n",
      "image[3][76] = 0.000000 \n",
      "image[3][77] = 0.000000 \n",
      "image[3][78] = 0.000000 \n",
      "image[3][79] = 0.000000 \n",
      "image[3][80] = 0.000000 \n",
      "image[3][81] = 0.000000 \n",
      "image[3][82] = 0.000000 \n",
      "image[3][83] = 0.000000 \n",
      "image[3][84] = 0.000000 \n",
      "image[3][85] = 0.000000 \n",
      "image[3][86] = 0.000000 \n",
      "image[3][87] = 0.000000 \n",
      "image[3][88] = 0.000000 \n",
      "image[3][89] = 0.000000 \n",
      "image[3][90] = 0.000000 \n",
      "image[3][91] = 0.000000 \n",
      "image[3][92] = 0.000000 \n",
      "image[3][93] = 0.000000 \n",
      "image[3][94] = 0.000000 \n",
      "image[3][95] = 0.000000 \n",
      "image[3][96] = 0.000000 \n",
      "image[3][97] = 0.000000 \n",
      "image[3][98] = 0.000000 \n",
      "image[3][99] = 0.000000 \n",
      "image[3][100] = 0.000000 \n",
      "image[3][101] = 0.000000 \n",
      "image[3][102] = 0.000000 \n",
      "image[3][103] = 0.000000 \n",
      "image[3][104] = 0.000000 \n",
      "image[3][105] = 0.000000 \n",
      "image[3][106] = 0.000000 \n",
      "image[3][107] = 0.000000 \n",
      "image[3][108] = 0.000000 \n",
      "image[3][109] = 0.000000 \n",
      "image[3][110] = 0.000000 \n",
      "image[3][111] = 0.000000 \n",
      "image[3][112] = 0.000000 \n",
      "image[3][113] = 0.000000 \n",
      "image[3][114] = 0.000000 \n",
      "image[3][115] = 0.000000 \n",
      "image[3][116] = 0.000000 \n",
      "image[3][117] = 0.000000 \n",
      "image[3][118] = 0.000000 \n",
      "image[3][119] = 0.000000 \n",
      "image[3][120] = 0.000000 \n",
      "image[3][121] = 0.000000 \n",
      "image[3][122] = 0.000000 \n",
      "image[3][123] = 0.000000 \n",
      "image[3][124] = 0.000000 \n",
      "image[3][125] = 0.000000 \n",
      "image[3][126] = 0.000000 \n",
      "image[3][127] = 0.000000 \n",
      "image[3][128] = 0.000000 \n",
      "image[3][129] = 0.000000 \n",
      "image[3][130] = 0.000000 \n",
      "image[3][131] = 0.000000 \n",
      "image[3][132] = 0.000000 \n",
      "image[3][133] = 0.000000 \n",
      "image[3][134] = 0.000000 \n",
      "image[3][135] = 0.000000 \n",
      "image[3][136] = 0.000000 \n",
      "image[3][137] = 0.000000 \n",
      "image[3][138] = 0.000000 \n",
      "image[3][139] = 0.000000 \n",
      "image[3][140] = 0.000000 \n",
      "image[3][141] = 0.000000 \n",
      "image[3][142] = 0.000000 \n",
      "image[3][143] = 0.000000 \n",
      "image[3][144] = 0.000000 \n",
      "image[3][145] = 0.000000 \n",
      "image[3][146] = 0.000000 \n",
      "image[3][147] = 0.000000 \n",
      "image[3][148] = 0.000000 \n",
      "image[3][149] = 0.000000 \n",
      "image[3][150] = 0.000000 \n",
      "image[3][151] = 0.000000 \n",
      "image[3][152] = 0.000000 \n",
      "image[3][153] = 0.000000 \n",
      "image[3][154] = 0.000000 \n",
      "image[3][155] = 0.000000 \n",
      "image[3][156] = 0.000000 \n",
      "image[3][157] = 0.000000 \n",
      "image[3][158] = 0.486275 \n",
      "image[3][159] = 0.992157 \n",
      "image[3][160] = 1.000000 \n",
      "image[3][161] = 0.247059 \n",
      "image[3][162] = 0.000000 \n",
      "image[3][163] = 0.000000 \n",
      "image[3][164] = 0.000000 \n",
      "image[3][165] = 0.000000 \n",
      "image[3][166] = 0.000000 \n",
      "image[3][167] = 0.000000 \n",
      "image[3][168] = 0.000000 \n",
      "image[3][169] = 0.000000 \n",
      "image[3][170] = 0.000000 \n",
      "image[3][171] = 0.000000 \n",
      "image[3][172] = 0.000000 \n",
      "image[3][173] = 0.000000 \n",
      "image[3][174] = 0.000000 \n",
      "image[3][175] = 0.000000 \n",
      "image[3][176] = 0.000000 \n",
      "image[3][177] = 0.000000 \n",
      "image[3][178] = 0.000000 \n",
      "image[3][179] = 0.000000 \n",
      "image[3][180] = 0.000000 \n",
      "image[3][181] = 0.000000 \n",
      "image[3][182] = 0.000000 \n",
      "image[3][183] = 0.000000 \n",
      "image[3][184] = 0.000000 \n",
      "image[3][185] = 0.376471 \n",
      "image[3][186] = 0.956863 \n",
      "image[3][187] = 0.984314 \n",
      "image[3][188] = 0.992157 \n",
      "image[3][189] = 0.243137 \n",
      "image[3][190] = 0.000000 \n",
      "image[3][191] = 0.000000 \n",
      "image[3][192] = 0.000000 \n",
      "image[3][193] = 0.000000 \n",
      "image[3][194] = 0.000000 \n",
      "image[3][195] = 0.000000 \n",
      "image[3][196] = 0.000000 \n",
      "image[3][197] = 0.000000 \n",
      "image[3][198] = 0.000000 \n",
      "image[3][199] = 0.000000 \n",
      "image[3][200] = 0.000000 \n",
      "image[3][201] = 0.000000 \n",
      "image[3][202] = 0.000000 \n",
      "image[3][203] = 0.000000 \n",
      "image[3][204] = 0.000000 \n",
      "image[3][205] = 0.000000 \n",
      "image[3][206] = 0.000000 \n",
      "image[3][207] = 0.000000 \n",
      "image[3][208] = 0.000000 \n",
      "image[3][209] = 0.000000 \n",
      "image[3][210] = 0.000000 \n",
      "image[3][211] = 0.000000 \n",
      "image[3][212] = 0.000000 \n",
      "image[3][213] = 0.498039 \n",
      "image[3][214] = 0.984314 \n",
      "image[3][215] = 0.984314 \n",
      "image[3][216] = 0.992157 \n",
      "image[3][217] = 0.243137 \n",
      "image[3][218] = 0.000000 \n",
      "image[3][219] = 0.000000 \n",
      "image[3][220] = 0.000000 \n",
      "image[3][221] = 0.000000 \n",
      "image[3][222] = 0.000000 \n",
      "image[3][223] = 0.000000 \n",
      "image[3][224] = 0.000000 \n",
      "image[3][225] = 0.000000 \n",
      "image[3][226] = 0.000000 \n",
      "image[3][227] = 0.000000 \n",
      "image[3][228] = 0.000000 \n",
      "image[3][229] = 0.000000 \n",
      "image[3][230] = 0.000000 \n",
      "image[3][231] = 0.000000 \n",
      "image[3][232] = 0.000000 \n",
      "image[3][233] = 0.000000 \n",
      "image[3][234] = 0.000000 \n",
      "image[3][235] = 0.000000 \n",
      "image[3][236] = 0.000000 \n",
      "image[3][237] = 0.000000 \n",
      "image[3][238] = 0.000000 \n",
      "image[3][239] = 0.000000 \n",
      "image[3][240] = 0.266667 \n",
      "image[3][241] = 0.925490 \n",
      "image[3][242] = 0.984314 \n",
      "image[3][243] = 0.827451 \n",
      "image[3][244] = 0.121569 \n",
      "image[3][245] = 0.031373 \n",
      "image[3][246] = 0.000000 \n",
      "image[3][247] = 0.000000 \n",
      "image[3][248] = 0.000000 \n",
      "image[3][249] = 0.000000 \n",
      "image[3][250] = 0.000000 \n",
      "image[3][251] = 0.000000 \n",
      "image[3][252] = 0.000000 \n",
      "image[3][253] = 0.000000 \n",
      "image[3][254] = 0.000000 \n",
      "image[3][255] = 0.000000 \n",
      "image[3][256] = 0.000000 \n",
      "image[3][257] = 0.000000 \n",
      "image[3][258] = 0.000000 \n",
      "image[3][259] = 0.000000 \n",
      "image[3][260] = 0.000000 \n",
      "image[3][261] = 0.000000 \n",
      "image[3][262] = 0.000000 \n",
      "image[3][263] = 0.000000 \n",
      "image[3][264] = 0.000000 \n",
      "image[3][265] = 0.000000 \n",
      "image[3][266] = 0.000000 \n",
      "image[3][267] = 0.235294 \n",
      "image[3][268] = 0.894118 \n",
      "image[3][269] = 0.984314 \n",
      "image[3][270] = 0.984314 \n",
      "image[3][271] = 0.368627 \n",
      "image[3][272] = 0.000000 \n",
      "image[3][273] = 0.000000 \n",
      "image[3][274] = 0.000000 \n",
      "image[3][275] = 0.000000 \n",
      "image[3][276] = 0.000000 \n",
      "image[3][277] = 0.000000 \n",
      "image[3][278] = 0.000000 \n",
      "image[3][279] = 0.000000 \n",
      "image[3][280] = 0.000000 \n",
      "image[3][281] = 0.000000 \n",
      "image[3][282] = 0.000000 \n",
      "image[3][283] = 0.000000 \n",
      "image[3][284] = 0.000000 \n",
      "image[3][285] = 0.000000 \n",
      "image[3][286] = 0.000000 \n",
      "image[3][287] = 0.000000 \n",
      "image[3][288] = 0.000000 \n",
      "image[3][289] = 0.000000 \n",
      "image[3][290] = 0.000000 \n",
      "image[3][291] = 0.000000 \n",
      "image[3][292] = 0.000000 \n",
      "image[3][293] = 0.000000 \n",
      "image[3][294] = 0.000000 \n",
      "image[3][295] = 0.607843 \n",
      "image[3][296] = 0.992157 \n",
      "image[3][297] = 0.992157 \n",
      "image[3][298] = 0.741176 \n",
      "image[3][299] = 0.000000 \n",
      "image[3][300] = 0.000000 \n",
      "image[3][301] = 0.000000 \n",
      "image[3][302] = 0.000000 \n",
      "image[3][303] = 0.000000 \n",
      "image[3][304] = 0.000000 \n",
      "image[3][305] = 0.000000 \n",
      "image[3][306] = 0.000000 \n",
      "image[3][307] = 0.000000 \n",
      "image[3][308] = 0.000000 \n",
      "image[3][309] = 0.000000 \n",
      "image[3][310] = 0.000000 \n",
      "image[3][311] = 0.000000 \n",
      "image[3][312] = 0.000000 \n",
      "image[3][313] = 0.000000 \n",
      "image[3][314] = 0.000000 \n",
      "image[3][315] = 0.000000 \n",
      "image[3][316] = 0.000000 \n",
      "image[3][317] = 0.000000 \n",
      "image[3][318] = 0.000000 \n",
      "image[3][319] = 0.000000 \n",
      "image[3][320] = 0.000000 \n",
      "image[3][321] = 0.000000 \n",
      "image[3][322] = 0.078431 \n",
      "image[3][323] = 0.992157 \n",
      "image[3][324] = 0.984314 \n",
      "image[3][325] = 0.921569 \n",
      "image[3][326] = 0.258824 \n",
      "image[3][327] = 0.000000 \n",
      "image[3][328] = 0.000000 \n",
      "image[3][329] = 0.000000 \n",
      "image[3][330] = 0.000000 \n",
      "image[3][331] = 0.000000 \n",
      "image[3][332] = 0.000000 \n",
      "image[3][333] = 0.000000 \n",
      "image[3][334] = 0.000000 \n",
      "image[3][335] = 0.000000 \n",
      "image[3][336] = 0.000000 \n",
      "image[3][337] = 0.000000 \n",
      "image[3][338] = 0.000000 \n",
      "image[3][339] = 0.000000 \n",
      "image[3][340] = 0.000000 \n",
      "image[3][341] = 0.000000 \n",
      "image[3][342] = 0.000000 \n",
      "image[3][343] = 0.000000 \n",
      "image[3][344] = 0.000000 \n",
      "image[3][345] = 0.000000 \n",
      "image[3][346] = 0.000000 \n",
      "image[3][347] = 0.000000 \n",
      "image[3][348] = 0.000000 \n",
      "image[3][349] = 0.125490 \n",
      "image[3][350] = 0.803922 \n",
      "image[3][351] = 0.992157 \n",
      "image[3][352] = 0.984314 \n",
      "image[3][353] = 0.494118 \n",
      "image[3][354] = 0.000000 \n",
      "image[3][355] = 0.000000 \n",
      "image[3][356] = 0.000000 \n",
      "image[3][357] = 0.000000 \n",
      "image[3][358] = 0.000000 \n",
      "image[3][359] = 0.000000 \n",
      "image[3][360] = 0.000000 \n",
      "image[3][361] = 0.000000 \n",
      "image[3][362] = 0.000000 \n",
      "image[3][363] = 0.000000 \n",
      "image[3][364] = 0.000000 \n",
      "image[3][365] = 0.000000 \n",
      "image[3][366] = 0.000000 \n",
      "image[3][367] = 0.000000 \n",
      "image[3][368] = 0.000000 \n",
      "image[3][369] = 0.000000 \n",
      "image[3][370] = 0.000000 \n",
      "image[3][371] = 0.000000 \n",
      "image[3][372] = 0.000000 \n",
      "image[3][373] = 0.000000 \n",
      "image[3][374] = 0.000000 \n",
      "image[3][375] = 0.000000 \n",
      "image[3][376] = 0.000000 \n",
      "image[3][377] = 0.407843 \n",
      "image[3][378] = 0.984314 \n",
      "image[3][379] = 0.992157 \n",
      "image[3][380] = 0.721569 \n",
      "image[3][381] = 0.058824 \n",
      "image[3][382] = 0.000000 \n",
      "image[3][383] = 0.000000 \n",
      "image[3][384] = 0.000000 \n",
      "image[3][385] = 0.000000 \n",
      "image[3][386] = 0.000000 \n",
      "image[3][387] = 0.000000 \n",
      "image[3][388] = 0.000000 \n",
      "image[3][389] = 0.000000 \n",
      "image[3][390] = 0.000000 \n",
      "image[3][391] = 0.000000 \n",
      "image[3][392] = 0.000000 \n",
      "image[3][393] = 0.000000 \n",
      "image[3][394] = 0.000000 \n",
      "image[3][395] = 0.000000 \n",
      "image[3][396] = 0.000000 \n",
      "image[3][397] = 0.000000 \n",
      "image[3][398] = 0.000000 \n",
      "image[3][399] = 0.000000 \n",
      "image[3][400] = 0.000000 \n",
      "image[3][401] = 0.000000 \n",
      "image[3][402] = 0.000000 \n",
      "image[3][403] = 0.000000 \n",
      "image[3][404] = 0.313726 \n",
      "image[3][405] = 0.941176 \n",
      "image[3][406] = 0.984314 \n",
      "image[3][407] = 0.756863 \n",
      "image[3][408] = 0.090196 \n",
      "image[3][409] = 0.000000 \n",
      "image[3][410] = 0.000000 \n",
      "image[3][411] = 0.000000 \n",
      "image[3][412] = 0.000000 \n",
      "image[3][413] = 0.000000 \n",
      "image[3][414] = 0.000000 \n",
      "image[3][415] = 0.000000 \n",
      "image[3][416] = 0.000000 \n",
      "image[3][417] = 0.000000 \n",
      "image[3][418] = 0.000000 \n",
      "image[3][419] = 0.000000 \n",
      "image[3][420] = 0.000000 \n",
      "image[3][421] = 0.000000 \n",
      "image[3][422] = 0.000000 \n",
      "image[3][423] = 0.000000 \n",
      "image[3][424] = 0.000000 \n",
      "image[3][425] = 0.000000 \n",
      "image[3][426] = 0.000000 \n",
      "image[3][427] = 0.000000 \n",
      "image[3][428] = 0.000000 \n",
      "image[3][429] = 0.000000 \n",
      "image[3][430] = 0.000000 \n",
      "image[3][431] = 0.125490 \n",
      "image[3][432] = 0.992157 \n",
      "image[3][433] = 0.992157 \n",
      "image[3][434] = 0.992157 \n",
      "image[3][435] = 0.623529 \n",
      "image[3][436] = 0.000000 \n",
      "image[3][437] = 0.000000 \n",
      "image[3][438] = 0.000000 \n",
      "image[3][439] = 0.000000 \n",
      "image[3][440] = 0.000000 \n",
      "image[3][441] = 0.000000 \n",
      "image[3][442] = 0.000000 \n",
      "image[3][443] = 0.000000 \n",
      "image[3][444] = 0.000000 \n",
      "image[3][445] = 0.000000 \n",
      "image[3][446] = 0.000000 \n",
      "image[3][447] = 0.000000 \n",
      "image[3][448] = 0.000000 \n",
      "image[3][449] = 0.000000 \n",
      "image[3][450] = 0.000000 \n",
      "image[3][451] = 0.000000 \n",
      "image[3][452] = 0.000000 \n",
      "image[3][453] = 0.000000 \n",
      "image[3][454] = 0.000000 \n",
      "image[3][455] = 0.000000 \n",
      "image[3][456] = 0.000000 \n",
      "image[3][457] = 0.000000 \n",
      "image[3][458] = 0.000000 \n",
      "image[3][459] = 0.592157 \n",
      "image[3][460] = 0.984314 \n",
      "image[3][461] = 0.984314 \n",
      "image[3][462] = 0.984314 \n",
      "image[3][463] = 0.152941 \n",
      "image[3][464] = 0.000000 \n",
      "image[3][465] = 0.000000 \n",
      "image[3][466] = 0.000000 \n",
      "image[3][467] = 0.000000 \n",
      "image[3][468] = 0.000000 \n",
      "image[3][469] = 0.000000 \n",
      "image[3][470] = 0.000000 \n",
      "image[3][471] = 0.000000 \n",
      "image[3][472] = 0.000000 \n",
      "image[3][473] = 0.000000 \n",
      "image[3][474] = 0.000000 \n",
      "image[3][475] = 0.000000 \n",
      "image[3][476] = 0.000000 \n",
      "image[3][477] = 0.000000 \n",
      "image[3][478] = 0.000000 \n",
      "image[3][479] = 0.000000 \n",
      "image[3][480] = 0.000000 \n",
      "image[3][481] = 0.000000 \n",
      "image[3][482] = 0.000000 \n",
      "image[3][483] = 0.000000 \n",
      "image[3][484] = 0.000000 \n",
      "image[3][485] = 0.000000 \n",
      "image[3][486] = 0.188235 \n",
      "image[3][487] = 0.866667 \n",
      "image[3][488] = 0.984314 \n",
      "image[3][489] = 0.984314 \n",
      "image[3][490] = 0.674510 \n",
      "image[3][491] = 0.000000 \n",
      "image[3][492] = 0.000000 \n",
      "image[3][493] = 0.000000 \n",
      "image[3][494] = 0.000000 \n",
      "image[3][495] = 0.000000 \n",
      "image[3][496] = 0.000000 \n",
      "image[3][497] = 0.000000 \n",
      "image[3][498] = 0.000000 \n",
      "image[3][499] = 0.000000 \n",
      "image[3][500] = 0.000000 \n",
      "image[3][501] = 0.000000 \n",
      "image[3][502] = 0.000000 \n",
      "image[3][503] = 0.000000 \n",
      "image[3][504] = 0.000000 \n",
      "image[3][505] = 0.000000 \n",
      "image[3][506] = 0.000000 \n",
      "image[3][507] = 0.000000 \n",
      "image[3][508] = 0.000000 \n",
      "image[3][509] = 0.000000 \n",
      "image[3][510] = 0.000000 \n",
      "image[3][511] = 0.000000 \n",
      "image[3][512] = 0.000000 \n",
      "image[3][513] = 0.000000 \n",
      "image[3][514] = 0.917647 \n",
      "image[3][515] = 0.984314 \n",
      "image[3][516] = 0.984314 \n",
      "image[3][517] = 0.768627 \n",
      "image[3][518] = 0.047059 \n",
      "image[3][519] = 0.000000 \n",
      "image[3][520] = 0.000000 \n",
      "image[3][521] = 0.000000 \n",
      "image[3][522] = 0.000000 \n",
      "image[3][523] = 0.000000 \n",
      "image[3][524] = 0.000000 \n",
      "image[3][525] = 0.000000 \n",
      "image[3][526] = 0.000000 \n",
      "image[3][527] = 0.000000 \n",
      "image[3][528] = 0.000000 \n",
      "image[3][529] = 0.000000 \n",
      "image[3][530] = 0.000000 \n",
      "image[3][531] = 0.000000 \n",
      "image[3][532] = 0.000000 \n",
      "image[3][533] = 0.000000 \n",
      "image[3][534] = 0.000000 \n",
      "image[3][535] = 0.000000 \n",
      "image[3][536] = 0.000000 \n",
      "image[3][537] = 0.000000 \n",
      "image[3][538] = 0.000000 \n",
      "image[3][539] = 0.000000 \n",
      "image[3][540] = 0.000000 \n",
      "image[3][541] = 0.000000 \n",
      "image[3][542] = 0.992157 \n",
      "image[3][543] = 0.984314 \n",
      "image[3][544] = 0.984314 \n",
      "image[3][545] = 0.349020 \n",
      "image[3][546] = 0.000000 \n",
      "image[3][547] = 0.000000 \n",
      "image[3][548] = 0.000000 \n",
      "image[3][549] = 0.000000 \n",
      "image[3][550] = 0.000000 \n",
      "image[3][551] = 0.000000 \n",
      "image[3][552] = 0.000000 \n",
      "image[3][553] = 0.000000 \n",
      "image[3][554] = 0.000000 \n",
      "image[3][555] = 0.000000 \n",
      "image[3][556] = 0.000000 \n",
      "image[3][557] = 0.000000 \n",
      "image[3][558] = 0.000000 \n",
      "image[3][559] = 0.000000 \n",
      "image[3][560] = 0.000000 \n",
      "image[3][561] = 0.000000 \n",
      "image[3][562] = 0.000000 \n",
      "image[3][563] = 0.000000 \n",
      "image[3][564] = 0.000000 \n",
      "image[3][565] = 0.000000 \n",
      "image[3][566] = 0.000000 \n",
      "image[3][567] = 0.000000 \n",
      "image[3][568] = 0.000000 \n",
      "image[3][569] = 0.623529 \n",
      "image[3][570] = 1.000000 \n",
      "image[3][571] = 0.992157 \n",
      "image[3][572] = 0.992157 \n",
      "image[3][573] = 0.121569 \n",
      "image[3][574] = 0.000000 \n",
      "image[3][575] = 0.000000 \n",
      "image[3][576] = 0.000000 \n",
      "image[3][577] = 0.000000 \n",
      "image[3][578] = 0.000000 \n",
      "image[3][579] = 0.000000 \n",
      "image[3][580] = 0.000000 \n",
      "image[3][581] = 0.000000 \n",
      "image[3][582] = 0.000000 \n",
      "image[3][583] = 0.000000 \n",
      "image[3][584] = 0.000000 \n",
      "image[3][585] = 0.000000 \n",
      "image[3][586] = 0.000000 \n",
      "image[3][587] = 0.000000 \n",
      "image[3][588] = 0.000000 \n",
      "image[3][589] = 0.000000 \n",
      "image[3][590] = 0.000000 \n",
      "image[3][591] = 0.000000 \n",
      "image[3][592] = 0.000000 \n",
      "image[3][593] = 0.000000 \n",
      "image[3][594] = 0.000000 \n",
      "image[3][595] = 0.000000 \n",
      "image[3][596] = 0.188235 \n",
      "image[3][597] = 0.894118 \n",
      "image[3][598] = 0.992157 \n",
      "image[3][599] = 0.968627 \n",
      "image[3][600] = 0.549020 \n",
      "image[3][601] = 0.031373 \n",
      "image[3][602] = 0.000000 \n",
      "image[3][603] = 0.000000 \n",
      "image[3][604] = 0.000000 \n",
      "image[3][605] = 0.000000 \n",
      "image[3][606] = 0.000000 \n",
      "image[3][607] = 0.000000 \n",
      "image[3][608] = 0.000000 \n",
      "image[3][609] = 0.000000 \n",
      "image[3][610] = 0.000000 \n",
      "image[3][611] = 0.000000 \n",
      "image[3][612] = 0.000000 \n",
      "image[3][613] = 0.000000 \n",
      "image[3][614] = 0.000000 \n",
      "image[3][615] = 0.000000 \n",
      "image[3][616] = 0.000000 \n",
      "image[3][617] = 0.000000 \n",
      "image[3][618] = 0.000000 \n",
      "image[3][619] = 0.000000 \n",
      "image[3][620] = 0.000000 \n",
      "image[3][621] = 0.000000 \n",
      "image[3][622] = 0.000000 \n",
      "image[3][623] = 0.000000 \n",
      "image[3][624] = 0.250980 \n",
      "image[3][625] = 0.984314 \n",
      "image[3][626] = 0.992157 \n",
      "image[3][627] = 0.862745 \n",
      "image[3][628] = 0.000000 \n",
      "image[3][629] = 0.000000 \n",
      "image[3][630] = 0.000000 \n",
      "image[3][631] = 0.000000 \n",
      "image[3][632] = 0.000000 \n",
      "image[3][633] = 0.000000 \n",
      "image[3][634] = 0.000000 \n",
      "image[3][635] = 0.000000 \n",
      "image[3][636] = 0.000000 \n",
      "image[3][637] = 0.000000 \n",
      "image[3][638] = 0.000000 \n",
      "image[3][639] = 0.000000 \n",
      "image[3][640] = 0.000000 \n",
      "image[3][641] = 0.000000 \n",
      "image[3][642] = 0.000000 \n",
      "image[3][643] = 0.000000 \n",
      "image[3][644] = 0.000000 \n",
      "image[3][645] = 0.000000 \n",
      "image[3][646] = 0.000000 \n",
      "image[3][647] = 0.000000 \n",
      "image[3][648] = 0.000000 \n",
      "image[3][649] = 0.000000 \n",
      "image[3][650] = 0.000000 \n",
      "image[3][651] = 0.000000 \n",
      "image[3][652] = 0.250980 \n",
      "image[3][653] = 0.984314 \n",
      "image[3][654] = 0.992157 \n",
      "image[3][655] = 0.862745 \n",
      "image[3][656] = 0.000000 \n",
      "image[3][657] = 0.000000 \n",
      "image[3][658] = 0.000000 \n",
      "image[3][659] = 0.000000 \n",
      "image[3][660] = 0.000000 \n",
      "image[3][661] = 0.000000 \n",
      "image[3][662] = 0.000000 \n",
      "image[3][663] = 0.000000 \n",
      "image[3][664] = 0.000000 \n",
      "image[3][665] = 0.000000 \n",
      "image[3][666] = 0.000000 \n",
      "image[3][667] = 0.000000 \n",
      "image[3][668] = 0.000000 \n",
      "image[3][669] = 0.000000 \n",
      "image[3][670] = 0.000000 \n",
      "image[3][671] = 0.000000 \n",
      "image[3][672] = 0.000000 \n",
      "image[3][673] = 0.000000 \n",
      "image[3][674] = 0.000000 \n",
      "image[3][675] = 0.000000 \n",
      "image[3][676] = 0.000000 \n",
      "image[3][677] = 0.000000 \n",
      "image[3][678] = 0.000000 \n",
      "image[3][679] = 0.000000 \n",
      "image[3][680] = 0.094118 \n",
      "image[3][681] = 0.756863 \n",
      "image[3][682] = 0.992157 \n",
      "image[3][683] = 0.862745 \n",
      "image[3][684] = 0.000000 \n",
      "image[3][685] = 0.000000 \n",
      "image[3][686] = 0.000000 \n",
      "image[3][687] = 0.000000 \n",
      "image[3][688] = 0.000000 \n",
      "image[3][689] = 0.000000 \n",
      "image[3][690] = 0.000000 \n",
      "image[3][691] = 0.000000 \n",
      "image[3][692] = 0.000000 \n",
      "image[3][693] = 0.000000 \n",
      "image[3][694] = 0.000000 \n",
      "image[3][695] = 0.000000 \n",
      "image[3][696] = 0.000000 \n",
      "image[3][697] = 0.000000 \n",
      "image[3][698] = 0.000000 \n",
      "image[3][699] = 0.000000 \n",
      "image[3][700] = 0.000000 \n",
      "image[3][701] = 0.000000 \n",
      "image[3][702] = 0.000000 \n",
      "image[3][703] = 0.000000 \n",
      "image[3][704] = 0.000000 \n",
      "image[3][705] = 0.000000 \n",
      "image[3][706] = 0.000000 \n",
      "image[3][707] = 0.000000 \n",
      "image[3][708] = 0.000000 \n",
      "image[3][709] = 0.000000 \n",
      "image[3][710] = 0.000000 \n",
      "image[3][711] = 0.000000 \n",
      "image[3][712] = 0.000000 \n",
      "image[3][713] = 0.000000 \n",
      "image[3][714] = 0.000000 \n",
      "image[3][715] = 0.000000 \n",
      "image[3][716] = 0.000000 \n",
      "image[3][717] = 0.000000 \n",
      "image[3][718] = 0.000000 \n",
      "image[3][719] = 0.000000 \n",
      "image[3][720] = 0.000000 \n",
      "image[3][721] = 0.000000 \n",
      "image[3][722] = 0.000000 \n",
      "image[3][723] = 0.000000 \n",
      "image[3][724] = 0.000000 \n",
      "image[3][725] = 0.000000 \n",
      "image[3][726] = 0.000000 \n",
      "image[3][727] = 0.000000 \n",
      "image[3][728] = 0.000000 \n",
      "image[3][729] = 0.000000 \n",
      "image[3][730] = 0.000000 \n",
      "image[3][731] = 0.000000 \n",
      "image[3][732] = 0.000000 \n",
      "image[3][733] = 0.000000 \n",
      "image[3][734] = 0.000000 \n",
      "image[3][735] = 0.000000 \n",
      "image[3][736] = 0.000000 \n",
      "image[3][737] = 0.000000 \n",
      "image[3][738] = 0.000000 \n",
      "image[3][739] = 0.000000 \n",
      "image[3][740] = 0.000000 \n",
      "image[3][741] = 0.000000 \n",
      "image[3][742] = 0.000000 \n",
      "image[3][743] = 0.000000 \n",
      "image[3][744] = 0.000000 \n",
      "image[3][745] = 0.000000 \n",
      "image[3][746] = 0.000000 \n",
      "image[3][747] = 0.000000 \n",
      "image[3][748] = 0.000000 \n",
      "image[3][749] = 0.000000 \n",
      "image[3][750] = 0.000000 \n",
      "image[3][751] = 0.000000 \n",
      "image[3][752] = 0.000000 \n",
      "image[3][753] = 0.000000 \n",
      "image[3][754] = 0.000000 \n",
      "image[3][755] = 0.000000 \n",
      "image[3][756] = 0.000000 \n",
      "image[3][757] = 0.000000 \n",
      "image[3][758] = 0.000000 \n",
      "image[3][759] = 0.000000 \n",
      "image[3][760] = 0.000000 \n",
      "image[3][761] = 0.000000 \n",
      "image[3][762] = 0.000000 \n",
      "image[3][763] = 0.000000 \n",
      "image[3][764] = 0.000000 \n",
      "image[3][765] = 0.000000 \n",
      "image[3][766] = 0.000000 \n",
      "image[3][767] = 0.000000 \n",
      "image[3][768] = 0.000000 \n",
      "image[3][769] = 0.000000 \n",
      "image[3][770] = 0.000000 \n",
      "image[3][771] = 0.000000 \n",
      "image[3][772] = 0.000000 \n",
      "image[3][773] = 0.000000 \n",
      "image[3][774] = 0.000000 \n",
      "image[3][775] = 0.000000 \n",
      "image[3][776] = 0.000000 \n",
      "image[3][777] = 0.000000 \n",
      "image[3][778] = 0.000000 \n",
      "image[3][779] = 0.000000 \n",
      "image[3][780] = 0.000000 \n",
      "image[3][781] = 0.000000 \n",
      "image[3][782] = 0.000000 \n",
      "image[3][783] = 0.000000 \n",
      "image[4][0] = 0.000000 \n",
      "image[4][1] = 0.000000 \n",
      "image[4][2] = 0.000000 \n",
      "image[4][3] = 0.000000 \n",
      "image[4][4] = 0.000000 \n",
      "image[4][5] = 0.000000 \n",
      "image[4][6] = 0.000000 \n",
      "image[4][7] = 0.000000 \n",
      "image[4][8] = 0.000000 \n",
      "image[4][9] = 0.000000 \n",
      "image[4][10] = 0.000000 \n",
      "image[4][11] = 0.000000 \n",
      "image[4][12] = 0.000000 \n",
      "image[4][13] = 0.000000 \n",
      "image[4][14] = 0.000000 \n",
      "image[4][15] = 0.000000 \n",
      "image[4][16] = 0.000000 \n",
      "image[4][17] = 0.000000 \n",
      "image[4][18] = 0.000000 \n",
      "image[4][19] = 0.000000 \n",
      "image[4][20] = 0.000000 \n",
      "image[4][21] = 0.000000 \n",
      "image[4][22] = 0.000000 \n",
      "image[4][23] = 0.000000 \n",
      "image[4][24] = 0.000000 \n",
      "image[4][25] = 0.000000 \n",
      "image[4][26] = 0.000000 \n",
      "image[4][27] = 0.000000 \n",
      "image[4][28] = 0.000000 \n",
      "image[4][29] = 0.000000 \n",
      "image[4][30] = 0.000000 \n",
      "image[4][31] = 0.000000 \n",
      "image[4][32] = 0.000000 \n",
      "image[4][33] = 0.000000 \n",
      "image[4][34] = 0.000000 \n",
      "image[4][35] = 0.000000 \n",
      "image[4][36] = 0.000000 \n",
      "image[4][37] = 0.000000 \n",
      "image[4][38] = 0.000000 \n",
      "image[4][39] = 0.000000 \n",
      "image[4][40] = 0.000000 \n",
      "image[4][41] = 0.000000 \n",
      "image[4][42] = 0.000000 \n",
      "image[4][43] = 0.000000 \n",
      "image[4][44] = 0.000000 \n",
      "image[4][45] = 0.000000 \n",
      "image[4][46] = 0.000000 \n",
      "image[4][47] = 0.000000 \n",
      "image[4][48] = 0.000000 \n",
      "image[4][49] = 0.000000 \n",
      "image[4][50] = 0.000000 \n",
      "image[4][51] = 0.000000 \n",
      "image[4][52] = 0.000000 \n",
      "image[4][53] = 0.000000 \n",
      "image[4][54] = 0.000000 \n",
      "image[4][55] = 0.000000 \n",
      "image[4][56] = 0.000000 \n",
      "image[4][57] = 0.000000 \n",
      "image[4][58] = 0.000000 \n",
      "image[4][59] = 0.000000 \n",
      "image[4][60] = 0.000000 \n",
      "image[4][61] = 0.000000 \n",
      "image[4][62] = 0.000000 \n",
      "image[4][63] = 0.000000 \n",
      "image[4][64] = 0.000000 \n",
      "image[4][65] = 0.000000 \n",
      "image[4][66] = 0.000000 \n",
      "image[4][67] = 0.000000 \n",
      "image[4][68] = 0.000000 \n",
      "image[4][69] = 0.000000 \n",
      "image[4][70] = 0.000000 \n",
      "image[4][71] = 0.000000 \n",
      "image[4][72] = 0.000000 \n",
      "image[4][73] = 0.000000 \n",
      "image[4][74] = 0.000000 \n",
      "image[4][75] = 0.000000 \n",
      "image[4][76] = 0.000000 \n",
      "image[4][77] = 0.000000 \n",
      "image[4][78] = 0.000000 \n",
      "image[4][79] = 0.000000 \n",
      "image[4][80] = 0.000000 \n",
      "image[4][81] = 0.000000 \n",
      "image[4][82] = 0.000000 \n",
      "image[4][83] = 0.000000 \n",
      "image[4][84] = 0.000000 \n",
      "image[4][85] = 0.000000 \n",
      "image[4][86] = 0.000000 \n",
      "image[4][87] = 0.000000 \n",
      "image[4][88] = 0.000000 \n",
      "image[4][89] = 0.000000 \n",
      "image[4][90] = 0.000000 \n",
      "image[4][91] = 0.000000 \n",
      "image[4][92] = 0.000000 \n",
      "image[4][93] = 0.000000 \n",
      "image[4][94] = 0.000000 \n",
      "image[4][95] = 0.000000 \n",
      "image[4][96] = 0.000000 \n",
      "image[4][97] = 0.000000 \n",
      "image[4][98] = 0.000000 \n",
      "image[4][99] = 0.000000 \n",
      "image[4][100] = 0.000000 \n",
      "image[4][101] = 0.000000 \n",
      "image[4][102] = 0.000000 \n",
      "image[4][103] = 0.000000 \n",
      "image[4][104] = 0.000000 \n",
      "image[4][105] = 0.000000 \n",
      "image[4][106] = 0.000000 \n",
      "image[4][107] = 0.000000 \n",
      "image[4][108] = 0.000000 \n",
      "image[4][109] = 0.000000 \n",
      "image[4][110] = 0.000000 \n",
      "image[4][111] = 0.000000 \n",
      "image[4][112] = 0.000000 \n",
      "image[4][113] = 0.000000 \n",
      "image[4][114] = 0.000000 \n",
      "image[4][115] = 0.000000 \n",
      "image[4][116] = 0.000000 \n",
      "image[4][117] = 0.000000 \n",
      "image[4][118] = 0.000000 \n",
      "image[4][119] = 0.000000 \n",
      "image[4][120] = 0.000000 \n",
      "image[4][121] = 0.000000 \n",
      "image[4][122] = 0.000000 \n",
      "image[4][123] = 0.000000 \n",
      "image[4][124] = 0.000000 \n",
      "image[4][125] = 0.000000 \n",
      "image[4][126] = 0.000000 \n",
      "image[4][127] = 0.000000 \n",
      "image[4][128] = 0.000000 \n",
      "image[4][129] = 0.000000 \n",
      "image[4][130] = 0.000000 \n",
      "image[4][131] = 0.000000 \n",
      "image[4][132] = 0.000000 \n",
      "image[4][133] = 0.000000 \n",
      "image[4][134] = 0.000000 \n",
      "image[4][135] = 0.000000 \n",
      "image[4][136] = 0.000000 \n",
      "image[4][137] = 0.000000 \n",
      "image[4][138] = 0.000000 \n",
      "image[4][139] = 0.000000 \n",
      "image[4][140] = 0.000000 \n",
      "image[4][141] = 0.000000 \n",
      "image[4][142] = 0.000000 \n",
      "image[4][143] = 0.000000 \n",
      "image[4][144] = 0.000000 \n",
      "image[4][145] = 0.000000 \n",
      "image[4][146] = 0.000000 \n",
      "image[4][147] = 0.000000 \n",
      "image[4][148] = 0.000000 \n",
      "image[4][149] = 0.000000 \n",
      "image[4][150] = 0.000000 \n",
      "image[4][151] = 0.000000 \n",
      "image[4][152] = 0.000000 \n",
      "image[4][153] = 0.000000 \n",
      "image[4][154] = 0.000000 \n",
      "image[4][155] = 0.000000 \n",
      "image[4][156] = 0.000000 \n",
      "image[4][157] = 0.000000 \n",
      "image[4][158] = 0.000000 \n",
      "image[4][159] = 0.000000 \n",
      "image[4][160] = 0.000000 \n",
      "image[4][161] = 0.000000 \n",
      "image[4][162] = 0.000000 \n",
      "image[4][163] = 0.000000 \n",
      "image[4][164] = 0.000000 \n",
      "image[4][165] = 0.000000 \n",
      "image[4][166] = 0.000000 \n",
      "image[4][167] = 0.000000 \n",
      "image[4][168] = 0.000000 \n",
      "image[4][169] = 0.000000 \n",
      "image[4][170] = 0.000000 \n",
      "image[4][171] = 0.000000 \n",
      "image[4][172] = 0.000000 \n",
      "image[4][173] = 0.000000 \n",
      "image[4][174] = 0.000000 \n",
      "image[4][175] = 0.000000 \n",
      "image[4][176] = 0.000000 \n",
      "image[4][177] = 0.000000 \n",
      "image[4][178] = 0.000000 \n",
      "image[4][179] = 0.000000 \n",
      "image[4][180] = 0.000000 \n",
      "image[4][181] = 0.000000 \n",
      "image[4][182] = 0.000000 \n",
      "image[4][183] = 0.000000 \n",
      "image[4][184] = 0.000000 \n",
      "image[4][185] = 0.000000 \n",
      "image[4][186] = 0.000000 \n",
      "image[4][187] = 0.000000 \n",
      "image[4][188] = 0.000000 \n",
      "image[4][189] = 0.000000 \n",
      "image[4][190] = 0.000000 \n",
      "image[4][191] = 0.000000 \n",
      "image[4][192] = 0.000000 \n",
      "image[4][193] = 0.000000 \n",
      "image[4][194] = 0.000000 \n",
      "image[4][195] = 0.000000 \n",
      "image[4][196] = 0.000000 \n",
      "image[4][197] = 0.000000 \n",
      "image[4][198] = 0.000000 \n",
      "image[4][199] = 0.000000 \n",
      "image[4][200] = 0.000000 \n",
      "image[4][201] = 0.000000 \n",
      "image[4][202] = 0.000000 \n",
      "image[4][203] = 0.000000 \n",
      "image[4][204] = 0.000000 \n",
      "image[4][205] = 0.000000 \n",
      "image[4][206] = 0.000000 \n",
      "image[4][207] = 0.000000 \n",
      "image[4][208] = 0.215686 \n",
      "image[4][209] = 0.580392 \n",
      "image[4][210] = 0.823529 \n",
      "image[4][211] = 0.992157 \n",
      "image[4][212] = 0.992157 \n",
      "image[4][213] = 0.443137 \n",
      "image[4][214] = 0.341176 \n",
      "image[4][215] = 0.580392 \n",
      "image[4][216] = 0.215686 \n",
      "image[4][217] = 0.000000 \n",
      "image[4][218] = 0.000000 \n",
      "image[4][219] = 0.000000 \n",
      "image[4][220] = 0.000000 \n",
      "image[4][221] = 0.000000 \n",
      "image[4][222] = 0.000000 \n",
      "image[4][223] = 0.000000 \n",
      "image[4][224] = 0.000000 \n",
      "image[4][225] = 0.000000 \n",
      "image[4][226] = 0.000000 \n",
      "image[4][227] = 0.000000 \n",
      "image[4][228] = 0.000000 \n",
      "image[4][229] = 0.000000 \n",
      "image[4][230] = 0.000000 \n",
      "image[4][231] = 0.000000 \n",
      "image[4][232] = 0.000000 \n",
      "image[4][233] = 0.000000 \n",
      "image[4][234] = 0.000000 \n",
      "image[4][235] = 0.341176 \n",
      "image[4][236] = 0.909804 \n",
      "image[4][237] = 0.988235 \n",
      "image[4][238] = 0.992157 \n",
      "image[4][239] = 0.741176 \n",
      "image[4][240] = 0.823529 \n",
      "image[4][241] = 0.988235 \n",
      "image[4][242] = 0.988235 \n",
      "image[4][243] = 0.992157 \n",
      "image[4][244] = 0.658824 \n",
      "image[4][245] = 0.000000 \n",
      "image[4][246] = 0.000000 \n",
      "image[4][247] = 0.000000 \n",
      "image[4][248] = 0.000000 \n",
      "image[4][249] = 0.000000 \n",
      "image[4][250] = 0.000000 \n",
      "image[4][251] = 0.000000 \n",
      "image[4][252] = 0.000000 \n",
      "image[4][253] = 0.000000 \n",
      "image[4][254] = 0.000000 \n",
      "image[4][255] = 0.000000 \n",
      "image[4][256] = 0.000000 \n",
      "image[4][257] = 0.000000 \n",
      "image[4][258] = 0.000000 \n",
      "image[4][259] = 0.000000 \n",
      "image[4][260] = 0.000000 \n",
      "image[4][261] = 0.015686 \n",
      "image[4][262] = 0.223529 \n",
      "image[4][263] = 0.949020 \n",
      "image[4][264] = 0.988235 \n",
      "image[4][265] = 0.745098 \n",
      "image[4][266] = 0.254902 \n",
      "image[4][267] = 0.019608 \n",
      "image[4][268] = 0.047059 \n",
      "image[4][269] = 0.713726 \n",
      "image[4][270] = 0.988235 \n",
      "image[4][271] = 0.992157 \n",
      "image[4][272] = 0.454902 \n",
      "image[4][273] = 0.000000 \n",
      "image[4][274] = 0.000000 \n",
      "image[4][275] = 0.000000 \n",
      "image[4][276] = 0.000000 \n",
      "image[4][277] = 0.000000 \n",
      "image[4][278] = 0.000000 \n",
      "image[4][279] = 0.000000 \n",
      "image[4][280] = 0.000000 \n",
      "image[4][281] = 0.000000 \n",
      "image[4][282] = 0.000000 \n",
      "image[4][283] = 0.000000 \n",
      "image[4][284] = 0.000000 \n",
      "image[4][285] = 0.000000 \n",
      "image[4][286] = 0.000000 \n",
      "image[4][287] = 0.000000 \n",
      "image[4][288] = 0.000000 \n",
      "image[4][289] = 0.376471 \n",
      "image[4][290] = 0.988235 \n",
      "image[4][291] = 0.988235 \n",
      "image[4][292] = 0.717647 \n",
      "image[4][293] = 0.054902 \n",
      "image[4][294] = 0.000000 \n",
      "image[4][295] = 0.000000 \n",
      "image[4][296] = 0.360784 \n",
      "image[4][297] = 0.988235 \n",
      "image[4][298] = 0.988235 \n",
      "image[4][299] = 0.882353 \n",
      "image[4][300] = 0.082353 \n",
      "image[4][301] = 0.000000 \n",
      "image[4][302] = 0.000000 \n",
      "image[4][303] = 0.000000 \n",
      "image[4][304] = 0.000000 \n",
      "image[4][305] = 0.000000 \n",
      "image[4][306] = 0.000000 \n",
      "image[4][307] = 0.000000 \n",
      "image[4][308] = 0.000000 \n",
      "image[4][309] = 0.000000 \n",
      "image[4][310] = 0.000000 \n",
      "image[4][311] = 0.000000 \n",
      "image[4][312] = 0.000000 \n",
      "image[4][313] = 0.000000 \n",
      "image[4][314] = 0.000000 \n",
      "image[4][315] = 0.000000 \n",
      "image[4][316] = 0.517647 \n",
      "image[4][317] = 0.992157 \n",
      "image[4][318] = 0.988235 \n",
      "image[4][319] = 0.572549 \n",
      "image[4][320] = 0.054902 \n",
      "image[4][321] = 0.000000 \n",
      "image[4][322] = 0.000000 \n",
      "image[4][323] = 0.000000 \n",
      "image[4][324] = 0.843137 \n",
      "image[4][325] = 0.988235 \n",
      "image[4][326] = 0.988235 \n",
      "image[4][327] = 0.309804 \n",
      "image[4][328] = 0.000000 \n",
      "image[4][329] = 0.000000 \n",
      "image[4][330] = 0.000000 \n",
      "image[4][331] = 0.000000 \n",
      "image[4][332] = 0.000000 \n",
      "image[4][333] = 0.000000 \n",
      "image[4][334] = 0.000000 \n",
      "image[4][335] = 0.000000 \n",
      "image[4][336] = 0.000000 \n",
      "image[4][337] = 0.000000 \n",
      "image[4][338] = 0.000000 \n",
      "image[4][339] = 0.000000 \n",
      "image[4][340] = 0.000000 \n",
      "image[4][341] = 0.000000 \n",
      "image[4][342] = 0.000000 \n",
      "image[4][343] = 0.494118 \n",
      "image[4][344] = 0.992157 \n",
      "image[4][345] = 0.968627 \n",
      "image[4][346] = 0.690196 \n",
      "image[4][347] = 0.035294 \n",
      "image[4][348] = 0.000000 \n",
      "image[4][349] = 0.000000 \n",
      "image[4][350] = 0.031373 \n",
      "image[4][351] = 0.305882 \n",
      "image[4][352] = 0.960784 \n",
      "image[4][353] = 0.992157 \n",
      "image[4][354] = 0.505882 \n",
      "image[4][355] = 0.000000 \n",
      "image[4][356] = 0.000000 \n",
      "image[4][357] = 0.000000 \n",
      "image[4][358] = 0.000000 \n",
      "image[4][359] = 0.000000 \n",
      "image[4][360] = 0.000000 \n",
      "image[4][361] = 0.000000 \n",
      "image[4][362] = 0.000000 \n",
      "image[4][363] = 0.000000 \n",
      "image[4][364] = 0.000000 \n",
      "image[4][365] = 0.000000 \n",
      "image[4][366] = 0.000000 \n",
      "image[4][367] = 0.000000 \n",
      "image[4][368] = 0.000000 \n",
      "image[4][369] = 0.000000 \n",
      "image[4][370] = 0.062745 \n",
      "image[4][371] = 0.909804 \n",
      "image[4][372] = 0.988235 \n",
      "image[4][373] = 0.690196 \n",
      "image[4][374] = 0.000000 \n",
      "image[4][375] = 0.000000 \n",
      "image[4][376] = 0.000000 \n",
      "image[4][377] = 0.141176 \n",
      "image[4][378] = 0.788235 \n",
      "image[4][379] = 0.988235 \n",
      "image[4][380] = 0.988235 \n",
      "image[4][381] = 0.662745 \n",
      "image[4][382] = 0.043137 \n",
      "image[4][383] = 0.000000 \n",
      "image[4][384] = 0.000000 \n",
      "image[4][385] = 0.000000 \n",
      "image[4][386] = 0.000000 \n",
      "image[4][387] = 0.000000 \n",
      "image[4][388] = 0.000000 \n",
      "image[4][389] = 0.000000 \n",
      "image[4][390] = 0.000000 \n",
      "image[4][391] = 0.000000 \n",
      "image[4][392] = 0.000000 \n",
      "image[4][393] = 0.000000 \n",
      "image[4][394] = 0.000000 \n",
      "image[4][395] = 0.000000 \n",
      "image[4][396] = 0.000000 \n",
      "image[4][397] = 0.000000 \n",
      "image[4][398] = 0.086275 \n",
      "image[4][399] = 0.988235 \n",
      "image[4][400] = 0.988235 \n",
      "image[4][401] = 0.117647 \n",
      "image[4][402] = 0.086275 \n",
      "image[4][403] = 0.466667 \n",
      "image[4][404] = 0.772549 \n",
      "image[4][405] = 0.945098 \n",
      "image[4][406] = 0.992157 \n",
      "image[4][407] = 0.988235 \n",
      "image[4][408] = 0.984314 \n",
      "image[4][409] = 0.301961 \n",
      "image[4][410] = 0.000000 \n",
      "image[4][411] = 0.000000 \n",
      "image[4][412] = 0.000000 \n",
      "image[4][413] = 0.000000 \n",
      "image[4][414] = 0.000000 \n",
      "image[4][415] = 0.000000 \n",
      "image[4][416] = 0.000000 \n",
      "image[4][417] = 0.000000 \n",
      "image[4][418] = 0.000000 \n",
      "image[4][419] = 0.000000 \n",
      "image[4][420] = 0.000000 \n",
      "image[4][421] = 0.000000 \n",
      "image[4][422] = 0.000000 \n",
      "image[4][423] = 0.000000 \n",
      "image[4][424] = 0.000000 \n",
      "image[4][425] = 0.000000 \n",
      "image[4][426] = 0.062745 \n",
      "image[4][427] = 0.905882 \n",
      "image[4][428] = 0.988235 \n",
      "image[4][429] = 0.992157 \n",
      "image[4][430] = 0.988235 \n",
      "image[4][431] = 0.988235 \n",
      "image[4][432] = 0.988235 \n",
      "image[4][433] = 0.886275 \n",
      "image[4][434] = 0.890196 \n",
      "image[4][435] = 0.988235 \n",
      "image[4][436] = 0.905882 \n",
      "image[4][437] = 0.000000 \n",
      "image[4][438] = 0.000000 \n",
      "image[4][439] = 0.000000 \n",
      "image[4][440] = 0.000000 \n",
      "image[4][441] = 0.000000 \n",
      "image[4][442] = 0.000000 \n",
      "image[4][443] = 0.000000 \n",
      "image[4][444] = 0.000000 \n",
      "image[4][445] = 0.000000 \n",
      "image[4][446] = 0.000000 \n",
      "image[4][447] = 0.000000 \n",
      "image[4][448] = 0.000000 \n",
      "image[4][449] = 0.000000 \n",
      "image[4][450] = 0.000000 \n",
      "image[4][451] = 0.000000 \n",
      "image[4][452] = 0.000000 \n",
      "image[4][453] = 0.000000 \n",
      "image[4][454] = 0.000000 \n",
      "image[4][455] = 0.215686 \n",
      "image[4][456] = 0.921569 \n",
      "image[4][457] = 0.992157 \n",
      "image[4][458] = 0.850980 \n",
      "image[4][459] = 0.541176 \n",
      "image[4][460] = 0.164706 \n",
      "image[4][461] = 0.094118 \n",
      "image[4][462] = 0.752941 \n",
      "image[4][463] = 0.988235 \n",
      "image[4][464] = 0.560784 \n",
      "image[4][465] = 0.000000 \n",
      "image[4][466] = 0.000000 \n",
      "image[4][467] = 0.000000 \n",
      "image[4][468] = 0.000000 \n",
      "image[4][469] = 0.000000 \n",
      "image[4][470] = 0.000000 \n",
      "image[4][471] = 0.000000 \n",
      "image[4][472] = 0.000000 \n",
      "image[4][473] = 0.000000 \n",
      "image[4][474] = 0.000000 \n",
      "image[4][475] = 0.000000 \n",
      "image[4][476] = 0.000000 \n",
      "image[4][477] = 0.000000 \n",
      "image[4][478] = 0.000000 \n",
      "image[4][479] = 0.000000 \n",
      "image[4][480] = 0.000000 \n",
      "image[4][481] = 0.000000 \n",
      "image[4][482] = 0.000000 \n",
      "image[4][483] = 0.000000 \n",
      "image[4][484] = 0.000000 \n",
      "image[4][485] = 0.000000 \n",
      "image[4][486] = 0.000000 \n",
      "image[4][487] = 0.000000 \n",
      "image[4][488] = 0.000000 \n",
      "image[4][489] = 0.243137 \n",
      "image[4][490] = 1.000000 \n",
      "image[4][491] = 0.992157 \n",
      "image[4][492] = 0.427451 \n",
      "image[4][493] = 0.000000 \n",
      "image[4][494] = 0.000000 \n",
      "image[4][495] = 0.000000 \n",
      "image[4][496] = 0.000000 \n",
      "image[4][497] = 0.000000 \n",
      "image[4][498] = 0.000000 \n",
      "image[4][499] = 0.000000 \n",
      "image[4][500] = 0.000000 \n",
      "image[4][501] = 0.000000 \n",
      "image[4][502] = 0.000000 \n",
      "image[4][503] = 0.000000 \n",
      "image[4][504] = 0.000000 \n",
      "image[4][505] = 0.000000 \n",
      "image[4][506] = 0.000000 \n",
      "image[4][507] = 0.000000 \n",
      "image[4][508] = 0.000000 \n",
      "image[4][509] = 0.000000 \n",
      "image[4][510] = 0.000000 \n",
      "image[4][511] = 0.000000 \n",
      "image[4][512] = 0.000000 \n",
      "image[4][513] = 0.000000 \n",
      "image[4][514] = 0.000000 \n",
      "image[4][515] = 0.000000 \n",
      "image[4][516] = 0.000000 \n",
      "image[4][517] = 0.278431 \n",
      "image[4][518] = 0.992157 \n",
      "image[4][519] = 0.988235 \n",
      "image[4][520] = 0.082353 \n",
      "image[4][521] = 0.000000 \n",
      "image[4][522] = 0.000000 \n",
      "image[4][523] = 0.000000 \n",
      "image[4][524] = 0.000000 \n",
      "image[4][525] = 0.000000 \n",
      "image[4][526] = 0.000000 \n",
      "image[4][527] = 0.000000 \n",
      "image[4][528] = 0.000000 \n",
      "image[4][529] = 0.000000 \n",
      "image[4][530] = 0.000000 \n",
      "image[4][531] = 0.000000 \n",
      "image[4][532] = 0.000000 \n",
      "image[4][533] = 0.000000 \n",
      "image[4][534] = 0.000000 \n",
      "image[4][535] = 0.000000 \n",
      "image[4][536] = 0.000000 \n",
      "image[4][537] = 0.000000 \n",
      "image[4][538] = 0.000000 \n",
      "image[4][539] = 0.000000 \n",
      "image[4][540] = 0.000000 \n",
      "image[4][541] = 0.000000 \n",
      "image[4][542] = 0.000000 \n",
      "image[4][543] = 0.000000 \n",
      "image[4][544] = 0.000000 \n",
      "image[4][545] = 0.000000 \n",
      "image[4][546] = 0.992157 \n",
      "image[4][547] = 0.988235 \n",
      "image[4][548] = 0.082353 \n",
      "image[4][549] = 0.000000 \n",
      "image[4][550] = 0.000000 \n",
      "image[4][551] = 0.000000 \n",
      "image[4][552] = 0.000000 \n",
      "image[4][553] = 0.000000 \n",
      "image[4][554] = 0.000000 \n",
      "image[4][555] = 0.000000 \n",
      "image[4][556] = 0.000000 \n",
      "image[4][557] = 0.000000 \n",
      "image[4][558] = 0.000000 \n",
      "image[4][559] = 0.000000 \n",
      "image[4][560] = 0.000000 \n",
      "image[4][561] = 0.000000 \n",
      "image[4][562] = 0.000000 \n",
      "image[4][563] = 0.000000 \n",
      "image[4][564] = 0.000000 \n",
      "image[4][565] = 0.000000 \n",
      "image[4][566] = 0.000000 \n",
      "image[4][567] = 0.000000 \n",
      "image[4][568] = 0.000000 \n",
      "image[4][569] = 0.000000 \n",
      "image[4][570] = 0.000000 \n",
      "image[4][571] = 0.000000 \n",
      "image[4][572] = 0.000000 \n",
      "image[4][573] = 0.278431 \n",
      "image[4][574] = 0.992157 \n",
      "image[4][575] = 0.988235 \n",
      "image[4][576] = 0.082353 \n",
      "image[4][577] = 0.000000 \n",
      "image[4][578] = 0.000000 \n",
      "image[4][579] = 0.000000 \n",
      "image[4][580] = 0.000000 \n",
      "image[4][581] = 0.000000 \n",
      "image[4][582] = 0.000000 \n",
      "image[4][583] = 0.000000 \n",
      "image[4][584] = 0.000000 \n",
      "image[4][585] = 0.000000 \n",
      "image[4][586] = 0.000000 \n",
      "image[4][587] = 0.000000 \n",
      "image[4][588] = 0.000000 \n",
      "image[4][589] = 0.000000 \n",
      "image[4][590] = 0.000000 \n",
      "image[4][591] = 0.000000 \n",
      "image[4][592] = 0.000000 \n",
      "image[4][593] = 0.000000 \n",
      "image[4][594] = 0.000000 \n",
      "image[4][595] = 0.000000 \n",
      "image[4][596] = 0.000000 \n",
      "image[4][597] = 0.000000 \n",
      "image[4][598] = 0.000000 \n",
      "image[4][599] = 0.000000 \n",
      "image[4][600] = 0.000000 \n",
      "image[4][601] = 0.415686 \n",
      "image[4][602] = 0.992157 \n",
      "image[4][603] = 0.988235 \n",
      "image[4][604] = 0.082353 \n",
      "image[4][605] = 0.000000 \n",
      "image[4][606] = 0.000000 \n",
      "image[4][607] = 0.000000 \n",
      "image[4][608] = 0.000000 \n",
      "image[4][609] = 0.000000 \n",
      "image[4][610] = 0.000000 \n",
      "image[4][611] = 0.000000 \n",
      "image[4][612] = 0.000000 \n",
      "image[4][613] = 0.000000 \n",
      "image[4][614] = 0.000000 \n",
      "image[4][615] = 0.000000 \n",
      "image[4][616] = 0.000000 \n",
      "image[4][617] = 0.000000 \n",
      "image[4][618] = 0.000000 \n",
      "image[4][619] = 0.000000 \n",
      "image[4][620] = 0.000000 \n",
      "image[4][621] = 0.000000 \n",
      "image[4][622] = 0.000000 \n",
      "image[4][623] = 0.000000 \n",
      "image[4][624] = 0.000000 \n",
      "image[4][625] = 0.000000 \n",
      "image[4][626] = 0.000000 \n",
      "image[4][627] = 0.000000 \n",
      "image[4][628] = 0.000000 \n",
      "image[4][629] = 0.176471 \n",
      "image[4][630] = 1.000000 \n",
      "image[4][631] = 0.992157 \n",
      "image[4][632] = 0.082353 \n",
      "image[4][633] = 0.000000 \n",
      "image[4][634] = 0.000000 \n",
      "image[4][635] = 0.000000 \n",
      "image[4][636] = 0.000000 \n",
      "image[4][637] = 0.000000 \n",
      "image[4][638] = 0.000000 \n",
      "image[4][639] = 0.000000 \n",
      "image[4][640] = 0.000000 \n",
      "image[4][641] = 0.000000 \n",
      "image[4][642] = 0.000000 \n",
      "image[4][643] = 0.000000 \n",
      "image[4][644] = 0.000000 \n",
      "image[4][645] = 0.000000 \n",
      "image[4][646] = 0.000000 \n",
      "image[4][647] = 0.000000 \n",
      "image[4][648] = 0.000000 \n",
      "image[4][649] = 0.000000 \n",
      "image[4][650] = 0.000000 \n",
      "image[4][651] = 0.000000 \n",
      "image[4][652] = 0.000000 \n",
      "image[4][653] = 0.000000 \n",
      "image[4][654] = 0.000000 \n",
      "image[4][655] = 0.000000 \n",
      "image[4][656] = 0.000000 \n",
      "image[4][657] = 0.000000 \n",
      "image[4][658] = 0.854902 \n",
      "image[4][659] = 0.988235 \n",
      "image[4][660] = 0.219608 \n",
      "image[4][661] = 0.000000 \n",
      "image[4][662] = 0.000000 \n",
      "image[4][663] = 0.000000 \n",
      "image[4][664] = 0.000000 \n",
      "image[4][665] = 0.000000 \n",
      "image[4][666] = 0.000000 \n",
      "image[4][667] = 0.000000 \n",
      "image[4][668] = 0.000000 \n",
      "image[4][669] = 0.000000 \n",
      "image[4][670] = 0.000000 \n",
      "image[4][671] = 0.000000 \n",
      "image[4][672] = 0.000000 \n",
      "image[4][673] = 0.000000 \n",
      "image[4][674] = 0.000000 \n",
      "image[4][675] = 0.000000 \n",
      "image[4][676] = 0.000000 \n",
      "image[4][677] = 0.000000 \n",
      "image[4][678] = 0.000000 \n",
      "image[4][679] = 0.000000 \n",
      "image[4][680] = 0.000000 \n",
      "image[4][681] = 0.000000 \n",
      "image[4][682] = 0.000000 \n",
      "image[4][683] = 0.000000 \n",
      "image[4][684] = 0.000000 \n",
      "image[4][685] = 0.000000 \n",
      "image[4][686] = 0.376471 \n",
      "image[4][687] = 0.988235 \n",
      "image[4][688] = 0.741176 \n",
      "image[4][689] = 0.164706 \n",
      "image[4][690] = 0.000000 \n",
      "image[4][691] = 0.000000 \n",
      "image[4][692] = 0.000000 \n",
      "image[4][693] = 0.000000 \n",
      "image[4][694] = 0.000000 \n",
      "image[4][695] = 0.000000 \n",
      "image[4][696] = 0.000000 \n",
      "image[4][697] = 0.000000 \n",
      "image[4][698] = 0.000000 \n",
      "image[4][699] = 0.000000 \n",
      "image[4][700] = 0.000000 \n",
      "image[4][701] = 0.000000 \n",
      "image[4][702] = 0.000000 \n",
      "image[4][703] = 0.000000 \n",
      "image[4][704] = 0.000000 \n",
      "image[4][705] = 0.000000 \n",
      "image[4][706] = 0.000000 \n",
      "image[4][707] = 0.000000 \n",
      "image[4][708] = 0.000000 \n",
      "image[4][709] = 0.000000 \n",
      "image[4][710] = 0.000000 \n",
      "image[4][711] = 0.000000 \n",
      "image[4][712] = 0.000000 \n",
      "image[4][713] = 0.000000 \n",
      "image[4][714] = 0.054902 \n",
      "image[4][715] = 0.721569 \n",
      "image[4][716] = 0.988235 \n",
      "image[4][717] = 0.666667 \n",
      "image[4][718] = 0.043137 \n",
      "image[4][719] = 0.000000 \n",
      "image[4][720] = 0.000000 \n",
      "image[4][721] = 0.000000 \n",
      "image[4][722] = 0.000000 \n",
      "image[4][723] = 0.000000 \n",
      "image[4][724] = 0.000000 \n",
      "image[4][725] = 0.000000 \n",
      "image[4][726] = 0.000000 \n",
      "image[4][727] = 0.000000 \n",
      "image[4][728] = 0.000000 \n",
      "image[4][729] = 0.000000 \n",
      "image[4][730] = 0.000000 \n",
      "image[4][731] = 0.000000 \n",
      "image[4][732] = 0.000000 \n",
      "image[4][733] = 0.000000 \n",
      "image[4][734] = 0.000000 \n",
      "image[4][735] = 0.000000 \n",
      "image[4][736] = 0.000000 \n",
      "image[4][737] = 0.000000 \n",
      "image[4][738] = 0.000000 \n",
      "image[4][739] = 0.000000 \n",
      "image[4][740] = 0.000000 \n",
      "image[4][741] = 0.000000 \n",
      "image[4][742] = 0.000000 \n",
      "image[4][743] = 0.054902 \n",
      "image[4][744] = 0.576471 \n",
      "image[4][745] = 0.988235 \n",
      "image[4][746] = 0.164706 \n",
      "image[4][747] = 0.000000 \n",
      "image[4][748] = 0.000000 \n",
      "image[4][749] = 0.000000 \n",
      "image[4][750] = 0.000000 \n",
      "image[4][751] = 0.000000 \n",
      "image[4][752] = 0.000000 \n",
      "image[4][753] = 0.000000 \n",
      "image[4][754] = 0.000000 \n",
      "image[4][755] = 0.000000 \n",
      "image[4][756] = 0.000000 \n",
      "image[4][757] = 0.000000 \n",
      "image[4][758] = 0.000000 \n",
      "image[4][759] = 0.000000 \n",
      "image[4][760] = 0.000000 \n",
      "image[4][761] = 0.000000 \n",
      "image[4][762] = 0.000000 \n",
      "image[4][763] = 0.000000 \n",
      "image[4][764] = 0.000000 \n",
      "image[4][765] = 0.000000 \n",
      "image[4][766] = 0.000000 \n",
      "image[4][767] = 0.000000 \n",
      "image[4][768] = 0.000000 \n",
      "image[4][769] = 0.000000 \n",
      "image[4][770] = 0.000000 \n",
      "image[4][771] = 0.000000 \n",
      "image[4][772] = 0.000000 \n",
      "image[4][773] = 0.000000 \n",
      "image[4][774] = 0.000000 \n",
      "image[4][775] = 0.000000 \n",
      "image[4][776] = 0.000000 \n",
      "image[4][777] = 0.000000 \n",
      "image[4][778] = 0.000000 \n",
      "image[4][779] = 0.000000 \n",
      "image[4][780] = 0.000000 \n",
      "image[4][781] = 0.000000 \n",
      "image[4][782] = 0.000000 \n",
      "image[4][783] = 0.000000 \n",
      "image[5][0] = 0.000000 \n",
      "image[5][1] = 0.000000 \n",
      "image[5][2] = 0.000000 \n",
      "image[5][3] = 0.000000 \n",
      "image[5][4] = 0.000000 \n",
      "image[5][5] = 0.000000 \n",
      "image[5][6] = 0.000000 \n",
      "image[5][7] = 0.000000 \n",
      "image[5][8] = 0.000000 \n",
      "image[5][9] = 0.000000 \n",
      "image[5][10] = 0.000000 \n",
      "image[5][11] = 0.000000 \n",
      "image[5][12] = 0.000000 \n",
      "image[5][13] = 0.000000 \n",
      "image[5][14] = 0.000000 \n",
      "image[5][15] = 0.000000 \n",
      "image[5][16] = 0.000000 \n",
      "image[5][17] = 0.000000 \n",
      "image[5][18] = 0.000000 \n",
      "image[5][19] = 0.000000 \n",
      "image[5][20] = 0.000000 \n",
      "image[5][21] = 0.000000 \n",
      "image[5][22] = 0.000000 \n",
      "image[5][23] = 0.000000 \n",
      "image[5][24] = 0.000000 \n",
      "image[5][25] = 0.000000 \n",
      "image[5][26] = 0.000000 \n",
      "image[5][27] = 0.000000 \n",
      "image[5][28] = 0.000000 \n",
      "image[5][29] = 0.000000 \n",
      "image[5][30] = 0.000000 \n",
      "image[5][31] = 0.000000 \n",
      "image[5][32] = 0.000000 \n",
      "image[5][33] = 0.000000 \n",
      "image[5][34] = 0.000000 \n",
      "image[5][35] = 0.000000 \n",
      "image[5][36] = 0.000000 \n",
      "image[5][37] = 0.000000 \n",
      "image[5][38] = 0.000000 \n",
      "image[5][39] = 0.000000 \n",
      "image[5][40] = 0.000000 \n",
      "image[5][41] = 0.000000 \n",
      "image[5][42] = 0.000000 \n",
      "image[5][43] = 0.000000 \n",
      "image[5][44] = 0.000000 \n",
      "image[5][45] = 0.000000 \n",
      "image[5][46] = 0.000000 \n",
      "image[5][47] = 0.000000 \n",
      "image[5][48] = 0.000000 \n",
      "image[5][49] = 0.000000 \n",
      "image[5][50] = 0.000000 \n",
      "image[5][51] = 0.000000 \n",
      "image[5][52] = 0.000000 \n",
      "image[5][53] = 0.000000 \n",
      "image[5][54] = 0.000000 \n",
      "image[5][55] = 0.000000 \n",
      "image[5][56] = 0.000000 \n",
      "image[5][57] = 0.000000 \n",
      "image[5][58] = 0.000000 \n",
      "image[5][59] = 0.000000 \n",
      "image[5][60] = 0.000000 \n",
      "image[5][61] = 0.000000 \n",
      "image[5][62] = 0.000000 \n",
      "image[5][63] = 0.000000 \n",
      "image[5][64] = 0.000000 \n",
      "image[5][65] = 0.000000 \n",
      "image[5][66] = 0.000000 \n",
      "image[5][67] = 0.000000 \n",
      "image[5][68] = 0.000000 \n",
      "image[5][69] = 0.000000 \n",
      "image[5][70] = 0.000000 \n",
      "image[5][71] = 0.000000 \n",
      "image[5][72] = 0.000000 \n",
      "image[5][73] = 0.000000 \n",
      "image[5][74] = 0.000000 \n",
      "image[5][75] = 0.000000 \n",
      "image[5][76] = 0.000000 \n",
      "image[5][77] = 0.000000 \n",
      "image[5][78] = 0.000000 \n",
      "image[5][79] = 0.000000 \n",
      "image[5][80] = 0.000000 \n",
      "image[5][81] = 0.000000 \n",
      "image[5][82] = 0.000000 \n",
      "image[5][83] = 0.000000 \n",
      "image[5][84] = 0.000000 \n",
      "image[5][85] = 0.000000 \n",
      "image[5][86] = 0.000000 \n",
      "image[5][87] = 0.000000 \n",
      "image[5][88] = 0.000000 \n",
      "image[5][89] = 0.000000 \n",
      "image[5][90] = 0.000000 \n",
      "image[5][91] = 0.000000 \n",
      "image[5][92] = 0.000000 \n",
      "image[5][93] = 0.000000 \n",
      "image[5][94] = 0.000000 \n",
      "image[5][95] = 0.000000 \n",
      "image[5][96] = 0.000000 \n",
      "image[5][97] = 0.000000 \n",
      "image[5][98] = 0.000000 \n",
      "image[5][99] = 0.000000 \n",
      "image[5][100] = 0.000000 \n",
      "image[5][101] = 0.000000 \n",
      "image[5][102] = 0.000000 \n",
      "image[5][103] = 0.000000 \n",
      "image[5][104] = 0.000000 \n",
      "image[5][105] = 0.000000 \n",
      "image[5][106] = 0.000000 \n",
      "image[5][107] = 0.000000 \n",
      "image[5][108] = 0.000000 \n",
      "image[5][109] = 0.000000 \n",
      "image[5][110] = 0.000000 \n",
      "image[5][111] = 0.000000 \n",
      "image[5][112] = 0.000000 \n",
      "image[5][113] = 0.000000 \n",
      "image[5][114] = 0.000000 \n",
      "image[5][115] = 0.000000 \n",
      "image[5][116] = 0.000000 \n",
      "image[5][117] = 0.000000 \n",
      "image[5][118] = 0.000000 \n",
      "image[5][119] = 0.000000 \n",
      "image[5][120] = 0.000000 \n",
      "image[5][121] = 0.000000 \n",
      "image[5][122] = 0.000000 \n",
      "image[5][123] = 0.000000 \n",
      "image[5][124] = 0.000000 \n",
      "image[5][125] = 0.000000 \n",
      "image[5][126] = 0.000000 \n",
      "image[5][127] = 0.000000 \n",
      "image[5][128] = 0.000000 \n",
      "image[5][129] = 0.000000 \n",
      "image[5][130] = 0.000000 \n",
      "image[5][131] = 0.000000 \n",
      "image[5][132] = 0.000000 \n",
      "image[5][133] = 0.000000 \n",
      "image[5][134] = 0.000000 \n",
      "image[5][135] = 0.000000 \n",
      "image[5][136] = 0.000000 \n",
      "image[5][137] = 0.000000 \n",
      "image[5][138] = 0.000000 \n",
      "image[5][139] = 0.000000 \n",
      "image[5][140] = 0.000000 \n",
      "image[5][141] = 0.000000 \n",
      "image[5][142] = 0.000000 \n",
      "image[5][143] = 0.000000 \n",
      "image[5][144] = 0.000000 \n",
      "image[5][145] = 0.000000 \n",
      "image[5][146] = 0.000000 \n",
      "image[5][147] = 0.000000 \n",
      "image[5][148] = 0.000000 \n",
      "image[5][149] = 0.000000 \n",
      "image[5][150] = 0.000000 \n",
      "image[5][151] = 0.000000 \n",
      "image[5][152] = 0.000000 \n",
      "image[5][153] = 0.000000 \n",
      "image[5][154] = 0.000000 \n",
      "image[5][155] = 0.050980 \n",
      "image[5][156] = 0.098039 \n",
      "image[5][157] = 0.392157 \n",
      "image[5][158] = 0.478431 \n",
      "image[5][159] = 0.027451 \n",
      "image[5][160] = 0.000000 \n",
      "image[5][161] = 0.000000 \n",
      "image[5][162] = 0.000000 \n",
      "image[5][163] = 0.000000 \n",
      "image[5][164] = 0.000000 \n",
      "image[5][165] = 0.000000 \n",
      "image[5][166] = 0.000000 \n",
      "image[5][167] = 0.000000 \n",
      "image[5][168] = 0.000000 \n",
      "image[5][169] = 0.000000 \n",
      "image[5][170] = 0.000000 \n",
      "image[5][171] = 0.000000 \n",
      "image[5][172] = 0.000000 \n",
      "image[5][173] = 0.000000 \n",
      "image[5][174] = 0.000000 \n",
      "image[5][175] = 0.000000 \n",
      "image[5][176] = 0.000000 \n",
      "image[5][177] = 0.000000 \n",
      "image[5][178] = 0.000000 \n",
      "image[5][179] = 0.000000 \n",
      "image[5][180] = 0.000000 \n",
      "image[5][181] = 0.129412 \n",
      "image[5][182] = 0.592157 \n",
      "image[5][183] = 0.815686 \n",
      "image[5][184] = 0.988235 \n",
      "image[5][185] = 0.988235 \n",
      "image[5][186] = 0.988235 \n",
      "image[5][187] = 0.572549 \n",
      "image[5][188] = 0.000000 \n",
      "image[5][189] = 0.000000 \n",
      "image[5][190] = 0.000000 \n",
      "image[5][191] = 0.000000 \n",
      "image[5][192] = 0.000000 \n",
      "image[5][193] = 0.000000 \n",
      "image[5][194] = 0.000000 \n",
      "image[5][195] = 0.000000 \n",
      "image[5][196] = 0.000000 \n",
      "image[5][197] = 0.000000 \n",
      "image[5][198] = 0.000000 \n",
      "image[5][199] = 0.000000 \n",
      "image[5][200] = 0.000000 \n",
      "image[5][201] = 0.000000 \n",
      "image[5][202] = 0.000000 \n",
      "image[5][203] = 0.000000 \n",
      "image[5][204] = 0.000000 \n",
      "image[5][205] = 0.000000 \n",
      "image[5][206] = 0.000000 \n",
      "image[5][207] = 0.156863 \n",
      "image[5][208] = 0.596078 \n",
      "image[5][209] = 0.956863 \n",
      "image[5][210] = 0.988235 \n",
      "image[5][211] = 0.992157 \n",
      "image[5][212] = 0.878431 \n",
      "image[5][213] = 0.827451 \n",
      "image[5][214] = 0.988235 \n",
      "image[5][215] = 0.909804 \n",
      "image[5][216] = 0.156863 \n",
      "image[5][217] = 0.000000 \n",
      "image[5][218] = 0.000000 \n",
      "image[5][219] = 0.000000 \n",
      "image[5][220] = 0.000000 \n",
      "image[5][221] = 0.000000 \n",
      "image[5][222] = 0.000000 \n",
      "image[5][223] = 0.000000 \n",
      "image[5][224] = 0.000000 \n",
      "image[5][225] = 0.000000 \n",
      "image[5][226] = 0.000000 \n",
      "image[5][227] = 0.000000 \n",
      "image[5][228] = 0.000000 \n",
      "image[5][229] = 0.000000 \n",
      "image[5][230] = 0.000000 \n",
      "image[5][231] = 0.000000 \n",
      "image[5][232] = 0.000000 \n",
      "image[5][233] = 0.058824 \n",
      "image[5][234] = 0.596078 \n",
      "image[5][235] = 0.937255 \n",
      "image[5][236] = 0.988235 \n",
      "image[5][237] = 0.988235 \n",
      "image[5][238] = 0.988235 \n",
      "image[5][239] = 0.847059 \n",
      "image[5][240] = 0.121569 \n",
      "image[5][241] = 0.145098 \n",
      "image[5][242] = 0.988235 \n",
      "image[5][243] = 0.988235 \n",
      "image[5][244] = 0.235294 \n",
      "image[5][245] = 0.000000 \n",
      "image[5][246] = 0.000000 \n",
      "image[5][247] = 0.000000 \n",
      "image[5][248] = 0.000000 \n",
      "image[5][249] = 0.000000 \n",
      "image[5][250] = 0.000000 \n",
      "image[5][251] = 0.000000 \n",
      "image[5][252] = 0.000000 \n",
      "image[5][253] = 0.000000 \n",
      "image[5][254] = 0.000000 \n",
      "image[5][255] = 0.000000 \n",
      "image[5][256] = 0.000000 \n",
      "image[5][257] = 0.000000 \n",
      "image[5][258] = 0.000000 \n",
      "image[5][259] = 0.000000 \n",
      "image[5][260] = 0.000000 \n",
      "image[5][261] = 0.376471 \n",
      "image[5][262] = 0.988235 \n",
      "image[5][263] = 0.988235 \n",
      "image[5][264] = 0.988235 \n",
      "image[5][265] = 0.988235 \n",
      "image[5][266] = 0.850980 \n",
      "image[5][267] = 0.113725 \n",
      "image[5][268] = 0.000000 \n",
      "image[5][269] = 0.145098 \n",
      "image[5][270] = 0.988235 \n",
      "image[5][271] = 0.988235 \n",
      "image[5][272] = 0.235294 \n",
      "image[5][273] = 0.000000 \n",
      "image[5][274] = 0.000000 \n",
      "image[5][275] = 0.000000 \n",
      "image[5][276] = 0.000000 \n",
      "image[5][277] = 0.000000 \n",
      "image[5][278] = 0.000000 \n",
      "image[5][279] = 0.000000 \n",
      "image[5][280] = 0.000000 \n",
      "image[5][281] = 0.000000 \n",
      "image[5][282] = 0.000000 \n",
      "image[5][283] = 0.000000 \n",
      "image[5][284] = 0.000000 \n",
      "image[5][285] = 0.000000 \n",
      "image[5][286] = 0.000000 \n",
      "image[5][287] = 0.000000 \n",
      "image[5][288] = 0.000000 \n",
      "image[5][289] = 0.709804 \n",
      "image[5][290] = 0.988235 \n",
      "image[5][291] = 0.988235 \n",
      "image[5][292] = 0.862745 \n",
      "image[5][293] = 0.654902 \n",
      "image[5][294] = 0.117647 \n",
      "image[5][295] = 0.000000 \n",
      "image[5][296] = 0.000000 \n",
      "image[5][297] = 0.301961 \n",
      "image[5][298] = 0.988235 \n",
      "image[5][299] = 0.988235 \n",
      "image[5][300] = 0.235294 \n",
      "image[5][301] = 0.000000 \n",
      "image[5][302] = 0.000000 \n",
      "image[5][303] = 0.000000 \n",
      "image[5][304] = 0.000000 \n",
      "image[5][305] = 0.000000 \n",
      "image[5][306] = 0.000000 \n",
      "image[5][307] = 0.000000 \n",
      "image[5][308] = 0.000000 \n",
      "image[5][309] = 0.000000 \n",
      "image[5][310] = 0.000000 \n",
      "image[5][311] = 0.000000 \n",
      "image[5][312] = 0.000000 \n",
      "image[5][313] = 0.000000 \n",
      "image[5][314] = 0.000000 \n",
      "image[5][315] = 0.000000 \n",
      "image[5][316] = 0.000000 \n",
      "image[5][317] = 0.101961 \n",
      "image[5][318] = 0.501961 \n",
      "image[5][319] = 0.227451 \n",
      "image[5][320] = 0.086275 \n",
      "image[5][321] = 0.000000 \n",
      "image[5][322] = 0.000000 \n",
      "image[5][323] = 0.000000 \n",
      "image[5][324] = 0.000000 \n",
      "image[5][325] = 0.392157 \n",
      "image[5][326] = 0.988235 \n",
      "image[5][327] = 0.988235 \n",
      "image[5][328] = 0.235294 \n",
      "image[5][329] = 0.000000 \n",
      "image[5][330] = 0.000000 \n",
      "image[5][331] = 0.000000 \n",
      "image[5][332] = 0.000000 \n",
      "image[5][333] = 0.000000 \n",
      "image[5][334] = 0.000000 \n",
      "image[5][335] = 0.000000 \n",
      "image[5][336] = 0.000000 \n",
      "image[5][337] = 0.000000 \n",
      "image[5][338] = 0.000000 \n",
      "image[5][339] = 0.000000 \n",
      "image[5][340] = 0.000000 \n",
      "image[5][341] = 0.000000 \n",
      "image[5][342] = 0.000000 \n",
      "image[5][343] = 0.000000 \n",
      "image[5][344] = 0.000000 \n",
      "image[5][345] = 0.000000 \n",
      "image[5][346] = 0.000000 \n",
      "image[5][347] = 0.000000 \n",
      "image[5][348] = 0.000000 \n",
      "image[5][349] = 0.000000 \n",
      "image[5][350] = 0.000000 \n",
      "image[5][351] = 0.000000 \n",
      "image[5][352] = 0.000000 \n",
      "image[5][353] = 0.615686 \n",
      "image[5][354] = 0.988235 \n",
      "image[5][355] = 0.988235 \n",
      "image[5][356] = 0.235294 \n",
      "image[5][357] = 0.000000 \n",
      "image[5][358] = 0.000000 \n",
      "image[5][359] = 0.000000 \n",
      "image[5][360] = 0.000000 \n",
      "image[5][361] = 0.000000 \n",
      "image[5][362] = 0.000000 \n",
      "image[5][363] = 0.000000 \n",
      "image[5][364] = 0.000000 \n",
      "image[5][365] = 0.000000 \n",
      "image[5][366] = 0.000000 \n",
      "image[5][367] = 0.000000 \n",
      "image[5][368] = 0.000000 \n",
      "image[5][369] = 0.000000 \n",
      "image[5][370] = 0.000000 \n",
      "image[5][371] = 0.000000 \n",
      "image[5][372] = 0.000000 \n",
      "image[5][373] = 0.000000 \n",
      "image[5][374] = 0.000000 \n",
      "image[5][375] = 0.000000 \n",
      "image[5][376] = 0.000000 \n",
      "image[5][377] = 0.431373 \n",
      "image[5][378] = 0.474510 \n",
      "image[5][379] = 0.478431 \n",
      "image[5][380] = 0.474510 \n",
      "image[5][381] = 0.792157 \n",
      "image[5][382] = 0.988235 \n",
      "image[5][383] = 0.760784 \n",
      "image[5][384] = 0.011765 \n",
      "image[5][385] = 0.000000 \n",
      "image[5][386] = 0.000000 \n",
      "image[5][387] = 0.000000 \n",
      "image[5][388] = 0.000000 \n",
      "image[5][389] = 0.000000 \n",
      "image[5][390] = 0.000000 \n",
      "image[5][391] = 0.000000 \n",
      "image[5][392] = 0.000000 \n",
      "image[5][393] = 0.000000 \n",
      "image[5][394] = 0.000000 \n",
      "image[5][395] = 0.000000 \n",
      "image[5][396] = 0.000000 \n",
      "image[5][397] = 0.000000 \n",
      "image[5][398] = 0.000000 \n",
      "image[5][399] = 0.000000 \n",
      "image[5][400] = 0.000000 \n",
      "image[5][401] = 0.000000 \n",
      "image[5][402] = 0.039216 \n",
      "image[5][403] = 0.207843 \n",
      "image[5][404] = 0.701961 \n",
      "image[5][405] = 0.992157 \n",
      "image[5][406] = 0.992157 \n",
      "image[5][407] = 1.000000 \n",
      "image[5][408] = 0.992157 \n",
      "image[5][409] = 0.992157 \n",
      "image[5][410] = 0.894118 \n",
      "image[5][411] = 0.137255 \n",
      "image[5][412] = 0.000000 \n",
      "image[5][413] = 0.000000 \n",
      "image[5][414] = 0.000000 \n",
      "image[5][415] = 0.000000 \n",
      "image[5][416] = 0.000000 \n",
      "image[5][417] = 0.000000 \n",
      "image[5][418] = 0.000000 \n",
      "image[5][419] = 0.000000 \n",
      "image[5][420] = 0.000000 \n",
      "image[5][421] = 0.000000 \n",
      "image[5][422] = 0.000000 \n",
      "image[5][423] = 0.000000 \n",
      "image[5][424] = 0.000000 \n",
      "image[5][425] = 0.000000 \n",
      "image[5][426] = 0.000000 \n",
      "image[5][427] = 0.000000 \n",
      "image[5][428] = 0.019608 \n",
      "image[5][429] = 0.211765 \n",
      "image[5][430] = 0.890196 \n",
      "image[5][431] = 0.988235 \n",
      "image[5][432] = 0.952941 \n",
      "image[5][433] = 0.894118 \n",
      "image[5][434] = 0.666667 \n",
      "image[5][435] = 0.949020 \n",
      "image[5][436] = 0.988235 \n",
      "image[5][437] = 0.988235 \n",
      "image[5][438] = 0.905882 \n",
      "image[5][439] = 0.458824 \n",
      "image[5][440] = 0.023529 \n",
      "image[5][441] = 0.000000 \n",
      "image[5][442] = 0.000000 \n",
      "image[5][443] = 0.000000 \n",
      "image[5][444] = 0.000000 \n",
      "image[5][445] = 0.000000 \n",
      "image[5][446] = 0.000000 \n",
      "image[5][447] = 0.000000 \n",
      "image[5][448] = 0.000000 \n",
      "image[5][449] = 0.000000 \n",
      "image[5][450] = 0.000000 \n",
      "image[5][451] = 0.000000 \n",
      "image[5][452] = 0.000000 \n",
      "image[5][453] = 0.000000 \n",
      "image[5][454] = 0.000000 \n",
      "image[5][455] = 0.023529 \n",
      "image[5][456] = 0.305882 \n",
      "image[5][457] = 0.988235 \n",
      "image[5][458] = 0.988235 \n",
      "image[5][459] = 0.490196 \n",
      "image[5][460] = 0.231373 \n",
      "image[5][461] = 0.000000 \n",
      "image[5][462] = 0.070588 \n",
      "image[5][463] = 0.815686 \n",
      "image[5][464] = 0.988235 \n",
      "image[5][465] = 0.988235 \n",
      "image[5][466] = 0.988235 \n",
      "image[5][467] = 0.988235 \n",
      "image[5][468] = 0.341176 \n",
      "image[5][469] = 0.027451 \n",
      "image[5][470] = 0.000000 \n",
      "image[5][471] = 0.000000 \n",
      "image[5][472] = 0.000000 \n",
      "image[5][473] = 0.000000 \n",
      "image[5][474] = 0.000000 \n",
      "image[5][475] = 0.000000 \n",
      "image[5][476] = 0.000000 \n",
      "image[5][477] = 0.000000 \n",
      "image[5][478] = 0.000000 \n",
      "image[5][479] = 0.000000 \n",
      "image[5][480] = 0.000000 \n",
      "image[5][481] = 0.000000 \n",
      "image[5][482] = 0.019608 \n",
      "image[5][483] = 0.529412 \n",
      "image[5][484] = 0.988235 \n",
      "image[5][485] = 0.988235 \n",
      "image[5][486] = 0.705882 \n",
      "image[5][487] = 0.062745 \n",
      "image[5][488] = 0.000000 \n",
      "image[5][489] = 0.082353 \n",
      "image[5][490] = 0.796078 \n",
      "image[5][491] = 0.992157 \n",
      "image[5][492] = 0.968627 \n",
      "image[5][493] = 0.505882 \n",
      "image[5][494] = 0.678431 \n",
      "image[5][495] = 0.988235 \n",
      "image[5][496] = 0.988235 \n",
      "image[5][497] = 0.721569 \n",
      "image[5][498] = 0.258824 \n",
      "image[5][499] = 0.192157 \n",
      "image[5][500] = 0.192157 \n",
      "image[5][501] = 0.000000 \n",
      "image[5][502] = 0.000000 \n",
      "image[5][503] = 0.000000 \n",
      "image[5][504] = 0.000000 \n",
      "image[5][505] = 0.000000 \n",
      "image[5][506] = 0.000000 \n",
      "image[5][507] = 0.000000 \n",
      "image[5][508] = 0.000000 \n",
      "image[5][509] = 0.011765 \n",
      "image[5][510] = 0.533333 \n",
      "image[5][511] = 0.988235 \n",
      "image[5][512] = 0.945098 \n",
      "image[5][513] = 0.415686 \n",
      "image[5][514] = 0.066667 \n",
      "image[5][515] = 0.000000 \n",
      "image[5][516] = 0.207843 \n",
      "image[5][517] = 0.784314 \n",
      "image[5][518] = 0.988235 \n",
      "image[5][519] = 0.847059 \n",
      "image[5][520] = 0.254902 \n",
      "image[5][521] = 0.000000 \n",
      "image[5][522] = 0.054902 \n",
      "image[5][523] = 0.282353 \n",
      "image[5][524] = 0.639216 \n",
      "image[5][525] = 0.945098 \n",
      "image[5][526] = 0.988235 \n",
      "image[5][527] = 0.988235 \n",
      "image[5][528] = 0.874510 \n",
      "image[5][529] = 0.000000 \n",
      "image[5][530] = 0.000000 \n",
      "image[5][531] = 0.000000 \n",
      "image[5][532] = 0.000000 \n",
      "image[5][533] = 0.000000 \n",
      "image[5][534] = 0.000000 \n",
      "image[5][535] = 0.000000 \n",
      "image[5][536] = 0.000000 \n",
      "image[5][537] = 0.411765 \n",
      "image[5][538] = 0.988235 \n",
      "image[5][539] = 0.949020 \n",
      "image[5][540] = 0.345098 \n",
      "image[5][541] = 0.070588 \n",
      "image[5][542] = 0.286275 \n",
      "image[5][543] = 0.666667 \n",
      "image[5][544] = 0.956863 \n",
      "image[5][545] = 0.988235 \n",
      "image[5][546] = 0.494118 \n",
      "image[5][547] = 0.113725 \n",
      "image[5][548] = 0.000000 \n",
      "image[5][549] = 0.000000 \n",
      "image[5][550] = 0.000000 \n",
      "image[5][551] = 0.000000 \n",
      "image[5][552] = 0.000000 \n",
      "image[5][553] = 0.349020 \n",
      "image[5][554] = 0.705882 \n",
      "image[5][555] = 0.705882 \n",
      "image[5][556] = 0.145098 \n",
      "image[5][557] = 0.000000 \n",
      "image[5][558] = 0.000000 \n",
      "image[5][559] = 0.000000 \n",
      "image[5][560] = 0.000000 \n",
      "image[5][561] = 0.000000 \n",
      "image[5][562] = 0.000000 \n",
      "image[5][563] = 0.000000 \n",
      "image[5][564] = 0.000000 \n",
      "image[5][565] = 0.905882 \n",
      "image[5][566] = 0.988235 \n",
      "image[5][567] = 0.960784 \n",
      "image[5][568] = 0.803922 \n",
      "image[5][569] = 0.847059 \n",
      "image[5][570] = 0.988235 \n",
      "image[5][571] = 0.988235 \n",
      "image[5][572] = 0.988235 \n",
      "image[5][573] = 0.486275 \n",
      "image[5][574] = 0.011765 \n",
      "image[5][575] = 0.000000 \n",
      "image[5][576] = 0.000000 \n",
      "image[5][577] = 0.000000 \n",
      "image[5][578] = 0.000000 \n",
      "image[5][579] = 0.000000 \n",
      "image[5][580] = 0.000000 \n",
      "image[5][581] = 0.000000 \n",
      "image[5][582] = 0.000000 \n",
      "image[5][583] = 0.000000 \n",
      "image[5][584] = 0.000000 \n",
      "image[5][585] = 0.000000 \n",
      "image[5][586] = 0.000000 \n",
      "image[5][587] = 0.000000 \n",
      "image[5][588] = 0.000000 \n",
      "image[5][589] = 0.000000 \n",
      "image[5][590] = 0.000000 \n",
      "image[5][591] = 0.000000 \n",
      "image[5][592] = 0.000000 \n",
      "image[5][593] = 0.811765 \n",
      "image[5][594] = 0.988235 \n",
      "image[5][595] = 0.988235 \n",
      "image[5][596] = 0.988235 \n",
      "image[5][597] = 0.988235 \n",
      "image[5][598] = 0.698039 \n",
      "image[5][599] = 0.454902 \n",
      "image[5][600] = 0.141176 \n",
      "image[5][601] = 0.015686 \n",
      "image[5][602] = 0.000000 \n",
      "image[5][603] = 0.000000 \n",
      "image[5][604] = 0.000000 \n",
      "image[5][605] = 0.000000 \n",
      "image[5][606] = 0.000000 \n",
      "image[5][607] = 0.000000 \n",
      "image[5][608] = 0.000000 \n",
      "image[5][609] = 0.000000 \n",
      "image[5][610] = 0.000000 \n",
      "image[5][611] = 0.000000 \n",
      "image[5][612] = 0.000000 \n",
      "image[5][613] = 0.000000 \n",
      "image[5][614] = 0.000000 \n",
      "image[5][615] = 0.000000 \n",
      "image[5][616] = 0.000000 \n",
      "image[5][617] = 0.000000 \n",
      "image[5][618] = 0.000000 \n",
      "image[5][619] = 0.000000 \n",
      "image[5][620] = 0.000000 \n",
      "image[5][621] = 0.050980 \n",
      "image[5][622] = 0.364706 \n",
      "image[5][623] = 0.560784 \n",
      "image[5][624] = 0.474510 \n",
      "image[5][625] = 0.090196 \n",
      "image[5][626] = 0.023529 \n",
      "image[5][627] = 0.000000 \n",
      "image[5][628] = 0.000000 \n",
      "image[5][629] = 0.000000 \n",
      "image[5][630] = 0.000000 \n",
      "image[5][631] = 0.000000 \n",
      "image[5][632] = 0.000000 \n",
      "image[5][633] = 0.000000 \n",
      "image[5][634] = 0.000000 \n",
      "image[5][635] = 0.000000 \n",
      "image[5][636] = 0.000000 \n",
      "image[5][637] = 0.000000 \n",
      "image[5][638] = 0.000000 \n",
      "image[5][639] = 0.000000 \n",
      "image[5][640] = 0.000000 \n",
      "image[5][641] = 0.000000 \n",
      "image[5][642] = 0.000000 \n",
      "image[5][643] = 0.000000 \n",
      "image[5][644] = 0.000000 \n",
      "image[5][645] = 0.000000 \n",
      "image[5][646] = 0.000000 \n",
      "image[5][647] = 0.000000 \n",
      "image[5][648] = 0.000000 \n",
      "image[5][649] = 0.000000 \n",
      "image[5][650] = 0.000000 \n",
      "image[5][651] = 0.000000 \n",
      "image[5][652] = 0.000000 \n",
      "image[5][653] = 0.000000 \n",
      "image[5][654] = 0.000000 \n",
      "image[5][655] = 0.000000 \n",
      "image[5][656] = 0.000000 \n",
      "image[5][657] = 0.000000 \n",
      "image[5][658] = 0.000000 \n",
      "image[5][659] = 0.000000 \n",
      "image[5][660] = 0.000000 \n",
      "image[5][661] = 0.000000 \n",
      "image[5][662] = 0.000000 \n",
      "image[5][663] = 0.000000 \n",
      "image[5][664] = 0.000000 \n",
      "image[5][665] = 0.000000 \n",
      "image[5][666] = 0.000000 \n",
      "image[5][667] = 0.000000 \n",
      "image[5][668] = 0.000000 \n",
      "image[5][669] = 0.000000 \n",
      "image[5][670] = 0.000000 \n",
      "image[5][671] = 0.000000 \n",
      "image[5][672] = 0.000000 \n",
      "image[5][673] = 0.000000 \n",
      "image[5][674] = 0.000000 \n",
      "image[5][675] = 0.000000 \n",
      "image[5][676] = 0.000000 \n",
      "image[5][677] = 0.000000 \n",
      "image[5][678] = 0.000000 \n",
      "image[5][679] = 0.000000 \n",
      "image[5][680] = 0.000000 \n",
      "image[5][681] = 0.000000 \n",
      "image[5][682] = 0.000000 \n",
      "image[5][683] = 0.000000 \n",
      "image[5][684] = 0.000000 \n",
      "image[5][685] = 0.000000 \n",
      "image[5][686] = 0.000000 \n",
      "image[5][687] = 0.000000 \n",
      "image[5][688] = 0.000000 \n",
      "image[5][689] = 0.000000 \n",
      "image[5][690] = 0.000000 \n",
      "image[5][691] = 0.000000 \n",
      "image[5][692] = 0.000000 \n",
      "image[5][693] = 0.000000 \n",
      "image[5][694] = 0.000000 \n",
      "image[5][695] = 0.000000 \n",
      "image[5][696] = 0.000000 \n",
      "image[5][697] = 0.000000 \n",
      "image[5][698] = 0.000000 \n",
      "image[5][699] = 0.000000 \n",
      "image[5][700] = 0.000000 \n",
      "image[5][701] = 0.000000 \n",
      "image[5][702] = 0.000000 \n",
      "image[5][703] = 0.000000 \n",
      "image[5][704] = 0.000000 \n",
      "image[5][705] = 0.000000 \n",
      "image[5][706] = 0.000000 \n",
      "image[5][707] = 0.000000 \n",
      "image[5][708] = 0.000000 \n",
      "image[5][709] = 0.000000 \n",
      "image[5][710] = 0.000000 \n",
      "image[5][711] = 0.000000 \n",
      "image[5][712] = 0.000000 \n",
      "image[5][713] = 0.000000 \n",
      "image[5][714] = 0.000000 \n",
      "image[5][715] = 0.000000 \n",
      "image[5][716] = 0.000000 \n",
      "image[5][717] = 0.000000 \n",
      "image[5][718] = 0.000000 \n",
      "image[5][719] = 0.000000 \n",
      "image[5][720] = 0.000000 \n",
      "image[5][721] = 0.000000 \n",
      "image[5][722] = 0.000000 \n",
      "image[5][723] = 0.000000 \n",
      "image[5][724] = 0.000000 \n",
      "image[5][725] = 0.000000 \n",
      "image[5][726] = 0.000000 \n",
      "image[5][727] = 0.000000 \n",
      "image[5][728] = 0.000000 \n",
      "image[5][729] = 0.000000 \n",
      "image[5][730] = 0.000000 \n",
      "image[5][731] = 0.000000 \n",
      "image[5][732] = 0.000000 \n",
      "image[5][733] = 0.000000 \n",
      "image[5][734] = 0.000000 \n",
      "image[5][735] = 0.000000 \n",
      "image[5][736] = 0.000000 \n",
      "image[5][737] = 0.000000 \n",
      "image[5][738] = 0.000000 \n",
      "image[5][739] = 0.000000 \n",
      "image[5][740] = 0.000000 \n",
      "image[5][741] = 0.000000 \n",
      "image[5][742] = 0.000000 \n",
      "image[5][743] = 0.000000 \n",
      "image[5][744] = 0.000000 \n",
      "image[5][745] = 0.000000 \n",
      "image[5][746] = 0.000000 \n",
      "image[5][747] = 0.000000 \n",
      "image[5][748] = 0.000000 \n",
      "image[5][749] = 0.000000 \n",
      "image[5][750] = 0.000000 \n",
      "image[5][751] = 0.000000 \n",
      "image[5][752] = 0.000000 \n",
      "image[5][753] = 0.000000 \n",
      "image[5][754] = 0.000000 \n",
      "image[5][755] = 0.000000 \n",
      "image[5][756] = 0.000000 \n",
      "image[5][757] = 0.000000 \n",
      "image[5][758] = 0.000000 \n",
      "image[5][759] = 0.000000 \n",
      "image[5][760] = 0.000000 \n",
      "image[5][761] = 0.000000 \n",
      "image[5][762] = 0.000000 \n",
      "image[5][763] = 0.000000 \n",
      "image[5][764] = 0.000000 \n",
      "image[5][765] = 0.000000 \n",
      "image[5][766] = 0.000000 \n",
      "image[5][767] = 0.000000 \n",
      "image[5][768] = 0.000000 \n",
      "image[5][769] = 0.000000 \n",
      "image[5][770] = 0.000000 \n",
      "image[5][771] = 0.000000 \n",
      "image[5][772] = 0.000000 \n",
      "image[5][773] = 0.000000 \n",
      "image[5][774] = 0.000000 \n",
      "image[5][775] = 0.000000 \n",
      "image[5][776] = 0.000000 \n",
      "image[5][777] = 0.000000 \n",
      "image[5][778] = 0.000000 \n",
      "image[5][779] = 0.000000 \n",
      "image[5][780] = 0.000000 \n",
      "image[5][781] = 0.000000 \n",
      "image[5][782] = 0.000000 \n",
      "image[5][783] = 0.000000 \n",
      "image[6][0] = 0.000000 \n",
      "image[6][1] = 0.000000 \n",
      "image[6][2] = 0.000000 \n",
      "image[6][3] = 0.000000 \n",
      "image[6][4] = 0.000000 \n",
      "image[6][5] = 0.000000 \n",
      "image[6][6] = 0.000000 \n",
      "image[6][7] = 0.000000 \n",
      "image[6][8] = 0.000000 \n",
      "image[6][9] = 0.000000 \n",
      "image[6][10] = 0.000000 \n",
      "image[6][11] = 0.000000 \n",
      "image[6][12] = 0.000000 \n",
      "image[6][13] = 0.000000 \n",
      "image[6][14] = 0.000000 \n",
      "image[6][15] = 0.000000 \n",
      "image[6][16] = 0.000000 \n",
      "image[6][17] = 0.000000 \n",
      "image[6][18] = 0.000000 \n",
      "image[6][19] = 0.000000 \n",
      "image[6][20] = 0.000000 \n",
      "image[6][21] = 0.000000 \n",
      "image[6][22] = 0.000000 \n",
      "image[6][23] = 0.000000 \n",
      "image[6][24] = 0.000000 \n",
      "image[6][25] = 0.000000 \n",
      "image[6][26] = 0.000000 \n",
      "image[6][27] = 0.000000 \n",
      "image[6][28] = 0.000000 \n",
      "image[6][29] = 0.000000 \n",
      "image[6][30] = 0.000000 \n",
      "image[6][31] = 0.000000 \n",
      "image[6][32] = 0.000000 \n",
      "image[6][33] = 0.000000 \n",
      "image[6][34] = 0.000000 \n",
      "image[6][35] = 0.000000 \n",
      "image[6][36] = 0.000000 \n",
      "image[6][37] = 0.000000 \n",
      "image[6][38] = 0.000000 \n",
      "image[6][39] = 0.000000 \n",
      "image[6][40] = 0.000000 \n",
      "image[6][41] = 0.000000 \n",
      "image[6][42] = 0.000000 \n",
      "image[6][43] = 0.000000 \n",
      "image[6][44] = 0.000000 \n",
      "image[6][45] = 0.000000 \n",
      "image[6][46] = 0.000000 \n",
      "image[6][47] = 0.000000 \n",
      "image[6][48] = 0.000000 \n",
      "image[6][49] = 0.000000 \n",
      "image[6][50] = 0.000000 \n",
      "image[6][51] = 0.000000 \n",
      "image[6][52] = 0.000000 \n",
      "image[6][53] = 0.000000 \n",
      "image[6][54] = 0.000000 \n",
      "image[6][55] = 0.000000 \n",
      "image[6][56] = 0.000000 \n",
      "image[6][57] = 0.000000 \n",
      "image[6][58] = 0.000000 \n",
      "image[6][59] = 0.000000 \n",
      "image[6][60] = 0.000000 \n",
      "image[6][61] = 0.000000 \n",
      "image[6][62] = 0.000000 \n",
      "image[6][63] = 0.000000 \n",
      "image[6][64] = 0.000000 \n",
      "image[6][65] = 0.000000 \n",
      "image[6][66] = 0.000000 \n",
      "image[6][67] = 0.000000 \n",
      "image[6][68] = 0.000000 \n",
      "image[6][69] = 0.000000 \n",
      "image[6][70] = 0.000000 \n",
      "image[6][71] = 0.000000 \n",
      "image[6][72] = 0.000000 \n",
      "image[6][73] = 0.000000 \n",
      "image[6][74] = 0.000000 \n",
      "image[6][75] = 0.000000 \n",
      "image[6][76] = 0.000000 \n",
      "image[6][77] = 0.000000 \n",
      "image[6][78] = 0.000000 \n",
      "image[6][79] = 0.000000 \n",
      "image[6][80] = 0.000000 \n",
      "image[6][81] = 0.000000 \n",
      "image[6][82] = 0.000000 \n",
      "image[6][83] = 0.000000 \n",
      "image[6][84] = 0.000000 \n",
      "image[6][85] = 0.000000 \n",
      "image[6][86] = 0.000000 \n",
      "image[6][87] = 0.000000 \n",
      "image[6][88] = 0.000000 \n",
      "image[6][89] = 0.000000 \n",
      "image[6][90] = 0.000000 \n",
      "image[6][91] = 0.000000 \n",
      "image[6][92] = 0.000000 \n",
      "image[6][93] = 0.000000 \n",
      "image[6][94] = 0.000000 \n",
      "image[6][95] = 0.000000 \n",
      "image[6][96] = 0.000000 \n",
      "image[6][97] = 0.000000 \n",
      "image[6][98] = 0.000000 \n",
      "image[6][99] = 0.000000 \n",
      "image[6][100] = 0.000000 \n",
      "image[6][101] = 0.000000 \n",
      "image[6][102] = 0.000000 \n",
      "image[6][103] = 0.000000 \n",
      "image[6][104] = 0.000000 \n",
      "image[6][105] = 0.000000 \n",
      "image[6][106] = 0.000000 \n",
      "image[6][107] = 0.000000 \n",
      "image[6][108] = 0.000000 \n",
      "image[6][109] = 0.000000 \n",
      "image[6][110] = 0.000000 \n",
      "image[6][111] = 0.000000 \n",
      "image[6][112] = 0.000000 \n",
      "image[6][113] = 0.000000 \n",
      "image[6][114] = 0.000000 \n",
      "image[6][115] = 0.000000 \n",
      "image[6][116] = 0.000000 \n",
      "image[6][117] = 0.000000 \n",
      "image[6][118] = 0.000000 \n",
      "image[6][119] = 0.000000 \n",
      "image[6][120] = 0.000000 \n",
      "image[6][121] = 0.000000 \n",
      "image[6][122] = 0.000000 \n",
      "image[6][123] = 0.000000 \n",
      "image[6][124] = 0.568627 \n",
      "image[6][125] = 1.000000 \n",
      "image[6][126] = 0.827451 \n",
      "image[6][127] = 0.121569 \n",
      "image[6][128] = 0.000000 \n",
      "image[6][129] = 0.000000 \n",
      "image[6][130] = 0.000000 \n",
      "image[6][131] = 0.000000 \n",
      "image[6][132] = 0.000000 \n",
      "image[6][133] = 0.000000 \n",
      "image[6][134] = 0.000000 \n",
      "image[6][135] = 0.000000 \n",
      "image[6][136] = 0.000000 \n",
      "image[6][137] = 0.000000 \n",
      "image[6][138] = 0.000000 \n",
      "image[6][139] = 0.000000 \n",
      "image[6][140] = 0.000000 \n",
      "image[6][141] = 0.000000 \n",
      "image[6][142] = 0.000000 \n",
      "image[6][143] = 0.000000 \n",
      "image[6][144] = 0.000000 \n",
      "image[6][145] = 0.000000 \n",
      "image[6][146] = 0.000000 \n",
      "image[6][147] = 0.000000 \n",
      "image[6][148] = 0.000000 \n",
      "image[6][149] = 0.000000 \n",
      "image[6][150] = 0.000000 \n",
      "image[6][151] = 0.125490 \n",
      "image[6][152] = 0.929412 \n",
      "image[6][153] = 0.992157 \n",
      "image[6][154] = 0.988235 \n",
      "image[6][155] = 0.278431 \n",
      "image[6][156] = 0.000000 \n",
      "image[6][157] = 0.000000 \n",
      "image[6][158] = 0.000000 \n",
      "image[6][159] = 0.000000 \n",
      "image[6][160] = 0.000000 \n",
      "image[6][161] = 0.000000 \n",
      "image[6][162] = 0.000000 \n",
      "image[6][163] = 0.000000 \n",
      "image[6][164] = 0.000000 \n",
      "image[6][165] = 0.000000 \n",
      "image[6][166] = 0.000000 \n",
      "image[6][167] = 0.000000 \n",
      "image[6][168] = 0.000000 \n",
      "image[6][169] = 0.000000 \n",
      "image[6][170] = 0.000000 \n",
      "image[6][171] = 0.000000 \n",
      "image[6][172] = 0.000000 \n",
      "image[6][173] = 0.000000 \n",
      "image[6][174] = 0.000000 \n",
      "image[6][175] = 0.000000 \n",
      "image[6][176] = 0.000000 \n",
      "image[6][177] = 0.000000 \n",
      "image[6][178] = 0.000000 \n",
      "image[6][179] = 0.043137 \n",
      "image[6][180] = 0.686275 \n",
      "image[6][181] = 0.992157 \n",
      "image[6][182] = 0.988235 \n",
      "image[6][183] = 0.278431 \n",
      "image[6][184] = 0.000000 \n",
      "image[6][185] = 0.000000 \n",
      "image[6][186] = 0.000000 \n",
      "image[6][187] = 0.000000 \n",
      "image[6][188] = 0.000000 \n",
      "image[6][189] = 0.000000 \n",
      "image[6][190] = 0.000000 \n",
      "image[6][191] = 0.000000 \n",
      "image[6][192] = 0.000000 \n",
      "image[6][193] = 0.000000 \n",
      "image[6][194] = 0.000000 \n",
      "image[6][195] = 0.000000 \n",
      "image[6][196] = 0.000000 \n",
      "image[6][197] = 0.000000 \n",
      "image[6][198] = 0.000000 \n",
      "image[6][199] = 0.000000 \n",
      "image[6][200] = 0.000000 \n",
      "image[6][201] = 0.000000 \n",
      "image[6][202] = 0.000000 \n",
      "image[6][203] = 0.000000 \n",
      "image[6][204] = 0.000000 \n",
      "image[6][205] = 0.000000 \n",
      "image[6][206] = 0.000000 \n",
      "image[6][207] = 0.000000 \n",
      "image[6][208] = 0.564706 \n",
      "image[6][209] = 0.992157 \n",
      "image[6][210] = 0.988235 \n",
      "image[6][211] = 0.278431 \n",
      "image[6][212] = 0.000000 \n",
      "image[6][213] = 0.000000 \n",
      "image[6][214] = 0.000000 \n",
      "image[6][215] = 0.000000 \n",
      "image[6][216] = 0.000000 \n",
      "image[6][217] = 0.000000 \n",
      "image[6][218] = 0.000000 \n",
      "image[6][219] = 0.000000 \n",
      "image[6][220] = 0.000000 \n",
      "image[6][221] = 0.000000 \n",
      "image[6][222] = 0.000000 \n",
      "image[6][223] = 0.000000 \n",
      "image[6][224] = 0.000000 \n",
      "image[6][225] = 0.000000 \n",
      "image[6][226] = 0.000000 \n",
      "image[6][227] = 0.000000 \n",
      "image[6][228] = 0.000000 \n",
      "image[6][229] = 0.000000 \n",
      "image[6][230] = 0.000000 \n",
      "image[6][231] = 0.000000 \n",
      "image[6][232] = 0.000000 \n",
      "image[6][233] = 0.000000 \n",
      "image[6][234] = 0.000000 \n",
      "image[6][235] = 0.062745 \n",
      "image[6][236] = 0.749020 \n",
      "image[6][237] = 0.992157 \n",
      "image[6][238] = 0.988235 \n",
      "image[6][239] = 0.278431 \n",
      "image[6][240] = 0.000000 \n",
      "image[6][241] = 0.000000 \n",
      "image[6][242] = 0.000000 \n",
      "image[6][243] = 0.000000 \n",
      "image[6][244] = 0.000000 \n",
      "image[6][245] = 0.000000 \n",
      "image[6][246] = 0.000000 \n",
      "image[6][247] = 0.000000 \n",
      "image[6][248] = 0.000000 \n",
      "image[6][249] = 0.000000 \n",
      "image[6][250] = 0.000000 \n",
      "image[6][251] = 0.000000 \n",
      "image[6][252] = 0.000000 \n",
      "image[6][253] = 0.000000 \n",
      "image[6][254] = 0.000000 \n",
      "image[6][255] = 0.000000 \n",
      "image[6][256] = 0.000000 \n",
      "image[6][257] = 0.000000 \n",
      "image[6][258] = 0.000000 \n",
      "image[6][259] = 0.000000 \n",
      "image[6][260] = 0.000000 \n",
      "image[6][261] = 0.000000 \n",
      "image[6][262] = 0.000000 \n",
      "image[6][263] = 0.101961 \n",
      "image[6][264] = 0.866667 \n",
      "image[6][265] = 0.992157 \n",
      "image[6][266] = 0.988235 \n",
      "image[6][267] = 0.486275 \n",
      "image[6][268] = 0.121569 \n",
      "image[6][269] = 0.000000 \n",
      "image[6][270] = 0.000000 \n",
      "image[6][271] = 0.000000 \n",
      "image[6][272] = 0.000000 \n",
      "image[6][273] = 0.000000 \n",
      "image[6][274] = 0.000000 \n",
      "image[6][275] = 0.000000 \n",
      "image[6][276] = 0.000000 \n",
      "image[6][277] = 0.000000 \n",
      "image[6][278] = 0.000000 \n",
      "image[6][279] = 0.000000 \n",
      "image[6][280] = 0.000000 \n",
      "image[6][281] = 0.000000 \n",
      "image[6][282] = 0.000000 \n",
      "image[6][283] = 0.000000 \n",
      "image[6][284] = 0.000000 \n",
      "image[6][285] = 0.000000 \n",
      "image[6][286] = 0.000000 \n",
      "image[6][287] = 0.000000 \n",
      "image[6][288] = 0.000000 \n",
      "image[6][289] = 0.000000 \n",
      "image[6][290] = 0.000000 \n",
      "image[6][291] = 0.000000 \n",
      "image[6][292] = 0.490196 \n",
      "image[6][293] = 0.992157 \n",
      "image[6][294] = 0.988235 \n",
      "image[6][295] = 0.988235 \n",
      "image[6][296] = 0.423529 \n",
      "image[6][297] = 0.000000 \n",
      "image[6][298] = 0.000000 \n",
      "image[6][299] = 0.000000 \n",
      "image[6][300] = 0.000000 \n",
      "image[6][301] = 0.000000 \n",
      "image[6][302] = 0.000000 \n",
      "image[6][303] = 0.000000 \n",
      "image[6][304] = 0.000000 \n",
      "image[6][305] = 0.000000 \n",
      "image[6][306] = 0.000000 \n",
      "image[6][307] = 0.000000 \n",
      "image[6][308] = 0.000000 \n",
      "image[6][309] = 0.000000 \n",
      "image[6][310] = 0.000000 \n",
      "image[6][311] = 0.000000 \n",
      "image[6][312] = 0.000000 \n",
      "image[6][313] = 0.000000 \n",
      "image[6][314] = 0.000000 \n",
      "image[6][315] = 0.000000 \n",
      "image[6][316] = 0.000000 \n",
      "image[6][317] = 0.000000 \n",
      "image[6][318] = 0.000000 \n",
      "image[6][319] = 0.000000 \n",
      "image[6][320] = 0.000000 \n",
      "image[6][321] = 0.992157 \n",
      "image[6][322] = 0.988235 \n",
      "image[6][323] = 0.988235 \n",
      "image[6][324] = 0.423529 \n",
      "image[6][325] = 0.000000 \n",
      "image[6][326] = 0.000000 \n",
      "image[6][327] = 0.000000 \n",
      "image[6][328] = 0.000000 \n",
      "image[6][329] = 0.000000 \n",
      "image[6][330] = 0.000000 \n",
      "image[6][331] = 0.000000 \n",
      "image[6][332] = 0.000000 \n",
      "image[6][333] = 0.000000 \n",
      "image[6][334] = 0.000000 \n",
      "image[6][335] = 0.000000 \n",
      "image[6][336] = 0.000000 \n",
      "image[6][337] = 0.000000 \n",
      "image[6][338] = 0.000000 \n",
      "image[6][339] = 0.000000 \n",
      "image[6][340] = 0.000000 \n",
      "image[6][341] = 0.000000 \n",
      "image[6][342] = 0.000000 \n",
      "image[6][343] = 0.000000 \n",
      "image[6][344] = 0.000000 \n",
      "image[6][345] = 0.000000 \n",
      "image[6][346] = 0.000000 \n",
      "image[6][347] = 0.000000 \n",
      "image[6][348] = 0.000000 \n",
      "image[6][349] = 1.000000 \n",
      "image[6][350] = 0.992157 \n",
      "image[6][351] = 0.992157 \n",
      "image[6][352] = 0.423529 \n",
      "image[6][353] = 0.000000 \n",
      "image[6][354] = 0.000000 \n",
      "image[6][355] = 0.000000 \n",
      "image[6][356] = 0.000000 \n",
      "image[6][357] = 0.000000 \n",
      "image[6][358] = 0.000000 \n",
      "image[6][359] = 0.000000 \n",
      "image[6][360] = 0.000000 \n",
      "image[6][361] = 0.000000 \n",
      "image[6][362] = 0.000000 \n",
      "image[6][363] = 0.000000 \n",
      "image[6][364] = 0.000000 \n",
      "image[6][365] = 0.000000 \n",
      "image[6][366] = 0.000000 \n",
      "image[6][367] = 0.000000 \n",
      "image[6][368] = 0.000000 \n",
      "image[6][369] = 0.000000 \n",
      "image[6][370] = 0.000000 \n",
      "image[6][371] = 0.000000 \n",
      "image[6][372] = 0.000000 \n",
      "image[6][373] = 0.000000 \n",
      "image[6][374] = 0.000000 \n",
      "image[6][375] = 0.000000 \n",
      "image[6][376] = 0.000000 \n",
      "image[6][377] = 0.992157 \n",
      "image[6][378] = 0.988235 \n",
      "image[6][379] = 0.988235 \n",
      "image[6][380] = 0.423529 \n",
      "image[6][381] = 0.000000 \n",
      "image[6][382] = 0.000000 \n",
      "image[6][383] = 0.000000 \n",
      "image[6][384] = 0.000000 \n",
      "image[6][385] = 0.000000 \n",
      "image[6][386] = 0.000000 \n",
      "image[6][387] = 0.000000 \n",
      "image[6][388] = 0.000000 \n",
      "image[6][389] = 0.000000 \n",
      "image[6][390] = 0.000000 \n",
      "image[6][391] = 0.000000 \n",
      "image[6][392] = 0.000000 \n",
      "image[6][393] = 0.000000 \n",
      "image[6][394] = 0.000000 \n",
      "image[6][395] = 0.000000 \n",
      "image[6][396] = 0.000000 \n",
      "image[6][397] = 0.000000 \n",
      "image[6][398] = 0.000000 \n",
      "image[6][399] = 0.000000 \n",
      "image[6][400] = 0.000000 \n",
      "image[6][401] = 0.000000 \n",
      "image[6][402] = 0.000000 \n",
      "image[6][403] = 0.000000 \n",
      "image[6][404] = 0.000000 \n",
      "image[6][405] = 0.992157 \n",
      "image[6][406] = 0.988235 \n",
      "image[6][407] = 0.988235 \n",
      "image[6][408] = 0.423529 \n",
      "image[6][409] = 0.000000 \n",
      "image[6][410] = 0.000000 \n",
      "image[6][411] = 0.000000 \n",
      "image[6][412] = 0.000000 \n",
      "image[6][413] = 0.000000 \n",
      "image[6][414] = 0.000000 \n",
      "image[6][415] = 0.000000 \n",
      "image[6][416] = 0.000000 \n",
      "image[6][417] = 0.000000 \n",
      "image[6][418] = 0.000000 \n",
      "image[6][419] = 0.000000 \n",
      "image[6][420] = 0.000000 \n",
      "image[6][421] = 0.000000 \n",
      "image[6][422] = 0.000000 \n",
      "image[6][423] = 0.000000 \n",
      "image[6][424] = 0.000000 \n",
      "image[6][425] = 0.000000 \n",
      "image[6][426] = 0.000000 \n",
      "image[6][427] = 0.000000 \n",
      "image[6][428] = 0.000000 \n",
      "image[6][429] = 0.000000 \n",
      "image[6][430] = 0.000000 \n",
      "image[6][431] = 0.000000 \n",
      "image[6][432] = 0.000000 \n",
      "image[6][433] = 0.992157 \n",
      "image[6][434] = 0.988235 \n",
      "image[6][435] = 0.988235 \n",
      "image[6][436] = 0.423529 \n",
      "image[6][437] = 0.000000 \n",
      "image[6][438] = 0.000000 \n",
      "image[6][439] = 0.000000 \n",
      "image[6][440] = 0.000000 \n",
      "image[6][441] = 0.000000 \n",
      "image[6][442] = 0.000000 \n",
      "image[6][443] = 0.000000 \n",
      "image[6][444] = 0.000000 \n",
      "image[6][445] = 0.000000 \n",
      "image[6][446] = 0.000000 \n",
      "image[6][447] = 0.000000 \n",
      "image[6][448] = 0.000000 \n",
      "image[6][449] = 0.000000 \n",
      "image[6][450] = 0.000000 \n",
      "image[6][451] = 0.000000 \n",
      "image[6][452] = 0.000000 \n",
      "image[6][453] = 0.000000 \n",
      "image[6][454] = 0.000000 \n",
      "image[6][455] = 0.000000 \n",
      "image[6][456] = 0.000000 \n",
      "image[6][457] = 0.000000 \n",
      "image[6][458] = 0.000000 \n",
      "image[6][459] = 0.000000 \n",
      "image[6][460] = 0.000000 \n",
      "image[6][461] = 1.000000 \n",
      "image[6][462] = 0.992157 \n",
      "image[6][463] = 0.992157 \n",
      "image[6][464] = 0.666667 \n",
      "image[6][465] = 0.000000 \n",
      "image[6][466] = 0.000000 \n",
      "image[6][467] = 0.000000 \n",
      "image[6][468] = 0.000000 \n",
      "image[6][469] = 0.000000 \n",
      "image[6][470] = 0.000000 \n",
      "image[6][471] = 0.000000 \n",
      "image[6][472] = 0.000000 \n",
      "image[6][473] = 0.000000 \n",
      "image[6][474] = 0.000000 \n",
      "image[6][475] = 0.000000 \n",
      "image[6][476] = 0.000000 \n",
      "image[6][477] = 0.000000 \n",
      "image[6][478] = 0.000000 \n",
      "image[6][479] = 0.000000 \n",
      "image[6][480] = 0.000000 \n",
      "image[6][481] = 0.000000 \n",
      "image[6][482] = 0.000000 \n",
      "image[6][483] = 0.000000 \n",
      "image[6][484] = 0.000000 \n",
      "image[6][485] = 0.000000 \n",
      "image[6][486] = 0.000000 \n",
      "image[6][487] = 0.000000 \n",
      "image[6][488] = 0.000000 \n",
      "image[6][489] = 0.992157 \n",
      "image[6][490] = 0.988235 \n",
      "image[6][491] = 0.988235 \n",
      "image[6][492] = 0.988235 \n",
      "image[6][493] = 0.164706 \n",
      "image[6][494] = 0.000000 \n",
      "image[6][495] = 0.000000 \n",
      "image[6][496] = 0.000000 \n",
      "image[6][497] = 0.000000 \n",
      "image[6][498] = 0.000000 \n",
      "image[6][499] = 0.000000 \n",
      "image[6][500] = 0.000000 \n",
      "image[6][501] = 0.000000 \n",
      "image[6][502] = 0.000000 \n",
      "image[6][503] = 0.000000 \n",
      "image[6][504] = 0.000000 \n",
      "image[6][505] = 0.000000 \n",
      "image[6][506] = 0.000000 \n",
      "image[6][507] = 0.000000 \n",
      "image[6][508] = 0.000000 \n",
      "image[6][509] = 0.000000 \n",
      "image[6][510] = 0.000000 \n",
      "image[6][511] = 0.000000 \n",
      "image[6][512] = 0.000000 \n",
      "image[6][513] = 0.000000 \n",
      "image[6][514] = 0.000000 \n",
      "image[6][515] = 0.000000 \n",
      "image[6][516] = 0.000000 \n",
      "image[6][517] = 0.584314 \n",
      "image[6][518] = 0.988235 \n",
      "image[6][519] = 0.988235 \n",
      "image[6][520] = 0.988235 \n",
      "image[6][521] = 0.564706 \n",
      "image[6][522] = 0.000000 \n",
      "image[6][523] = 0.000000 \n",
      "image[6][524] = 0.000000 \n",
      "image[6][525] = 0.000000 \n",
      "image[6][526] = 0.000000 \n",
      "image[6][527] = 0.000000 \n",
      "image[6][528] = 0.000000 \n",
      "image[6][529] = 0.000000 \n",
      "image[6][530] = 0.000000 \n",
      "image[6][531] = 0.000000 \n",
      "image[6][532] = 0.000000 \n",
      "image[6][533] = 0.000000 \n",
      "image[6][534] = 0.000000 \n",
      "image[6][535] = 0.000000 \n",
      "image[6][536] = 0.000000 \n",
      "image[6][537] = 0.000000 \n",
      "image[6][538] = 0.000000 \n",
      "image[6][539] = 0.000000 \n",
      "image[6][540] = 0.000000 \n",
      "image[6][541] = 0.000000 \n",
      "image[6][542] = 0.000000 \n",
      "image[6][543] = 0.000000 \n",
      "image[6][544] = 0.000000 \n",
      "image[6][545] = 0.427451 \n",
      "image[6][546] = 0.988235 \n",
      "image[6][547] = 0.988235 \n",
      "image[6][548] = 0.988235 \n",
      "image[6][549] = 0.564706 \n",
      "image[6][550] = 0.000000 \n",
      "image[6][551] = 0.000000 \n",
      "image[6][552] = 0.000000 \n",
      "image[6][553] = 0.000000 \n",
      "image[6][554] = 0.000000 \n",
      "image[6][555] = 0.000000 \n",
      "image[6][556] = 0.000000 \n",
      "image[6][557] = 0.000000 \n",
      "image[6][558] = 0.000000 \n",
      "image[6][559] = 0.000000 \n",
      "image[6][560] = 0.000000 \n",
      "image[6][561] = 0.000000 \n",
      "image[6][562] = 0.000000 \n",
      "image[6][563] = 0.000000 \n",
      "image[6][564] = 0.000000 \n",
      "image[6][565] = 0.000000 \n",
      "image[6][566] = 0.000000 \n",
      "image[6][567] = 0.000000 \n",
      "image[6][568] = 0.000000 \n",
      "image[6][569] = 0.000000 \n",
      "image[6][570] = 0.000000 \n",
      "image[6][571] = 0.000000 \n",
      "image[6][572] = 0.000000 \n",
      "image[6][573] = 0.000000 \n",
      "image[6][574] = 0.854902 \n",
      "image[6][575] = 0.992157 \n",
      "image[6][576] = 0.992157 \n",
      "image[6][577] = 1.000000 \n",
      "image[6][578] = 0.137255 \n",
      "image[6][579] = 0.000000 \n",
      "image[6][580] = 0.000000 \n",
      "image[6][581] = 0.000000 \n",
      "image[6][582] = 0.000000 \n",
      "image[6][583] = 0.000000 \n",
      "image[6][584] = 0.000000 \n",
      "image[6][585] = 0.000000 \n",
      "image[6][586] = 0.000000 \n",
      "image[6][587] = 0.000000 \n",
      "image[6][588] = 0.000000 \n",
      "image[6][589] = 0.000000 \n",
      "image[6][590] = 0.000000 \n",
      "image[6][591] = 0.000000 \n",
      "image[6][592] = 0.000000 \n",
      "image[6][593] = 0.000000 \n",
      "image[6][594] = 0.000000 \n",
      "image[6][595] = 0.000000 \n",
      "image[6][596] = 0.000000 \n",
      "image[6][597] = 0.000000 \n",
      "image[6][598] = 0.000000 \n",
      "image[6][599] = 0.000000 \n",
      "image[6][600] = 0.000000 \n",
      "image[6][601] = 0.000000 \n",
      "image[6][602] = 0.686275 \n",
      "image[6][603] = 0.988235 \n",
      "image[6][604] = 0.988235 \n",
      "image[6][605] = 0.992157 \n",
      "image[6][606] = 0.137255 \n",
      "image[6][607] = 0.000000 \n",
      "image[6][608] = 0.000000 \n",
      "image[6][609] = 0.000000 \n",
      "image[6][610] = 0.000000 \n",
      "image[6][611] = 0.000000 \n",
      "image[6][612] = 0.000000 \n",
      "image[6][613] = 0.000000 \n",
      "image[6][614] = 0.000000 \n",
      "image[6][615] = 0.000000 \n",
      "image[6][616] = 0.000000 \n",
      "image[6][617] = 0.000000 \n",
      "image[6][618] = 0.000000 \n",
      "image[6][619] = 0.000000 \n",
      "image[6][620] = 0.000000 \n",
      "image[6][621] = 0.000000 \n",
      "image[6][622] = 0.000000 \n",
      "image[6][623] = 0.000000 \n",
      "image[6][624] = 0.000000 \n",
      "image[6][625] = 0.000000 \n",
      "image[6][626] = 0.000000 \n",
      "image[6][627] = 0.000000 \n",
      "image[6][628] = 0.000000 \n",
      "image[6][629] = 0.000000 \n",
      "image[6][630] = 0.286275 \n",
      "image[6][631] = 0.988235 \n",
      "image[6][632] = 0.988235 \n",
      "image[6][633] = 0.992157 \n",
      "image[6][634] = 0.137255 \n",
      "image[6][635] = 0.000000 \n",
      "image[6][636] = 0.000000 \n",
      "image[6][637] = 0.000000 \n",
      "image[6][638] = 0.000000 \n",
      "image[6][639] = 0.000000 \n",
      "image[6][640] = 0.000000 \n",
      "image[6][641] = 0.000000 \n",
      "image[6][642] = 0.000000 \n",
      "image[6][643] = 0.000000 \n",
      "image[6][644] = 0.000000 \n",
      "image[6][645] = 0.000000 \n",
      "image[6][646] = 0.000000 \n",
      "image[6][647] = 0.000000 \n",
      "image[6][648] = 0.000000 \n",
      "image[6][649] = 0.000000 \n",
      "image[6][650] = 0.000000 \n",
      "image[6][651] = 0.000000 \n",
      "image[6][652] = 0.000000 \n",
      "image[6][653] = 0.000000 \n",
      "image[6][654] = 0.000000 \n",
      "image[6][655] = 0.000000 \n",
      "image[6][656] = 0.000000 \n",
      "image[6][657] = 0.000000 \n",
      "image[6][658] = 0.121569 \n",
      "image[6][659] = 0.827451 \n",
      "image[6][660] = 0.988235 \n",
      "image[6][661] = 0.992157 \n",
      "image[6][662] = 0.137255 \n",
      "image[6][663] = 0.000000 \n",
      "image[6][664] = 0.000000 \n",
      "image[6][665] = 0.000000 \n",
      "image[6][666] = 0.000000 \n",
      "image[6][667] = 0.000000 \n",
      "image[6][668] = 0.000000 \n",
      "image[6][669] = 0.000000 \n",
      "image[6][670] = 0.000000 \n",
      "image[6][671] = 0.000000 \n",
      "image[6][672] = 0.000000 \n",
      "image[6][673] = 0.000000 \n",
      "image[6][674] = 0.000000 \n",
      "image[6][675] = 0.000000 \n",
      "image[6][676] = 0.000000 \n",
      "image[6][677] = 0.000000 \n",
      "image[6][678] = 0.000000 \n",
      "image[6][679] = 0.000000 \n",
      "image[6][680] = 0.000000 \n",
      "image[6][681] = 0.000000 \n",
      "image[6][682] = 0.000000 \n",
      "image[6][683] = 0.000000 \n",
      "image[6][684] = 0.000000 \n",
      "image[6][685] = 0.000000 \n",
      "image[6][686] = 0.000000 \n",
      "image[6][687] = 0.000000 \n",
      "image[6][688] = 0.000000 \n",
      "image[6][689] = 0.000000 \n",
      "image[6][690] = 0.000000 \n",
      "image[6][691] = 0.000000 \n",
      "image[6][692] = 0.000000 \n",
      "image[6][693] = 0.000000 \n",
      "image[6][694] = 0.000000 \n",
      "image[6][695] = 0.000000 \n",
      "image[6][696] = 0.000000 \n",
      "image[6][697] = 0.000000 \n",
      "image[6][698] = 0.000000 \n",
      "image[6][699] = 0.000000 \n",
      "image[6][700] = 0.000000 \n",
      "image[6][701] = 0.000000 \n",
      "image[6][702] = 0.000000 \n",
      "image[6][703] = 0.000000 \n",
      "image[6][704] = 0.000000 \n",
      "image[6][705] = 0.000000 \n",
      "image[6][706] = 0.000000 \n",
      "image[6][707] = 0.000000 \n",
      "image[6][708] = 0.000000 \n",
      "image[6][709] = 0.000000 \n",
      "image[6][710] = 0.000000 \n",
      "image[6][711] = 0.000000 \n",
      "image[6][712] = 0.000000 \n",
      "image[6][713] = 0.000000 \n",
      "image[6][714] = 0.000000 \n",
      "image[6][715] = 0.000000 \n",
      "image[6][716] = 0.000000 \n",
      "image[6][717] = 0.000000 \n",
      "image[6][718] = 0.000000 \n",
      "image[6][719] = 0.000000 \n",
      "image[6][720] = 0.000000 \n",
      "image[6][721] = 0.000000 \n",
      "image[6][722] = 0.000000 \n",
      "image[6][723] = 0.000000 \n",
      "image[6][724] = 0.000000 \n",
      "image[6][725] = 0.000000 \n",
      "image[6][726] = 0.000000 \n",
      "image[6][727] = 0.000000 \n",
      "image[6][728] = 0.000000 \n",
      "image[6][729] = 0.000000 \n",
      "image[6][730] = 0.000000 \n",
      "image[6][731] = 0.000000 \n",
      "image[6][732] = 0.000000 \n",
      "image[6][733] = 0.000000 \n",
      "image[6][734] = 0.000000 \n",
      "image[6][735] = 0.000000 \n",
      "image[6][736] = 0.000000 \n",
      "image[6][737] = 0.000000 \n",
      "image[6][738] = 0.000000 \n",
      "image[6][739] = 0.000000 \n",
      "image[6][740] = 0.000000 \n",
      "image[6][741] = 0.000000 \n",
      "image[6][742] = 0.000000 \n",
      "image[6][743] = 0.000000 \n",
      "image[6][744] = 0.000000 \n",
      "image[6][745] = 0.000000 \n",
      "image[6][746] = 0.000000 \n",
      "image[6][747] = 0.000000 \n",
      "image[6][748] = 0.000000 \n",
      "image[6][749] = 0.000000 \n",
      "image[6][750] = 0.000000 \n",
      "image[6][751] = 0.000000 \n",
      "image[6][752] = 0.000000 \n",
      "image[6][753] = 0.000000 \n",
      "image[6][754] = 0.000000 \n",
      "image[6][755] = 0.000000 \n",
      "image[6][756] = 0.000000 \n",
      "image[6][757] = 0.000000 \n",
      "image[6][758] = 0.000000 \n",
      "image[6][759] = 0.000000 \n",
      "image[6][760] = 0.000000 \n",
      "image[6][761] = 0.000000 \n",
      "image[6][762] = 0.000000 \n",
      "image[6][763] = 0.000000 \n",
      "image[6][764] = 0.000000 \n",
      "image[6][765] = 0.000000 \n",
      "image[6][766] = 0.000000 \n",
      "image[6][767] = 0.000000 \n",
      "image[6][768] = 0.000000 \n",
      "image[6][769] = 0.000000 \n",
      "image[6][770] = 0.000000 \n",
      "image[6][771] = 0.000000 \n",
      "image[6][772] = 0.000000 \n",
      "image[6][773] = 0.000000 \n",
      "image[6][774] = 0.000000 \n",
      "image[6][775] = 0.000000 \n",
      "image[6][776] = 0.000000 \n",
      "image[6][777] = 0.000000 \n",
      "image[6][778] = 0.000000 \n",
      "image[6][779] = 0.000000 \n",
      "image[6][780] = 0.000000 \n",
      "image[6][781] = 0.000000 \n",
      "image[6][782] = 0.000000 \n",
      "image[6][783] = 0.000000 \n",
      "image[7][0] = 0.000000 \n",
      "image[7][1] = 0.000000 \n",
      "image[7][2] = 0.000000 \n",
      "image[7][3] = 0.000000 \n",
      "image[7][4] = 0.000000 \n",
      "image[7][5] = 0.000000 \n",
      "image[7][6] = 0.000000 \n",
      "image[7][7] = 0.000000 \n",
      "image[7][8] = 0.000000 \n",
      "image[7][9] = 0.000000 \n",
      "image[7][10] = 0.000000 \n",
      "image[7][11] = 0.000000 \n",
      "image[7][12] = 0.000000 \n",
      "image[7][13] = 0.000000 \n",
      "image[7][14] = 0.000000 \n",
      "image[7][15] = 0.000000 \n",
      "image[7][16] = 0.000000 \n",
      "image[7][17] = 0.000000 \n",
      "image[7][18] = 0.000000 \n",
      "image[7][19] = 0.000000 \n",
      "image[7][20] = 0.000000 \n",
      "image[7][21] = 0.000000 \n",
      "image[7][22] = 0.000000 \n",
      "image[7][23] = 0.000000 \n",
      "image[7][24] = 0.000000 \n",
      "image[7][25] = 0.000000 \n",
      "image[7][26] = 0.000000 \n",
      "image[7][27] = 0.000000 \n",
      "image[7][28] = 0.000000 \n",
      "image[7][29] = 0.000000 \n",
      "image[7][30] = 0.000000 \n",
      "image[7][31] = 0.000000 \n",
      "image[7][32] = 0.000000 \n",
      "image[7][33] = 0.000000 \n",
      "image[7][34] = 0.000000 \n",
      "image[7][35] = 0.000000 \n",
      "image[7][36] = 0.000000 \n",
      "image[7][37] = 0.000000 \n",
      "image[7][38] = 0.000000 \n",
      "image[7][39] = 0.000000 \n",
      "image[7][40] = 0.000000 \n",
      "image[7][41] = 0.000000 \n",
      "image[7][42] = 0.000000 \n",
      "image[7][43] = 0.000000 \n",
      "image[7][44] = 0.000000 \n",
      "image[7][45] = 0.000000 \n",
      "image[7][46] = 0.000000 \n",
      "image[7][47] = 0.000000 \n",
      "image[7][48] = 0.000000 \n",
      "image[7][49] = 0.000000 \n",
      "image[7][50] = 0.000000 \n",
      "image[7][51] = 0.000000 \n",
      "image[7][52] = 0.000000 \n",
      "image[7][53] = 0.000000 \n",
      "image[7][54] = 0.000000 \n",
      "image[7][55] = 0.000000 \n",
      "image[7][56] = 0.000000 \n",
      "image[7][57] = 0.000000 \n",
      "image[7][58] = 0.000000 \n",
      "image[7][59] = 0.000000 \n",
      "image[7][60] = 0.000000 \n",
      "image[7][61] = 0.000000 \n",
      "image[7][62] = 0.000000 \n",
      "image[7][63] = 0.000000 \n",
      "image[7][64] = 0.000000 \n",
      "image[7][65] = 0.000000 \n",
      "image[7][66] = 0.000000 \n",
      "image[7][67] = 0.000000 \n",
      "image[7][68] = 0.000000 \n",
      "image[7][69] = 0.000000 \n",
      "image[7][70] = 0.000000 \n",
      "image[7][71] = 0.000000 \n",
      "image[7][72] = 0.000000 \n",
      "image[7][73] = 0.000000 \n",
      "image[7][74] = 0.000000 \n",
      "image[7][75] = 0.000000 \n",
      "image[7][76] = 0.000000 \n",
      "image[7][77] = 0.000000 \n",
      "image[7][78] = 0.000000 \n",
      "image[7][79] = 0.000000 \n",
      "image[7][80] = 0.000000 \n",
      "image[7][81] = 0.000000 \n",
      "image[7][82] = 0.000000 \n",
      "image[7][83] = 0.000000 \n",
      "image[7][84] = 0.000000 \n",
      "image[7][85] = 0.000000 \n",
      "image[7][86] = 0.000000 \n",
      "image[7][87] = 0.000000 \n",
      "image[7][88] = 0.000000 \n",
      "image[7][89] = 0.000000 \n",
      "image[7][90] = 0.000000 \n",
      "image[7][91] = 0.000000 \n",
      "image[7][92] = 0.000000 \n",
      "image[7][93] = 0.000000 \n",
      "image[7][94] = 0.000000 \n",
      "image[7][95] = 0.000000 \n",
      "image[7][96] = 0.000000 \n",
      "image[7][97] = 0.000000 \n",
      "image[7][98] = 0.000000 \n",
      "image[7][99] = 0.000000 \n",
      "image[7][100] = 0.000000 \n",
      "image[7][101] = 0.000000 \n",
      "image[7][102] = 0.000000 \n",
      "image[7][103] = 0.000000 \n",
      "image[7][104] = 0.000000 \n",
      "image[7][105] = 0.000000 \n",
      "image[7][106] = 0.000000 \n",
      "image[7][107] = 0.000000 \n",
      "image[7][108] = 0.000000 \n",
      "image[7][109] = 0.000000 \n",
      "image[7][110] = 0.000000 \n",
      "image[7][111] = 0.000000 \n",
      "image[7][112] = 0.000000 \n",
      "image[7][113] = 0.000000 \n",
      "image[7][114] = 0.000000 \n",
      "image[7][115] = 0.000000 \n",
      "image[7][116] = 0.000000 \n",
      "image[7][117] = 0.000000 \n",
      "image[7][118] = 0.000000 \n",
      "image[7][119] = 0.000000 \n",
      "image[7][120] = 0.000000 \n",
      "image[7][121] = 0.000000 \n",
      "image[7][122] = 0.000000 \n",
      "image[7][123] = 0.000000 \n",
      "image[7][124] = 0.000000 \n",
      "image[7][125] = 0.000000 \n",
      "image[7][126] = 0.000000 \n",
      "image[7][127] = 0.000000 \n",
      "image[7][128] = 0.000000 \n",
      "image[7][129] = 0.000000 \n",
      "image[7][130] = 0.000000 \n",
      "image[7][131] = 0.000000 \n",
      "image[7][132] = 0.000000 \n",
      "image[7][133] = 0.000000 \n",
      "image[7][134] = 0.000000 \n",
      "image[7][135] = 0.000000 \n",
      "image[7][136] = 0.000000 \n",
      "image[7][137] = 0.000000 \n",
      "image[7][138] = 0.000000 \n",
      "image[7][139] = 0.000000 \n",
      "image[7][140] = 0.000000 \n",
      "image[7][141] = 0.000000 \n",
      "image[7][142] = 0.000000 \n",
      "image[7][143] = 0.000000 \n",
      "image[7][144] = 0.000000 \n",
      "image[7][145] = 0.000000 \n",
      "image[7][146] = 0.000000 \n",
      "image[7][147] = 0.000000 \n",
      "image[7][148] = 0.000000 \n",
      "image[7][149] = 0.000000 \n",
      "image[7][150] = 0.000000 \n",
      "image[7][151] = 0.149020 \n",
      "image[7][152] = 0.168627 \n",
      "image[7][153] = 0.411765 \n",
      "image[7][154] = 1.000000 \n",
      "image[7][155] = 0.992157 \n",
      "image[7][156] = 0.992157 \n",
      "image[7][157] = 0.992157 \n",
      "image[7][158] = 0.992157 \n",
      "image[7][159] = 0.992157 \n",
      "image[7][160] = 0.682353 \n",
      "image[7][161] = 0.023529 \n",
      "image[7][162] = 0.000000 \n",
      "image[7][163] = 0.000000 \n",
      "image[7][164] = 0.000000 \n",
      "image[7][165] = 0.000000 \n",
      "image[7][166] = 0.000000 \n",
      "image[7][167] = 0.000000 \n",
      "image[7][168] = 0.000000 \n",
      "image[7][169] = 0.000000 \n",
      "image[7][170] = 0.000000 \n",
      "image[7][171] = 0.000000 \n",
      "image[7][172] = 0.000000 \n",
      "image[7][173] = 0.000000 \n",
      "image[7][174] = 0.000000 \n",
      "image[7][175] = 0.000000 \n",
      "image[7][176] = 0.000000 \n",
      "image[7][177] = 0.168627 \n",
      "image[7][178] = 0.545098 \n",
      "image[7][179] = 0.878431 \n",
      "image[7][180] = 0.886275 \n",
      "image[7][181] = 0.988235 \n",
      "image[7][182] = 0.992157 \n",
      "image[7][183] = 0.988235 \n",
      "image[7][184] = 0.988235 \n",
      "image[7][185] = 0.988235 \n",
      "image[7][186] = 0.988235 \n",
      "image[7][187] = 0.988235 \n",
      "image[7][188] = 0.988235 \n",
      "image[7][189] = 0.619608 \n",
      "image[7][190] = 0.054902 \n",
      "image[7][191] = 0.000000 \n",
      "image[7][192] = 0.000000 \n",
      "image[7][193] = 0.000000 \n",
      "image[7][194] = 0.000000 \n",
      "image[7][195] = 0.000000 \n",
      "image[7][196] = 0.000000 \n",
      "image[7][197] = 0.000000 \n",
      "image[7][198] = 0.000000 \n",
      "image[7][199] = 0.000000 \n",
      "image[7][200] = 0.000000 \n",
      "image[7][201] = 0.000000 \n",
      "image[7][202] = 0.000000 \n",
      "image[7][203] = 0.000000 \n",
      "image[7][204] = 0.000000 \n",
      "image[7][205] = 0.698039 \n",
      "image[7][206] = 0.988235 \n",
      "image[7][207] = 0.988235 \n",
      "image[7][208] = 0.988235 \n",
      "image[7][209] = 0.988235 \n",
      "image[7][210] = 0.992157 \n",
      "image[7][211] = 0.988235 \n",
      "image[7][212] = 0.988235 \n",
      "image[7][213] = 0.988235 \n",
      "image[7][214] = 0.988235 \n",
      "image[7][215] = 0.988235 \n",
      "image[7][216] = 0.988235 \n",
      "image[7][217] = 0.988235 \n",
      "image[7][218] = 0.231373 \n",
      "image[7][219] = 0.000000 \n",
      "image[7][220] = 0.000000 \n",
      "image[7][221] = 0.000000 \n",
      "image[7][222] = 0.000000 \n",
      "image[7][223] = 0.000000 \n",
      "image[7][224] = 0.000000 \n",
      "image[7][225] = 0.000000 \n",
      "image[7][226] = 0.000000 \n",
      "image[7][227] = 0.000000 \n",
      "image[7][228] = 0.000000 \n",
      "image[7][229] = 0.000000 \n",
      "image[7][230] = 0.000000 \n",
      "image[7][231] = 0.000000 \n",
      "image[7][232] = 0.000000 \n",
      "image[7][233] = 0.427451 \n",
      "image[7][234] = 0.988235 \n",
      "image[7][235] = 0.988235 \n",
      "image[7][236] = 0.901961 \n",
      "image[7][237] = 0.517647 \n",
      "image[7][238] = 0.521569 \n",
      "image[7][239] = 0.517647 \n",
      "image[7][240] = 0.517647 \n",
      "image[7][241] = 0.741176 \n",
      "image[7][242] = 0.988235 \n",
      "image[7][243] = 0.988235 \n",
      "image[7][244] = 0.988235 \n",
      "image[7][245] = 0.988235 \n",
      "image[7][246] = 0.231373 \n",
      "image[7][247] = 0.000000 \n",
      "image[7][248] = 0.000000 \n",
      "image[7][249] = 0.000000 \n",
      "image[7][250] = 0.000000 \n",
      "image[7][251] = 0.000000 \n",
      "image[7][252] = 0.000000 \n",
      "image[7][253] = 0.000000 \n",
      "image[7][254] = 0.000000 \n",
      "image[7][255] = 0.000000 \n",
      "image[7][256] = 0.000000 \n",
      "image[7][257] = 0.000000 \n",
      "image[7][258] = 0.000000 \n",
      "image[7][259] = 0.000000 \n",
      "image[7][260] = 0.000000 \n",
      "image[7][261] = 0.015686 \n",
      "image[7][262] = 0.113725 \n",
      "image[7][263] = 0.113725 \n",
      "image[7][264] = 0.094118 \n",
      "image[7][265] = 0.000000 \n",
      "image[7][266] = 0.000000 \n",
      "image[7][267] = 0.000000 \n",
      "image[7][268] = 0.000000 \n",
      "image[7][269] = 0.054902 \n",
      "image[7][270] = 0.886275 \n",
      "image[7][271] = 0.988235 \n",
      "image[7][272] = 0.988235 \n",
      "image[7][273] = 0.674510 \n",
      "image[7][274] = 0.027451 \n",
      "image[7][275] = 0.000000 \n",
      "image[7][276] = 0.000000 \n",
      "image[7][277] = 0.000000 \n",
      "image[7][278] = 0.000000 \n",
      "image[7][279] = 0.000000 \n",
      "image[7][280] = 0.000000 \n",
      "image[7][281] = 0.000000 \n",
      "image[7][282] = 0.000000 \n",
      "image[7][283] = 0.000000 \n",
      "image[7][284] = 0.000000 \n",
      "image[7][285] = 0.000000 \n",
      "image[7][286] = 0.000000 \n",
      "image[7][287] = 0.000000 \n",
      "image[7][288] = 0.000000 \n",
      "image[7][289] = 0.000000 \n",
      "image[7][290] = 0.000000 \n",
      "image[7][291] = 0.000000 \n",
      "image[7][292] = 0.000000 \n",
      "image[7][293] = 0.000000 \n",
      "image[7][294] = 0.000000 \n",
      "image[7][295] = 0.000000 \n",
      "image[7][296] = 0.000000 \n",
      "image[7][297] = 0.333333 \n",
      "image[7][298] = 0.952941 \n",
      "image[7][299] = 0.988235 \n",
      "image[7][300] = 0.988235 \n",
      "image[7][301] = 0.564706 \n",
      "image[7][302] = 0.000000 \n",
      "image[7][303] = 0.000000 \n",
      "image[7][304] = 0.000000 \n",
      "image[7][305] = 0.000000 \n",
      "image[7][306] = 0.000000 \n",
      "image[7][307] = 0.000000 \n",
      "image[7][308] = 0.000000 \n",
      "image[7][309] = 0.000000 \n",
      "image[7][310] = 0.000000 \n",
      "image[7][311] = 0.000000 \n",
      "image[7][312] = 0.000000 \n",
      "image[7][313] = 0.000000 \n",
      "image[7][314] = 0.000000 \n",
      "image[7][315] = 0.000000 \n",
      "image[7][316] = 0.000000 \n",
      "image[7][317] = 0.000000 \n",
      "image[7][318] = 0.000000 \n",
      "image[7][319] = 0.000000 \n",
      "image[7][320] = 0.000000 \n",
      "image[7][321] = 0.000000 \n",
      "image[7][322] = 0.000000 \n",
      "image[7][323] = 0.000000 \n",
      "image[7][324] = 0.345098 \n",
      "image[7][325] = 0.741176 \n",
      "image[7][326] = 0.988235 \n",
      "image[7][327] = 0.988235 \n",
      "image[7][328] = 0.988235 \n",
      "image[7][329] = 0.054902 \n",
      "image[7][330] = 0.000000 \n",
      "image[7][331] = 0.000000 \n",
      "image[7][332] = 0.000000 \n",
      "image[7][333] = 0.000000 \n",
      "image[7][334] = 0.000000 \n",
      "image[7][335] = 0.000000 \n",
      "image[7][336] = 0.000000 \n",
      "image[7][337] = 0.000000 \n",
      "image[7][338] = 0.000000 \n",
      "image[7][339] = 0.000000 \n",
      "image[7][340] = 0.000000 \n",
      "image[7][341] = 0.000000 \n",
      "image[7][342] = 0.000000 \n",
      "image[7][343] = 0.000000 \n",
      "image[7][344] = 0.000000 \n",
      "image[7][345] = 0.000000 \n",
      "image[7][346] = 0.000000 \n",
      "image[7][347] = 0.000000 \n",
      "image[7][348] = 0.000000 \n",
      "image[7][349] = 0.000000 \n",
      "image[7][350] = 0.356863 \n",
      "image[7][351] = 0.831373 \n",
      "image[7][352] = 0.968627 \n",
      "image[7][353] = 0.988235 \n",
      "image[7][354] = 0.988235 \n",
      "image[7][355] = 0.988235 \n",
      "image[7][356] = 0.800000 \n",
      "image[7][357] = 0.035294 \n",
      "image[7][358] = 0.000000 \n",
      "image[7][359] = 0.000000 \n",
      "image[7][360] = 0.000000 \n",
      "image[7][361] = 0.000000 \n",
      "image[7][362] = 0.000000 \n",
      "image[7][363] = 0.000000 \n",
      "image[7][364] = 0.000000 \n",
      "image[7][365] = 0.000000 \n",
      "image[7][366] = 0.000000 \n",
      "image[7][367] = 0.000000 \n",
      "image[7][368] = 0.000000 \n",
      "image[7][369] = 0.000000 \n",
      "image[7][370] = 0.000000 \n",
      "image[7][371] = 0.000000 \n",
      "image[7][372] = 0.000000 \n",
      "image[7][373] = 0.125490 \n",
      "image[7][374] = 0.490196 \n",
      "image[7][375] = 0.756863 \n",
      "image[7][376] = 0.756863 \n",
      "image[7][377] = 0.756863 \n",
      "image[7][378] = 0.992157 \n",
      "image[7][379] = 0.988235 \n",
      "image[7][380] = 0.988235 \n",
      "image[7][381] = 0.988235 \n",
      "image[7][382] = 0.933333 \n",
      "image[7][383] = 0.400000 \n",
      "image[7][384] = 0.109804 \n",
      "image[7][385] = 0.000000 \n",
      "image[7][386] = 0.000000 \n",
      "image[7][387] = 0.000000 \n",
      "image[7][388] = 0.000000 \n",
      "image[7][389] = 0.000000 \n",
      "image[7][390] = 0.000000 \n",
      "image[7][391] = 0.000000 \n",
      "image[7][392] = 0.000000 \n",
      "image[7][393] = 0.000000 \n",
      "image[7][394] = 0.000000 \n",
      "image[7][395] = 0.000000 \n",
      "image[7][396] = 0.000000 \n",
      "image[7][397] = 0.000000 \n",
      "image[7][398] = 0.000000 \n",
      "image[7][399] = 0.000000 \n",
      "image[7][400] = 0.176471 \n",
      "image[7][401] = 0.870588 \n",
      "image[7][402] = 0.988235 \n",
      "image[7][403] = 0.988235 \n",
      "image[7][404] = 0.988235 \n",
      "image[7][405] = 0.988235 \n",
      "image[7][406] = 0.992157 \n",
      "image[7][407] = 0.988235 \n",
      "image[7][408] = 0.988235 \n",
      "image[7][409] = 0.988235 \n",
      "image[7][410] = 0.694118 \n",
      "image[7][411] = 0.000000 \n",
      "image[7][412] = 0.000000 \n",
      "image[7][413] = 0.000000 \n",
      "image[7][414] = 0.000000 \n",
      "image[7][415] = 0.000000 \n",
      "image[7][416] = 0.000000 \n",
      "image[7][417] = 0.000000 \n",
      "image[7][418] = 0.000000 \n",
      "image[7][419] = 0.000000 \n",
      "image[7][420] = 0.000000 \n",
      "image[7][421] = 0.000000 \n",
      "image[7][422] = 0.000000 \n",
      "image[7][423] = 0.000000 \n",
      "image[7][424] = 0.000000 \n",
      "image[7][425] = 0.000000 \n",
      "image[7][426] = 0.000000 \n",
      "image[7][427] = 0.000000 \n",
      "image[7][428] = 0.176471 \n",
      "image[7][429] = 0.874510 \n",
      "image[7][430] = 0.992157 \n",
      "image[7][431] = 0.992157 \n",
      "image[7][432] = 0.992157 \n",
      "image[7][433] = 0.992157 \n",
      "image[7][434] = 1.000000 \n",
      "image[7][435] = 0.992157 \n",
      "image[7][436] = 0.992157 \n",
      "image[7][437] = 0.992157 \n",
      "image[7][438] = 0.992157 \n",
      "image[7][439] = 0.290196 \n",
      "image[7][440] = 0.000000 \n",
      "image[7][441] = 0.000000 \n",
      "image[7][442] = 0.000000 \n",
      "image[7][443] = 0.000000 \n",
      "image[7][444] = 0.000000 \n",
      "image[7][445] = 0.000000 \n",
      "image[7][446] = 0.000000 \n",
      "image[7][447] = 0.000000 \n",
      "image[7][448] = 0.000000 \n",
      "image[7][449] = 0.000000 \n",
      "image[7][450] = 0.000000 \n",
      "image[7][451] = 0.000000 \n",
      "image[7][452] = 0.000000 \n",
      "image[7][453] = 0.000000 \n",
      "image[7][454] = 0.000000 \n",
      "image[7][455] = 0.000000 \n",
      "image[7][456] = 0.000000 \n",
      "image[7][457] = 0.121569 \n",
      "image[7][458] = 0.482353 \n",
      "image[7][459] = 0.203922 \n",
      "image[7][460] = 0.172549 \n",
      "image[7][461] = 0.172549 \n",
      "image[7][462] = 0.172549 \n",
      "image[7][463] = 0.172549 \n",
      "image[7][464] = 0.560784 \n",
      "image[7][465] = 0.988235 \n",
      "image[7][466] = 0.988235 \n",
      "image[7][467] = 0.290196 \n",
      "image[7][468] = 0.000000 \n",
      "image[7][469] = 0.000000 \n",
      "image[7][470] = 0.000000 \n",
      "image[7][471] = 0.000000 \n",
      "image[7][472] = 0.000000 \n",
      "image[7][473] = 0.000000 \n",
      "image[7][474] = 0.000000 \n",
      "image[7][475] = 0.000000 \n",
      "image[7][476] = 0.000000 \n",
      "image[7][477] = 0.000000 \n",
      "image[7][478] = 0.000000 \n",
      "image[7][479] = 0.000000 \n",
      "image[7][480] = 0.000000 \n",
      "image[7][481] = 0.000000 \n",
      "image[7][482] = 0.000000 \n",
      "image[7][483] = 0.000000 \n",
      "image[7][484] = 0.000000 \n",
      "image[7][485] = 0.000000 \n",
      "image[7][486] = 0.000000 \n",
      "image[7][487] = 0.000000 \n",
      "image[7][488] = 0.000000 \n",
      "image[7][489] = 0.000000 \n",
      "image[7][490] = 0.000000 \n",
      "image[7][491] = 0.000000 \n",
      "image[7][492] = 0.058824 \n",
      "image[7][493] = 0.988235 \n",
      "image[7][494] = 0.988235 \n",
      "image[7][495] = 0.290196 \n",
      "image[7][496] = 0.000000 \n",
      "image[7][497] = 0.000000 \n",
      "image[7][498] = 0.000000 \n",
      "image[7][499] = 0.000000 \n",
      "image[7][500] = 0.000000 \n",
      "image[7][501] = 0.000000 \n",
      "image[7][502] = 0.000000 \n",
      "image[7][503] = 0.000000 \n",
      "image[7][504] = 0.000000 \n",
      "image[7][505] = 0.000000 \n",
      "image[7][506] = 0.000000 \n",
      "image[7][507] = 0.000000 \n",
      "image[7][508] = 0.000000 \n",
      "image[7][509] = 0.000000 \n",
      "image[7][510] = 0.000000 \n",
      "image[7][511] = 0.000000 \n",
      "image[7][512] = 0.000000 \n",
      "image[7][513] = 0.000000 \n",
      "image[7][514] = 0.000000 \n",
      "image[7][515] = 0.000000 \n",
      "image[7][516] = 0.000000 \n",
      "image[7][517] = 0.000000 \n",
      "image[7][518] = 0.000000 \n",
      "image[7][519] = 0.000000 \n",
      "image[7][520] = 0.337255 \n",
      "image[7][521] = 0.988235 \n",
      "image[7][522] = 0.988235 \n",
      "image[7][523] = 0.290196 \n",
      "image[7][524] = 0.000000 \n",
      "image[7][525] = 0.000000 \n",
      "image[7][526] = 0.000000 \n",
      "image[7][527] = 0.000000 \n",
      "image[7][528] = 0.000000 \n",
      "image[7][529] = 0.000000 \n",
      "image[7][530] = 0.000000 \n",
      "image[7][531] = 0.000000 \n",
      "image[7][532] = 0.000000 \n",
      "image[7][533] = 0.000000 \n",
      "image[7][534] = 0.000000 \n",
      "image[7][535] = 0.000000 \n",
      "image[7][536] = 0.000000 \n",
      "image[7][537] = 0.000000 \n",
      "image[7][538] = 0.019608 \n",
      "image[7][539] = 0.294118 \n",
      "image[7][540] = 0.035294 \n",
      "image[7][541] = 0.000000 \n",
      "image[7][542] = 0.000000 \n",
      "image[7][543] = 0.000000 \n",
      "image[7][544] = 0.000000 \n",
      "image[7][545] = 0.000000 \n",
      "image[7][546] = 0.000000 \n",
      "image[7][547] = 0.384314 \n",
      "image[7][548] = 0.949020 \n",
      "image[7][549] = 0.988235 \n",
      "image[7][550] = 0.988235 \n",
      "image[7][551] = 0.290196 \n",
      "image[7][552] = 0.000000 \n",
      "image[7][553] = 0.000000 \n",
      "image[7][554] = 0.000000 \n",
      "image[7][555] = 0.000000 \n",
      "image[7][556] = 0.000000 \n",
      "image[7][557] = 0.000000 \n",
      "image[7][558] = 0.000000 \n",
      "image[7][559] = 0.000000 \n",
      "image[7][560] = 0.000000 \n",
      "image[7][561] = 0.000000 \n",
      "image[7][562] = 0.000000 \n",
      "image[7][563] = 0.000000 \n",
      "image[7][564] = 0.000000 \n",
      "image[7][565] = 0.239216 \n",
      "image[7][566] = 0.717647 \n",
      "image[7][567] = 0.988235 \n",
      "image[7][568] = 0.113725 \n",
      "image[7][569] = 0.000000 \n",
      "image[7][570] = 0.000000 \n",
      "image[7][571] = 0.000000 \n",
      "image[7][572] = 0.000000 \n",
      "image[7][573] = 0.070588 \n",
      "image[7][574] = 0.360784 \n",
      "image[7][575] = 0.937255 \n",
      "image[7][576] = 0.988235 \n",
      "image[7][577] = 0.988235 \n",
      "image[7][578] = 0.952941 \n",
      "image[7][579] = 0.254902 \n",
      "image[7][580] = 0.000000 \n",
      "image[7][581] = 0.000000 \n",
      "image[7][582] = 0.000000 \n",
      "image[7][583] = 0.000000 \n",
      "image[7][584] = 0.000000 \n",
      "image[7][585] = 0.000000 \n",
      "image[7][586] = 0.000000 \n",
      "image[7][587] = 0.000000 \n",
      "image[7][588] = 0.000000 \n",
      "image[7][589] = 0.000000 \n",
      "image[7][590] = 0.000000 \n",
      "image[7][591] = 0.000000 \n",
      "image[7][592] = 0.000000 \n",
      "image[7][593] = 0.815686 \n",
      "image[7][594] = 0.988235 \n",
      "image[7][595] = 0.988235 \n",
      "image[7][596] = 0.576471 \n",
      "image[7][597] = 0.525490 \n",
      "image[7][598] = 0.525490 \n",
      "image[7][599] = 0.525490 \n",
      "image[7][600] = 0.525490 \n",
      "image[7][601] = 0.796078 \n",
      "image[7][602] = 0.992157 \n",
      "image[7][603] = 0.988235 \n",
      "image[7][604] = 0.988235 \n",
      "image[7][605] = 0.737255 \n",
      "image[7][606] = 0.325490 \n",
      "image[7][607] = 0.000000 \n",
      "image[7][608] = 0.000000 \n",
      "image[7][609] = 0.000000 \n",
      "image[7][610] = 0.000000 \n",
      "image[7][611] = 0.000000 \n",
      "image[7][612] = 0.000000 \n",
      "image[7][613] = 0.000000 \n",
      "image[7][614] = 0.000000 \n",
      "image[7][615] = 0.000000 \n",
      "image[7][616] = 0.000000 \n",
      "image[7][617] = 0.000000 \n",
      "image[7][618] = 0.000000 \n",
      "image[7][619] = 0.000000 \n",
      "image[7][620] = 0.000000 \n",
      "image[7][621] = 0.815686 \n",
      "image[7][622] = 0.988235 \n",
      "image[7][623] = 0.988235 \n",
      "image[7][624] = 0.988235 \n",
      "image[7][625] = 0.988235 \n",
      "image[7][626] = 0.988235 \n",
      "image[7][627] = 0.988235 \n",
      "image[7][628] = 0.988235 \n",
      "image[7][629] = 0.988235 \n",
      "image[7][630] = 0.992157 \n",
      "image[7][631] = 0.901961 \n",
      "image[7][632] = 0.600000 \n",
      "image[7][633] = 0.031373 \n",
      "image[7][634] = 0.000000 \n",
      "image[7][635] = 0.000000 \n",
      "image[7][636] = 0.000000 \n",
      "image[7][637] = 0.000000 \n",
      "image[7][638] = 0.000000 \n",
      "image[7][639] = 0.000000 \n",
      "image[7][640] = 0.000000 \n",
      "image[7][641] = 0.000000 \n",
      "image[7][642] = 0.000000 \n",
      "image[7][643] = 0.000000 \n",
      "image[7][644] = 0.000000 \n",
      "image[7][645] = 0.000000 \n",
      "image[7][646] = 0.000000 \n",
      "image[7][647] = 0.000000 \n",
      "image[7][648] = 0.000000 \n",
      "image[7][649] = 0.192157 \n",
      "image[7][650] = 0.615686 \n",
      "image[7][651] = 0.988235 \n",
      "image[7][652] = 0.988235 \n",
      "image[7][653] = 0.988235 \n",
      "image[7][654] = 0.988235 \n",
      "image[7][655] = 0.988235 \n",
      "image[7][656] = 0.850980 \n",
      "image[7][657] = 0.811765 \n",
      "image[7][658] = 0.572549 \n",
      "image[7][659] = 0.176471 \n",
      "image[7][660] = 0.000000 \n",
      "image[7][661] = 0.000000 \n",
      "image[7][662] = 0.000000 \n",
      "image[7][663] = 0.000000 \n",
      "image[7][664] = 0.000000 \n",
      "image[7][665] = 0.000000 \n",
      "image[7][666] = 0.000000 \n",
      "image[7][667] = 0.000000 \n",
      "image[7][668] = 0.000000 \n",
      "image[7][669] = 0.000000 \n",
      "image[7][670] = 0.000000 \n",
      "image[7][671] = 0.000000 \n",
      "image[7][672] = 0.000000 \n",
      "image[7][673] = 0.000000 \n",
      "image[7][674] = 0.000000 \n",
      "image[7][675] = 0.000000 \n",
      "image[7][676] = 0.000000 \n",
      "image[7][677] = 0.000000 \n",
      "image[7][678] = 0.027451 \n",
      "image[7][679] = 0.403922 \n",
      "image[7][680] = 0.921569 \n",
      "image[7][681] = 0.988235 \n",
      "image[7][682] = 0.674510 \n",
      "image[7][683] = 0.403922 \n",
      "image[7][684] = 0.094118 \n",
      "image[7][685] = 0.000000 \n",
      "image[7][686] = 0.000000 \n",
      "image[7][687] = 0.000000 \n",
      "image[7][688] = 0.000000 \n",
      "image[7][689] = 0.000000 \n",
      "image[7][690] = 0.000000 \n",
      "image[7][691] = 0.000000 \n",
      "image[7][692] = 0.000000 \n",
      "image[7][693] = 0.000000 \n",
      "image[7][694] = 0.000000 \n",
      "image[7][695] = 0.000000 \n",
      "image[7][696] = 0.000000 \n",
      "image[7][697] = 0.000000 \n",
      "image[7][698] = 0.000000 \n",
      "image[7][699] = 0.000000 \n",
      "image[7][700] = 0.000000 \n",
      "image[7][701] = 0.000000 \n",
      "image[7][702] = 0.000000 \n",
      "image[7][703] = 0.000000 \n",
      "image[7][704] = 0.000000 \n",
      "image[7][705] = 0.000000 \n",
      "image[7][706] = 0.000000 \n",
      "image[7][707] = 0.000000 \n",
      "image[7][708] = 0.000000 \n",
      "image[7][709] = 0.000000 \n",
      "image[7][710] = 0.000000 \n",
      "image[7][711] = 0.000000 \n",
      "image[7][712] = 0.000000 \n",
      "image[7][713] = 0.000000 \n",
      "image[7][714] = 0.000000 \n",
      "image[7][715] = 0.000000 \n",
      "image[7][716] = 0.000000 \n",
      "image[7][717] = 0.000000 \n",
      "image[7][718] = 0.000000 \n",
      "image[7][719] = 0.000000 \n",
      "image[7][720] = 0.000000 \n",
      "image[7][721] = 0.000000 \n",
      "image[7][722] = 0.000000 \n",
      "image[7][723] = 0.000000 \n",
      "image[7][724] = 0.000000 \n",
      "image[7][725] = 0.000000 \n",
      "image[7][726] = 0.000000 \n",
      "image[7][727] = 0.000000 \n",
      "image[7][728] = 0.000000 \n",
      "image[7][729] = 0.000000 \n",
      "image[7][730] = 0.000000 \n",
      "image[7][731] = 0.000000 \n",
      "image[7][732] = 0.000000 \n",
      "image[7][733] = 0.000000 \n",
      "image[7][734] = 0.000000 \n",
      "image[7][735] = 0.000000 \n",
      "image[7][736] = 0.000000 \n",
      "image[7][737] = 0.000000 \n",
      "image[7][738] = 0.000000 \n",
      "image[7][739] = 0.000000 \n",
      "image[7][740] = 0.000000 \n",
      "image[7][741] = 0.000000 \n",
      "image[7][742] = 0.000000 \n",
      "image[7][743] = 0.000000 \n",
      "image[7][744] = 0.000000 \n",
      "image[7][745] = 0.000000 \n",
      "image[7][746] = 0.000000 \n",
      "image[7][747] = 0.000000 \n",
      "image[7][748] = 0.000000 \n",
      "image[7][749] = 0.000000 \n",
      "image[7][750] = 0.000000 \n",
      "image[7][751] = 0.000000 \n",
      "image[7][752] = 0.000000 \n",
      "image[7][753] = 0.000000 \n",
      "image[7][754] = 0.000000 \n",
      "image[7][755] = 0.000000 \n",
      "image[7][756] = 0.000000 \n",
      "image[7][757] = 0.000000 \n",
      "image[7][758] = 0.000000 \n",
      "image[7][759] = 0.000000 \n",
      "image[7][760] = 0.000000 \n",
      "image[7][761] = 0.000000 \n",
      "image[7][762] = 0.000000 \n",
      "image[7][763] = 0.000000 \n",
      "image[7][764] = 0.000000 \n",
      "image[7][765] = 0.000000 \n",
      "image[7][766] = 0.000000 \n",
      "image[7][767] = 0.000000 \n",
      "image[7][768] = 0.000000 \n",
      "image[7][769] = 0.000000 \n",
      "image[7][770] = 0.000000 \n",
      "image[7][771] = 0.000000 \n",
      "image[7][772] = 0.000000 \n",
      "image[7][773] = 0.000000 \n",
      "image[7][774] = 0.000000 \n",
      "image[7][775] = 0.000000 \n",
      "image[7][776] = 0.000000 \n",
      "image[7][777] = 0.000000 \n",
      "image[7][778] = 0.000000 \n",
      "image[7][779] = 0.000000 \n",
      "image[7][780] = 0.000000 \n",
      "image[7][781] = 0.000000 \n",
      "image[7][782] = 0.000000 \n",
      "image[7][783] = 0.000000 \n",
      "image[8][0] = 0.000000 \n",
      "image[8][1] = 0.000000 \n",
      "image[8][2] = 0.000000 \n",
      "image[8][3] = 0.000000 \n",
      "image[8][4] = 0.000000 \n",
      "image[8][5] = 0.000000 \n",
      "image[8][6] = 0.000000 \n",
      "image[8][7] = 0.000000 \n",
      "image[8][8] = 0.000000 \n",
      "image[8][9] = 0.000000 \n",
      "image[8][10] = 0.000000 \n",
      "image[8][11] = 0.000000 \n",
      "image[8][12] = 0.000000 \n",
      "image[8][13] = 0.000000 \n",
      "image[8][14] = 0.000000 \n",
      "image[8][15] = 0.000000 \n",
      "image[8][16] = 0.000000 \n",
      "image[8][17] = 0.000000 \n",
      "image[8][18] = 0.000000 \n",
      "image[8][19] = 0.000000 \n",
      "image[8][20] = 0.000000 \n",
      "image[8][21] = 0.000000 \n",
      "image[8][22] = 0.000000 \n",
      "image[8][23] = 0.000000 \n",
      "image[8][24] = 0.000000 \n",
      "image[8][25] = 0.000000 \n",
      "image[8][26] = 0.000000 \n",
      "image[8][27] = 0.000000 \n",
      "image[8][28] = 0.000000 \n",
      "image[8][29] = 0.000000 \n",
      "image[8][30] = 0.000000 \n",
      "image[8][31] = 0.000000 \n",
      "image[8][32] = 0.000000 \n",
      "image[8][33] = 0.000000 \n",
      "image[8][34] = 0.000000 \n",
      "image[8][35] = 0.000000 \n",
      "image[8][36] = 0.000000 \n",
      "image[8][37] = 0.000000 \n",
      "image[8][38] = 0.000000 \n",
      "image[8][39] = 0.000000 \n",
      "image[8][40] = 0.000000 \n",
      "image[8][41] = 0.000000 \n",
      "image[8][42] = 0.000000 \n",
      "image[8][43] = 0.000000 \n",
      "image[8][44] = 0.000000 \n",
      "image[8][45] = 0.000000 \n",
      "image[8][46] = 0.000000 \n",
      "image[8][47] = 0.000000 \n",
      "image[8][48] = 0.000000 \n",
      "image[8][49] = 0.000000 \n",
      "image[8][50] = 0.000000 \n",
      "image[8][51] = 0.000000 \n",
      "image[8][52] = 0.000000 \n",
      "image[8][53] = 0.000000 \n",
      "image[8][54] = 0.000000 \n",
      "image[8][55] = 0.000000 \n",
      "image[8][56] = 0.000000 \n",
      "image[8][57] = 0.000000 \n",
      "image[8][58] = 0.000000 \n",
      "image[8][59] = 0.000000 \n",
      "image[8][60] = 0.000000 \n",
      "image[8][61] = 0.000000 \n",
      "image[8][62] = 0.000000 \n",
      "image[8][63] = 0.000000 \n",
      "image[8][64] = 0.000000 \n",
      "image[8][65] = 0.000000 \n",
      "image[8][66] = 0.000000 \n",
      "image[8][67] = 0.000000 \n",
      "image[8][68] = 0.000000 \n",
      "image[8][69] = 0.000000 \n",
      "image[8][70] = 0.000000 \n",
      "image[8][71] = 0.000000 \n",
      "image[8][72] = 0.000000 \n",
      "image[8][73] = 0.000000 \n",
      "image[8][74] = 0.000000 \n",
      "image[8][75] = 0.000000 \n",
      "image[8][76] = 0.000000 \n",
      "image[8][77] = 0.000000 \n",
      "image[8][78] = 0.000000 \n",
      "image[8][79] = 0.000000 \n",
      "image[8][80] = 0.000000 \n",
      "image[8][81] = 0.000000 \n",
      "image[8][82] = 0.000000 \n",
      "image[8][83] = 0.000000 \n",
      "image[8][84] = 0.000000 \n",
      "image[8][85] = 0.000000 \n",
      "image[8][86] = 0.000000 \n",
      "image[8][87] = 0.000000 \n",
      "image[8][88] = 0.000000 \n",
      "image[8][89] = 0.000000 \n",
      "image[8][90] = 0.000000 \n",
      "image[8][91] = 0.000000 \n",
      "image[8][92] = 0.000000 \n",
      "image[8][93] = 0.000000 \n",
      "image[8][94] = 0.000000 \n",
      "image[8][95] = 0.000000 \n",
      "image[8][96] = 0.000000 \n",
      "image[8][97] = 0.000000 \n",
      "image[8][98] = 0.000000 \n",
      "image[8][99] = 0.000000 \n",
      "image[8][100] = 0.000000 \n",
      "image[8][101] = 0.000000 \n",
      "image[8][102] = 0.000000 \n",
      "image[8][103] = 0.000000 \n",
      "image[8][104] = 0.000000 \n",
      "image[8][105] = 0.000000 \n",
      "image[8][106] = 0.000000 \n",
      "image[8][107] = 0.000000 \n",
      "image[8][108] = 0.000000 \n",
      "image[8][109] = 0.000000 \n",
      "image[8][110] = 0.000000 \n",
      "image[8][111] = 0.000000 \n",
      "image[8][112] = 0.000000 \n",
      "image[8][113] = 0.000000 \n",
      "image[8][114] = 0.000000 \n",
      "image[8][115] = 0.000000 \n",
      "image[8][116] = 0.000000 \n",
      "image[8][117] = 0.000000 \n",
      "image[8][118] = 0.000000 \n",
      "image[8][119] = 0.000000 \n",
      "image[8][120] = 0.000000 \n",
      "image[8][121] = 0.000000 \n",
      "image[8][122] = 0.000000 \n",
      "image[8][123] = 0.000000 \n",
      "image[8][124] = 0.000000 \n",
      "image[8][125] = 0.000000 \n",
      "image[8][126] = 0.000000 \n",
      "image[8][127] = 0.000000 \n",
      "image[8][128] = 0.000000 \n",
      "image[8][129] = 0.000000 \n",
      "image[8][130] = 0.000000 \n",
      "image[8][131] = 0.000000 \n",
      "image[8][132] = 0.000000 \n",
      "image[8][133] = 0.000000 \n",
      "image[8][134] = 0.000000 \n",
      "image[8][135] = 0.000000 \n",
      "image[8][136] = 0.000000 \n",
      "image[8][137] = 0.000000 \n",
      "image[8][138] = 0.000000 \n",
      "image[8][139] = 0.000000 \n",
      "image[8][140] = 0.000000 \n",
      "image[8][141] = 0.000000 \n",
      "image[8][142] = 0.000000 \n",
      "image[8][143] = 0.000000 \n",
      "image[8][144] = 0.000000 \n",
      "image[8][145] = 0.000000 \n",
      "image[8][146] = 0.000000 \n",
      "image[8][147] = 0.000000 \n",
      "image[8][148] = 0.000000 \n",
      "image[8][149] = 0.000000 \n",
      "image[8][150] = 0.000000 \n",
      "image[8][151] = 0.000000 \n",
      "image[8][152] = 0.019608 \n",
      "image[8][153] = 0.247059 \n",
      "image[8][154] = 0.772549 \n",
      "image[8][155] = 0.000000 \n",
      "image[8][156] = 0.000000 \n",
      "image[8][157] = 0.000000 \n",
      "image[8][158] = 0.000000 \n",
      "image[8][159] = 0.000000 \n",
      "image[8][160] = 0.000000 \n",
      "image[8][161] = 0.000000 \n",
      "image[8][162] = 0.000000 \n",
      "image[8][163] = 0.000000 \n",
      "image[8][164] = 0.000000 \n",
      "image[8][165] = 0.000000 \n",
      "image[8][166] = 0.000000 \n",
      "image[8][167] = 0.000000 \n",
      "image[8][168] = 0.000000 \n",
      "image[8][169] = 0.000000 \n",
      "image[8][170] = 0.000000 \n",
      "image[8][171] = 0.000000 \n",
      "image[8][172] = 0.000000 \n",
      "image[8][173] = 0.000000 \n",
      "image[8][174] = 0.000000 \n",
      "image[8][175] = 0.000000 \n",
      "image[8][176] = 0.000000 \n",
      "image[8][177] = 0.000000 \n",
      "image[8][178] = 0.000000 \n",
      "image[8][179] = 0.000000 \n",
      "image[8][180] = 0.078431 \n",
      "image[8][181] = 0.996078 \n",
      "image[8][182] = 0.901961 \n",
      "image[8][183] = 0.094118 \n",
      "image[8][184] = 0.000000 \n",
      "image[8][185] = 0.000000 \n",
      "image[8][186] = 0.000000 \n",
      "image[8][187] = 0.000000 \n",
      "image[8][188] = 0.000000 \n",
      "image[8][189] = 0.000000 \n",
      "image[8][190] = 0.000000 \n",
      "image[8][191] = 0.000000 \n",
      "image[8][192] = 0.000000 \n",
      "image[8][193] = 0.000000 \n",
      "image[8][194] = 0.000000 \n",
      "image[8][195] = 0.000000 \n",
      "image[8][196] = 0.000000 \n",
      "image[8][197] = 0.000000 \n",
      "image[8][198] = 0.000000 \n",
      "image[8][199] = 0.000000 \n",
      "image[8][200] = 0.000000 \n",
      "image[8][201] = 0.000000 \n",
      "image[8][202] = 0.000000 \n",
      "image[8][203] = 0.000000 \n",
      "image[8][204] = 0.000000 \n",
      "image[8][205] = 0.000000 \n",
      "image[8][206] = 0.000000 \n",
      "image[8][207] = 0.000000 \n",
      "image[8][208] = 0.078431 \n",
      "image[8][209] = 0.996078 \n",
      "image[8][210] = 0.996078 \n",
      "image[8][211] = 0.188235 \n",
      "image[8][212] = 0.000000 \n",
      "image[8][213] = 0.000000 \n",
      "image[8][214] = 0.000000 \n",
      "image[8][215] = 0.000000 \n",
      "image[8][216] = 0.000000 \n",
      "image[8][217] = 0.000000 \n",
      "image[8][218] = 0.000000 \n",
      "image[8][219] = 0.000000 \n",
      "image[8][220] = 0.000000 \n",
      "image[8][221] = 0.000000 \n",
      "image[8][222] = 0.000000 \n",
      "image[8][223] = 0.000000 \n",
      "image[8][224] = 0.000000 \n",
      "image[8][225] = 0.000000 \n",
      "image[8][226] = 0.000000 \n",
      "image[8][227] = 0.000000 \n",
      "image[8][228] = 0.000000 \n",
      "image[8][229] = 0.000000 \n",
      "image[8][230] = 0.000000 \n",
      "image[8][231] = 0.000000 \n",
      "image[8][232] = 0.000000 \n",
      "image[8][233] = 0.000000 \n",
      "image[8][234] = 0.000000 \n",
      "image[8][235] = 0.000000 \n",
      "image[8][236] = 0.078431 \n",
      "image[8][237] = 0.996078 \n",
      "image[8][238] = 1.000000 \n",
      "image[8][239] = 0.188235 \n",
      "image[8][240] = 0.000000 \n",
      "image[8][241] = 0.000000 \n",
      "image[8][242] = 0.000000 \n",
      "image[8][243] = 0.000000 \n",
      "image[8][244] = 0.000000 \n",
      "image[8][245] = 0.000000 \n",
      "image[8][246] = 0.000000 \n",
      "image[8][247] = 0.000000 \n",
      "image[8][248] = 0.000000 \n",
      "image[8][249] = 0.000000 \n",
      "image[8][250] = 0.000000 \n",
      "image[8][251] = 0.000000 \n",
      "image[8][252] = 0.000000 \n",
      "image[8][253] = 0.000000 \n",
      "image[8][254] = 0.000000 \n",
      "image[8][255] = 0.000000 \n",
      "image[8][256] = 0.000000 \n",
      "image[8][257] = 0.000000 \n",
      "image[8][258] = 0.000000 \n",
      "image[8][259] = 0.000000 \n",
      "image[8][260] = 0.000000 \n",
      "image[8][261] = 0.000000 \n",
      "image[8][262] = 0.000000 \n",
      "image[8][263] = 0.000000 \n",
      "image[8][264] = 0.078431 \n",
      "image[8][265] = 0.996078 \n",
      "image[8][266] = 0.996078 \n",
      "image[8][267] = 0.223529 \n",
      "image[8][268] = 0.000000 \n",
      "image[8][269] = 0.000000 \n",
      "image[8][270] = 0.000000 \n",
      "image[8][271] = 0.000000 \n",
      "image[8][272] = 0.000000 \n",
      "image[8][273] = 0.000000 \n",
      "image[8][274] = 0.000000 \n",
      "image[8][275] = 0.000000 \n",
      "image[8][276] = 0.000000 \n",
      "image[8][277] = 0.000000 \n",
      "image[8][278] = 0.000000 \n",
      "image[8][279] = 0.000000 \n",
      "image[8][280] = 0.000000 \n",
      "image[8][281] = 0.000000 \n",
      "image[8][282] = 0.000000 \n",
      "image[8][283] = 0.000000 \n",
      "image[8][284] = 0.000000 \n",
      "image[8][285] = 0.000000 \n",
      "image[8][286] = 0.000000 \n",
      "image[8][287] = 0.000000 \n",
      "image[8][288] = 0.000000 \n",
      "image[8][289] = 0.000000 \n",
      "image[8][290] = 0.000000 \n",
      "image[8][291] = 0.000000 \n",
      "image[8][292] = 0.078431 \n",
      "image[8][293] = 0.996078 \n",
      "image[8][294] = 0.996078 \n",
      "image[8][295] = 0.423529 \n",
      "image[8][296] = 0.000000 \n",
      "image[8][297] = 0.000000 \n",
      "image[8][298] = 0.000000 \n",
      "image[8][299] = 0.000000 \n",
      "image[8][300] = 0.000000 \n",
      "image[8][301] = 0.000000 \n",
      "image[8][302] = 0.000000 \n",
      "image[8][303] = 0.000000 \n",
      "image[8][304] = 0.000000 \n",
      "image[8][305] = 0.000000 \n",
      "image[8][306] = 0.000000 \n",
      "image[8][307] = 0.000000 \n",
      "image[8][308] = 0.000000 \n",
      "image[8][309] = 0.000000 \n",
      "image[8][310] = 0.000000 \n",
      "image[8][311] = 0.000000 \n",
      "image[8][312] = 0.000000 \n",
      "image[8][313] = 0.000000 \n",
      "image[8][314] = 0.000000 \n",
      "image[8][315] = 0.000000 \n",
      "image[8][316] = 0.000000 \n",
      "image[8][317] = 0.000000 \n",
      "image[8][318] = 0.000000 \n",
      "image[8][319] = 0.000000 \n",
      "image[8][320] = 0.062745 \n",
      "image[8][321] = 0.937255 \n",
      "image[8][322] = 0.996078 \n",
      "image[8][323] = 0.560784 \n",
      "image[8][324] = 0.000000 \n",
      "image[8][325] = 0.000000 \n",
      "image[8][326] = 0.000000 \n",
      "image[8][327] = 0.000000 \n",
      "image[8][328] = 0.000000 \n",
      "image[8][329] = 0.000000 \n",
      "image[8][330] = 0.000000 \n",
      "image[8][331] = 0.000000 \n",
      "image[8][332] = 0.000000 \n",
      "image[8][333] = 0.000000 \n",
      "image[8][334] = 0.000000 \n",
      "image[8][335] = 0.000000 \n",
      "image[8][336] = 0.000000 \n",
      "image[8][337] = 0.000000 \n",
      "image[8][338] = 0.000000 \n",
      "image[8][339] = 0.000000 \n",
      "image[8][340] = 0.000000 \n",
      "image[8][341] = 0.000000 \n",
      "image[8][342] = 0.000000 \n",
      "image[8][343] = 0.000000 \n",
      "image[8][344] = 0.000000 \n",
      "image[8][345] = 0.000000 \n",
      "image[8][346] = 0.000000 \n",
      "image[8][347] = 0.000000 \n",
      "image[8][348] = 0.000000 \n",
      "image[8][349] = 0.698039 \n",
      "image[8][350] = 0.996078 \n",
      "image[8][351] = 0.560784 \n",
      "image[8][352] = 0.000000 \n",
      "image[8][353] = 0.000000 \n",
      "image[8][354] = 0.000000 \n",
      "image[8][355] = 0.000000 \n",
      "image[8][356] = 0.000000 \n",
      "image[8][357] = 0.000000 \n",
      "image[8][358] = 0.000000 \n",
      "image[8][359] = 0.000000 \n",
      "image[8][360] = 0.000000 \n",
      "image[8][361] = 0.000000 \n",
      "image[8][362] = 0.000000 \n",
      "image[8][363] = 0.000000 \n",
      "image[8][364] = 0.000000 \n",
      "image[8][365] = 0.000000 \n",
      "image[8][366] = 0.000000 \n",
      "image[8][367] = 0.000000 \n",
      "image[8][368] = 0.000000 \n",
      "image[8][369] = 0.000000 \n",
      "image[8][370] = 0.000000 \n",
      "image[8][371] = 0.000000 \n",
      "image[8][372] = 0.000000 \n",
      "image[8][373] = 0.000000 \n",
      "image[8][374] = 0.000000 \n",
      "image[8][375] = 0.000000 \n",
      "image[8][376] = 0.000000 \n",
      "image[8][377] = 0.698039 \n",
      "image[8][378] = 0.996078 \n",
      "image[8][379] = 0.560784 \n",
      "image[8][380] = 0.000000 \n",
      "image[8][381] = 0.000000 \n",
      "image[8][382] = 0.000000 \n",
      "image[8][383] = 0.000000 \n",
      "image[8][384] = 0.000000 \n",
      "image[8][385] = 0.000000 \n",
      "image[8][386] = 0.000000 \n",
      "image[8][387] = 0.000000 \n",
      "image[8][388] = 0.000000 \n",
      "image[8][389] = 0.000000 \n",
      "image[8][390] = 0.000000 \n",
      "image[8][391] = 0.000000 \n",
      "image[8][392] = 0.000000 \n",
      "image[8][393] = 0.000000 \n",
      "image[8][394] = 0.000000 \n",
      "image[8][395] = 0.000000 \n",
      "image[8][396] = 0.000000 \n",
      "image[8][397] = 0.000000 \n",
      "image[8][398] = 0.000000 \n",
      "image[8][399] = 0.000000 \n",
      "image[8][400] = 0.000000 \n",
      "image[8][401] = 0.000000 \n",
      "image[8][402] = 0.000000 \n",
      "image[8][403] = 0.000000 \n",
      "image[8][404] = 0.000000 \n",
      "image[8][405] = 0.698039 \n",
      "image[8][406] = 0.996078 \n",
      "image[8][407] = 0.635294 \n",
      "image[8][408] = 0.000000 \n",
      "image[8][409] = 0.000000 \n",
      "image[8][410] = 0.000000 \n",
      "image[8][411] = 0.000000 \n",
      "image[8][412] = 0.000000 \n",
      "image[8][413] = 0.000000 \n",
      "image[8][414] = 0.000000 \n",
      "image[8][415] = 0.000000 \n",
      "image[8][416] = 0.000000 \n",
      "image[8][417] = 0.000000 \n",
      "image[8][418] = 0.000000 \n",
      "image[8][419] = 0.000000 \n",
      "image[8][420] = 0.000000 \n",
      "image[8][421] = 0.000000 \n",
      "image[8][422] = 0.000000 \n",
      "image[8][423] = 0.000000 \n",
      "image[8][424] = 0.000000 \n",
      "image[8][425] = 0.000000 \n",
      "image[8][426] = 0.000000 \n",
      "image[8][427] = 0.000000 \n",
      "image[8][428] = 0.000000 \n",
      "image[8][429] = 0.000000 \n",
      "image[8][430] = 0.000000 \n",
      "image[8][431] = 0.000000 \n",
      "image[8][432] = 0.000000 \n",
      "image[8][433] = 0.698039 \n",
      "image[8][434] = 0.996078 \n",
      "image[8][435] = 0.941176 \n",
      "image[8][436] = 0.000000 \n",
      "image[8][437] = 0.000000 \n",
      "image[8][438] = 0.000000 \n",
      "image[8][439] = 0.000000 \n",
      "image[8][440] = 0.000000 \n",
      "image[8][441] = 0.000000 \n",
      "image[8][442] = 0.000000 \n",
      "image[8][443] = 0.000000 \n",
      "image[8][444] = 0.000000 \n",
      "image[8][445] = 0.000000 \n",
      "image[8][446] = 0.000000 \n",
      "image[8][447] = 0.000000 \n",
      "image[8][448] = 0.000000 \n",
      "image[8][449] = 0.000000 \n",
      "image[8][450] = 0.000000 \n",
      "image[8][451] = 0.000000 \n",
      "image[8][452] = 0.000000 \n",
      "image[8][453] = 0.000000 \n",
      "image[8][454] = 0.000000 \n",
      "image[8][455] = 0.000000 \n",
      "image[8][456] = 0.000000 \n",
      "image[8][457] = 0.000000 \n",
      "image[8][458] = 0.000000 \n",
      "image[8][459] = 0.000000 \n",
      "image[8][460] = 0.000000 \n",
      "image[8][461] = 0.443137 \n",
      "image[8][462] = 0.996078 \n",
      "image[8][463] = 0.941176 \n",
      "image[8][464] = 0.000000 \n",
      "image[8][465] = 0.000000 \n",
      "image[8][466] = 0.000000 \n",
      "image[8][467] = 0.000000 \n",
      "image[8][468] = 0.000000 \n",
      "image[8][469] = 0.000000 \n",
      "image[8][470] = 0.000000 \n",
      "image[8][471] = 0.000000 \n",
      "image[8][472] = 0.000000 \n",
      "image[8][473] = 0.000000 \n",
      "image[8][474] = 0.000000 \n",
      "image[8][475] = 0.000000 \n",
      "image[8][476] = 0.000000 \n",
      "image[8][477] = 0.000000 \n",
      "image[8][478] = 0.000000 \n",
      "image[8][479] = 0.000000 \n",
      "image[8][480] = 0.000000 \n",
      "image[8][481] = 0.000000 \n",
      "image[8][482] = 0.000000 \n",
      "image[8][483] = 0.000000 \n",
      "image[8][484] = 0.000000 \n",
      "image[8][485] = 0.000000 \n",
      "image[8][486] = 0.000000 \n",
      "image[8][487] = 0.000000 \n",
      "image[8][488] = 0.000000 \n",
      "image[8][489] = 0.325490 \n",
      "image[8][490] = 0.996078 \n",
      "image[8][491] = 0.960784 \n",
      "image[8][492] = 0.121569 \n",
      "image[8][493] = 0.000000 \n",
      "image[8][494] = 0.000000 \n",
      "image[8][495] = 0.000000 \n",
      "image[8][496] = 0.000000 \n",
      "image[8][497] = 0.000000 \n",
      "image[8][498] = 0.000000 \n",
      "image[8][499] = 0.000000 \n",
      "image[8][500] = 0.000000 \n",
      "image[8][501] = 0.000000 \n",
      "image[8][502] = 0.000000 \n",
      "image[8][503] = 0.000000 \n",
      "image[8][504] = 0.000000 \n",
      "image[8][505] = 0.000000 \n",
      "image[8][506] = 0.000000 \n",
      "image[8][507] = 0.000000 \n",
      "image[8][508] = 0.000000 \n",
      "image[8][509] = 0.000000 \n",
      "image[8][510] = 0.000000 \n",
      "image[8][511] = 0.000000 \n",
      "image[8][512] = 0.000000 \n",
      "image[8][513] = 0.000000 \n",
      "image[8][514] = 0.000000 \n",
      "image[8][515] = 0.000000 \n",
      "image[8][516] = 0.000000 \n",
      "image[8][517] = 0.309804 \n",
      "image[8][518] = 0.996078 \n",
      "image[8][519] = 0.964706 \n",
      "image[8][520] = 0.149020 \n",
      "image[8][521] = 0.000000 \n",
      "image[8][522] = 0.000000 \n",
      "image[8][523] = 0.000000 \n",
      "image[8][524] = 0.000000 \n",
      "image[8][525] = 0.000000 \n",
      "image[8][526] = 0.000000 \n",
      "image[8][527] = 0.000000 \n",
      "image[8][528] = 0.000000 \n",
      "image[8][529] = 0.000000 \n",
      "image[8][530] = 0.000000 \n",
      "image[8][531] = 0.000000 \n",
      "image[8][532] = 0.000000 \n",
      "image[8][533] = 0.000000 \n",
      "image[8][534] = 0.000000 \n",
      "image[8][535] = 0.000000 \n",
      "image[8][536] = 0.000000 \n",
      "image[8][537] = 0.000000 \n",
      "image[8][538] = 0.000000 \n",
      "image[8][539] = 0.000000 \n",
      "image[8][540] = 0.000000 \n",
      "image[8][541] = 0.000000 \n",
      "image[8][542] = 0.000000 \n",
      "image[8][543] = 0.000000 \n",
      "image[8][544] = 0.000000 \n",
      "image[8][545] = 0.000000 \n",
      "image[8][546] = 0.839216 \n",
      "image[8][547] = 0.996078 \n",
      "image[8][548] = 0.588235 \n",
      "image[8][549] = 0.000000 \n",
      "image[8][550] = 0.000000 \n",
      "image[8][551] = 0.000000 \n",
      "image[8][552] = 0.000000 \n",
      "image[8][553] = 0.000000 \n",
      "image[8][554] = 0.000000 \n",
      "image[8][555] = 0.000000 \n",
      "image[8][556] = 0.000000 \n",
      "image[8][557] = 0.000000 \n",
      "image[8][558] = 0.000000 \n",
      "image[8][559] = 0.000000 \n",
      "image[8][560] = 0.000000 \n",
      "image[8][561] = 0.000000 \n",
      "image[8][562] = 0.000000 \n",
      "image[8][563] = 0.000000 \n",
      "image[8][564] = 0.000000 \n",
      "image[8][565] = 0.000000 \n",
      "image[8][566] = 0.000000 \n",
      "image[8][567] = 0.000000 \n",
      "image[8][568] = 0.000000 \n",
      "image[8][569] = 0.000000 \n",
      "image[8][570] = 0.000000 \n",
      "image[8][571] = 0.000000 \n",
      "image[8][572] = 0.000000 \n",
      "image[8][573] = 0.000000 \n",
      "image[8][574] = 0.564706 \n",
      "image[8][575] = 0.945098 \n",
      "image[8][576] = 0.031373 \n",
      "image[8][577] = 0.000000 \n",
      "image[8][578] = 0.000000 \n",
      "image[8][579] = 0.000000 \n",
      "image[8][580] = 0.000000 \n",
      "image[8][581] = 0.000000 \n",
      "image[8][582] = 0.000000 \n",
      "image[8][583] = 0.000000 \n",
      "image[8][584] = 0.000000 \n",
      "image[8][585] = 0.000000 \n",
      "image[8][586] = 0.000000 \n",
      "image[8][587] = 0.000000 \n",
      "image[8][588] = 0.000000 \n",
      "image[8][589] = 0.000000 \n",
      "image[8][590] = 0.000000 \n",
      "image[8][591] = 0.000000 \n",
      "image[8][592] = 0.000000 \n",
      "image[8][593] = 0.000000 \n",
      "image[8][594] = 0.000000 \n",
      "image[8][595] = 0.000000 \n",
      "image[8][596] = 0.000000 \n",
      "image[8][597] = 0.000000 \n",
      "image[8][598] = 0.000000 \n",
      "image[8][599] = 0.000000 \n",
      "image[8][600] = 0.000000 \n",
      "image[8][601] = 0.000000 \n",
      "image[8][602] = 0.564706 \n",
      "image[8][603] = 0.941176 \n",
      "image[8][604] = 0.007843 \n",
      "image[8][605] = 0.000000 \n",
      "image[8][606] = 0.000000 \n",
      "image[8][607] = 0.000000 \n",
      "image[8][608] = 0.000000 \n",
      "image[8][609] = 0.000000 \n",
      "image[8][610] = 0.000000 \n",
      "image[8][611] = 0.000000 \n",
      "image[8][612] = 0.000000 \n",
      "image[8][613] = 0.000000 \n",
      "image[8][614] = 0.000000 \n",
      "image[8][615] = 0.000000 \n",
      "image[8][616] = 0.000000 \n",
      "image[8][617] = 0.000000 \n",
      "image[8][618] = 0.000000 \n",
      "image[8][619] = 0.000000 \n",
      "image[8][620] = 0.000000 \n",
      "image[8][621] = 0.000000 \n",
      "image[8][622] = 0.000000 \n",
      "image[8][623] = 0.000000 \n",
      "image[8][624] = 0.000000 \n",
      "image[8][625] = 0.000000 \n",
      "image[8][626] = 0.000000 \n",
      "image[8][627] = 0.000000 \n",
      "image[8][628] = 0.000000 \n",
      "image[8][629] = 0.000000 \n",
      "image[8][630] = 0.564706 \n",
      "image[8][631] = 0.996078 \n",
      "image[8][632] = 0.321569 \n",
      "image[8][633] = 0.000000 \n",
      "image[8][634] = 0.000000 \n",
      "image[8][635] = 0.000000 \n",
      "image[8][636] = 0.000000 \n",
      "image[8][637] = 0.000000 \n",
      "image[8][638] = 0.000000 \n",
      "image[8][639] = 0.000000 \n",
      "image[8][640] = 0.000000 \n",
      "image[8][641] = 0.000000 \n",
      "image[8][642] = 0.000000 \n",
      "image[8][643] = 0.000000 \n",
      "image[8][644] = 0.000000 \n",
      "image[8][645] = 0.000000 \n",
      "image[8][646] = 0.000000 \n",
      "image[8][647] = 0.000000 \n",
      "image[8][648] = 0.000000 \n",
      "image[8][649] = 0.000000 \n",
      "image[8][650] = 0.000000 \n",
      "image[8][651] = 0.000000 \n",
      "image[8][652] = 0.000000 \n",
      "image[8][653] = 0.000000 \n",
      "image[8][654] = 0.000000 \n",
      "image[8][655] = 0.000000 \n",
      "image[8][656] = 0.000000 \n",
      "image[8][657] = 0.000000 \n",
      "image[8][658] = 0.901961 \n",
      "image[8][659] = 0.968627 \n",
      "image[8][660] = 0.156863 \n",
      "image[8][661] = 0.000000 \n",
      "image[8][662] = 0.000000 \n",
      "image[8][663] = 0.000000 \n",
      "image[8][664] = 0.000000 \n",
      "image[8][665] = 0.000000 \n",
      "image[8][666] = 0.000000 \n",
      "image[8][667] = 0.000000 \n",
      "image[8][668] = 0.000000 \n",
      "image[8][669] = 0.000000 \n",
      "image[8][670] = 0.000000 \n",
      "image[8][671] = 0.000000 \n",
      "image[8][672] = 0.000000 \n",
      "image[8][673] = 0.000000 \n",
      "image[8][674] = 0.000000 \n",
      "image[8][675] = 0.000000 \n",
      "image[8][676] = 0.000000 \n",
      "image[8][677] = 0.000000 \n",
      "image[8][678] = 0.000000 \n",
      "image[8][679] = 0.000000 \n",
      "image[8][680] = 0.000000 \n",
      "image[8][681] = 0.000000 \n",
      "image[8][682] = 0.000000 \n",
      "image[8][683] = 0.000000 \n",
      "image[8][684] = 0.000000 \n",
      "image[8][685] = 0.000000 \n",
      "image[8][686] = 0.658824 \n",
      "image[8][687] = 0.819608 \n",
      "image[8][688] = 0.121569 \n",
      "image[8][689] = 0.000000 \n",
      "image[8][690] = 0.000000 \n",
      "image[8][691] = 0.000000 \n",
      "image[8][692] = 0.000000 \n",
      "image[8][693] = 0.000000 \n",
      "image[8][694] = 0.000000 \n",
      "image[8][695] = 0.000000 \n",
      "image[8][696] = 0.000000 \n",
      "image[8][697] = 0.000000 \n",
      "image[8][698] = 0.000000 \n",
      "image[8][699] = 0.000000 \n",
      "image[8][700] = 0.000000 \n",
      "image[8][701] = 0.000000 \n",
      "image[8][702] = 0.000000 \n",
      "image[8][703] = 0.000000 \n",
      "image[8][704] = 0.000000 \n",
      "image[8][705] = 0.000000 \n",
      "image[8][706] = 0.000000 \n",
      "image[8][707] = 0.000000 \n",
      "image[8][708] = 0.000000 \n",
      "image[8][709] = 0.000000 \n",
      "image[8][710] = 0.000000 \n",
      "image[8][711] = 0.000000 \n",
      "image[8][712] = 0.000000 \n",
      "image[8][713] = 0.000000 \n",
      "image[8][714] = 0.000000 \n",
      "image[8][715] = 0.000000 \n",
      "image[8][716] = 0.000000 \n",
      "image[8][717] = 0.000000 \n",
      "image[8][718] = 0.000000 \n",
      "image[8][719] = 0.000000 \n",
      "image[8][720] = 0.000000 \n",
      "image[8][721] = 0.000000 \n",
      "image[8][722] = 0.000000 \n",
      "image[8][723] = 0.000000 \n",
      "image[8][724] = 0.000000 \n",
      "image[8][725] = 0.000000 \n",
      "image[8][726] = 0.000000 \n",
      "image[8][727] = 0.000000 \n",
      "image[8][728] = 0.000000 \n",
      "image[8][729] = 0.000000 \n",
      "image[8][730] = 0.000000 \n",
      "image[8][731] = 0.000000 \n",
      "image[8][732] = 0.000000 \n",
      "image[8][733] = 0.000000 \n",
      "image[8][734] = 0.000000 \n",
      "image[8][735] = 0.000000 \n",
      "image[8][736] = 0.000000 \n",
      "image[8][737] = 0.000000 \n",
      "image[8][738] = 0.000000 \n",
      "image[8][739] = 0.000000 \n",
      "image[8][740] = 0.000000 \n",
      "image[8][741] = 0.000000 \n",
      "image[8][742] = 0.000000 \n",
      "image[8][743] = 0.000000 \n",
      "image[8][744] = 0.000000 \n",
      "image[8][745] = 0.000000 \n",
      "image[8][746] = 0.000000 \n",
      "image[8][747] = 0.000000 \n",
      "image[8][748] = 0.000000 \n",
      "image[8][749] = 0.000000 \n",
      "image[8][750] = 0.000000 \n",
      "image[8][751] = 0.000000 \n",
      "image[8][752] = 0.000000 \n",
      "image[8][753] = 0.000000 \n",
      "image[8][754] = 0.000000 \n",
      "image[8][755] = 0.000000 \n",
      "image[8][756] = 0.000000 \n",
      "image[8][757] = 0.000000 \n",
      "image[8][758] = 0.000000 \n",
      "image[8][759] = 0.000000 \n",
      "image[8][760] = 0.000000 \n",
      "image[8][761] = 0.000000 \n",
      "image[8][762] = 0.000000 \n",
      "image[8][763] = 0.000000 \n",
      "image[8][764] = 0.000000 \n",
      "image[8][765] = 0.000000 \n",
      "image[8][766] = 0.000000 \n",
      "image[8][767] = 0.000000 \n",
      "image[8][768] = 0.000000 \n",
      "image[8][769] = 0.000000 \n",
      "image[8][770] = 0.000000 \n",
      "image[8][771] = 0.000000 \n",
      "image[8][772] = 0.000000 \n",
      "image[8][773] = 0.000000 \n",
      "image[8][774] = 0.000000 \n",
      "image[8][775] = 0.000000 \n",
      "image[8][776] = 0.000000 \n",
      "image[8][777] = 0.000000 \n",
      "image[8][778] = 0.000000 \n",
      "image[8][779] = 0.000000 \n",
      "image[8][780] = 0.000000 \n",
      "image[8][781] = 0.000000 \n",
      "image[8][782] = 0.000000 \n",
      "image[8][783] = 0.000000 \n",
      "image[9][0] = 0.000000 \n",
      "image[9][1] = 0.000000 \n",
      "image[9][2] = 0.000000 \n",
      "image[9][3] = 0.000000 \n",
      "image[9][4] = 0.000000 \n",
      "image[9][5] = 0.000000 \n",
      "image[9][6] = 0.000000 \n",
      "image[9][7] = 0.000000 \n",
      "image[9][8] = 0.000000 \n",
      "image[9][9] = 0.000000 \n",
      "image[9][10] = 0.000000 \n",
      "image[9][11] = 0.000000 \n",
      "image[9][12] = 0.000000 \n",
      "image[9][13] = 0.000000 \n",
      "image[9][14] = 0.000000 \n",
      "image[9][15] = 0.000000 \n",
      "image[9][16] = 0.000000 \n",
      "image[9][17] = 0.000000 \n",
      "image[9][18] = 0.000000 \n",
      "image[9][19] = 0.000000 \n",
      "image[9][20] = 0.000000 \n",
      "image[9][21] = 0.000000 \n",
      "image[9][22] = 0.000000 \n",
      "image[9][23] = 0.000000 \n",
      "image[9][24] = 0.000000 \n",
      "image[9][25] = 0.000000 \n",
      "image[9][26] = 0.000000 \n",
      "image[9][27] = 0.000000 \n",
      "image[9][28] = 0.000000 \n",
      "image[9][29] = 0.000000 \n",
      "image[9][30] = 0.000000 \n",
      "image[9][31] = 0.000000 \n",
      "image[9][32] = 0.000000 \n",
      "image[9][33] = 0.000000 \n",
      "image[9][34] = 0.000000 \n",
      "image[9][35] = 0.000000 \n",
      "image[9][36] = 0.000000 \n",
      "image[9][37] = 0.000000 \n",
      "image[9][38] = 0.000000 \n",
      "image[9][39] = 0.000000 \n",
      "image[9][40] = 0.000000 \n",
      "image[9][41] = 0.000000 \n",
      "image[9][42] = 0.000000 \n",
      "image[9][43] = 0.000000 \n",
      "image[9][44] = 0.000000 \n",
      "image[9][45] = 0.000000 \n",
      "image[9][46] = 0.000000 \n",
      "image[9][47] = 0.000000 \n",
      "image[9][48] = 0.000000 \n",
      "image[9][49] = 0.000000 \n",
      "image[9][50] = 0.000000 \n",
      "image[9][51] = 0.000000 \n",
      "image[9][52] = 0.000000 \n",
      "image[9][53] = 0.000000 \n",
      "image[9][54] = 0.000000 \n",
      "image[9][55] = 0.000000 \n",
      "image[9][56] = 0.000000 \n",
      "image[9][57] = 0.000000 \n",
      "image[9][58] = 0.000000 \n",
      "image[9][59] = 0.000000 \n",
      "image[9][60] = 0.000000 \n",
      "image[9][61] = 0.000000 \n",
      "image[9][62] = 0.000000 \n",
      "image[9][63] = 0.000000 \n",
      "image[9][64] = 0.000000 \n",
      "image[9][65] = 0.000000 \n",
      "image[9][66] = 0.000000 \n",
      "image[9][67] = 0.000000 \n",
      "image[9][68] = 0.000000 \n",
      "image[9][69] = 0.000000 \n",
      "image[9][70] = 0.000000 \n",
      "image[9][71] = 0.000000 \n",
      "image[9][72] = 0.000000 \n",
      "image[9][73] = 0.000000 \n",
      "image[9][74] = 0.000000 \n",
      "image[9][75] = 0.000000 \n",
      "image[9][76] = 0.000000 \n",
      "image[9][77] = 0.000000 \n",
      "image[9][78] = 0.000000 \n",
      "image[9][79] = 0.000000 \n",
      "image[9][80] = 0.000000 \n",
      "image[9][81] = 0.000000 \n",
      "image[9][82] = 0.000000 \n",
      "image[9][83] = 0.000000 \n",
      "image[9][84] = 0.000000 \n",
      "image[9][85] = 0.000000 \n",
      "image[9][86] = 0.000000 \n",
      "image[9][87] = 0.000000 \n",
      "image[9][88] = 0.000000 \n",
      "image[9][89] = 0.000000 \n",
      "image[9][90] = 0.000000 \n",
      "image[9][91] = 0.000000 \n",
      "image[9][92] = 0.000000 \n",
      "image[9][93] = 0.000000 \n",
      "image[9][94] = 0.000000 \n",
      "image[9][95] = 0.000000 \n",
      "image[9][96] = 0.000000 \n",
      "image[9][97] = 0.000000 \n",
      "image[9][98] = 0.000000 \n",
      "image[9][99] = 0.000000 \n",
      "image[9][100] = 0.000000 \n",
      "image[9][101] = 0.000000 \n",
      "image[9][102] = 0.000000 \n",
      "image[9][103] = 0.000000 \n",
      "image[9][104] = 0.000000 \n",
      "image[9][105] = 0.000000 \n",
      "image[9][106] = 0.000000 \n",
      "image[9][107] = 0.000000 \n",
      "image[9][108] = 0.000000 \n",
      "image[9][109] = 0.000000 \n",
      "image[9][110] = 0.000000 \n",
      "image[9][111] = 0.000000 \n",
      "image[9][112] = 0.000000 \n",
      "image[9][113] = 0.000000 \n",
      "image[9][114] = 0.000000 \n",
      "image[9][115] = 0.000000 \n",
      "image[9][116] = 0.000000 \n",
      "image[9][117] = 0.000000 \n",
      "image[9][118] = 0.000000 \n",
      "image[9][119] = 0.000000 \n",
      "image[9][120] = 0.000000 \n",
      "image[9][121] = 0.000000 \n",
      "image[9][122] = 0.000000 \n",
      "image[9][123] = 0.000000 \n",
      "image[9][124] = 0.000000 \n",
      "image[9][125] = 0.000000 \n",
      "image[9][126] = 0.000000 \n",
      "image[9][127] = 0.000000 \n",
      "image[9][128] = 0.000000 \n",
      "image[9][129] = 0.000000 \n",
      "image[9][130] = 0.000000 \n",
      "image[9][131] = 0.000000 \n",
      "image[9][132] = 0.000000 \n",
      "image[9][133] = 0.000000 \n",
      "image[9][134] = 0.741176 \n",
      "image[9][135] = 0.745098 \n",
      "image[9][136] = 0.000000 \n",
      "image[9][137] = 0.000000 \n",
      "image[9][138] = 0.000000 \n",
      "image[9][139] = 0.000000 \n",
      "image[9][140] = 0.000000 \n",
      "image[9][141] = 0.000000 \n",
      "image[9][142] = 0.000000 \n",
      "image[9][143] = 0.000000 \n",
      "image[9][144] = 0.000000 \n",
      "image[9][145] = 0.000000 \n",
      "image[9][146] = 0.000000 \n",
      "image[9][147] = 0.000000 \n",
      "image[9][148] = 0.000000 \n",
      "image[9][149] = 0.000000 \n",
      "image[9][150] = 0.000000 \n",
      "image[9][151] = 0.000000 \n",
      "image[9][152] = 0.000000 \n",
      "image[9][153] = 0.000000 \n",
      "image[9][154] = 0.000000 \n",
      "image[9][155] = 0.000000 \n",
      "image[9][156] = 0.000000 \n",
      "image[9][157] = 0.000000 \n",
      "image[9][158] = 0.000000 \n",
      "image[9][159] = 0.000000 \n",
      "image[9][160] = 0.000000 \n",
      "image[9][161] = 0.560784 \n",
      "image[9][162] = 0.968627 \n",
      "image[9][163] = 0.600000 \n",
      "image[9][164] = 0.000000 \n",
      "image[9][165] = 0.000000 \n",
      "image[9][166] = 0.000000 \n",
      "image[9][167] = 0.000000 \n",
      "image[9][168] = 0.000000 \n",
      "image[9][169] = 0.000000 \n",
      "image[9][170] = 0.000000 \n",
      "image[9][171] = 0.000000 \n",
      "image[9][172] = 0.000000 \n",
      "image[9][173] = 0.000000 \n",
      "image[9][174] = 0.000000 \n",
      "image[9][175] = 0.000000 \n",
      "image[9][176] = 0.000000 \n",
      "image[9][177] = 0.000000 \n",
      "image[9][178] = 0.000000 \n",
      "image[9][179] = 0.000000 \n",
      "image[9][180] = 0.000000 \n",
      "image[9][181] = 0.000000 \n",
      "image[9][182] = 0.000000 \n",
      "image[9][183] = 0.000000 \n",
      "image[9][184] = 0.000000 \n",
      "image[9][185] = 0.000000 \n",
      "image[9][186] = 0.000000 \n",
      "image[9][187] = 0.000000 \n",
      "image[9][188] = 0.533333 \n",
      "image[9][189] = 0.968627 \n",
      "image[9][190] = 0.949020 \n",
      "image[9][191] = 0.337255 \n",
      "image[9][192] = 0.000000 \n",
      "image[9][193] = 0.000000 \n",
      "image[9][194] = 0.000000 \n",
      "image[9][195] = 0.000000 \n",
      "image[9][196] = 0.000000 \n",
      "image[9][197] = 0.000000 \n",
      "image[9][198] = 0.000000 \n",
      "image[9][199] = 0.000000 \n",
      "image[9][200] = 0.000000 \n",
      "image[9][201] = 0.000000 \n",
      "image[9][202] = 0.000000 \n",
      "image[9][203] = 0.000000 \n",
      "image[9][204] = 0.000000 \n",
      "image[9][205] = 0.000000 \n",
      "image[9][206] = 0.000000 \n",
      "image[9][207] = 0.000000 \n",
      "image[9][208] = 0.000000 \n",
      "image[9][209] = 0.000000 \n",
      "image[9][210] = 0.000000 \n",
      "image[9][211] = 0.000000 \n",
      "image[9][212] = 0.000000 \n",
      "image[9][213] = 0.000000 \n",
      "image[9][214] = 0.000000 \n",
      "image[9][215] = 0.000000 \n",
      "image[9][216] = 0.752941 \n",
      "image[9][217] = 0.988235 \n",
      "image[9][218] = 0.733333 \n",
      "image[9][219] = 0.000000 \n",
      "image[9][220] = 0.000000 \n",
      "image[9][221] = 0.000000 \n",
      "image[9][222] = 0.000000 \n",
      "image[9][223] = 0.000000 \n",
      "image[9][224] = 0.000000 \n",
      "image[9][225] = 0.000000 \n",
      "image[9][226] = 0.000000 \n",
      "image[9][227] = 0.000000 \n",
      "image[9][228] = 0.000000 \n",
      "image[9][229] = 0.000000 \n",
      "image[9][230] = 0.000000 \n",
      "image[9][231] = 0.000000 \n",
      "image[9][232] = 0.000000 \n",
      "image[9][233] = 0.000000 \n",
      "image[9][234] = 0.000000 \n",
      "image[9][235] = 0.000000 \n",
      "image[9][236] = 0.243137 \n",
      "image[9][237] = 0.725490 \n",
      "image[9][238] = 0.070588 \n",
      "image[9][239] = 0.000000 \n",
      "image[9][240] = 0.000000 \n",
      "image[9][241] = 0.000000 \n",
      "image[9][242] = 0.000000 \n",
      "image[9][243] = 0.349020 \n",
      "image[9][244] = 0.925490 \n",
      "image[9][245] = 0.850980 \n",
      "image[9][246] = 0.184314 \n",
      "image[9][247] = 0.000000 \n",
      "image[9][248] = 0.000000 \n",
      "image[9][249] = 0.000000 \n",
      "image[9][250] = 0.000000 \n",
      "image[9][251] = 0.000000 \n",
      "image[9][252] = 0.000000 \n",
      "image[9][253] = 0.000000 \n",
      "image[9][254] = 0.000000 \n",
      "image[9][255] = 0.000000 \n",
      "image[9][256] = 0.000000 \n",
      "image[9][257] = 0.000000 \n",
      "image[9][258] = 0.000000 \n",
      "image[9][259] = 0.000000 \n",
      "image[9][260] = 0.000000 \n",
      "image[9][261] = 0.000000 \n",
      "image[9][262] = 0.000000 \n",
      "image[9][263] = 0.000000 \n",
      "image[9][264] = 0.847059 \n",
      "image[9][265] = 0.992157 \n",
      "image[9][266] = 0.235294 \n",
      "image[9][267] = 0.000000 \n",
      "image[9][268] = 0.000000 \n",
      "image[9][269] = 0.000000 \n",
      "image[9][270] = 0.000000 \n",
      "image[9][271] = 0.831373 \n",
      "image[9][272] = 1.000000 \n",
      "image[9][273] = 0.317647 \n",
      "image[9][274] = 0.000000 \n",
      "image[9][275] = 0.000000 \n",
      "image[9][276] = 0.000000 \n",
      "image[9][277] = 0.000000 \n",
      "image[9][278] = 0.000000 \n",
      "image[9][279] = 0.000000 \n",
      "image[9][280] = 0.000000 \n",
      "image[9][281] = 0.000000 \n",
      "image[9][282] = 0.000000 \n",
      "image[9][283] = 0.000000 \n",
      "image[9][284] = 0.000000 \n",
      "image[9][285] = 0.000000 \n",
      "image[9][286] = 0.000000 \n",
      "image[9][287] = 0.000000 \n",
      "image[9][288] = 0.000000 \n",
      "image[9][289] = 0.000000 \n",
      "image[9][290] = 0.000000 \n",
      "image[9][291] = 0.000000 \n",
      "image[9][292] = 0.807843 \n",
      "image[9][293] = 0.988235 \n",
      "image[9][294] = 0.266667 \n",
      "image[9][295] = 0.000000 \n",
      "image[9][296] = 0.000000 \n",
      "image[9][297] = 0.000000 \n",
      "image[9][298] = 0.188235 \n",
      "image[9][299] = 0.949020 \n",
      "image[9][300] = 0.992157 \n",
      "image[9][301] = 0.349020 \n",
      "image[9][302] = 0.000000 \n",
      "image[9][303] = 0.000000 \n",
      "image[9][304] = 0.000000 \n",
      "image[9][305] = 0.000000 \n",
      "image[9][306] = 0.000000 \n",
      "image[9][307] = 0.000000 \n",
      "image[9][308] = 0.000000 \n",
      "image[9][309] = 0.000000 \n",
      "image[9][310] = 0.000000 \n",
      "image[9][311] = 0.000000 \n",
      "image[9][312] = 0.000000 \n",
      "image[9][313] = 0.000000 \n",
      "image[9][314] = 0.000000 \n",
      "image[9][315] = 0.000000 \n",
      "image[9][316] = 0.000000 \n",
      "image[9][317] = 0.000000 \n",
      "image[9][318] = 0.000000 \n",
      "image[9][319] = 0.513726 \n",
      "image[9][320] = 0.984314 \n",
      "image[9][321] = 0.831373 \n",
      "image[9][322] = 0.082353 \n",
      "image[9][323] = 0.000000 \n",
      "image[9][324] = 0.000000 \n",
      "image[9][325] = 0.043137 \n",
      "image[9][326] = 0.654902 \n",
      "image[9][327] = 0.988235 \n",
      "image[9][328] = 0.772549 \n",
      "image[9][329] = 0.019608 \n",
      "image[9][330] = 0.000000 \n",
      "image[9][331] = 0.000000 \n",
      "image[9][332] = 0.000000 \n",
      "image[9][333] = 0.000000 \n",
      "image[9][334] = 0.000000 \n",
      "image[9][335] = 0.000000 \n",
      "image[9][336] = 0.000000 \n",
      "image[9][337] = 0.000000 \n",
      "image[9][338] = 0.000000 \n",
      "image[9][339] = 0.000000 \n",
      "image[9][340] = 0.000000 \n",
      "image[9][341] = 0.000000 \n",
      "image[9][342] = 0.000000 \n",
      "image[9][343] = 0.000000 \n",
      "image[9][344] = 0.000000 \n",
      "image[9][345] = 0.000000 \n",
      "image[9][346] = 0.113725 \n",
      "image[9][347] = 0.909804 \n",
      "image[9][348] = 0.968627 \n",
      "image[9][349] = 0.247059 \n",
      "image[9][350] = 0.000000 \n",
      "image[9][351] = 0.000000 \n",
      "image[9][352] = 0.000000 \n",
      "image[9][353] = 0.600000 \n",
      "image[9][354] = 0.988235 \n",
      "image[9][355] = 0.886275 \n",
      "image[9][356] = 0.000000 \n",
      "image[9][357] = 0.000000 \n",
      "image[9][358] = 0.000000 \n",
      "image[9][359] = 0.000000 \n",
      "image[9][360] = 0.000000 \n",
      "image[9][361] = 0.000000 \n",
      "image[9][362] = 0.000000 \n",
      "image[9][363] = 0.000000 \n",
      "image[9][364] = 0.000000 \n",
      "image[9][365] = 0.000000 \n",
      "image[9][366] = 0.000000 \n",
      "image[9][367] = 0.000000 \n",
      "image[9][368] = 0.000000 \n",
      "image[9][369] = 0.000000 \n",
      "image[9][370] = 0.000000 \n",
      "image[9][371] = 0.000000 \n",
      "image[9][372] = 0.000000 \n",
      "image[9][373] = 0.176471 \n",
      "image[9][374] = 0.858824 \n",
      "image[9][375] = 0.988235 \n",
      "image[9][376] = 0.560784 \n",
      "image[9][377] = 0.000000 \n",
      "image[9][378] = 0.000000 \n",
      "image[9][379] = 0.000000 \n",
      "image[9][380] = 0.454902 \n",
      "image[9][381] = 0.976471 \n",
      "image[9][382] = 0.988235 \n",
      "image[9][383] = 0.403922 \n",
      "image[9][384] = 0.000000 \n",
      "image[9][385] = 0.000000 \n",
      "image[9][386] = 0.000000 \n",
      "image[9][387] = 0.000000 \n",
      "image[9][388] = 0.000000 \n",
      "image[9][389] = 0.000000 \n",
      "image[9][390] = 0.000000 \n",
      "image[9][391] = 0.000000 \n",
      "image[9][392] = 0.000000 \n",
      "image[9][393] = 0.000000 \n",
      "image[9][394] = 0.000000 \n",
      "image[9][395] = 0.000000 \n",
      "image[9][396] = 0.000000 \n",
      "image[9][397] = 0.000000 \n",
      "image[9][398] = 0.000000 \n",
      "image[9][399] = 0.015686 \n",
      "image[9][400] = 0.376471 \n",
      "image[9][401] = 0.992157 \n",
      "image[9][402] = 1.000000 \n",
      "image[9][403] = 0.992157 \n",
      "image[9][404] = 0.784314 \n",
      "image[9][405] = 0.478431 \n",
      "image[9][406] = 0.027451 \n",
      "image[9][407] = 0.098039 \n",
      "image[9][408] = 0.788235 \n",
      "image[9][409] = 0.980392 \n",
      "image[9][410] = 0.619608 \n",
      "image[9][411] = 0.000000 \n",
      "image[9][412] = 0.000000 \n",
      "image[9][413] = 0.000000 \n",
      "image[9][414] = 0.000000 \n",
      "image[9][415] = 0.000000 \n",
      "image[9][416] = 0.000000 \n",
      "image[9][417] = 0.000000 \n",
      "image[9][418] = 0.000000 \n",
      "image[9][419] = 0.000000 \n",
      "image[9][420] = 0.000000 \n",
      "image[9][421] = 0.000000 \n",
      "image[9][422] = 0.000000 \n",
      "image[9][423] = 0.000000 \n",
      "image[9][424] = 0.000000 \n",
      "image[9][425] = 0.000000 \n",
      "image[9][426] = 0.000000 \n",
      "image[9][427] = 0.360784 \n",
      "image[9][428] = 0.988235 \n",
      "image[9][429] = 0.988235 \n",
      "image[9][430] = 0.992157 \n",
      "image[9][431] = 0.850980 \n",
      "image[9][432] = 0.988235 \n",
      "image[9][433] = 0.988235 \n",
      "image[9][434] = 0.784314 \n",
      "image[9][435] = 0.890196 \n",
      "image[9][436] = 0.988235 \n",
      "image[9][437] = 0.905882 \n",
      "image[9][438] = 0.000000 \n",
      "image[9][439] = 0.000000 \n",
      "image[9][440] = 0.000000 \n",
      "image[9][441] = 0.000000 \n",
      "image[9][442] = 0.000000 \n",
      "image[9][443] = 0.000000 \n",
      "image[9][444] = 0.000000 \n",
      "image[9][445] = 0.000000 \n",
      "image[9][446] = 0.000000 \n",
      "image[9][447] = 0.000000 \n",
      "image[9][448] = 0.000000 \n",
      "image[9][449] = 0.000000 \n",
      "image[9][450] = 0.000000 \n",
      "image[9][451] = 0.000000 \n",
      "image[9][452] = 0.000000 \n",
      "image[9][453] = 0.000000 \n",
      "image[9][454] = 0.341176 \n",
      "image[9][455] = 0.984314 \n",
      "image[9][456] = 0.968627 \n",
      "image[9][457] = 0.905882 \n",
      "image[9][458] = 0.254902 \n",
      "image[9][459] = 0.188235 \n",
      "image[9][460] = 0.741176 \n",
      "image[9][461] = 0.988235 \n",
      "image[9][462] = 0.988235 \n",
      "image[9][463] = 0.992157 \n",
      "image[9][464] = 0.988235 \n",
      "image[9][465] = 0.984314 \n",
      "image[9][466] = 0.890196 \n",
      "image[9][467] = 0.137255 \n",
      "image[9][468] = 0.000000 \n",
      "image[9][469] = 0.000000 \n",
      "image[9][470] = 0.000000 \n",
      "image[9][471] = 0.000000 \n",
      "image[9][472] = 0.000000 \n",
      "image[9][473] = 0.000000 \n",
      "image[9][474] = 0.000000 \n",
      "image[9][475] = 0.000000 \n",
      "image[9][476] = 0.000000 \n",
      "image[9][477] = 0.000000 \n",
      "image[9][478] = 0.000000 \n",
      "image[9][479] = 0.000000 \n",
      "image[9][480] = 0.000000 \n",
      "image[9][481] = 0.000000 \n",
      "image[9][482] = 0.745098 \n",
      "image[9][483] = 0.866667 \n",
      "image[9][484] = 0.384314 \n",
      "image[9][485] = 0.000000 \n",
      "image[9][486] = 0.000000 \n",
      "image[9][487] = 0.000000 \n",
      "image[9][488] = 0.164706 \n",
      "image[9][489] = 0.768627 \n",
      "image[9][490] = 0.988235 \n",
      "image[9][491] = 0.992157 \n",
      "image[9][492] = 0.988235 \n",
      "image[9][493] = 0.988235 \n",
      "image[9][494] = 0.635294 \n",
      "image[9][495] = 0.000000 \n",
      "image[9][496] = 0.000000 \n",
      "image[9][497] = 0.000000 \n",
      "image[9][498] = 0.000000 \n",
      "image[9][499] = 0.000000 \n",
      "image[9][500] = 0.000000 \n",
      "image[9][501] = 0.000000 \n",
      "image[9][502] = 0.000000 \n",
      "image[9][503] = 0.000000 \n",
      "image[9][504] = 0.000000 \n",
      "image[9][505] = 0.000000 \n",
      "image[9][506] = 0.000000 \n",
      "image[9][507] = 0.000000 \n",
      "image[9][508] = 0.000000 \n",
      "image[9][509] = 0.000000 \n",
      "image[9][510] = 0.435294 \n",
      "image[9][511] = 0.113725 \n",
      "image[9][512] = 0.000000 \n",
      "image[9][513] = 0.000000 \n",
      "image[9][514] = 0.000000 \n",
      "image[9][515] = 0.000000 \n",
      "image[9][516] = 0.243137 \n",
      "image[9][517] = 0.937255 \n",
      "image[9][518] = 0.988235 \n",
      "image[9][519] = 0.337255 \n",
      "image[9][520] = 0.164706 \n",
      "image[9][521] = 0.164706 \n",
      "image[9][522] = 0.054902 \n",
      "image[9][523] = 0.000000 \n",
      "image[9][524] = 0.000000 \n",
      "image[9][525] = 0.000000 \n",
      "image[9][526] = 0.000000 \n",
      "image[9][527] = 0.000000 \n",
      "image[9][528] = 0.000000 \n",
      "image[9][529] = 0.000000 \n",
      "image[9][530] = 0.000000 \n",
      "image[9][531] = 0.000000 \n",
      "image[9][532] = 0.000000 \n",
      "image[9][533] = 0.000000 \n",
      "image[9][534] = 0.000000 \n",
      "image[9][535] = 0.000000 \n",
      "image[9][536] = 0.000000 \n",
      "image[9][537] = 0.000000 \n",
      "image[9][538] = 0.000000 \n",
      "image[9][539] = 0.000000 \n",
      "image[9][540] = 0.000000 \n",
      "image[9][541] = 0.000000 \n",
      "image[9][542] = 0.000000 \n",
      "image[9][543] = 0.058824 \n",
      "image[9][544] = 0.580392 \n",
      "image[9][545] = 0.992157 \n",
      "image[9][546] = 0.854902 \n",
      "image[9][547] = 0.000000 \n",
      "image[9][548] = 0.000000 \n",
      "image[9][549] = 0.000000 \n",
      "image[9][550] = 0.000000 \n",
      "image[9][551] = 0.000000 \n",
      "image[9][552] = 0.000000 \n",
      "image[9][553] = 0.000000 \n",
      "image[9][554] = 0.000000 \n",
      "image[9][555] = 0.000000 \n",
      "image[9][556] = 0.000000 \n",
      "image[9][557] = 0.000000 \n",
      "image[9][558] = 0.000000 \n",
      "image[9][559] = 0.000000 \n",
      "image[9][560] = 0.000000 \n",
      "image[9][561] = 0.000000 \n",
      "image[9][562] = 0.000000 \n",
      "image[9][563] = 0.000000 \n",
      "image[9][564] = 0.000000 \n",
      "image[9][565] = 0.000000 \n",
      "image[9][566] = 0.000000 \n",
      "image[9][567] = 0.000000 \n",
      "image[9][568] = 0.000000 \n",
      "image[9][569] = 0.000000 \n",
      "image[9][570] = 0.000000 \n",
      "image[9][571] = 0.474510 \n",
      "image[9][572] = 0.988235 \n",
      "image[9][573] = 0.905882 \n",
      "image[9][574] = 0.109804 \n",
      "image[9][575] = 0.000000 \n",
      "image[9][576] = 0.000000 \n",
      "image[9][577] = 0.000000 \n",
      "image[9][578] = 0.000000 \n",
      "image[9][579] = 0.000000 \n",
      "image[9][580] = 0.000000 \n",
      "image[9][581] = 0.000000 \n",
      "image[9][582] = 0.000000 \n",
      "image[9][583] = 0.000000 \n",
      "image[9][584] = 0.000000 \n",
      "image[9][585] = 0.000000 \n",
      "image[9][586] = 0.000000 \n",
      "image[9][587] = 0.000000 \n",
      "image[9][588] = 0.000000 \n",
      "image[9][589] = 0.000000 \n",
      "image[9][590] = 0.000000 \n",
      "image[9][591] = 0.000000 \n",
      "image[9][592] = 0.000000 \n",
      "image[9][593] = 0.000000 \n",
      "image[9][594] = 0.000000 \n",
      "image[9][595] = 0.000000 \n",
      "image[9][596] = 0.000000 \n",
      "image[9][597] = 0.000000 \n",
      "image[9][598] = 0.121569 \n",
      "image[9][599] = 0.866667 \n",
      "image[9][600] = 0.984314 \n",
      "image[9][601] = 0.505882 \n",
      "image[9][602] = 0.000000 \n",
      "image[9][603] = 0.000000 \n",
      "image[9][604] = 0.000000 \n",
      "image[9][605] = 0.000000 \n",
      "image[9][606] = 0.000000 \n",
      "image[9][607] = 0.000000 \n",
      "image[9][608] = 0.000000 \n",
      "image[9][609] = 0.000000 \n",
      "image[9][610] = 0.000000 \n",
      "image[9][611] = 0.000000 \n",
      "image[9][612] = 0.000000 \n",
      "image[9][613] = 0.000000 \n",
      "image[9][614] = 0.000000 \n",
      "image[9][615] = 0.000000 \n",
      "image[9][616] = 0.000000 \n",
      "image[9][617] = 0.000000 \n",
      "image[9][618] = 0.000000 \n",
      "image[9][619] = 0.000000 \n",
      "image[9][620] = 0.000000 \n",
      "image[9][621] = 0.000000 \n",
      "image[9][622] = 0.000000 \n",
      "image[9][623] = 0.000000 \n",
      "image[9][624] = 0.000000 \n",
      "image[9][625] = 0.000000 \n",
      "image[9][626] = 0.854902 \n",
      "image[9][627] = 0.988235 \n",
      "image[9][628] = 0.627451 \n",
      "image[9][629] = 0.000000 \n",
      "image[9][630] = 0.000000 \n",
      "image[9][631] = 0.000000 \n",
      "image[9][632] = 0.000000 \n",
      "image[9][633] = 0.000000 \n",
      "image[9][634] = 0.000000 \n",
      "image[9][635] = 0.000000 \n",
      "image[9][636] = 0.000000 \n",
      "image[9][637] = 0.000000 \n",
      "image[9][638] = 0.000000 \n",
      "image[9][639] = 0.000000 \n",
      "image[9][640] = 0.000000 \n",
      "image[9][641] = 0.000000 \n",
      "image[9][642] = 0.000000 \n",
      "image[9][643] = 0.000000 \n",
      "image[9][644] = 0.000000 \n",
      "image[9][645] = 0.000000 \n",
      "image[9][646] = 0.000000 \n",
      "image[9][647] = 0.000000 \n",
      "image[9][648] = 0.000000 \n",
      "image[9][649] = 0.000000 \n",
      "image[9][650] = 0.000000 \n",
      "image[9][651] = 0.000000 \n",
      "image[9][652] = 0.000000 \n",
      "image[9][653] = 0.000000 \n",
      "image[9][654] = 0.478431 \n",
      "image[9][655] = 0.988235 \n",
      "image[9][656] = 0.321569 \n",
      "image[9][657] = 0.000000 \n",
      "image[9][658] = 0.000000 \n",
      "image[9][659] = 0.000000 \n",
      "image[9][660] = 0.000000 \n",
      "image[9][661] = 0.000000 \n",
      "image[9][662] = 0.000000 \n",
      "image[9][663] = 0.000000 \n",
      "image[9][664] = 0.000000 \n",
      "image[9][665] = 0.000000 \n",
      "image[9][666] = 0.000000 \n",
      "image[9][667] = 0.000000 \n",
      "image[9][668] = 0.000000 \n",
      "image[9][669] = 0.000000 \n",
      "image[9][670] = 0.000000 \n",
      "image[9][671] = 0.000000 \n",
      "image[9][672] = 0.000000 \n",
      "image[9][673] = 0.000000 \n",
      "image[9][674] = 0.000000 \n",
      "image[9][675] = 0.000000 \n",
      "image[9][676] = 0.000000 \n",
      "image[9][677] = 0.000000 \n",
      "image[9][678] = 0.000000 \n",
      "image[9][679] = 0.000000 \n",
      "image[9][680] = 0.000000 \n",
      "image[9][681] = 0.000000 \n",
      "image[9][682] = 0.000000 \n",
      "image[9][683] = 0.000000 \n",
      "image[9][684] = 0.000000 \n",
      "image[9][685] = 0.000000 \n",
      "image[9][686] = 0.000000 \n",
      "image[9][687] = 0.000000 \n",
      "image[9][688] = 0.000000 \n",
      "image[9][689] = 0.000000 \n",
      "image[9][690] = 0.000000 \n",
      "image[9][691] = 0.000000 \n",
      "image[9][692] = 0.000000 \n",
      "image[9][693] = 0.000000 \n",
      "image[9][694] = 0.000000 \n",
      "image[9][695] = 0.000000 \n",
      "image[9][696] = 0.000000 \n",
      "image[9][697] = 0.000000 \n",
      "image[9][698] = 0.000000 \n",
      "image[9][699] = 0.000000 \n",
      "image[9][700] = 0.000000 \n",
      "image[9][701] = 0.000000 \n",
      "image[9][702] = 0.000000 \n",
      "image[9][703] = 0.000000 \n",
      "image[9][704] = 0.000000 \n",
      "image[9][705] = 0.000000 \n",
      "image[9][706] = 0.000000 \n",
      "image[9][707] = 0.000000 \n",
      "image[9][708] = 0.000000 \n",
      "image[9][709] = 0.000000 \n",
      "image[9][710] = 0.000000 \n",
      "image[9][711] = 0.000000 \n",
      "image[9][712] = 0.000000 \n",
      "image[9][713] = 0.000000 \n",
      "image[9][714] = 0.000000 \n",
      "image[9][715] = 0.000000 \n",
      "image[9][716] = 0.000000 \n",
      "image[9][717] = 0.000000 \n",
      "image[9][718] = 0.000000 \n",
      "image[9][719] = 0.000000 \n",
      "image[9][720] = 0.000000 \n",
      "image[9][721] = 0.000000 \n",
      "image[9][722] = 0.000000 \n",
      "image[9][723] = 0.000000 \n",
      "image[9][724] = 0.000000 \n",
      "image[9][725] = 0.000000 \n",
      "image[9][726] = 0.000000 \n",
      "image[9][727] = 0.000000 \n",
      "image[9][728] = 0.000000 \n",
      "image[9][729] = 0.000000 \n",
      "image[9][730] = 0.000000 \n",
      "image[9][731] = 0.000000 \n",
      "image[9][732] = 0.000000 \n",
      "image[9][733] = 0.000000 \n",
      "image[9][734] = 0.000000 \n",
      "image[9][735] = 0.000000 \n",
      "image[9][736] = 0.000000 \n",
      "image[9][737] = 0.000000 \n",
      "image[9][738] = 0.000000 \n",
      "image[9][739] = 0.000000 \n",
      "image[9][740] = 0.000000 \n",
      "image[9][741] = 0.000000 \n",
      "image[9][742] = 0.000000 \n",
      "image[9][743] = 0.000000 \n",
      "image[9][744] = 0.000000 \n",
      "image[9][745] = 0.000000 \n",
      "image[9][746] = 0.000000 \n",
      "image[9][747] = 0.000000 \n",
      "image[9][748] = 0.000000 \n",
      "image[9][749] = 0.000000 \n",
      "image[9][750] = 0.000000 \n",
      "image[9][751] = 0.000000 \n",
      "image[9][752] = 0.000000 \n",
      "image[9][753] = 0.000000 \n",
      "image[9][754] = 0.000000 \n",
      "image[9][755] = 0.000000 \n",
      "image[9][756] = 0.000000 \n",
      "image[9][757] = 0.000000 \n",
      "image[9][758] = 0.000000 \n",
      "image[9][759] = 0.000000 \n",
      "image[9][760] = 0.000000 \n",
      "image[9][761] = 0.000000 \n",
      "image[9][762] = 0.000000 \n",
      "image[9][763] = 0.000000 \n",
      "image[9][764] = 0.000000 \n",
      "image[9][765] = 0.000000 \n",
      "image[9][766] = 0.000000 \n",
      "image[9][767] = 0.000000 \n",
      "image[9][768] = 0.000000 \n",
      "image[9][769] = 0.000000 \n",
      "image[9][770] = 0.000000 \n",
      "image[9][771] = 0.000000 \n",
      "image[9][772] = 0.000000 \n",
      "image[9][773] = 0.000000 \n",
      "image[9][774] = 0.000000 \n",
      "image[9][775] = 0.000000 \n",
      "image[9][776] = 0.000000 \n",
      "image[9][777] = 0.000000 \n",
      "image[9][778] = 0.000000 \n",
      "image[9][779] = 0.000000 \n",
      "image[9][780] = 0.000000 \n",
      "image[9][781] = 0.000000 \n",
      "image[9][782] = 0.000000 \n",
      "image[9][783] = 0.000000 \n"
     ]
    }
   ],
   "source": [
    "it = iter(mnist_dl) \n",
    "for i in range(10):\n",
    "    image, label = next(it)\n",
    "    flattened_image = image.numpy().flatten()\n",
    "    # iterate over each pixel\n",
    "    for j in range(len(flattened_image)):\n",
    "        print(\"image[%u][%u] = %f \" %(i, j, flattened_image[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "initial biases: Parameter containing:\n",
      "tensor([ 0.0298, -0.0277,  0.0149,  0.0131,  0.0262,  0.0057, -0.0165,  0.0169,\n",
      "         0.0078,  0.0310], dtype=torch.float64, requires_grad=True)\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0534,  0.1614,  0.2875,  0.0104,  0.2178, -0.2916, -0.0588,  0.4338,\n",
      "          0.1176,  0.0230]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.4337690970363521\n",
      "Loss:  2.7073488867340796\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4588, -2.5553, -3.0357, -2.6422, -2.9448, 25.6119, -2.2329, -3.3231,\n",
      "         -2.6493, -2.2711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 25.61193495108353\n",
      "Loss:  28.07068671607529\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.2849, -0.9206, -1.1436, -0.8039, -0.7831, -0.7927, -0.5572, -0.9406,\n",
      "         -1.1909, -0.5899]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 8.284903398395752\n",
      "Loss:  9.068988800057403\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.7396, -1.5233, -1.5975, -1.0658,  3.1014,  0.1288, -1.3690, -1.8258,\n",
      "         -1.3836, -0.9889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 5.739610472511881\n",
      "Loss:  7.340708289577105\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.7627, 10.8726, -1.6495, -1.4589,  6.7155, -4.9545, -0.9927, -2.0368,\n",
      "         -1.8057, -1.3511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 10.872565885773323\n",
      "Loss:  12.239257459230066\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.3904, -10.8087,  -2.5617,  -2.1675,   9.2251,  -2.8482,  -1.9434,\n",
      "          -2.6673,  -2.2597,  21.9068]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.906758976275075\n",
      "Loss:  24.46848055744289\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-4.5241, -8.7365, 11.5721, -1.3072,  2.4178,  4.2531, -1.6225, -2.3553,\n",
      "         -1.7593,  1.5756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  1\n",
      "activation[2] = 11.572134556173209\n",
      "Loss:  20.30945990349797\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.6482,   9.8051,   9.8859,  -3.4788,  13.6183,   1.8350,  -2.9905,\n",
      "          -4.6525,  -3.5650, -10.6238]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 13.618329563377674\n",
      "Loss:  17.142116306401956\n",
      "Accuracy: 0.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0423,  11.0469, -11.3621,   9.7608,  -9.8021,   2.7463,  -0.9932,\n",
      "          -1.4744,  -1.1412,   2.8389]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.046938071585652\n",
      "Loss:  0.24441774914447043\n",
      "Accuracy: 0.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.7212,   4.8599,   8.1747,  19.8318,  -9.6092,  -0.0278,  -1.5691,\n",
      "          -1.8112,  -1.5290,  -5.8177]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 19.83183731614045\n",
      "Loss:  29.441021537712103\n",
      "Accuracy: 0.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.0668,  18.9111,  -4.6294,  17.4911, -18.6480,   1.7483,  -2.8422,\n",
      "          -4.0363,  -2.9250,  -6.0171]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 18.911112314431744\n",
      "Loss:  1.6364890021879437\n",
      "Accuracy: 0.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-8.7563,  4.6080,  5.2388,  2.6383,  6.8059, -4.8575, -0.3904, -0.2935,\n",
      "         -0.4876, -4.5507]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 6.805914557691123\n",
      "Loss:  11.954177267465964\n",
      "Accuracy: 0.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.5636, -10.7639,  -2.6712,  44.0937, -16.0480,  10.5383,  -2.5129,\n",
      "          -3.4623,  -2.4597,  -9.2454]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 44.09371109930233\n",
      "Loss:  2.664535259100372e-15\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.3750, -10.7007,   5.8455,  16.5695,  -0.8695,   3.5183,  -1.8493,\n",
      "          -2.5407,  -1.9519,  -7.9477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.56954043661735\n",
      "Loss:  18.418876352428253\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4157,   3.0401, -11.4510,  -1.5976,  -5.7690,   9.9287,  10.0795,\n",
      "          -1.5662,  -1.1559,   1.5022]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.079539225048208\n",
      "Loss:  7.660614779412338\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6590, -6.9401,  9.9448, -8.3241, -0.3278, -1.2065, 13.9631, -2.2669,\n",
      "         -1.8275, -2.0573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 13.963064002590173\n",
      "Loss:  16.247806426621697\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.0462,  -6.3889,   8.9699,   8.8062, -13.3994,   4.2624,  -1.8223,\n",
      "          14.6387,  -1.9769, -12.5520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 14.638717874641207\n",
      "Loss:  5.675180706238129\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.9787,   4.5562,  23.4886,   3.9434, -15.0109,   8.3773, -12.1563,\n",
      "           2.7152,  -2.8291,  -3.7779]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  8\n",
      "activation[2] = 23.488582029856307\n",
      "Loss:  26.317700633131565\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3352, -0.8050, -2.0700, -0.3574, -2.4271, -0.1822,  4.6317, -2.2539,\n",
      "          9.5776, -3.9196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 9.577605641583816\n",
      "Loss:  4.953207110455209\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.4807,   1.6499, -13.2025,  -0.9885,  -4.9805,   6.2507,  -8.7296,\n",
      "          10.5030,  16.8952,  -1.0984]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.895179646349064\n",
      "Loss:  17.995228779505226\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-22.7318,  -8.7601,  12.8896,   0.9407,   4.5971,   3.8604,   8.6973,\n",
      "          -1.0403,  -6.9020,   9.4623]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  4\n",
      "activation[2] = 12.889626629923496\n",
      "Loss:  8.339345296451864\n",
      "Accuracy: 0.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.8027,  -9.7211, -20.5301,  11.2295,   5.3449, -17.3589,   1.6379,\n",
      "           4.6163,  -3.8728,   9.1744]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 20.802746790919453\n",
      "Loss:  7.87637804953497e-05\n",
      "Accuracy: 1.171875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.9414,   1.1298, -17.2636,  -7.7571,  15.0434,   3.7541,  -1.4274,\n",
      "           6.2500,  -7.7888,  15.1756]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.17560176233353\n",
      "Loss:  0.6293103285521616\n",
      "Accuracy: 1.5625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-21.4752,  17.8230, -25.7475,   6.8306,  -5.7180,   8.9987,  -1.3613,\n",
      "           1.1791,   2.0907,  16.4649]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.822973891769358\n",
      "Loss:  0.22898380768855292\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.9392,  -0.2383, -14.4172,   2.6603,  -4.2848,   0.2063,   7.3143,\n",
      "           2.1815,  -8.4781,  10.7575]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.757487727187206\n",
      "Loss:  11.030643414118655\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.1762,  24.7534, -27.9981,  28.7557,  -6.2897,   7.0034,  13.5284,\n",
      "         -13.3683,  -3.5229, -14.2239]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 28.755729223139653\n",
      "Loss:  56.77193325308588\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-6.6523,  4.6277,  2.5964, -7.4246,  2.2800,  3.4134,  0.0690,  0.6084,\n",
      "         -4.4692,  4.6775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 4.6774760102104604\n",
      "Loss:  3.304423717307917\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.3687,  13.9201,  22.0049,  -8.4401,   9.5557,   6.5737,   2.0622,\n",
      "          -9.8642, -10.2585, -16.7935]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  3\n",
      "activation[2] = 22.004881034355716\n",
      "Loss:  30.44527701644568\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.2677,  15.9293, -28.5721,  22.8861,  18.9346,   2.0709,  -6.3862,\n",
      "          -0.5993, -10.3220,  -8.8501]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 22.88614888075078\n",
      "Loss:  51.47821327064986\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.1315,  22.4783,   0.2644, -24.7270,  14.8081,   2.9273,  -0.4952,\n",
      "           6.3741,  -4.7245,  -5.6129]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  7\n",
      "activation[1] = 22.478325019356678\n",
      "Loss:  16.10474090403699\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.4653,  10.2875, -14.4631, -10.1793,  22.2100,   5.6413,   3.5916,\n",
      "           7.4607,  -8.5299,  -7.0095]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 22.209968133129767\n",
      "Loss:  32.3892802919641\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.2955,  15.4630,  -6.1509,   4.2292, -16.2080,   3.0672,  -2.4128,\n",
      "          14.5473,   1.6243,  -6.5156]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.463019811717583\n",
      "Loss:  14.175316068716052\n",
      "Accuracy: 1.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.8564, -2.4087,  3.1495, -8.9165, -1.6128, -0.2654, 16.0049,  1.4721,\n",
      "         -1.3789, -7.5261]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 16.004894938142755\n",
      "Loss:  5.194863874058407e-06\n",
      "Accuracy: 2.34375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.5740, -20.2389,  -5.9040,  -2.2887,  -3.4078,   6.1528, -13.8177,\n",
      "          22.7314,  18.3132,   6.6112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 22.731409530394824\n",
      "Loss:  16.13220453827399\n",
      "Accuracy: 2.34375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.0394, -27.3458,   8.2894,  -0.2048,  -3.8041,  -2.5838,  10.8617,\n",
      "         -19.7637,  25.1506,  10.0822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.150590849416588\n",
      "Loss:  25.111156451560667\n",
      "Accuracy: 2.34375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[11.2171, -4.3057, -1.8344,  1.8376, -5.4640,  6.6757, -4.5474, -5.3690,\n",
      "         -3.8850,  5.5684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 11.217073629254976\n",
      "Loss:  4.555549482910949\n",
      "Accuracy: 2.34375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.2837,  -2.2165, -11.5304,   0.1254,  -4.6538,  19.8226,  21.1172,\n",
      "         -15.8702, -27.6254,   3.1026]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 21.1171900961456\n",
      "Loss:  0.36037858002376266\n",
      "Accuracy: 2.734375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 47.1910, -27.9916,  14.6733, -14.1287,  -0.9510,   1.0522,  24.7989,\n",
      "         -17.1174, -33.0371,   6.9954]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 47.19101609046501\n",
      "Loss:  1.8847279291023514e-10\n",
      "Accuracy: 3.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.8771, -13.8440,   6.9109,   0.1381,  -0.6877,   8.0204,  11.4840,\n",
      "         -17.5302,  -6.4795,   6.2929]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 11.484031284943987\n",
      "Loss:  29.063835459279105\n",
      "Accuracy: 3.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.8603, -14.8282,   9.2615, -18.3694,   2.8088,   1.8123,  15.9132,\n",
      "           7.1206, -31.3757,   5.2457]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 23.860338912022595\n",
      "Loss:  7.947480998113975\n",
      "Accuracy: 3.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.3082,   4.2761,  -9.6123,   5.7455, -15.5763,   5.8827,   7.2177,\n",
      "          -1.3486,   1.0831,  13.2881]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.28812610213384\n",
      "Loss:  9.015634522997646\n",
      "Accuracy: 3.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-10.1079,  -2.6729,  -9.1954,   8.9756, -13.7323,  13.0349,  19.3650,\n",
      "           2.9141,  -8.0580,  -0.7924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 19.36495998788114\n",
      "Loss:  27.424746431306886\n",
      "Accuracy: 3.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.3026,   3.7256,  -5.5198,   5.7208,  -3.6484,   3.0018, -16.1159,\n",
      "           9.6792,   9.2147,   2.0023]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.679186609823082\n",
      "Loss:  0.5019038807474446\n",
      "Accuracy: 3.515625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.0034,  -0.8005,  -6.9174,   5.5238, -12.5306,  10.8677, -15.2524,\n",
      "           5.9250,  12.1109,  13.9058]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 13.905801771679972\n",
      "Loss:  0.19444700833738884\n",
      "Accuracy: 3.90625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-10.6624,  11.6933, -11.1766,  19.8725,  -9.4433,   9.7753, -11.2531,\n",
      "           5.8049,   0.7899,  -5.3967]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 19.872464505994042\n",
      "Loss:  0.0003223545281832369\n",
      "Accuracy: 4.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.9207, -19.3475,  -5.8810,   1.4362,  11.1262,   1.4714, -18.1709,\n",
      "          17.4789,   5.3544,  16.5425]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 17.478884875414224\n",
      "Loss:  1.268411876061313\n",
      "Accuracy: 4.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.9461,   5.3641,  -4.1979,   8.8701,  -8.7845,   5.8637, -16.7363,\n",
      "          -0.1934,   8.4753,  10.8611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 10.861109504066375\n",
      "Loss:  2.6004324719881358\n",
      "Accuracy: 4.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.7768,  -4.7706,  -5.0667,  -4.5279,  -3.3796,  15.5210, -11.9126,\n",
      "          -9.0935,  25.0233,   7.6103]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 25.023332840030644\n",
      "Loss:  9.502450503609484\n",
      "Accuracy: 4.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-6.7997,  6.4851, -4.0774, 10.6137, -9.4791, 11.3322, -5.8556, -1.2094,\n",
      "          4.8990, -5.2104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 11.332230808054751\n",
      "Loss:  16.94601776594882\n",
      "Accuracy: 4.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6673,  -3.1507, -14.0972,  34.6160, -27.3354,  23.7746, -18.4615,\n",
      "         -20.3728,  13.3601,  14.6012]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 34.616043663660555\n",
      "Loss:  1.9573876539913383e-05\n",
      "Accuracy: 4.6875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.7825,   2.2290,  -2.3245,  15.5235, -12.1053,   4.9798,   3.5821,\n",
      "         -10.2394,  -4.3734,   2.4003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 15.52352354014249\n",
      "Loss:  3.697007398412777e-05\n",
      "Accuracy: 5.078125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.8779, -16.4545,   5.1498,   7.6419,  -9.9480,  -0.8819, -15.1621,\n",
      "          -5.7044,  10.8768,   5.7370]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 19.877867269914873\n",
      "Loss:  0.00012924140336598847\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.9580, -13.1241,   9.3650,  -1.4537,   3.2049,  -1.8732, -18.4486,\n",
      "           5.6947,  -7.5546,  16.7299]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.729897383753052\n",
      "Loss:  11.035967102143307\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-19.7473,   7.2339, -15.8701,  -1.1709,  -1.2436,  19.8061,  -6.5436,\n",
      "          11.7131,  -4.8826,  10.7757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 19.806063842912593\n",
      "Loss:  21.05007150906344\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-15.6230, -16.3298,  -4.1682,   0.8294,  15.9184,   4.8561, -11.1756,\n",
      "          21.0955,   3.9811,   0.6113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 21.095473486923982\n",
      "Loss:  20.489835567049436\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-18.9228, -14.4872,  -6.5831,  -3.8151,   8.6804,  14.7689, -24.8003,\n",
      "          -5.7574,  21.9575,  28.6590]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 28.65898971707612\n",
      "Loss:  6.702679894210952\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.3522, -16.7607,  32.4712, -33.5064,   6.2743, -15.3607, -16.3794,\n",
      "          10.5746,  37.6050, -22.2504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 37.604983005990064\n",
      "Loss:  19.25869587444842\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.6440, -15.9066,  -3.2453, -11.1377,  22.6286,   4.8060, -16.6960,\n",
      "          -6.7751,   5.8792,  19.0108]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 22.6286322503948\n",
      "Loss:  3.6442823706285443\n",
      "Accuracy: 5.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.8110, -18.7508, -16.6779,   8.1501,  20.0785,   0.3563, -14.3415,\n",
      "          -0.8332,   3.9239,  15.5703]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 20.078473922923944\n",
      "Loss:  0.010965482697084628\n",
      "Accuracy: 5.859375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2772,  11.4709,  -7.3234,  -0.7726,  -5.0565,   9.2302, -22.8544,\n",
      "          -4.4844,  30.4129,  -9.1669]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 30.41289488411525\n",
      "Loss:  18.942013501110775\n",
      "Accuracy: 5.859375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.2522,   0.6296,  11.9788, -23.8243,  21.9074,  -2.0090, -13.5545,\n",
      "           6.7779, -11.3131,  -9.3086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 21.90742396744148\n",
      "Loss:  0.06797014532482329\n",
      "Accuracy: 6.25 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.3982,  15.8046, -14.3432,  -9.6027,  11.2357,   8.7923,  -7.4326,\n",
      "          -1.4826,  -1.6701,  12.7017]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 15.804580416362631\n",
      "Loss:  4.623517496569182\n",
      "Accuracy: 6.25 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.8059,  -1.1891,  -7.1263,  -7.7530,  21.7978, -10.3354,  28.0128,\n",
      "          -3.8396, -22.4326,  -8.4655]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 28.012831179393366\n",
      "Loss:  0.001997411331092335\n",
      "Accuracy: 6.640625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 59.3868, -20.0697,  -9.2524,  13.1552,   5.4165, -15.5286,  -8.0286,\n",
      "          -3.4518, -16.2833,  -4.1128]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 59.38676715022619\n",
      "Loss:  0.0\n",
      "Accuracy: 7.03125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.3995, -10.1505,  10.0177, -33.9682,  20.3626,  -5.3860,  12.1848,\n",
      "          10.0398, -11.0384, -12.0325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 20.399471295260746\n",
      "Loss:  0.711947598538503\n",
      "Accuracy: 7.03125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-9.2087,  1.1197, -4.5830, -9.2288, 17.1245, 15.8249, -3.7037, -6.3590,\n",
      "          3.4506, -3.7729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 17.124481841250457\n",
      "Loss:  1.5406844211068975\n",
      "Accuracy: 7.03125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.1534,  -4.3496,  -1.7841, -15.2966,  16.6490,   2.5151,  38.0108,\n",
      "         -11.9368, -25.9917,   0.0450]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 38.01081846943229\n",
      "Loss:  5.280804681033852e-10\n",
      "Accuracy: 7.421875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.7704,  26.7308, -13.2639,  -3.2851,  -1.0412,  13.3218, -16.6932,\n",
      "          -0.8161,   0.9440,   3.3410]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 26.730770762686088\n",
      "Loss:  1.5017585263258062e-06\n",
      "Accuracy: 7.8125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.8707,   0.9253,  21.4861, -11.5934,   0.9943,   5.9385,  -5.9868,\n",
      "          -6.5919, -22.2046,  -8.8395]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 26.8707408896956\n",
      "Loss:  0.004576180357031757\n",
      "Accuracy: 8.203125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.3484, -21.0412,  12.7450,  -8.7029,  16.2709,  -2.3272,  11.3761,\n",
      "           2.0570, -36.4769, -10.9999]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 38.34839845015449\n",
      "Loss:  2.6767854595958305e-10\n",
      "Accuracy: 8.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1711,  31.5247,  -4.0689,  -4.8471, -13.3973,   2.0094,   8.8091,\n",
      "          -7.0514,  -6.7761,  -3.1533]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 31.524660202940687\n",
      "Loss:  1.365436652540668e-10\n",
      "Accuracy: 8.984375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.0756, -13.0396,   1.2132, -18.1408,  14.1156,  11.5578, -18.2954,\n",
      "          10.1717, -15.2195,  26.8243]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 26.824328433675337\n",
      "Loss:  16.65267183262121\n",
      "Accuracy: 8.984375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-7.9449, 27.5047, -8.7971, -6.1910, -9.0503,  3.7238, -2.4914,  1.9930,\n",
      "          1.7929, -0.5350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 27.504688374595656\n",
      "Loss:  6.290190590420918e-11\n",
      "Accuracy: 9.375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.1505,   1.6706,  -0.7353, -29.2293,  20.3999,   3.9764,  31.2750,\n",
      "           9.3940,  -9.1427, -17.3026]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 31.27495409078418\n",
      "Loss:  1.8924749951455443e-05\n",
      "Accuracy: 9.765625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.0450,   5.6206, -10.0294,  21.7892,  -2.5471,  -1.9760,  -4.1363,\n",
      "           9.0300, -11.9671, -10.7791]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 21.789244387445507\n",
      "Loss:  3.024220484309358e-06\n",
      "Accuracy: 10.15625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 39.7088, -16.5499,  -0.4966,   6.5589,   6.9279,   6.0200,  -0.5332,\n",
      "          17.8173, -28.7467, -29.3015]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 39.70882807722793\n",
      "Loss:  3.1091174074900415e-10\n",
      "Accuracy: 10.546875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.7844,  19.9099,   9.0538,   0.0584,  -7.1439,  10.6451,  -7.5099,\n",
      "          -1.0935,  -9.0663, -18.7283]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 19.909859328022296\n",
      "Loss:  10.856128932463964\n",
      "Accuracy: 10.546875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.6686,   6.3416,  11.6811,   3.6644,  -0.2102,  15.3877, -22.6216,\n",
      "          10.5677,   3.6766, -25.4100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 15.387655812188981\n",
      "Loss:  9.078257475883332\n",
      "Accuracy: 10.546875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-15.0528,  20.4636,  22.6875,  -8.3078,   3.2184,  -4.3726, -18.9765,\n",
      "          10.1646,   3.9820, -14.5028]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  1\n",
      "activation[2] = 22.687461060131454\n",
      "Loss:  2.3265674763365736\n",
      "Accuracy: 10.546875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2989,  13.3800, -16.9486, -15.6484,  15.3757,  -0.2687, -24.3309,\n",
      "          42.9284,  -5.7197,  -7.5594]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 42.92835733782178\n",
      "Loss:  1.2285727990494435e-12\n",
      "Accuracy: 10.9375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.0565,  -7.3196,  19.4423, -14.2680,   6.3439, -10.5103,  11.4227,\n",
      "           9.1629, -16.9729,  -9.7270]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  9\n",
      "activation[2] = 19.44234841292478\n",
      "Loss:  29.174254716375735\n",
      "Accuracy: 10.9375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 41.9575, -10.7036, -20.9871,  -1.8567,   9.1691, -10.9134,   9.2722,\n",
      "          17.0453, -29.5604,  -1.9695]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 41.95752452271739\n",
      "Loss:  1.5174306255856585e-11\n",
      "Accuracy: 11.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2066,   0.6381,   7.4698, -23.4059,  16.6977,  -0.5530,  11.4794,\n",
      "           2.4437, -19.4518,  -4.0389]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 16.697738765559404\n",
      "Loss:  9.234911396499328\n",
      "Accuracy: 11.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.3092,   6.9245,   7.5492, -33.4807, -14.6692,  -7.7506,  30.1554,\n",
      "          10.2138, -14.3334,  12.9089]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 30.155401452532722\n",
      "Loss:  3.477487215451204e-08\n",
      "Accuracy: 11.71875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.3430, -12.9021,  24.0277,   2.1015, -17.8035,   1.0526, -17.0149,\n",
      "           8.6374,  -3.2265,   7.6693]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  7\n",
      "activation[2] = 24.027692580030504\n",
      "Loss:  15.390334983618835\n",
      "Accuracy: 11.71875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.1785,   6.8253, -17.4698,  10.7082, -26.4611,   3.5557, -20.8401,\n",
      "           9.4112,  24.4604,   6.0391]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 24.46035718062397\n",
      "Loss:  1.3899801055528245e-06\n",
      "Accuracy: 12.109375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.6558,  -1.8079,  -5.2937,   0.9306,  -5.9725, -16.2875,   0.0718,\n",
      "          21.7982, -13.6749,  12.5631]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 21.79817901634756\n",
      "Loss:  20.867646673961932\n",
      "Accuracy: 12.109375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.0132,  -5.5939, -16.2552, -13.4772,  -7.2408,  -6.2778, -23.3830,\n",
      "          31.2725,  -3.8464,  39.9024]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 39.90238107881327\n",
      "Loss:  0.00017867630222790398\n",
      "Accuracy: 12.5 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 59.1007,  -9.6351,  30.7056,   0.9489, -35.1309, -19.7788, -11.3359,\n",
      "          13.3613, -27.9733,   0.2149]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 59.10069665244148\n",
      "Loss:  4.658495811326071e-13\n",
      "Accuracy: 12.890625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.9089, -11.4198,  -9.1533, -27.9807,  17.4815,   5.8396,  -4.7550,\n",
      "          23.0010, -11.3889,  25.8831]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.883110790648843\n",
      "Loss:  8.456311102516812\n",
      "Accuracy: 12.890625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.5937,   5.3415,  10.1082, -24.1770,  16.5160, -17.8093,  39.6306,\n",
      "          15.4292, -16.9414, -26.7358]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 39.630631334229854\n",
      "Loss:  1.2252043823184292e-10\n",
      "Accuracy: 13.28125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.5085,   2.6909, -19.7000,  -2.0104,  24.6971,  -4.5712, -22.9016,\n",
      "          41.4120, -19.7653,  -9.7394]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 41.41202942222008\n",
      "Loss:  5.505640125454465e-08\n",
      "Accuracy: 13.671875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.4808, -14.6650,  -1.6400,  -2.1528,  23.4442,  -2.9191,  -1.6575,\n",
      "          11.7748,  -3.7241,   0.5521]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 23.44420798476268\n",
      "Loss:  8.551229876413218e-06\n",
      "Accuracy: 14.0625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6099,  13.9933,  -7.2077, -12.1592,   2.5856, -11.9948,  32.8447,\n",
      "           3.3135, -15.6287,  -2.8766]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 32.84470863119242\n",
      "Loss:  6.500388206565087e-09\n",
      "Accuracy: 14.453125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.7074,  20.5583, -16.4675,   1.4538, -10.5435,  -0.1504, -14.0200,\n",
      "          10.8328,  18.7423, -14.3157]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 20.55825215624604\n",
      "Loss:  1.9667035627766682\n",
      "Accuracy: 14.453125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 43.4835, -44.9023,  10.2806,  -0.4973, -10.0313, -14.0028,  16.3400,\n",
      "          20.0112,  -5.6363, -13.2592]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 43.48346890627761\n",
      "Loss:  6.562350662660037e-11\n",
      "Accuracy: 14.84375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.4992,  -8.3848, -17.0453,   2.4350,  -3.5371,  -2.9027, -24.1700,\n",
      "          26.6366,  15.7046,   8.6130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 26.636582307027474\n",
      "Loss:  1.7892333562178442e-05\n",
      "Accuracy: 15.234375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.2556, -24.3987, -16.1220,   5.1868,  -8.5860,   9.2012, -22.9336,\n",
      "           4.6086,  61.3343, -10.1618]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 61.33426717018762\n",
      "Loss:  0.0\n",
      "Accuracy: 15.625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.1992,  -3.2374,  -7.8855,  42.3803, -19.2521, -13.9256,  -4.5268,\n",
      "          -2.9502,   4.3997,   0.5439]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 42.38030185217522\n",
      "Loss:  0.0\n",
      "Accuracy: 16.015625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.0410,  27.5439, -10.0680,   1.6434,   0.4369,  -6.1281, -17.5852,\n",
      "          10.8805,  15.3080, -11.6617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 27.543865522476537\n",
      "Loss:  4.911076846632375e-06\n",
      "Accuracy: 16.40625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.1447, -6.2865, -8.0996,  1.0881,  1.8277, -2.9376, -1.9736, 10.6456,\n",
      "          9.6178, -6.1017]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 10.64564602097174\n",
      "Loss:  13.88939928786265\n",
      "Accuracy: 16.40625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.5691, -24.3265, -14.7730,   3.1868,  22.5614,   8.5468, -14.6637,\n",
      "          29.5670,  -6.0885, -16.8017]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 29.567036906526305\n",
      "Loss:  0.0009064422099926539\n",
      "Accuracy: 16.796875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.0841,  22.9164, -10.5572,   3.0410, -12.5355,  -0.1315,  -1.9495,\n",
      "          -7.3339,  12.9711,  -2.3682]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 22.916377995174546\n",
      "Loss:  4.795315624736315e-05\n",
      "Accuracy: 17.1875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.9435, -18.2231, -10.9270,  -4.0846,   5.9116,  10.1208, -25.6617,\n",
      "          24.2603,   2.8025,   4.1429]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.260317307889768\n",
      "Loss:  5.21197812450666e-06\n",
      "Accuracy: 17.578125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.3854,  11.9697, -14.6670,   4.8942,  -6.5376,   7.4407,  -5.9299,\n",
      "          -1.9771,   9.5045,   2.2842]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.969724083404452\n",
      "Loss:  0.09229899411405008\n",
      "Accuracy: 17.96875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.6079,  43.6738,  -6.1928,   2.8153, -10.4918,   0.9105, -18.3526,\n",
      "          -4.0033,  11.2154, -16.6063]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 43.67382446372467\n",
      "Loss:  7.993605777301096e-15\n",
      "Accuracy: 18.359375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.0071, -22.4936,   7.1614,   3.1658,   1.2543,   1.3061,  34.4080,\n",
      "          -8.8221,  -3.4059,  -5.9878]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 34.40798901072841\n",
      "Loss:  1.504130153761031e-12\n",
      "Accuracy: 18.75 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.0272, -19.3463,   0.9491,  33.5543, -20.8423,  11.6475,  -1.7538,\n",
      "         -20.3752,  17.1083,  -1.6235]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 33.55425766713286\n",
      "Loss:  7.235450909780142e-08\n",
      "Accuracy: 19.140625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.8543, -18.1703,  37.4940,  -7.4429, -14.9601,   5.5547,  -4.0447,\n",
      "          -3.7207, -16.4194,  -7.1828]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  0\n",
      "activation[2] = 37.493968978446034\n",
      "Loss:  7.6401681917633235\n",
      "Accuracy: 19.140625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 4.0184, -3.5223, -6.4574,  0.5649,  4.7595, 11.8114,  6.4759, -8.2284,\n",
      "         -1.9276, -6.8573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 11.8114424370926\n",
      "Loss:  18.274979246613583\n",
      "Accuracy: 19.140625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.2045, -27.9314,  -8.5074,  12.8633,  22.5482, -10.1041,  -6.7356,\n",
      "          -1.7029,  10.8970,   1.8311]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 22.54822399819557\n",
      "Loss:  20.717156130164256\n",
      "Accuracy: 19.140625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.5867, -46.8751, -20.6688,  37.3976, -20.5394,  -1.8048, -15.4140,\n",
      "          -7.0947,  23.3717,  22.4642]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 37.39755333686422\n",
      "Loss:  0.00040636527912443754\n",
      "Accuracy: 19.53125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0004,  29.5908, -10.1204,   8.9873, -22.3112,  -7.2284,  -6.8832,\n",
      "          -0.6453,  14.2626,  -2.8549]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 29.590754196820246\n",
      "Loss:  2.2146063551018245e-07\n",
      "Accuracy: 19.921875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.2579e-02,  3.6656e+01, -5.6699e+00,  8.8188e+00, -2.6329e+01,\n",
      "         -3.3873e+00, -1.8579e+01, -2.3828e+00,  2.7635e+01, -1.7562e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 36.65573781023334\n",
      "Loss:  0.0001208123728355151\n",
      "Accuracy: 20.3125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 88.6279, -24.0523,  -7.7083,   9.5416, -33.5408, -10.5970, -11.3575,\n",
      "          15.8007, -24.2696,  -0.8077]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 88.62791811340088\n",
      "Loss:  0.0\n",
      "Accuracy: 20.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6503, -36.0918, -13.9081, -13.2569,  24.5101,   9.7858,  -5.1865,\n",
      "           4.8096,   5.2659,  26.4357]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 26.435746131991213\n",
      "Loss:  2.061719658854217\n",
      "Accuracy: 20.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.4877, -32.1160, -14.7890,   6.7818,  22.6064,  -8.2854, -11.8713,\n",
      "          21.2682,   3.8048,   7.3506]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 22.606427516808527\n",
      "Loss:  15.488730558967804\n",
      "Accuracy: 20.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 39.2506, -11.9256,  12.2087,  11.7492, -65.5496,  12.4772,  -6.8834,\n",
      "         -24.0805,   9.8426,  24.0398]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 39.250617891691036\n",
      "Loss:  27.041908588248933\n",
      "Accuracy: 20.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 37.6262, -17.4968,  22.4505,  -6.2271, -19.8893, -23.1456,  10.8278,\n",
      "          -1.3337, -12.2442,  10.6411]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 37.62619071859349\n",
      "Loss:  2.5660852347977795e-07\n",
      "Accuracy: 21.09375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.0700, -17.0951,  33.4480,   7.8618, -24.2711,  -3.5021,  -7.8919,\n",
      "           4.3290, -19.2159,  -9.9734]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 38.06999671492427\n",
      "Loss:  0.009785101412795346\n",
      "Accuracy: 21.484375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.4311, -11.3193,  61.6386,  14.3131, -52.0662, -14.4608, -11.7050,\n",
      "          15.4511,  -8.0355,  12.9955]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 61.63864468435442\n",
      "Loss:  0.0\n",
      "Accuracy: 21.875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.0553e+01, -1.4949e+01,  5.3985e+01,  2.1215e+00, -5.2659e+01,\n",
      "         -6.2769e+00, -1.2509e-02, -1.2969e+01, -1.5199e+01, -3.3775e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  0\n",
      "activation[2] = 53.984671515080706\n",
      "Loss:  3.4631040981087162\n",
      "Accuracy: 21.875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-15.9432,  13.7136,  10.3057,  -5.5959, -36.7931,   6.5938,  -0.5739,\n",
      "          -2.1646,  25.9885,   4.4427]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 25.98851723402059\n",
      "Loss:  15.682843246578894\n",
      "Accuracy: 21.875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.4431,  -9.9611,   2.9893, -10.1609,   4.9595,   1.5361, -23.7108,\n",
      "          34.6498, -11.4480,  -1.0709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 34.64982251464042\n",
      "Loss:  2.2699109256318374e-10\n",
      "Accuracy: 22.265625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2002,  27.5687,   5.0702,   4.8517, -19.8217,  -7.9285,  -4.9052,\n",
      "          -7.0867,   4.2067,   0.2255]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 27.568730522822282\n",
      "Loss:  3.7852410088076404e-10\n",
      "Accuracy: 22.65625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.2618,   5.9148,  20.3471,  18.2186, -35.1344,   0.0457, -19.5306,\n",
      "         -16.5034,   7.3227,   3.5987]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  8\n",
      "activation[2] = 20.347062401481956\n",
      "Loss:  13.142290205466361\n",
      "Accuracy: 22.65625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.1502, -17.0753,  13.4162, -16.4703, -16.1650, -12.9106,  30.8391,\n",
      "          -6.8686,  -0.3610,  16.4448]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 30.839108807339393\n",
      "Loss:  5.905259412020617e-07\n",
      "Accuracy: 23.046875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-19.4161, -14.5852,  11.3667, -25.0770,  31.0213,   3.6905,   2.7467,\n",
      "           1.0293,   7.5033,   2.3697]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 31.02127839287812\n",
      "Loss:  2.9751394636941644e-09\n",
      "Accuracy: 23.4375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.2491,  30.5261,  -6.0869,   9.5589, -36.3935,  -7.1617,  -9.6736,\n",
      "          -7.7509,  25.9711,   7.6199]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 30.526129197098264\n",
      "Loss:  0.010459669229208875\n",
      "Accuracy: 23.828125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.2504,   0.7715,   8.1288,  -6.8981, -22.9461,  -7.2994,  15.2064,\n",
      "         -18.0918,  13.6659,  16.5219]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.521939053889138\n",
      "Loss:  1.5977676841615283\n",
      "Accuracy: 23.828125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2708,   0.6772, -15.8000,  36.4045, -50.6490,  -9.7864,  -7.0609,\n",
      "          -7.8441,  21.6674,  22.0669]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 36.4044994898072\n",
      "Loss:  9.911817614978541e-07\n",
      "Accuracy: 24.21875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-10.1360, -24.7343,  -6.0470, -19.6317,  29.8605,  -1.0112,  14.6661,\n",
      "           1.3147,  13.6921,   2.9455]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 29.860520379290413\n",
      "Loss:  3.4694731641978336e-07\n",
      "Accuracy: 24.609375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.9637,  12.5330, -13.5108,  11.3820, -28.7258, -14.8303,  10.9511,\n",
      "         -10.4925,  23.4039,   0.1325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 23.40385659090204\n",
      "Loss:  38.23417983089525\n",
      "Accuracy: 24.609375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.0985, -10.9193, -14.6748,  15.9943, -17.3658,  17.4808,   1.8302,\n",
      "          -3.7424,  -1.6507,  19.9300]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.93004918406601\n",
      "Loss:  0.10065284093973892\n",
      "Accuracy: 25.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.3412,  -9.5977,  -6.6504,  17.8338, -10.7269,   6.6898,   8.6091,\n",
      "         -11.6963,  -2.1978,  17.4252]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 17.833803400562218\n",
      "Loss:  27.941104773404906\n",
      "Accuracy: 25.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.0743,   8.2442, -10.6559,  16.0076, -45.4469,  33.8440,   5.4538,\n",
      "         -24.8226,  16.1277,  -4.9224]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 33.844036669208066\n",
      "Loss:  17.836447906025032\n",
      "Accuracy: 25.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.5869,  19.4871,  -4.4445,  39.1248, -31.4634, -18.1746,   9.9608,\n",
      "         -14.4518, -10.5802,   3.9902]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 39.12478523295496\n",
      "Loss:  2.9612505736973283e-09\n",
      "Accuracy: 25.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.1071,  30.1036,  -7.2942,  20.4443, -31.2619, -12.4160,   2.4693,\n",
      "         -11.2036,  22.6865, -13.9009]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 30.10356087173576\n",
      "Loss:  7.41775855570723\n",
      "Accuracy: 25.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.3869,  -9.7929,  -4.4844,  27.6473, -44.5656, -24.3188,  37.6011,\n",
      "         -19.2662,   6.5168, -10.4183]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 42.38688352171947\n",
      "Loss:  66.7139791703342\n",
      "Accuracy: 25.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-36.3964, -33.5428,  10.9341,  -7.0697,  21.5321,   7.2604,  17.9184,\n",
      "          -3.0772,  21.8399,   1.6498]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.839945146703805\n",
      "Loss:  0.8702193139845631\n",
      "Accuracy: 25.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.0072, -12.0824,  -0.2054,  16.0252,  -9.4267,   2.1191,  -5.7400,\n",
      "          -0.6800,  10.0550,   8.5551]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 16.02518148143714\n",
      "Loss:  16.708312006831406\n",
      "Accuracy: 25.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-21.8208, -20.9349, -10.2137,  -2.2814,  15.9295,   5.9893,  -4.3208,\n",
      "          33.2813,  23.2583, -18.8046]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 33.2812892657951\n",
      "Loss:  4.439444049461118e-05\n",
      "Accuracy: 25.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-15.4467, -30.6316,   9.8645,  -6.4279,   5.4064,   2.6138,   4.6642,\n",
      "          10.5755,   9.3309,  10.6449]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 10.644917759024546\n",
      "Loss:  6.219894060997627\n",
      "Accuracy: 25.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-25.7575,  -3.3166,  11.9318,   1.2436, -17.0179,   5.0276,   6.2570,\n",
      "           1.1000,  24.2530,  -3.9584]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 24.25304427006717\n",
      "Loss:  12.321216052063722\n",
      "Accuracy: 25.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-6.6953, -7.6136, 13.1441,  8.5609, -1.0358, -5.4276,  5.2530, -9.7794,\n",
      "          2.7511,  1.0340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  8\n",
      "activation[2] = 13.144126910119883\n",
      "Loss:  10.403583505547212\n",
      "Accuracy: 25.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-12.2088, -10.4433,  17.2659, -17.5088,  16.2858,  31.6055,   6.9358,\n",
      "          10.7502, -12.1066, -29.6815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 31.605477621965175\n",
      "Loss:  8.151724816640088e-07\n",
      "Accuracy: 26.171875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3353, -26.8048,  -0.5999,   3.1163,  -1.6312,   7.7008,  24.4488,\n",
      "          -8.3267,  34.7081, -31.2814]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 34.7081054755767\n",
      "Loss:  3.503088797531023e-05\n",
      "Accuracy: 26.5625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-49.1095, -24.5945,  25.3327, -17.4561,  32.2315,  12.8454,  62.7738,\n",
      "          -4.6736,  -9.5028, -26.8429]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 62.77378933775221\n",
      "Loss:  5.4400928206631194e-14\n",
      "Accuracy: 26.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.9587, -30.1877,  16.8277, -16.0124,  14.2377,  10.8355,   7.8861,\n",
      "           2.6317,  11.6208,  -3.6966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  7\n",
      "activation[2] = 16.8277399221923\n",
      "Loss:  14.275852568582657\n",
      "Accuracy: 26.953125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-17.3760, -30.3715, -30.2550,  51.6560, -11.9637,  -5.5618,  12.5233,\n",
      "          -2.3708,  23.6902,  10.0222]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 51.65602186825418\n",
      "Loss:  7.15427717068195e-13\n",
      "Accuracy: 27.34375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.5373,   6.2712, -16.0048,  -4.8371,  31.9049,  -8.0143,  17.6758,\n",
      "          19.1922, -10.0521, -26.7876]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 31.90492964685354\n",
      "Loss:  3.673684840280052e-06\n",
      "Accuracy: 27.734375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-23.6927, -20.7378,   6.3312, -23.7014,  23.6490,  12.8280,  66.2051,\n",
      "          24.1988, -33.4365, -30.1057]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 66.2051453006693\n",
      "Loss:  0.0\n",
      "Accuracy: 28.125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.7963,  18.5446, -10.0494,   0.0597, -16.9787,   2.6606,  12.6284,\n",
      "          15.9231,   7.4491, -20.3878]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 18.54457167552255\n",
      "Loss:  0.0726997903996942\n",
      "Accuracy: 28.515625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-22.1735, -18.5108, -20.6904,  -1.4762,  10.1547,   5.6892,   5.7664,\n",
      "          18.1081,   6.7032,  16.1200]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.108058008459082\n",
      "Loss:  2.1167657315214012\n",
      "Accuracy: 28.515625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4329, -25.6305, -22.5739,  21.5652,   3.8572,   0.8129,  -1.5819,\n",
      "          12.3805,   3.7719,  10.8878]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 21.56521159633288\n",
      "Loss:  10.677528242702753\n",
      "Accuracy: 28.515625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-28.4884, -19.0122,   7.5199, -32.5431,  16.5815,  12.9113,  67.3459,\n",
      "           3.5730, -24.6439,  -1.6915]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 67.34588383381855\n",
      "Loss:  0.0\n",
      "Accuracy: 28.90625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 48.1031, -18.2911, -25.3521,   5.8558, -20.1389,  16.4374,   0.6381,\n",
      "          -0.8782, -13.5886,   8.3875]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 48.10308226227059\n",
      "Loss:  1.7763568394002347e-14\n",
      "Accuracy: 29.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-22.1682, -36.7770, -34.8494,  29.6997,  -2.6874,   8.3957,  20.3977,\n",
      "         -14.9162,  29.7562,  23.2902]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 29.756169972152218\n",
      "Loss:  0.7226210976545004\n",
      "Accuracy: 29.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.1872, -11.7131,  -9.4149, -10.4868,  19.0623,  -4.8265,   3.3293,\n",
      "           7.5848, -16.9600,  20.4041]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.4041261484233\n",
      "Loss:  13.05154876662653\n",
      "Accuracy: 29.296875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-21.3852, -28.1007,  36.5833,  -9.8383, -16.0637,  16.6667,  15.9443,\n",
      "          11.3059,  -2.2523,  -2.6586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 36.583271839549084\n",
      "Loss:  3.3388827202821824e-09\n",
      "Accuracy: 29.6875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-25.3517, -11.5238, -32.5352,   8.4099,  -0.1510,   3.1179,   8.8083,\n",
      "          14.9637,   3.1843,  31.4237]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 31.423711505104958\n",
      "Loss:  28.239387362754464\n",
      "Accuracy: 29.6875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.6636, -33.8235,  -0.8590,  36.1290, -48.7140,  30.3096,  13.3134,\n",
      "         -11.0021,  21.8864, -12.1677]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 36.12902541057491\n",
      "Loss:  36.99095511988478\n",
      "Accuracy: 29.6875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-20.7056, -31.0776,   4.8701, -21.8976,  -0.1872,   1.4174,   1.9396,\n",
      "          19.3900,  18.5399,  27.6848]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.684760116839833\n",
      "Loss:  0.00035653961038550056\n",
      "Accuracy: 30.078125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-41.0924, -17.8034,   9.4262, -30.4539,  56.6554,  -0.7572,  12.7509,\n",
      "          14.6769,  10.8064, -13.8210]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 56.65541378985577\n",
      "Loss:  0.0\n",
      "Accuracy: 30.46875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-20.7585, -30.5088,  19.1835, -34.2446,  43.5293,  -4.9170,  13.8013,\n",
      "          25.3356, -13.1596,   2.8961]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 43.5292515563016\n",
      "Loss:  1.2576090312212903e-08\n",
      "Accuracy: 30.859375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-41.4872, -17.7521,  33.8739, -34.8289,  15.6396,   7.8938,  77.0789,\n",
      "          -5.5441,  -8.4213, -24.6814]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 77.0788893869674\n",
      "Loss:  0.0\n",
      "Accuracy: 31.25 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-30.0807, -37.1327,   2.2841, -38.4414,  41.3417,  10.2745,  11.7558,\n",
      "          13.2379,  18.4075,   8.5904]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 41.34171767434831\n",
      "Loss:  1.1040013347342162e-10\n",
      "Accuracy: 31.640625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.4450, -35.8027,  -6.5263, -22.8778,  32.9959,   6.1546,   7.4183,\n",
      "          16.9083,  -5.6830,  14.1485]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 32.99589633021725\n",
      "Loss:  18.84735429138744\n",
      "Accuracy: 31.640625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-24.5953,  -4.0196,  19.2922, -29.8831, -39.3511,   2.9632,  -7.7654,\n",
      "          20.0662,  39.5304,  22.9303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 39.53044310842427\n",
      "Loss:  19.464290726722624\n",
      "Accuracy: 31.640625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.0845, -49.5898,  26.3851, -29.4559, -49.8605,  17.3528,  50.1738,\n",
      "          48.1414, -46.1534,  22.5189]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 50.1737777540161\n",
      "Loss:  38.21241945057264\n",
      "Accuracy: 31.640625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.3601, -28.4046,   3.5624, -23.0938, -24.2958,  -1.7165, -22.7670,\n",
      "          38.9114,  -6.0026,  56.3702]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 56.37017873708191\n",
      "Loss:  2.616792837041448e-08\n",
      "Accuracy: 32.03125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.8439, -29.8999,  81.7172, -42.6918, -56.8743,  21.8717, -10.8269,\n",
      "          36.1599, -28.4058,  16.8836]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 81.71718527623904\n",
      "Loss:  0.0\n",
      "Accuracy: 32.421875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.1145, -33.6981, -20.1417, -24.1983,   2.9132,   5.6889, -25.5643,\n",
      "          53.1696, -11.6142,  33.9586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 53.16958185778295\n",
      "Loss:  19.210979529809133\n",
      "Accuracy: 32.421875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-12.7941,   0.6297,  22.0372, -17.0742,  -3.5212,  17.1298, -10.3936,\n",
      "          10.5523,  -3.1507,  -3.5365]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  5\n",
      "activation[2] = 22.037187311037496\n",
      "Loss:  4.914772336204764\n",
      "Accuracy: 32.421875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2667,  21.4828,  -8.2307,  -5.6211, -22.8738,  10.6371,  -5.1197,\n",
      "          15.6624,  -6.6773,   2.8743]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.482842284475083\n",
      "Loss:  0.0029812656334786574\n",
      "Accuracy: 32.8125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.9227,  -7.0250,   2.8379, -21.2939, -17.6955,  50.8354, -14.4466,\n",
      "          10.3418, -20.8859,  13.5122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 50.83538018798383\n",
      "Loss:  0.0\n",
      "Accuracy: 33.203125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3816,  -7.0659, -16.3734,  -5.6421, -26.2946,  14.4993, -19.5271,\n",
      "          10.3354,  -8.5918,  59.5865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 59.58650601881023\n",
      "Loss:  0.0\n",
      "Accuracy: 33.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.5104,  17.3987,  -9.1893, -12.8367, -17.9324,  13.3116, -23.6023,\n",
      "          38.8481,  -8.1092,   5.9492]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 38.84811437750061\n",
      "Loss:  21.44939957190085\n",
      "Accuracy: 33.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.2228, -10.0048,  16.3158, -19.5650,   3.5653,  15.4890,   2.1679,\n",
      "          -5.4647, -25.4579,  -3.1111]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 27.222832551984197\n",
      "Loss:  10.907051857365074\n",
      "Accuracy: 33.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2384, -22.6494,  22.3775,  11.9930, -41.9822,  26.0424, -17.7228,\n",
      "         -20.0593,  -6.2510,  38.1963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 38.19626263860122\n",
      "Loss:  26.20322720337848\n",
      "Accuracy: 33.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.2607,  25.0550,   8.0898,  -7.3830, -26.5695,  19.1491,  -5.0925,\n",
      "          12.0189, -21.8182,   0.9787]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 25.054961675593326\n",
      "Loss:  16.96792815525217\n",
      "Accuracy: 33.59375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.2862, -29.3447,  12.1306,  44.2030, -35.7740,  19.1023, -35.0793,\n",
      "           5.6860,  -0.0765,  -3.3041]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 44.203038023708\n",
      "Loss:  3.156948035821957e-10\n",
      "Accuracy: 33.984375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.2630, -11.8489,  26.0044,  21.7467, -48.1208,  13.8844,  -6.3565,\n",
      "          -2.3623, -16.8093, -13.3199]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 38.263019473588386\n",
      "Loss:  24.37862722880171\n",
      "Accuracy: 33.984375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-12.2273, -33.0109,  11.9586,  -0.2784, -20.0102,  28.5338, -26.0577,\n",
      "           5.9736, -21.4324,  66.9522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 66.9522130333722\n",
      "Loss:  0.0\n",
      "Accuracy: 34.375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-23.1748,  20.4436,   7.3414,   4.4074, -21.0971,  23.4495,  -5.1221,\n",
      "          -5.1209,  -5.0445,   3.4242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 23.449455799496825\n",
      "Loss:  3.054130275297308\n",
      "Accuracy: 34.375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.2060,  -8.9856,   4.0922, -17.2744,   6.9356,  21.4390, -31.3521,\n",
      "          31.9362, -37.0375,  25.1307]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 31.936165381227067\n",
      "Loss:  0.0011346843773756734\n",
      "Accuracy: 34.765625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-28.5685,   4.2834,  44.5235,  -7.3046, -10.0927,  11.7391,  15.5187,\n",
      "         -11.7290, -19.3970,   1.8518]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  6\n",
      "activation[2] = 44.523462518362905\n",
      "Loss:  29.004716043324766\n",
      "Accuracy: 34.765625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-14.6472,  14.2920,  76.7983,  -6.4867, -49.9947,  53.5646,  25.2699,\n",
      "         -21.8096, -55.8378, -19.5451]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 76.79834127010695\n",
      "Loss:  8.122991168261028e-11\n",
      "Accuracy: 35.15625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-14.3856, -15.8983,   4.7378,  -6.7305,  -4.0514,  26.5232,   9.7825,\n",
      "           1.2945,   3.3835,  -4.5064]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 26.523231962206395\n",
      "Loss:  23.139721543455373\n",
      "Accuracy: 35.15625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-28.2879,  16.7527,  64.1101, -12.6352, -48.6649,  26.0578,   5.9511,\n",
      "          -2.8491, -29.5915,  10.0403]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 64.11012255434238\n",
      "Loss:  0.0\n",
      "Accuracy: 35.546875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-18.2652,  32.3144,  51.3475,  -6.5703, -48.6084,   5.1882,  33.9955,\n",
      "          -4.7257, -18.0639, -26.0796]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 51.347489383400614\n",
      "Loss:  3.453517412362379e-08\n",
      "Accuracy: 35.9375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-14.3540,  -4.8375,  24.4804, -21.2553,  -1.2944,  32.1503,   5.2019,\n",
      "          -4.2963,  -9.9337,  -4.7629]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 32.15034340989953\n",
      "Loss:  0.0004665268910794116\n",
      "Accuracy: 36.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.2301, -31.7078,  41.0436, -15.2425, -28.7797,  10.6758,  22.6382,\n",
      "           3.7834, -23.8883,  -8.0193]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  0\n",
      "activation[2] = 41.04358071359722\n",
      "Loss:  9.813536022105481\n",
      "Accuracy: 36.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.6414,  -6.5214, -37.9355, -12.7828,  12.2680,   5.1490, -23.6599,\n",
      "          26.2018,  -8.8406,  19.2366]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 27.641355085656084\n",
      "Loss:  1.652413665566342\n",
      "Accuracy: 36.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-20.5962, -18.9507, -10.3054,  -6.4745,   7.9737, -21.4117,   3.7731,\n",
      "          21.7051,  19.6020,  25.2435]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.24354797149103\n",
      "Loss:  17.301886505790428\n",
      "Accuracy: 36.328125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-12.5774, -13.2758, -29.2004,   8.5865,   2.4671,   4.3830, -11.8168,\n",
      "           4.7496,  18.8850,  27.7705]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.77045795366491\n",
      "Loss:  0.00013838603410721561\n",
      "Accuracy: 36.71875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.2824, -12.7434, -21.9826,  -2.1928,  14.4607,   0.8010, -15.1393,\n",
      "          45.5348, -16.8034,   6.5542]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 45.53478276873022\n",
      "Loss:  3.1974423109204e-14\n",
      "Accuracy: 37.109375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-16.0055,   7.4730,  -8.5174,   8.1509,  -7.8456,  13.2946,  -4.4941,\n",
      "          -2.6128,  34.4125, -24.4100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 34.412505277670896\n",
      "Loss:  6.798261951067142e-10\n",
      "Accuracy: 37.5 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-17.3670,  19.9021,  -5.2539,  17.5343, -22.7229,   4.3072,  12.0715,\n",
      "          15.1683,  -0.2297, -23.0821]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 19.90206159378814\n",
      "Loss:  2.4656672341074293\n",
      "Accuracy: 37.5 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-19.9346, -24.2141,  32.5480,  -3.2605,  -2.8539,  10.3956,   1.4261,\n",
      "          24.0845,  -1.8489, -16.4091]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 32.54804857932444\n",
      "Loss:  0.00021100282422991922\n",
      "Accuracy: 37.890625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-26.2831,  25.5260, -13.8395,  18.2220, -14.6137,   0.9928,   7.1399,\n",
      "           2.5423,   4.9114,  -4.7960]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.526006763247555\n",
      "Loss:  0.0006726357580494702\n",
      "Accuracy: 38.28125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-32.4853,   6.0540,  -3.2325,  18.0446,  11.6439,  -0.8800, -12.6336,\n",
      "          11.7693,  26.1972, -25.4001]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 26.197169802136607\n",
      "Loss:  20.143440172716552\n",
      "Accuracy: 38.28125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.2526,   4.9296,  -4.0580,  24.1023,  -0.0483,  14.1450,  -7.1739,\n",
      "          -6.5289,  -0.8050, -18.4134]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 24.102348818560145\n",
      "Loss:  24.90737804728496\n",
      "Accuracy: 38.28125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.8201, -15.6404, -24.4073,  47.5425, -17.6956,   5.4701, -21.9847,\n",
      "           5.9218,  46.8670, -19.7459]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 47.54251525672967\n",
      "Loss:  0.4113732941304179\n",
      "Accuracy: 38.671875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-47.4930,  -7.4718,   4.1850,  -8.8874,  30.1488,   3.1243,  40.2927,\n",
      "          10.8437,  -0.1769, -23.8799]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 40.292719431959675\n",
      "Loss:  3.931305049318162e-05\n",
      "Accuracy: 39.0625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-21.2127,  49.3628,   5.1511,  14.2600, -13.3554,   2.9925,  -7.3895,\n",
      "          -0.2667,   7.7017, -38.1064]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 49.36283640433895\n",
      "Loss:  6.661338147750937e-16\n",
      "Accuracy: 39.453125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 68.4112, -18.5590, -15.4600,  31.1563, -28.0840,   8.5839, -20.5937,\n",
      "          15.7073,   7.6384, -48.6218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 68.411176646042\n",
      "Loss:  0.0\n",
      "Accuracy: 39.84375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4156e-02, -1.3438e+01,  4.5938e+00,  2.8295e+01, -1.2266e+01,\n",
      "          2.2583e+00, -1.4675e+01,  3.1607e+01,  1.0300e+00, -2.7321e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 31.60660126391769\n",
      "Loss:  3.3474207117260266\n",
      "Accuracy: 39.84375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-22.3392,  41.9384,   0.7555,  25.3350, -22.1220,   0.2866,   3.6509,\n",
      "          -7.1886,  -8.3363, -12.5240]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 41.938389853788\n",
      "Loss:  6.154924713663511e-08\n",
      "Accuracy: 40.234375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 83.4932, -34.6328,  -2.6835,  47.7950, -36.2984,  19.8739, -10.0526,\n",
      "          -7.0348, -16.1707, -43.2339]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 83.4931838738272\n",
      "Loss:  2.2204460492503128e-16\n",
      "Accuracy: 40.625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.0491, -20.3194, -14.1455,   7.7243,  -8.5775,  -1.3532,  -3.4345,\n",
      "           3.7907,  13.0387, -14.8605]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 38.04906965453381\n",
      "Loss:  1.3813394872290792e-11\n",
      "Accuracy: 41.015625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-19.5517,  46.0007,  -5.0768,  26.9052, -21.0267,   1.9412,   4.5827,\n",
      "         -10.3012,  -4.2805, -19.4232]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 46.00068707767458\n",
      "Loss:  5.092500630433163e-09\n",
      "Accuracy: 41.40625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.3256,  13.5379, -20.7973,  17.1045, -14.5978,  -3.6192,  -1.6597,\n",
      "           3.7938,  12.8589,   6.1892]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.104508950681947\n",
      "Loss:  13.352467565370484\n",
      "Accuracy: 41.40625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-29.6591,  -0.7623,  29.6663,   3.7904,  25.5133,   8.7996,  25.4477,\n",
      "          -7.6208,  -8.1801, -46.7374]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 29.666269059821364\n",
      "Loss:  0.029983435559331757\n",
      "Accuracy: 41.796875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.7510, -22.0948,  -4.9813,  27.5550,  -4.1672,  -0.4288, -18.0277,\n",
      "          43.5540, -17.0596,  -0.1442]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 43.55401490305354\n",
      "Loss:  1.1264958997277234e-07\n",
      "Accuracy: 42.1875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.0509,  -6.8261,  -6.2327,  96.1192, -31.6875,   2.3722,  -9.4688,\n",
      "         -18.8691,  10.2276, -27.8630]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 96.11923777859968\n",
      "Loss:  0.0\n",
      "Accuracy: 42.578125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.4537, -40.2291, -13.2918,   0.6092,  -2.9212,   9.2854,  15.6907,\n",
      "           9.2196,  -3.6236,  -3.4776]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 29.45374729279975\n",
      "Loss:  1.0572323414663487e-06\n",
      "Accuracy: 42.96875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2049, -22.8092, -12.8261, -10.4381,  39.2637,  -4.2662,   3.5230,\n",
      "           6.3794,   2.4435,   2.4679]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 39.26371000361604\n",
      "Loss:  5.551115123125767e-15\n",
      "Accuracy: 43.359375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.1408,  -7.0280,  -2.7889,   1.7197,   2.3732, -11.2555,  48.5678,\n",
      "          -2.2110,  -2.3681, -14.4824]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 48.56777063451512\n",
      "Loss:  0.0\n",
      "Accuracy: 43.75 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.5075,  -6.4812, -12.4950,  31.5550,  -1.7337,  26.4136,   2.9279,\n",
      "         -25.1253,   3.9190, -18.7312]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 31.554974565842766\n",
      "Loss:  5.147180248422075\n",
      "Accuracy: 43.75 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.2395, -21.8141,  15.1889,   3.0272,   6.8519,  38.8464,  14.1679,\n",
      "          -5.2397,  16.1552, -75.2065]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 38.846417697029075\n",
      "Loss:  23.657530210949073\n",
      "Accuracy: 43.75 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.5153, -17.3354,  20.0500, -47.1659,  22.2519,  -5.2017,  52.4169,\n",
      "          20.3777, -14.2348, -32.1099]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 52.41692767066506\n",
      "Loss:  1.0036416142610912e-13\n",
      "Accuracy: 44.140625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.6732, -20.5742,  13.9193,  12.5290,  51.2165, -21.7205,  14.3635,\n",
      "           8.0342, -22.9528, -27.3212]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 51.21649674106238\n",
      "Loss:  2.2204460492503128e-16\n",
      "Accuracy: 44.53125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.5990, -18.6514,  -8.3851, -24.4160,  22.8185,   5.4595, -12.2039,\n",
      "          38.4405,  -3.0733,  14.5542]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 38.44053154296511\n",
      "Loss:  1.6425911991558944e-07\n",
      "Accuracy: 44.921875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.9678, -13.6127,  -5.0041,  -3.3001,  -5.1699,  10.4623, -23.6168,\n",
      "          12.8131,  19.7833,  -4.5181]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 19.78333301392964\n",
      "Loss:  33.397464196657026\n",
      "Accuracy: 44.921875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.3778,  22.2545,  19.2212,   3.7233,  -0.1014,  17.4911,  -3.4510,\n",
      "         -22.3458,  -6.7118, -22.5739]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 22.254533263923253\n",
      "Loss:  29.02148308032238\n",
      "Accuracy: 44.921875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-20.7519,  -6.5482,  -0.5161,   5.0446,   2.2090,  -0.5879, -10.3373,\n",
      "          16.1383,  -3.1244,  18.3423]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.342303539867025\n",
      "Loss:  0.10468437210812225\n",
      "Accuracy: 45.3125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-10.1509, -23.1924, -12.2862, -13.4184,   3.3280,   5.4994,   1.4123,\n",
      "           7.9631,  20.5866,  19.8922]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 20.58659112382781\n",
      "Loss:  1.0994354015533663\n",
      "Accuracy: 45.3125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.2156, -11.2729,  -6.3891,  -7.0342,  15.0245, -11.4485,  15.4700,\n",
      "           0.7983,   3.6269,  -0.8477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 15.46996845057884\n",
      "Loss:  22.999207561792158\n",
      "Accuracy: 45.3125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 86.6243, -40.3355,  25.6403,  14.9109, -33.1488,  -9.5641, -34.4165,\n",
      "          22.9220, -26.3252,  -5.5964]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 86.6242644186611\n",
      "Loss:  0.0\n",
      "Accuracy: 45.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.8553,  -3.1880,   6.7185, -10.9549,   0.7426,   1.5991, -25.5252,\n",
      "          25.1457, -17.8035,  31.8036]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 31.803587203062897\n",
      "Loss:  6.659178022690911\n",
      "Accuracy: 45.703125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-19.4986,  37.9589,  12.9153,   2.1429, -22.4093,  -1.4826,   4.9800,\n",
      "          14.2518,  -1.1797, -27.6323]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 37.95886027478994\n",
      "Loss:  6.390155071551828e-11\n",
      "Accuracy: 46.09375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.1248, -28.8634,  10.8565,  -3.2970,   0.7901,   1.8357,  23.6572,\n",
      "          12.8250, -10.1038, -11.8000]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 23.65719015575724\n",
      "Loss:  18.532453953500152\n",
      "Accuracy: 46.09375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-26.9532, -14.8684,  52.9420,  -0.5978,  30.2349,  -5.3502,  -4.0443,\n",
      "           9.8708,  14.7204, -55.9635]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 52.94199108996213\n",
      "Loss:  1.3754064553004359e-10\n",
      "Accuracy: 46.484375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 48.6310, -40.0173,   5.3112,   4.7399,   5.4114,   8.3834, -20.1798,\n",
      "          23.5341,   1.9241, -36.4163]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 48.630976661214504\n",
      "Loss:  1.2606138355329345e-11\n",
      "Accuracy: 46.875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4931e-03, -1.6038e+01,  2.5720e+01,  5.7596e+01, -1.6912e+01,\n",
      "         -2.0889e+00, -3.2565e+01, -3.1049e+00,  1.3849e+01, -2.6694e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 57.596260522122506\n",
      "Loss:  1.443289932012693e-14\n",
      "Accuracy: 47.265625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.2816,   1.8654,  -8.3979,   5.2080, -20.7861,  39.4073, -49.3919,\n",
      "          24.9520,   0.4226, -22.3845]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 39.407278501187236\n",
      "Loss:  4.056490151027727e-05\n",
      "Accuracy: 47.65625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.9463, -16.7119,   1.2828, -14.8525,  44.6938,  -9.4856, -23.3040,\n",
      "          25.2287, -14.8621,   4.2055]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 44.693763469865125\n",
      "Loss:  3.519001528421467e-09\n",
      "Accuracy: 48.046875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.2335,  -9.1924,   5.6919,  -6.2931,  22.7496, -15.5124,  16.4769,\n",
      "          29.3774, -14.2638, -32.1539]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 29.377383068532435\n",
      "Loss:  12.901851892727278\n",
      "Accuracy: 48.046875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.3107,  -4.6476,  10.3433,  11.3428, -17.1906,  51.6493, -12.8605,\n",
      "          -2.6427, -22.3581, -17.1357]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 51.649313903455216\n",
      "Loss:  0.0\n",
      "Accuracy: 48.4375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-18.1260,   9.9023,  13.7838,   6.8319, -15.4711,  -5.8766,  -5.5057,\n",
      "           5.0814,   7.6981,   1.0620]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  8\n",
      "activation[2] = 13.78378035858783\n",
      "Loss:  6.109397177605671\n",
      "Accuracy: 48.4375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 25.6702,  -4.8778,   8.9213, -13.2752,  26.2494, -12.6270,  28.0946,\n",
      "           7.1459, -25.9101, -38.0146]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 28.0945684105313\n",
      "Loss:  0.22035980544207587\n",
      "Accuracy: 48.828125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.5166, -17.7562,  20.9719,  77.8319, -40.6034,   6.3209,   3.7089,\n",
      "         -30.3579,  12.9086, -41.9077]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 77.8318641999353\n",
      "Loss:  0.0\n",
      "Accuracy: 49.21875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.7462, -16.8616, -21.0897,  -5.7237,   4.2425,   0.2219, -21.7605,\n",
      "          49.5897, -14.8660,  15.2296]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 49.58969722545175\n",
      "Loss:  1.332267629550187e-15\n",
      "Accuracy: 49.609375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 39.8344, -38.4980, -30.0881,  46.9797,  -7.6313, -12.6895,  29.5299,\n",
      "         -30.8797,  22.5185, -18.1120]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 46.97966665663215\n",
      "Loss:  59.66996456644389\n",
      "Accuracy: 49.609375 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.3138, -24.9136,  -7.3099, -29.7536, -10.1896,  49.1350,  -7.6967,\n",
      "         -16.1962,  65.6979, -24.7791]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 65.6978650872916\n",
      "Loss:  6.409560676635681e-08\n",
      "Accuracy: 50.0 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 43.3700, -13.1483,   8.3463,  -1.9896,  -8.9126,  13.8110, -15.2466,\n",
      "          -2.6175,  15.2964, -38.5778]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 43.370000579794514\n",
      "Loss:  7.884803920884753e-13\n",
      "Accuracy: 50.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.4104, -21.2830, -28.2311, -29.1567,   1.0461,  31.9141,   4.9524,\n",
      "           2.7608,  20.2308,  18.1416]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 31.914080115757873\n",
      "Loss:  13.772506349655675\n",
      "Accuracy: 50.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-23.0677,  21.6018, -24.9761, -11.3089, -21.3874,   9.9477,  11.0097,\n",
      "          -4.4572,  31.2769,  11.0823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 31.276913422548734\n",
      "Loss:  9.675153431381405\n",
      "Accuracy: 50.390625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 89.1651, -22.4115,  14.8198, -11.7678, -39.4583,  21.3896, -13.8423,\n",
      "           7.7205, -25.5558, -18.8925]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 89.16507122997126\n",
      "Loss:  0.0\n",
      "Accuracy: 50.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-24.2205,   8.9551,  -1.7664,  -3.0732,   1.7106,  26.7885,  21.5174,\n",
      "           6.2827, -28.3582,  -6.5644]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 26.788500384007396\n",
      "Loss:  29.866828461494\n",
      "Accuracy: 50.78125 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-18.8895,  57.6384,  -8.1781,  -2.7158, -21.0868,  -8.9531,   1.7214,\n",
      "           7.4996, -13.1211,   5.5722]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 57.63840946769967\n",
      "Loss:  0.0\n",
      "Accuracy: 51.171875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-18.5887,  50.0377,  36.0584,   7.8815, -46.9846,  -9.8249,  25.1260,\n",
      "           0.5302, -19.3837, -24.6601]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 50.03772888993301\n",
      "Loss:  13.979349912871722\n",
      "Accuracy: 51.171875 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-22.1661, -22.5473,  69.7537,   5.8781,  31.6252,  -6.5527,  40.0994,\n",
      "         -26.2003,  -4.0532, -65.2189]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 69.75369615131932\n",
      "Loss:  1.321165399303849e-13\n",
      "Accuracy: 51.5625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.8649,  -4.7713,  -8.9832,  11.3587,  -6.1491,  13.6680,  12.0602,\n",
      "         -12.4059, -20.7633,  -3.1306]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 19.864913723236633\n",
      "Loss:  8.508871992710416\n",
      "Accuracy: 51.5625 %\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0251e+01, -1.4502e+01,  1.7970e+01,  5.4160e+01, -1.6304e+01,\n",
      "          5.0798e-02, -1.3975e+01, -2.5835e+01,  2.7437e+01,  7.3383e-01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 54.159985517616526\n",
      "Loss:  2.4784618801701282e-12\n",
      "Accuracy: 51.953125 %\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import optimizers\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "\n",
    "net = LinLayer()\n",
    "weights = net.lin.weight\n",
    "print(\"initial weights: {}\".format(weights))\n",
    "biases = net.lin.bias\n",
    "print(\"initial biases: {}\".format(biases))\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "it = iter(mnist_dl) \n",
    "correct = 0\n",
    "\n",
    "for i in range(256):\n",
    "    net.zero_grad()\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    image, label = next(it)\n",
    "    # print(label[0].numpy())\n",
    "    l = label[0].numpy()\n",
    "    # print(\"image: \", image.flatten().numpy())\n",
    "    output = net(image.to(torch.float64))\n",
    "    print(\"output: \", output)\n",
    "    pred = torch.argmax(output).numpy()\n",
    "    print(\"Pred: \", pred, \"Label: \", l)\n",
    "    print(\"activation[{}] = {}\".format(pred, output[0][pred]))\n",
    "    if(pred == l):\n",
    "        correct += 1\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    weight_grads = net.lin.weight.grad\n",
    "    bias_grads = net.lin.bias.grad\n",
    "    optimizer.step()\n",
    "    print(\"Loss: \", loss.item())\n",
    "    # print(\"Correct: \", correct)\n",
    "    print(\"Accuracy: {} %\".format(100*correct/256))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    # # print(\"acc = \", (correct/256) * 100)\n",
    "    # # print(torch.argmax(output).numpy())\n",
    "    # optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "initial biases: Parameter containing:\n",
      "tensor([ 0.0298, -0.0277,  0.0149,  0.0131,  0.0262,  0.0057, -0.0165,  0.0169,\n",
      "         0.0078,  0.0310], dtype=torch.float64, requires_grad=True)\n",
      "----------------------------------------------------\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([ 0.0298, -0.0277,  0.0149,  0.0131,  0.0262,  0.0057, -0.0165,  0.0169,\n",
      "         0.0078,  0.0310], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ 0.0534,  0.1614,  0.2875,  0.0104,  0.2178, -0.2916, -0.0588,  0.4338,\n",
      "          0.1176,  0.0230]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.4337690970363521\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1206,  0.3183,  0.2240, -0.1714,  0.0955,  0.0566,  0.0727,  0.4501,\n",
      "          0.1011,  0.2312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.45009454601878124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1338, -0.0194, -0.1213, -0.0290,  0.1704,  0.1527,  0.1659,  0.2427,\n",
      "         -0.3283,  0.1948]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 0.2427357998033874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1902, -0.1749, -0.0681,  0.0937,  0.0351, -0.2296, -0.2869, -0.0555,\n",
      "         -0.0931,  0.1854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.18541030951089774\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3302, -0.0004,  0.1674, -0.0741, -0.1373, -0.1931,  0.2974,  0.0637,\n",
      "         -0.2696,  0.0524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 0.2974020008539473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0222,  0.1496,  0.0463, -0.1815,  0.2252, -0.1608, -0.0925,  0.3485,\n",
      "         -0.0555,  0.1837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.34846555334598583\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1763,  0.1303, -0.1686,  0.1605,  0.1711, -0.2156, -0.2545, -0.1243,\n",
      "         -0.1294,  0.1206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.17105783726174426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0227, -0.1058,  0.0499, -0.2108,  0.0181, -0.4102,  0.0559,  0.3151,\n",
      "          0.0639,  0.3867]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.3866677858665837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0542,  0.0751, -0.1175, -0.0564,  0.0888, -0.1167, -0.0978, -0.0143,\n",
      "         -0.0744, -0.0551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.08883737003918363\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0277,  0.2472,  0.0582, -0.1081,  0.1499,  0.0062, -0.2328,  0.3652,\n",
      "          0.0617,  0.2061]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 0.3651651211333304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2552,  0.1520,  0.0624,  0.0633,  0.1918, -0.2732, -0.2768,  0.1486,\n",
      "          0.1319,  0.1745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 0.19183556676711802\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0046,  0.1246, -0.1086, -0.0898,  0.1284, -0.0217, -0.1164,  0.1446,\n",
      "         -0.1633,  0.0618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.14455160959513763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0408,  0.1538, -0.0592, -0.1174, -0.0215, -0.1626, -0.2847,  0.1691,\n",
      "          0.1934,  0.0751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 0.19341563869082784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1521,  0.2750,  0.1968, -0.0608,  0.4242, -0.0112, -0.1486,  0.2284,\n",
      "          0.0721,  0.3206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 0.4241637823738784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0969,  0.0748, -0.0708, -0.1923,  0.2019, -0.1923, -0.1363, -0.0076,\n",
      "         -0.0163,  0.0309]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.2019374403734678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0945, -0.0046,  0.1664,  0.2108, -0.0849, -0.3480,  0.1288,  0.2253,\n",
      "         -0.0047,  0.1038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.2253364243025801\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1268, -0.0522,  0.2865, -0.0322, -0.0162, -0.2318, -0.1724,  0.0996,\n",
      "          0.0700,  0.4133]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.4133088473292486\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2610, -0.0608, -0.0302, -0.1357,  0.1453,  0.0152, -0.1796,  0.0009,\n",
      "         -0.2873,  0.1210]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 0.14532634386008092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2384,  0.1675,  0.1551, -0.1176,  0.1905,  0.2484, -0.0984,  0.0286,\n",
      "         -0.0208,  0.0669]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 0.24838940662973366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2198,  0.0749, -0.0210,  0.0518,  0.0067, -0.1122, -0.0437,  0.2329,\n",
      "         -0.1846,  0.0337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.2329163275297801\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1485,  0.2055,  0.2778,  0.0502,  0.0371, -0.0665, -0.1985,  0.2145,\n",
      "          0.1271,  0.5147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.5146556909574485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1567,  0.3049,  0.0240, -0.1346,  0.1345,  0.0462, -0.0161,  0.4726,\n",
      "          0.1410,  0.1934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.4726033741349284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0169, -0.0693,  0.1771, -0.0172,  0.1157, -0.0417, -0.1138,  0.1791,\n",
      "         -0.1567,  0.0847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.17906613068139043\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1704, -0.1790, -0.1373,  0.0924,  0.0141, -0.2587, -0.2516, -0.0916,\n",
      "         -0.1830,  0.2501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.25014121556979657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0938,  0.2388,  0.1150,  0.0929,  0.1468, -0.1596,  0.0450,  0.0483,\n",
      "          0.0862,  0.1210]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 0.23878045488798502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.2812e-01,  3.0054e-02,  3.9902e-01, -2.0367e-01,  5.0927e-02,\n",
      "         -2.6854e-01,  8.5526e-03,  1.5468e-04, -3.8317e-02,  3.5542e-01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 0.3990186048710408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0913, -0.0833,  0.0220,  0.0266, -0.0080, -0.2378, -0.0220, -0.0140,\n",
      "          0.0482,  0.0860]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.08602569538494531\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0051,  0.0108,  0.2474, -0.1496,  0.2062, -0.6172, -0.0040,  0.2403,\n",
      "          0.1572,  0.2954]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.2954263379748703\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0928,  0.0212,  0.1515,  0.1491, -0.2345, -0.5056, -0.0777,  0.3036,\n",
      "         -0.1083,  0.0315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.3036214978247592\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0621, -0.0951, -0.0675,  0.0382,  0.0544,  0.0237, -0.1186,  0.1182,\n",
      "         -0.1273,  0.2731]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.27311295162340377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0416,  0.1212,  0.0374,  0.2056,  0.0909, -0.1734, -0.1135,  0.2314,\n",
      "         -0.0138,  0.1996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 0.23143287827747522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2192, -0.1824,  0.1623, -0.2782,  0.3247, -0.2435, -0.2657, -0.0593,\n",
      "         -0.2668,  0.3762]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.37623526751969233\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1701,  0.2816,  0.0924, -0.0129,  0.1181,  0.0938,  0.0546,  0.2161,\n",
      "          0.1938,  0.1669]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.28160446360921415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1307, -0.0823,  0.1249,  0.1477, -0.1231, -0.2214, -0.2409,  0.2117,\n",
      "         -0.1876,  0.0793]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.21173090618663395\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2293,  0.1389,  0.1197,  0.1266, -0.1654,  0.0319, -0.0066,  0.1803,\n",
      "          0.0818, -0.0153]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.22931085570473836\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0916,  0.1578, -0.1582,  0.1552, -0.0341, -0.0821, -0.0819, -0.0200,\n",
      "         -0.0042,  0.0523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.15776395544050478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0537,  0.3287,  0.0693, -0.0841,  0.2679,  0.1073, -0.0245,  0.3094,\n",
      "          0.3278,  0.1998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.328706245051235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1491,  0.2988,  0.1593,  0.0852, -0.0125,  0.2074, -0.0081,  0.3905,\n",
      "          0.0225,  0.1927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.3904814901663039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0877, -0.0557,  0.2615,  0.1272,  0.0556, -0.2531, -0.1613,  0.0821,\n",
      "         -0.0762,  0.2897]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.2896583367931229\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3461,  0.2721,  0.1381,  0.0026,  0.2056,  0.1211,  0.0998,  0.1747,\n",
      "         -0.0035,  0.0924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 0.3460710351836687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2213,  0.1178, -0.0356, -0.1345,  0.2474, -0.1249, -0.1225, -0.1134,\n",
      "         -0.0508,  0.0856]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.24741405240544437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2950,  0.0502,  0.0148, -0.0086,  0.0149, -0.1116,  0.0334,  0.0262,\n",
      "         -0.0910,  0.0975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.0975219994409113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1139,  0.0092, -0.0910, -0.0016,  0.0893, -0.2013,  0.0340,  0.0130,\n",
      "         -0.0861,  0.1060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.1059572802165898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2253,  0.0853,  0.1445, -0.0876,  0.1130, -0.2059, -0.0595,  0.1735,\n",
      "         -0.0567, -0.0523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.17348529862263418\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0179,  0.1973,  0.0629, -0.2985,  0.0080, -0.1731, -0.0895,  0.1199,\n",
      "          0.1326,  0.0618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 0.19728917854650566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2153,  0.0721,  0.1943,  0.0028, -0.0340, -0.2324,  0.1533,  0.0852,\n",
      "         -0.0484,  0.1119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  9\n",
      "activation[2] = 0.19427514766131285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0348,  0.0220, -0.0024,  0.1046, -0.0885, -0.0788,  0.0300, -0.2649,\n",
      "         -0.0771, -0.0340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 0.10457226793389748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1270,  0.0928,  0.1177,  0.1233, -0.0291, -0.0138, -0.1313,  0.2303,\n",
      "          0.0509,  0.0592]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.23030140294170715\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1428,  0.1898,  0.0511,  0.0450,  0.0838, -0.0539, -0.0580, -0.0487,\n",
      "          0.2971,  0.0494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 0.2971078930633837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0011,  0.0950, -0.0601, -0.0931,  0.1505, -0.2437, -0.0540,  0.2632,\n",
      "          0.1436,  0.0646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 0.26316001745494094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0251,  0.0450,  0.1208, -0.0368,  0.0861,  0.0247, -0.2242,  0.0878,\n",
      "          0.0973,  0.2288]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.22876178746610787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3597,  0.0170, -0.0059, -0.1716,  0.0810, -0.0980,  0.1728,  0.4008,\n",
      "          0.2002,  0.1763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.40081367646999283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0404, -0.0281,  0.0429,  0.1512, -0.1671, -0.3055,  0.2562,  0.2138,\n",
      "          0.1506,  0.1438]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 0.2562147040581743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1706, -0.0018, -0.0618,  0.0561,  0.1363, -0.1609, -0.1833,  0.2287,\n",
      "          0.0804,  0.1477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 0.22865371411653573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1471,  0.0357,  0.1216, -0.0781, -0.1001, -0.2460,  0.1180,  0.1479,\n",
      "         -0.0017,  0.1449]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.14786585131881225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0538,  0.0596,  0.0597,  0.0121, -0.0497, -0.2221,  0.0290,  0.0932,\n",
      "         -0.1606, -0.0675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 0.09323456701662457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4855,  0.1284,  0.0320,  0.0187, -0.2364,  0.1334,  0.1718,  0.2052,\n",
      "          0.1041, -0.0232]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.485501185080544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1469,  0.0099,  0.1275,  0.0571,  0.0990, -0.1328, -0.0932,  0.1520,\n",
      "         -0.0108,  0.1462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.15198197667158345\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2842,  0.2050,  0.2966,  0.0251, -0.1458, -0.2831, -0.2186,  0.2457,\n",
      "          0.1458,  0.2999]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.2999422456915089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1938, -0.1231, -0.0644,  0.0997, -0.0904, -0.2002, -0.3688, -0.0448,\n",
      "         -0.0085,  0.1731]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.17305712261789633\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0240, -0.0448,  0.3122,  0.1499, -0.3443, -0.0422,  0.1095,  0.1262,\n",
      "          0.1180,  0.1280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  4\n",
      "activation[2] = 0.312240213841645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0035,  0.0087,  0.0713,  0.1699, -0.0485, -0.0740,  0.0373,  0.0925,\n",
      "          0.0136,  0.3307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.33067785544347755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2971,  0.2531,  0.2239, -0.0809,  0.2003,  0.2164, -0.1788,  0.1647,\n",
      "          0.2515,  0.1277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 0.2971383835262044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1153,  0.1624,  0.1384, -0.0717,  0.2618,  0.0489, -0.0181,  0.3471,\n",
      "          0.0047,  0.2425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.3470765666041125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1135,  0.3198, -0.2935, -0.2590,  0.0081,  0.0538, -0.0588,  0.1732,\n",
      "          0.1761,  0.1955]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 0.31982387876895535\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0464, -0.0145, -0.0071, -0.1138,  0.3207,  0.0965, -0.1098,  0.1529,\n",
      "          0.0978,  0.1945]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 0.32069913390261023\n",
      "----------------------------------------------------\n",
      "output:  tensor([[0.1466, 0.3857, 0.2992, 0.0283, 0.2868, 0.2184, 0.0276, 0.2164, 0.0272,\n",
      "         0.3782]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.38570399651279785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1834,  0.0104, -0.0552,  0.0634,  0.2350, -0.2628, -0.3995, -0.0150,\n",
      "          0.0253,  0.0493]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.23495267844315953\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2733,  0.2496,  0.4173,  0.2281, -0.2322, -0.0175,  0.1221, -0.0776,\n",
      "          0.1349, -0.0991]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  0\n",
      "activation[2] = 0.41732996742448525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3984,  0.2098,  0.0200, -0.1214,  0.1315,  0.1072, -0.2099,  0.3940,\n",
      "          0.2212,  0.0985]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.39844781401072993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1366,  0.2056,  0.0396,  0.0156,  0.3547, -0.2737, -0.1510,  0.2001,\n",
      "          0.1982,  0.1522]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.3547215575959994\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0218,  0.0406,  0.0353,  0.1473, -0.0083, -0.1957,  0.0572,  0.1467,\n",
      "         -0.0369,  0.0548]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 0.1473497032860563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0982,  0.1256, -0.0180, -0.0568,  0.3099, -0.0882, -0.2042, -0.0140,\n",
      "          0.0195,  0.0290]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.3099332755403627\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0604,  0.2208,  0.2783, -0.0010,  0.4034, -0.0307, -0.1085,  0.0952,\n",
      "         -0.0389,  0.2765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 0.40341912285246984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0033,  0.0952, -0.0299, -0.0866,  0.0341, -0.1911, -0.1567,  0.0939,\n",
      "          0.2245,  0.0701]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 0.22449934315822606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4189,  0.0531,  0.0339, -0.1504,  0.1908,  0.1726, -0.1242,  0.5753,\n",
      "          0.0166,  0.2184]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.5753260935714868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0787,  0.1049,  0.3026, -0.0041, -0.0571, -0.2467, -0.2557, -0.1133,\n",
      "          0.0375,  0.2203]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 0.3026209960229965\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1920, -0.0570,  0.0213,  0.0695,  0.1143, -0.2506, -0.3992, -0.0012,\n",
      "         -0.0164,  0.1202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.12018855413112925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2873, -0.0174,  0.2167, -0.0280,  0.0680, -0.1798, -0.4522, -0.0338,\n",
      "         -0.1663,  0.1835]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  1\n",
      "activation[2] = 0.2167448299911117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0510, -0.1262,  0.0592,  0.2642, -0.1262, -0.2777, -0.0822,  0.1683,\n",
      "         -0.1463,  0.1254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 0.2642262691059044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.5159,  0.1148,  0.2118,  0.1026,  0.1533,  0.1069, -0.0895,  0.1506,\n",
      "          0.0988,  0.2653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  9\n",
      "activation[0] = 0.51587599890985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3570,  0.1838, -0.0139, -0.1557,  0.1447,  0.1988,  0.0596,  0.4606,\n",
      "          0.1026,  0.1159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.4606152230875444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2802,  0.2061,  0.1357,  0.0018,  0.0171, -0.1612, -0.1064,  0.3723,\n",
      "          0.2336,  0.5063]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.5063324919061309\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1065,  0.3119,  0.1689, -0.1100,  0.2404, -0.0942, -0.0732,  0.1828,\n",
      "         -0.2038,  0.2977]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.3118936988175216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0728,  0.0112,  0.0910,  0.0521, -0.1731, -0.3124,  0.0149,  0.1196,\n",
      "         -0.1082,  0.1165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.11961276492444306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1783, -0.0642,  0.0480, -0.0095, -0.0071, -0.2133, -0.0658, -0.1223,\n",
      "         -0.0491,  0.0689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.06888411710536647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1245, -0.0481,  0.0563, -0.2183,  0.0918, -0.0392, -0.2841,  0.1724,\n",
      "         -0.0011,  0.1290]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 0.17237491898519813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1134,  0.0464,  0.1364,  0.0636,  0.0158, -0.2857,  0.1306,  0.1132,\n",
      "         -0.1476,  0.1545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.1545010941187176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2805,  0.0935,  0.0448,  0.0510, -0.2443, -0.1478,  0.0322,  0.2545,\n",
      "          0.0023,  0.1106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.28045469581994437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0532,  0.2744,  0.1297, -0.0826,  0.1999,  0.0307, -0.0595,  0.1630,\n",
      "          0.0059, -0.0097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 0.2743799127608246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2760,  0.3568,  0.1319, -0.0992,  0.4763,  0.1020,  0.0249,  0.1724,\n",
      "          0.1429,  0.3716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 0.47627079223684604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1545,  0.1270,  0.1475,  0.2638, -0.0178, -0.0647, -0.0969,  0.0969,\n",
      "          0.2477,  0.0715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 0.26382660155877863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0583, -0.0710,  0.0455,  0.0726,  0.2056, -0.0648, -0.1867,  0.1232,\n",
      "          0.0154,  0.3337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.33371284316735667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0688,  0.2468,  0.2669, -0.1002,  0.3422,  0.1545, -0.2158,  0.1624,\n",
      "          0.0265,  0.3082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 0.3422198954607543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0205,  0.0216,  0.0496, -0.0510, -0.0857, -0.1888,  0.1560,  0.0679,\n",
      "         -0.1254, -0.0672]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 0.15603676575207456\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3272,  0.3644,  0.2038, -0.1921,  0.0889,  0.2407,  0.0862,  0.4666,\n",
      "          0.0890,  0.1113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.4665971996164821\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1709, -0.0774,  0.0401,  0.0841,  0.0016, -0.3068,  0.0249,  0.0768,\n",
      "         -0.0560,  0.2322]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.23220439363511916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0900,  0.0318, -0.0234, -0.1693, -0.0074, -0.1494,  0.0124, -0.0385,\n",
      "         -0.2224,  0.0408]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.04078127507808017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0032,  0.0015, -0.0916, -0.1276,  0.0400, -0.1696, -0.2106,  0.0258,\n",
      "          0.2506,  0.0302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 0.25062456061839156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1567, -0.0623,  0.0584, -0.0078,  0.0832, -0.3174, -0.3258,  0.0544,\n",
      "         -0.1276,  0.1302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.1302214994457633\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0252, -0.0399, -0.0725,  0.1606, -0.1698,  0.0550,  0.0008,  0.2033,\n",
      "         -0.2036, -0.0343]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.2033202862950712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1270,  0.1163,  0.1465,  0.1902, -0.0844, -0.1377,  0.2908,  0.1018,\n",
      "          0.1919,  0.0892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 0.29082514102215745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0460,  0.1157, -0.0163, -0.1200,  0.2571, -0.1258, -0.1778,  0.0509,\n",
      "          0.0200,  0.0108]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.2570834485277506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0700,  0.0118,  0.0917,  0.1331, -0.0624, -0.1536, -0.0170,  0.1806,\n",
      "          0.0047,  0.0263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.1806352425854702\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1362,  0.0613, -0.1008,  0.0506,  0.0348, -0.1554, -0.1326,  0.0707,\n",
      "         -0.1512,  0.0552]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 0.0707003156606293\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2601,  0.0309,  0.0494,  0.0172,  0.0494, -0.1548, -0.4836, -0.0150,\n",
      "          0.0310,  0.0960]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.09596545847847224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1252,  0.3145,  0.1805, -0.1704,  0.3045,  0.0918,  0.0862,  0.1958,\n",
      "          0.2999,  0.1511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.31449874069782624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0094, -0.0429,  0.2972, -0.0729, -0.1144, -0.2834, -0.2405,  0.2235,\n",
      "          0.1235,  0.4644]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.46442375746892467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0174,  0.0970,  0.3089,  0.2233, -0.1924, -0.0608,  0.4838,  0.0119,\n",
      "          0.0963,  0.0114]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 0.48381870983521497\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1475,  0.1218, -0.2054,  0.0872,  0.1933, -0.0350, -0.1220,  0.3062,\n",
      "          0.0508,  0.0928]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.3061761600571155\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2335,  0.1399,  0.0669, -0.1886,  0.2070, -0.0888, -0.0181,  0.1952,\n",
      "         -0.0994,  0.3824]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.3823994734633711\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0596,  0.0396,  0.2758, -0.2076, -0.1385, -0.4882,  0.1651,  0.3029,\n",
      "          0.1102,  0.3045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.3044824546450741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1469,  0.1247, -0.0050, -0.1247,  0.2750, -0.0982, -0.0733, -0.0829,\n",
      "         -0.0958,  0.0242]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.27495748052536806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2378, -0.0136, -0.0920,  0.0120,  0.0488, -0.1723, -0.4605, -0.0983,\n",
      "         -0.0315,  0.2118]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.21184375386427398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[0.1035, 0.1417, 0.0906, 0.1545, 0.0256, 0.1582, 0.3441, 0.4013, 0.1589,\n",
      "         0.0586]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.4013210096243723\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1368,  0.1674,  0.0665, -0.0051,  0.0584,  0.0471,  0.1167,  0.2207,\n",
      "          0.0053,  0.1734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 0.22065410581983907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1913,  0.0289,  0.0718, -0.0141,  0.0313, -0.1246,  0.0095,  0.1494,\n",
      "          0.0042,  0.2725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.272465767418196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0776,  0.3386,  0.2768, -0.1824,  0.0215, -0.1977,  0.0982,  0.3575,\n",
      "          0.0232,  0.3158]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.3575386962731029\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4112,  0.1632,  0.0737, -0.1113,  0.0483,  0.1345,  0.0050,  0.2125,\n",
      "          0.1322,  0.1396]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.41115701018064404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1014,  0.3057,  0.1249,  0.0376,  0.2142, -0.0051,  0.1088,  0.4120,\n",
      "          0.1820,  0.2777]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.4119860954485564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2132,  0.0600,  0.2808,  0.1338, -0.0685, -0.5161, -0.1867,  0.4295,\n",
      "          0.0564, -0.0219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.4294874720305172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2253,  0.0487,  0.1660,  0.1210,  0.0176, -0.0233,  0.0852,  0.3069,\n",
      "          0.2778, -0.0086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.3068639106879647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1187, -0.1991,  0.1988, -0.0504,  0.0986, -0.1661, -0.2044, -0.0095,\n",
      "         -0.0240,  0.4485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.448542636875602\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0224,  0.0443,  0.0729,  0.3195, -0.1599, -0.2435, -0.0257,  0.1080,\n",
      "         -0.0099,  0.0981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 0.3194622393021318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2295,  0.0540,  0.0577, -0.0190,  0.2843, -0.0143, -0.1749, -0.0662,\n",
      "          0.0248,  0.0636]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.28433046875469076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2538,  0.1365, -0.0954, -0.0582, -0.0931, -0.1537, -0.0896,  0.0201,\n",
      "          0.0768,  0.0515]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 0.13647498329506447\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4025,  0.2567,  0.0343, -0.0536,  0.2053,  0.1003,  0.1328,  0.2232,\n",
      "          0.3607,  0.3375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 0.4024892772322099\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0716,  0.2231, -0.0640, -0.0248,  0.1798,  0.0305, -0.2218,  0.2269,\n",
      "          0.1779,  0.0501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 0.22692197927025956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2685,  0.2121,  0.0364, -0.1220,  0.0951, -0.2165, -0.2056, -0.1197,\n",
      "         -0.0152, -0.0357]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 0.21212935162980642\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0991,  0.2329,  0.1580,  0.0252,  0.1736,  0.1007, -0.0383,  0.0722,\n",
      "          0.1407,  0.3453]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.3453264903974469\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1815,  0.0649, -0.0624, -0.1480, -0.0136, -0.3417, -0.0154,  0.3029,\n",
      "          0.1859,  0.1553]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 0.30291564251702574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0938,  0.0956,  0.2470,  0.0599,  0.2075, -0.0802, -0.0830,  0.2424,\n",
      "         -0.0148,  0.1506]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  4\n",
      "activation[2] = 0.24702768166616726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2335,  0.1927, -0.0587,  0.1179,  0.0987, -0.2425, -0.1311,  0.0185,\n",
      "          0.0097,  0.0349]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.1927272088435504\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1542,  0.0118,  0.0867, -0.0723, -0.1259, -0.1091,  0.0273,  0.1287,\n",
      "         -0.0705,  0.0614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.12874986190771456\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2219,  0.2172, -0.0937,  0.0617, -0.0276, -0.1849, -0.0115,  0.1014,\n",
      "          0.1877,  0.3191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.3191399644423737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1803,  0.1190,  0.1549,  0.0078, -0.2354, -0.4201,  0.0009,  0.0753,\n",
      "          0.0404,  0.3413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.3412592359239607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0473,  0.1435, -0.0874, -0.2605,  0.0575, -0.0659, -0.1436,  0.0877,\n",
      "          0.2310,  0.1202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 0.23099265041742423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1626,  0.0213,  0.1017, -0.0884, -0.0092, -0.1656, -0.1948,  0.0704,\n",
      "         -0.1910,  0.1381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.1380778349686009\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3693,  0.2310,  0.0486, -0.3180,  0.1844,  0.1875, -0.1515,  0.3197,\n",
      "          0.2422,  0.1927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 0.3692593150171532\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0153,  0.0090,  0.1350,  0.1287,  0.1116,  0.1135, -0.0113,  0.2340,\n",
      "          0.0951,  0.2484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.24836985353924437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2102, -0.0582,  0.0452,  0.0521,  0.0652, -0.3010, -0.0037,  0.0082,\n",
      "         -0.0575,  0.0725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.0725176890722352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0243, -0.1024,  0.0887,  0.2182, -0.0377, -0.1806, -0.1142,  0.0938,\n",
      "         -0.1293,  0.2213]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.22130958338380805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1084,  0.1094,  0.1156, -0.0157, -0.1160, -0.1813, -0.0098,  0.1019,\n",
      "          0.1973,  0.2842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.28417747101840574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3359e-01,  2.8561e-04,  7.7324e-02, -5.8170e-02,  1.6000e-01,\n",
      "         -9.3653e-02, -3.4222e-01,  2.4295e-01, -1.9172e-01,  2.0146e-01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.24294541996008662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0172,  0.0672,  0.1064,  0.0699, -0.0225, -0.2520, -0.1813, -0.0614,\n",
      "          0.2265,  0.2217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 0.22649887807122923\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0649,  0.2537, -0.0021,  0.0253,  0.1999,  0.0071,  0.0544,  0.1986,\n",
      "          0.0076,  0.0845]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.25373011432560966\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0661, -0.0993,  0.0508, -0.2353,  0.1058, -0.1097, -0.0261, -0.0568,\n",
      "          0.0196,  0.4116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.41163287384190517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0555,  0.1455,  0.1603, -0.0224,  0.2605,  0.0393, -0.0773,  0.1984,\n",
      "          0.0617,  0.1825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 0.26050727804881024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1059,  0.0739,  0.3099, -0.1100, -0.0066, -0.0844, -0.1109, -0.0336,\n",
      "          0.1349,  0.1169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  7\n",
      "activation[2] = 0.3098917398006186\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0320, -0.0254,  0.1876, -0.1154, -0.0408, -0.3665, -0.2425,  0.1659,\n",
      "          0.1519,  0.3101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.3100930179841639\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1804,  0.3366,  0.0918, -0.0392,  0.2663,  0.0581, -0.0398,  0.0835,\n",
      "          0.1979,  0.0361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 0.3365836617447768\n",
      "----------------------------------------------------\n",
      "output:  tensor([[0.1937, 0.3705, 0.1228, 0.0581, 0.1982, 0.0680, 0.0531, 0.2192, 0.0654,\n",
      "         0.1891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 0.3705232135655337\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0511,  0.0932,  0.0328, -0.0667,  0.3047, -0.1149, -0.2441,  0.0821,\n",
      "          0.0205, -0.0032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.3047413046442998\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1859,  0.0381,  0.0330, -0.1231,  0.1075, -0.1831, -0.0288,  0.1720,\n",
      "         -0.1621,  0.0231]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.17196885110534016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0241, -0.0484,  0.1370,  0.0670, -0.1540, -0.1341, -0.0801,  0.1731,\n",
      "          0.0812,  0.0388]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.17306387161784015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1408,  0.2908,  0.2070,  0.0315,  0.2243,  0.0269,  0.0071,  0.2292,\n",
      "         -0.0386,  0.4337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.43367102351132325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0816,  0.0681,  0.1457,  0.1038,  0.1298, -0.2205,  0.1714,  0.3221,\n",
      "          0.2412,  0.1298]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.32205206983325446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0928,  0.0994,  0.2467, -0.1339, -0.0443, -0.2866, -0.1587,  0.1667,\n",
      "         -0.0046,  0.3495]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.34954028197791737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0111,  0.1289,  0.0194, -0.0171,  0.1535,  0.2067, -0.0275,  0.1994,\n",
      "          0.2023,  0.3120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.31198376624400304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0537, -0.0222,  0.2433, -0.2330,  0.1565, -0.2133, -0.0017,  0.2493,\n",
      "         -0.2548,  0.2235]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.2493199907634485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1358,  0.1340,  0.0704, -0.1440,  0.2112, -0.2067, -0.1485,  0.1356,\n",
      "          0.2136,  0.2163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.2163307723724762\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1227,  0.0503,  0.3374, -0.1800,  0.1762, -0.0681,  0.0634,  0.1198,\n",
      "         -0.0943,  0.2084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 0.33735227181879207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1639, -0.0269,  0.1645, -0.0950, -0.1267, -0.1724,  0.1065,  0.0789,\n",
      "          0.0043,  0.2045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.2044831747703595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0919,  0.0446,  0.0452,  0.0918,  0.1092, -0.0339, -0.1344,  0.1128,\n",
      "         -0.0860,  0.3303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.33027544465366343\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1863,  0.1412,  0.2509,  0.0270,  0.0557, -0.1278, -0.1594,  0.3937,\n",
      "          0.1648,  0.5975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.5974807938683815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0753,  0.3299,  0.2703, -0.0282,  0.3795,  0.1450, -0.0899,  0.1749,\n",
      "          0.1124,  0.4023]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.40229040840022695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0703,  0.0048,  0.0981, -0.0991, -0.0094, -0.0318,  0.1360,  0.0294,\n",
      "         -0.0769,  0.2564]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.2563769601642381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1541,  0.1160, -0.0111,  0.0191, -0.0028, -0.2158,  0.1345,  0.2399,\n",
      "          0.1153,  0.0498]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 0.23985863941312854\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1699, -0.0210,  0.0350, -0.0803,  0.0603, -0.5044, -0.2128,  0.0015,\n",
      "         -0.0782,  0.1376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 0.13757571003422236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3706,  0.2662,  0.1983, -0.2123,  0.1177,  0.3555, -0.0839,  0.4418,\n",
      "          0.0274,  0.1158]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.44176878409254344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2224,  0.0355,  0.2443, -0.0437, -0.0450, -0.1635,  0.0670,  0.0250,\n",
      "         -0.1279,  0.1545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  9\n",
      "activation[2] = 0.24430760887951022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1350,  0.0986,  0.3302, -0.2076,  0.1354, -0.2299,  0.0904,  0.2393,\n",
      "         -0.1257,  0.3119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  2\n",
      "activation[2] = 0.3301930973285402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1052,  0.0685,  0.1643,  0.1267, -0.1141, -0.2022,  0.0944,  0.0932,\n",
      "          0.2158,  0.2870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.2870068707553292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0023,  0.1095, -0.2651, -0.0540,  0.0895, -0.0143,  0.0493,  0.0751,\n",
      "         -0.1759,  0.0624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.10947171905745202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1728,  0.1655,  0.1012, -0.2194,  0.1645, -0.1267, -0.0840, -0.0624,\n",
      "          0.0345,  0.0665]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 0.16553711763479437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1190,  0.4547, -0.0454,  0.0921,  0.2338, -0.1118,  0.1152,  0.2009,\n",
      "          0.0798,  0.2026]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.45472356570440625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1912,  0.0592,  0.0156, -0.0006, -0.1654, -0.0656, -0.0635,  0.0138,\n",
      "         -0.0542, -0.0032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 0.05918495069551369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3088, -0.0143,  0.1018,  0.0432,  0.0853, -0.3876, -0.3189,  0.0229,\n",
      "         -0.0503,  0.1540]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.15398919418768534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1639,  0.1951,  0.0756, -0.0913,  0.0764, -0.1612,  0.1069,  0.3031,\n",
      "          0.1943,  0.2948]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.3030506548187791\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0166, -0.0374,  0.2197, -0.4747, -0.0113, -0.3769,  0.1128,  0.3968,\n",
      "          0.1732,  0.1974]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 0.3968300713163296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0114, -0.0635,  0.0412,  0.0259,  0.2586, -0.1685, -0.1190,  0.1401,\n",
      "         -0.0157,  0.0570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 0.25862429202277404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1914, -0.1327,  0.2160,  0.0328,  0.0279, -0.6491,  0.3139, -0.0904,\n",
      "          0.0979,  0.2045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 0.31394511568866973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4540,  0.0344,  0.1357, -0.0609,  0.0616, -0.0395, -0.1539,  0.1148,\n",
      "          0.3456,  0.1891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 0.45400961463871053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1259,  0.1769,  0.0384,  0.0512,  0.0498, -0.3123,  0.1164,  0.1926,\n",
      "          0.0021,  0.2123]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.212285394095276\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1134,  0.0915, -0.1365, -0.0305,  0.2165, -0.2969, -0.1536,  0.0215,\n",
      "         -0.1573,  0.0654]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.216526043602157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1279,  0.1834,  0.2375,  0.3235,  0.0796, -0.1017,  0.1702,  0.0985,\n",
      "          0.1570,  0.0700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 0.32348001475590604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1493, -0.2452,  0.1585,  0.0885,  0.2199, -0.1084, -0.0523,  0.1646,\n",
      "          0.0435,  0.4064]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.4064298628868652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1554,  0.2839,  0.0418,  0.1514,  0.0840,  0.0450, -0.1090,  0.1737,\n",
      "          0.1926,  0.5851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.5851185675972949\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1960,  0.0040,  0.0123,  0.0851, -0.1666, -0.2410, -0.0239, -0.0119,\n",
      "          0.0586,  0.2366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.2365846408737543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0067,  0.3907, -0.0254, -0.0398,  0.1414, -0.0475, -0.1769,  0.5900,\n",
      "         -0.1280,  0.1722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 0.5900468653867852\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1088,  0.1628,  0.1612, -0.0699,  0.4078, -0.1931, -0.1107,  0.0563,\n",
      "         -0.0944,  0.3212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 0.40778349507447303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0910,  0.2453,  0.1378,  0.0715,  0.1219, -0.0025,  0.0831,  0.1833,\n",
      "          0.0882,  0.0790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 0.24526045964376655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.4652,  0.3645,  0.1976, -0.1407,  0.0850,  0.0779,  0.0787,  0.3248,\n",
      "          0.1563,  0.1241]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.4652237986072751\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2236,  0.1367,  0.1819,  0.2145,  0.0176, -0.1488,  0.2255, -0.0127,\n",
      "          0.2442,  0.1215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 0.2441577814874225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0063, -0.1226,  0.1484,  0.1182, -0.0538, -0.3296,  0.0553,  0.1196,\n",
      "          0.1289,  0.5010]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.5009977584990967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2010,  0.1354,  0.1963,  0.0257, -0.0734, -0.0924, -0.0284,  0.1837,\n",
      "         -0.1150, -0.0596]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  9\n",
      "activation[2] = 0.19634140396202004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0667, -0.0068,  0.1778,  0.1572, -0.0347, -0.0503, -0.1529,  0.3316,\n",
      "          0.0770,  0.2061]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.3315637547169064\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2895,  0.0732,  0.1003, -0.2275,  0.2763, -0.0498, -0.3230, -0.0430,\n",
      "         -0.0979,  0.0265]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 0.27632867890699847\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1806,  0.2077, -0.1095,  0.0514,  0.2116, -0.3262, -0.1612,  0.1119,\n",
      "          0.1845,  0.3381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.3380754571118478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0379,  0.0271, -0.1524, -0.0802,  0.3287, -0.0904, -0.2467,  0.2684,\n",
      "         -0.3403,  0.2569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 0.3287350686201948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1267,  0.1390, -0.1056,  0.0843,  0.2005, -0.2580, -0.0981, -0.0087,\n",
      "         -0.0807,  0.0560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.20053617572120472\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1786, -0.2049, -0.0970, -0.0225,  0.0088, -0.1612, -0.2682, -0.0641,\n",
      "         -0.2187,  0.2838]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.28378641486825984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3066,  0.2878,  0.1024,  0.0026, -0.0245, -0.0542, -0.0884,  0.0629,\n",
      "         -0.0883,  0.0035]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 0.28775804908275804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1733, -0.1188,  0.1610, -0.1410,  0.0044, -0.5961,  0.1751,  0.0544,\n",
      "         -0.0594,  0.2011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.20106959008008232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0262,  0.0119,  0.0009,  0.1258,  0.1518, -0.1765, -0.1180,  0.2972,\n",
      "          0.1367,  0.2296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 0.29716140479285913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1705, -0.0364, -0.1001,  0.0761, -0.0557, -0.1530, -0.4264, -0.1107,\n",
      "         -0.0687,  0.1828]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 0.18281806050012295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1571, -0.1728,  0.0809,  0.2302, -0.2464, -0.2215,  0.1829,  0.1389,\n",
      "          0.0497, -0.0203]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 0.23015764336310462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2453,  0.0561,  0.1051,  0.0337, -0.0382, -0.4641,  0.2288,  0.0223,\n",
      "          0.0746,  0.2864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.28638709749252883\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2923,  0.0805,  0.1163, -0.1609,  0.2671, -0.2065, -0.3109, -0.0332,\n",
      "         -0.0417,  0.0380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.26706688003550716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2203, -0.0937,  0.1929,  0.1893, -0.3164, -0.1108,  0.3267,  0.2608,\n",
      "          0.1989,  0.1874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 0.3267235655750671\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2076,  0.0632, -0.0718, -0.1681, -0.1554, -0.0469, -0.0965,  0.0413,\n",
      "          0.1149,  0.0239]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.20758444164733225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1307,  0.1857,  0.0784, -0.1196,  0.2393, -0.2357, -0.3112,  0.0613,\n",
      "          0.0110, -0.0089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.23932923309566773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1236,  0.0579, -0.1225, -0.0654,  0.0700, -0.1871,  0.0213, -0.0710,\n",
      "         -0.0565, -0.0382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 0.07000339408997469\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1483,  0.0698, -0.0700, -0.0512,  0.0651, -0.2574, -0.4295,  0.1163,\n",
      "          0.0909,  0.5753]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.5753317972472517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0995,  0.0614,  0.1695,  0.2053, -0.1507, -0.2188, -0.0683,  0.2989,\n",
      "         -0.0583,  0.1159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.2988704802359417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0771, -0.0803,  0.0972, -0.0818, -0.0082, -0.4000, -0.3069,  0.1387,\n",
      "          0.1133,  0.3260]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.32596603919182976\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3268,  0.1251,  0.0251, -0.0819, -0.0649,  0.1262, -0.0442,  0.2341,\n",
      "          0.0341,  0.0351]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.32677138729384286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1609,  0.0593,  0.2073,  0.0605, -0.1342, -0.0618, -0.1210,  0.1169,\n",
      "          0.0706,  0.1745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  4\n",
      "activation[2] = 0.20729016043807874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0705,  0.1109,  0.2429, -0.0481,  0.3269, -0.0345, -0.0882,  0.2327,\n",
      "          0.1136,  0.4594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.4593632323131319\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0062,  0.1976, -0.0721, -0.0413,  0.0681,  0.0316, -0.1390,  0.5368,\n",
      "          0.1674,  0.0138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.53676153790708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2423, -0.1367, -0.0355, -0.0553, -0.0360, -0.1269, -0.0890,  0.0545,\n",
      "         -0.0871,  0.4865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.4864756163209791\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1585,  0.2949,  0.1328, -0.1584,  0.4463, -0.2450,  0.0574,  0.2941,\n",
      "          0.0980,  0.4854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.4854430766816588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1639,  0.1203,  0.3496, -0.0907,  0.0007, -0.1289, -0.0343,  0.0610,\n",
      "          0.0768,  0.6300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.6300103778368266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0984,  0.1571,  0.1992,  0.0131,  0.0985, -0.2275,  0.1114,  0.2906,\n",
      "          0.1776,  0.0256]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.2906351806755629\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0488, -0.0935,  0.1100, -0.0856, -0.1456, -0.3803,  0.0340,  0.2847,\n",
      "         -0.0369,  0.1668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 0.28468097926444785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0491,  0.1810,  0.0060, -0.2299, -0.1363, -0.0076, -0.0174,  0.2624,\n",
      "         -0.1146,  0.2338]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 0.26237507115560654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2394, -0.0731,  0.2193,  0.1659, -0.0516, -0.1966, -0.0273,  0.0082,\n",
      "         -0.0633,  0.1262]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  2 Label:  9\n",
      "activation[2] = 0.21932146591864296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1511,  0.0480,  0.0450, -0.2117, -0.0398, -0.2087,  0.1000,  0.0642,\n",
      "         -0.1254,  0.1133]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 0.1133065546334166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0889,  0.2969, -0.3103, -0.0927, -0.0084, -0.1319,  0.0436,  0.1726,\n",
      "          0.1443,  0.1176]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 0.29692452504455413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2909,  0.0131, -0.1315,  0.0493, -0.0074, -0.1141,  0.1041,  0.3366,\n",
      "          0.0964,  0.0735]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 0.3366450627238103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0149, -0.0476, -0.0049,  0.0223,  0.0615, -0.3467, -0.0017,  0.1757,\n",
      "         -0.1698, -0.0213]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.17572206239965232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-7.6092e-02,  1.6646e-01,  7.1839e-03,  3.4706e-02,  2.4475e-01,\n",
      "         -6.9224e-02, -3.0806e-01, -2.3192e-04,  4.0297e-02,  6.5582e-03]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 0.24474527619937336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[0.2548, 0.0614, 0.0350, 0.0133, 0.0641, 0.0432, 0.0993, 0.1683, 0.0616,\n",
      "         0.2242]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.2548251910068868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0808,  0.0193, -0.1858, -0.1171,  0.1388, -0.2974, -0.0916,  0.0948,\n",
      "         -0.1389,  0.4882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.48816339092036387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3663,  0.1173, -0.0151, -0.4053,  0.2083,  0.0744,  0.0179,  0.3661,\n",
      "          0.3358,  0.2560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 0.3662909571969501\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0195, -0.0506,  0.1277, -0.0096, -0.0411, -0.4012, -0.3149,  0.1503,\n",
      "          0.0501,  0.2696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.26962561024662623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0523,  0.0957, -0.0493,  0.0577, -0.0543, -0.1043, -0.0182,  0.3034,\n",
      "          0.0367, -0.1434]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.30340586636848277\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0012, -0.0739,  0.0957,  0.1708, -0.2330, -0.1597,  0.0132,  0.0535,\n",
      "          0.0413,  0.2344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 0.23444447983466035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1329,  0.1181, -0.0040, -0.1922,  0.3449, -0.0711, -0.0600,  0.2236,\n",
      "          0.1870,  0.4344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 0.43435531148580764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0269,  0.1884, -0.0889,  0.1161,  0.1102, -0.0685,  0.0740,  0.3423,\n",
      "          0.0671,  0.0971]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.3423221757785811\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3058,  0.0335, -0.0483, -0.0122,  0.0073, -0.1514, -0.1410, -0.1155,\n",
      "         -0.0077,  0.1211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.12105378951883601\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0646,  0.2536, -0.0092,  0.2219,  0.1896, -0.2537,  0.0498,  0.2550,\n",
      "          0.3173,  0.2879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 0.31726334811050744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0277,  0.0615,  0.0574, -0.1076,  0.1966, -0.4429, -0.3198,  0.3235,\n",
      "          0.1987,  0.6384]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.6383699458608515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1051,  0.0534,  0.1795,  0.1481, -0.0015, -0.3279,  0.0705,  0.2858,\n",
      "          0.1517,  0.0637]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 0.285757572267827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3180, -0.0342,  0.2740, -0.2220,  0.1826, -0.1629,  0.0059,  0.2116,\n",
      "          0.0943,  0.2967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 0.3180442546380051\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1763, -0.0261,  0.0723, -0.2276, -0.1127, -0.1973,  0.0290, -0.0847,\n",
      "         -0.1957,  0.2269]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 0.226925297259039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.1223,  0.0466,  0.1102, -0.1408, -0.0870, -0.0579, -0.0317,  0.0325,\n",
      "          0.2632,  0.0736]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 0.26318575771921415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1515,  0.1242,  0.0863, -0.1476,  0.0231, -0.1713,  0.0821,  0.0096,\n",
      "          0.0775,  0.0321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 0.12416415570980287\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1443,  0.0556, -0.2352,  0.1857,  0.1293, -0.1721, -0.0970, -0.0545,\n",
      "         -0.1214,  0.1751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 0.18565855248536572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.3031, -0.0551,  0.0903,  0.2935, -0.1247, -0.0919,  0.3579,  0.1144,\n",
      "          0.2564,  0.0228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 0.3578878479285931\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0855,  0.0201,  0.2127,  0.1875,  0.2456, -0.0225, -0.0432,  0.1695,\n",
      "          0.1867,  0.4008]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.4008055084309572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3000,  0.1542,  0.1328, -0.1246,  0.1481, -0.2558, -0.2915,  0.0519,\n",
      "         -0.0302,  0.0024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 0.15423410514513733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1970,  0.0760,  0.1555,  0.0043,  0.3426, -0.3782, -0.0917, -0.1745,\n",
      "          0.0734,  0.3814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.38136117576310163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0476,  0.2816, -0.2057,  0.0437,  0.0493, -0.3139,  0.0584,  0.0888,\n",
      "          0.0326,  0.5354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 0.5354344274169432\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2616,  0.1572,  0.0500, -0.0314, -0.0164,  0.1334, -0.2843,  0.1043,\n",
      "          0.1826,  0.1916]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 0.2615864640939249\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3078,  0.1045, -0.0869,  0.0696, -0.0338, -0.4095, -0.0505,  0.0253,\n",
      "         -0.0269,  0.2001]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 0.20009081296270817\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [1]: loss = 2.299, accuracy = 13.28\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327,  0.4575, -0.0239, -0.0287, -0.0659, -0.0364,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327,  0.4575, -0.0239, -0.0287, -0.0659, -0.0364,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.9265, -2.3153, -2.1695, 19.9388, -2.3043, -1.5747, -2.3183, -2.5186,\n",
      "         -2.1516, -2.6845]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 19.93879398634718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5208, -2.3346, -1.8118, 18.2175, -2.1248, -1.3789, -2.0037, -2.0453,\n",
      "         -2.0688, -2.4257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 18.21750980175017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3643, -2.1195, -1.5057, 15.5199, -1.7587, -1.5484, -1.6849, -1.6699,\n",
      "         -1.8925, -2.2142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 15.51988092510279\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8561, -2.3841, -2.2909, 21.1367, -2.4439, -1.7315, -2.3151, -2.1866,\n",
      "         -2.3934, -2.8299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 21.136735158348543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6228, -0.7260, -0.6480,  6.3326, -0.6723, -0.5515, -0.4867, -0.5681,\n",
      "         -0.5502, -0.6397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 6.332644649923236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2141, -1.6770, -1.7628, 16.5869, -1.6181, -1.2220, -1.7689, -1.6264,\n",
      "         -1.7983, -2.2544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.586902268849865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7072, -1.0962, -0.9862, 10.0184, -0.9077, -0.6910, -1.1401, -0.9972,\n",
      "         -0.9983, -1.3362]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 10.018435859659899\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7198, -2.6460, -2.0209, 20.8923, -2.2419, -2.0106, -2.1941, -2.2695,\n",
      "         -2.2354, -2.8858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 20.892313548008303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9126, -1.4739, -1.0491, 10.4812, -1.2007, -1.0288, -1.2635, -1.1284,\n",
      "         -1.0538, -0.9912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 10.481168180210691\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9131, -4.4793, -3.4746, 33.1654, -3.8536, -2.8605, -3.6393, -3.9793,\n",
      "         -3.8888, -4.7415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 33.16538220692298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9609, -2.9195, -2.6669, 24.8107, -2.7700, -2.2555, -2.8407, -2.8312,\n",
      "         -2.5064, -3.4508]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 24.810695400072465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8381, -2.4037, -1.9489, 19.2385, -2.2273, -1.7706, -2.0348, -2.2636,\n",
      "         -2.1616, -2.7270]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 19.23854200514957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1956, -1.8273, -1.4220, 14.3923, -1.5011, -1.2742, -1.7314, -1.5675,\n",
      "         -1.5944, -1.8878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 14.39231534647741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3630, -1.6683, -1.3210, 13.7900, -1.3714, -1.1972, -1.9447, -1.7201,\n",
      "         -1.6045, -1.9513]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 13.78996410226874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7121, -0.8508, -0.7009,  7.0075, -0.5676, -0.5674, -0.9423, -0.8528,\n",
      "         -0.7463, -0.9671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 7.007495066614329\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6666, -2.4870, -1.8898, 19.2356, -2.3078, -1.5798, -2.1929, -2.2270,\n",
      "         -2.1356, -2.5299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 19.235554343146216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0755, -2.8262, -2.2287, 22.4199, -2.9066, -1.9050, -2.3050, -2.5518,\n",
      "         -2.2826, -3.0684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 22.41991964544985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8549, -2.6901, -2.4621, 22.3303, -2.4524, -1.7509, -2.4152, -2.3421,\n",
      "         -2.4265, -3.0407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 22.33032539623005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3742, -1.8585, -1.8585, 16.1282, -1.8402, -1.1117, -1.9230, -1.8436,\n",
      "         -1.5862, -2.0703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.12824631621144\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4753, -2.1584, -1.9788, 18.4599, -2.2139, -1.4970, -1.8938, -1.9741,\n",
      "         -2.0487, -2.3422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 18.459908010147135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0579, -1.1087, -0.9472,  9.4421, -0.9330, -0.8255, -1.2733, -1.1818,\n",
      "         -1.1188, -1.3043]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 9.442106333414188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9000, -4.3774, -3.7395, 34.6689, -3.9475, -3.0042, -3.9858, -3.9116,\n",
      "         -3.8061, -4.4245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 34.66889011746598\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6525, -2.5090, -2.2788, 21.6623, -2.1045, -1.6888, -2.7173, -2.4470,\n",
      "         -2.2188, -2.7579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 21.66233193427207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1766, -5.0641, -3.8210, 36.9089, -4.0976, -3.4036, -3.9720, -4.5005,\n",
      "         -4.1858, -5.0778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 36.908946262444275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4852, -1.8673, -1.3767, 14.8324, -1.6597, -1.2664, -1.6531, -1.6196,\n",
      "         -1.7105, -1.9189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 14.832375281630888\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0872, -4.9600, -3.7804, 36.8960, -4.1487, -3.1533, -4.4174, -4.2262,\n",
      "         -4.1821, -4.8742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 36.89603402579069\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6085, -0.8508, -0.7703,  7.0495, -0.6341, -0.5543, -0.8849, -0.5002,\n",
      "         -0.6815, -0.8048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 7.049459522629177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5734, -2.8983, -2.1999, 22.9795, -2.6214, -1.8128, -2.1536, -2.5647,\n",
      "         -2.3098, -2.9027]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 22.979542719740788\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3819, -2.2077, -1.7554, 16.5975, -1.8590, -1.3512, -1.9436, -1.8862,\n",
      "         -1.7070, -2.1855]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.59749696218186\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7376, -2.1517, -1.8816, 17.7917, -1.9738, -1.5942, -1.7891, -2.0735,\n",
      "         -1.9568, -2.5926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 17.791700438124142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6865, -3.8138, -3.4351, 32.4110, -3.2792, -2.6640, -3.6603, -3.6994,\n",
      "         -3.3335, -4.2359]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 32.41104755670728\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6031, -1.9056, -1.9167, 16.1973, -1.8002, -1.2964, -1.8173, -1.7948,\n",
      "         -1.9270, -2.1854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.19728997294502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1816, -1.8223, -1.2669, 14.0693, -1.6698, -1.3627, -1.5722, -1.5832,\n",
      "         -1.6555, -1.8484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 14.069289099175688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3988, -2.2313, -1.7621, 17.3046, -2.1086, -1.3689, -1.8093, -1.9931,\n",
      "         -1.9425, -2.3140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 17.30458326722405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2379, -1.4935, -1.2970, 12.6843, -1.2561, -1.0922, -1.7899, -1.5147,\n",
      "         -1.3469, -1.8087]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 12.684282839955706\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4337, -4.6061, -3.8470, 36.6601, -4.1839, -3.3533, -4.3553, -4.3938,\n",
      "         -3.9987, -5.0651]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 36.660069116851986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5139, -2.3838, -1.6684, 18.3076, -2.0230, -1.4880, -2.1822, -2.0798,\n",
      "         -2.0661, -2.3505]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 18.30762607326519\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2571, -3.8139, -3.2026, 31.4710, -3.4642, -2.5458, -3.2370, -3.4270,\n",
      "         -3.3679, -4.2375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 31.47103303487911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0262, -1.4368, -0.7989, 11.4064, -1.4554, -0.9804, -1.2468, -1.2058,\n",
      "         -1.1332, -1.1671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 11.40644439663371\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5900, -3.8536, -3.0088, 29.3070, -3.3507, -2.2050, -3.5130, -3.5774,\n",
      "         -3.5386, -4.1090]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 29.30697626512021\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2199, -1.9996, -1.5399, 17.2429, -1.8906, -1.3086, -1.5501, -1.8699,\n",
      "         -1.6815, -2.1644]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 17.24292547270485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2878, -1.9258, -1.6196, 16.2459, -1.9514, -1.1372, -1.7243, -1.7571,\n",
      "         -1.7687, -2.2298]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 16.24592410094173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1956, -3.1391, -2.8232, 25.7774, -2.8843, -2.1854, -3.0912, -2.8727,\n",
      "         -2.7127, -3.6485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 25.777417141543072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6018, -2.2385, -1.9452, 19.3782, -1.7941, -1.7578, -2.2314, -2.1175,\n",
      "         -2.1017, -2.3306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 19.37817637636162\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9217, -2.7329, -2.1629, 21.1579, -2.5237, -1.9176, -2.4114, -2.4257,\n",
      "         -2.3768, -3.0472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 21.157941586459852\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4422, -2.1727, -1.7992, 17.1405, -1.9556, -1.5863, -1.8152, -1.8397,\n",
      "         -1.9357, -2.4660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.140471747388435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6837, -2.2252, -2.0954, 20.9061, -2.1381, -1.5965, -2.3527, -2.3551,\n",
      "         -2.3385, -2.6810]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 20.906081730918938\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4194, -3.7278, -3.2776, 31.8952, -3.5634, -2.4164, -3.3144, -3.3444,\n",
      "         -3.5194, -4.3394]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 31.895192328607383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0712, -1.6019, -1.2480, 11.8136, -1.4011, -1.0377, -1.2926, -1.4665,\n",
      "         -1.2508, -1.5686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 11.813607711799708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5046, -2.2894, -1.8610, 17.7033, -1.9493, -1.7028, -1.9162, -1.9656,\n",
      "         -2.1051, -2.4789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.70332383559383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1840, -2.5278, -2.0422, 18.2493, -1.9452, -1.3543, -1.8515, -1.8617,\n",
      "         -2.0969, -2.2768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 18.249305358635226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4771, -2.2024, -1.7599, 17.0140, -1.8766, -1.6796, -1.8222, -1.7836,\n",
      "         -1.9937, -2.4608]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.01398745245638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0154, -3.1239, -2.8197, 25.0287, -2.7626, -2.1333, -2.9461, -3.0757,\n",
      "         -2.9562, -3.0196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 25.02873860804033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3138, -1.6525, -1.2968, 13.2036, -1.4251, -1.1126, -1.8323, -1.6767,\n",
      "         -1.5405, -1.8069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 13.203568539044621\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1151, -1.3487, -1.2126, 11.1006, -1.0736, -1.0129, -1.3130, -1.3805,\n",
      "         -1.3643, -1.5395]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 11.10059247226856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2857, -1.8689, -1.8484, 17.2509, -1.7280, -1.3671, -1.9778, -1.7291,\n",
      "         -1.7335, -2.3170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 17.25086964584419\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1682, -3.1774, -2.6809, 26.0491, -3.0113, -2.3256, -2.8063, -3.1529,\n",
      "         -2.5620, -3.5003]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 26.049115340361862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7656, -2.1671, -1.7418, 17.4848, -1.9145, -1.6255, -2.0133, -2.0044,\n",
      "         -2.0077, -2.3768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 17.484821760234485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8583, -1.0992, -1.1271, 10.8000, -1.1474, -0.8776, -0.9323, -1.1259,\n",
      "         -0.9201, -1.2863]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 10.799983101537372\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7568, -2.4830, -1.8668, 18.4252, -1.9991, -1.7423, -2.5212, -2.1957,\n",
      "         -2.1500, -2.4628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 18.425199474795573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8369, -1.3911, -1.0848, 10.8882, -1.3826, -0.9028, -1.3261, -1.2714,\n",
      "         -0.9351, -1.4456]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 10.888163555337297\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3896, -3.6623, -3.3450, 30.0434, -3.2831, -2.6830, -3.3067, -3.3899,\n",
      "         -3.4183, -3.7295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 30.043405982275804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3790, -1.8857, -1.7484, 15.7125, -1.6801, -1.3304, -2.1273, -1.7594,\n",
      "         -1.5749, -2.2769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 15.712482800469804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9096, -2.6947, -2.0422, 21.0603, -2.2712, -1.6899, -2.3388, -2.2640,\n",
      "         -2.4794, -2.9894]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 21.060293572561594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6023, -2.8044, -2.3675, 23.9114, -2.6119, -1.8301, -2.5725, -2.6286,\n",
      "         -2.5186, -3.3470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 23.911353817785614\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.5074, -5.1809, -4.2041, 39.3787, -4.5670, -3.3833, -4.5927, -4.6160,\n",
      "         -4.3671, -5.3883]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 39.37869021843461\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0025, -1.5675, -1.0354, 11.2337, -1.1739, -0.8942, -1.3898, -1.3688,\n",
      "         -1.2539, -1.2979]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 11.233662723054941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0453, -1.4835, -1.5480, 14.4838, -1.4650, -1.3868, -1.4761, -1.4963,\n",
      "         -1.3219, -1.8833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 14.483802043723653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4816, -2.1973, -1.6062, 16.6917, -1.9477, -1.5274, -1.9386, -1.9134,\n",
      "         -1.8462, -2.1142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 16.691680922511445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5985, -3.9703, -3.5646, 31.4554, -3.4810, -2.6763, -3.5100, -3.8766,\n",
      "         -3.7355, -4.0060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 31.45541913394256\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3901, -2.2083, -1.9956, 18.4946, -2.0760, -1.2722, -2.0914, -1.8425,\n",
      "         -2.0340, -2.6429]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 18.494576896050457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4128, -4.9048, -3.9569, 37.9163, -4.3609, -3.2734, -4.6336, -4.5124,\n",
      "         -4.2767, -5.1200]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 37.91625787291846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4477, -3.3790, -3.0388, 29.2497, -3.3000, -2.2381, -3.1491, -3.1941,\n",
      "         -3.0923, -4.1146]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 29.24965217096216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6619, -2.3908, -1.8239, 19.0413, -2.1835, -1.5516, -1.9330, -2.1139,\n",
      "         -2.1359, -2.4733]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 19.041270673866777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8105, -3.0053, -2.4150, 22.7256, -2.4266, -2.0198, -2.7000, -2.3876,\n",
      "         -2.3968, -2.9305]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 22.725559296136947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2232, -1.7686, -1.6460, 15.8962, -1.5998, -1.1611, -1.7868, -1.6899,\n",
      "         -1.6512, -2.2029]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 15.896216973372976\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6947, -2.4101, -2.3117, 19.8470, -2.2751, -1.6257, -2.2441, -2.1322,\n",
      "         -1.9582, -3.0197]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 19.847047453712793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4700, -3.7131, -2.9721, 28.3023, -3.1719, -2.2675, -3.2910, -3.4804,\n",
      "         -3.0668, -3.9278]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 28.30226522727688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5088, -2.3074, -1.7938, 17.4421, -2.0381, -1.4965, -2.0176, -1.9640,\n",
      "         -1.9079, -2.0094]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 17.442125097252383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2374, -1.5608, -1.5925, 15.2376, -1.6348, -1.1926, -1.7145, -1.5695,\n",
      "         -1.6624, -2.1814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 15.237560170167907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5268, -2.4234, -1.7679, 18.0800, -2.0744, -1.7413, -1.9319, -2.0917,\n",
      "         -1.9904, -2.3546]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 18.079973083999473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7004, -2.5058, -1.9477, 20.0661, -2.2846, -2.0534, -2.0297, -2.1112,\n",
      "         -2.1810, -2.7912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 20.066097549122492\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1367, -1.9207, -1.4766, 14.6048, -1.8273, -1.3029, -1.3498, -1.6753,\n",
      "         -1.6854, -1.8422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 14.60480708269667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5340, -4.0423, -3.8199, 31.9743, -3.5025, -2.7157, -3.5907, -3.7967,\n",
      "         -3.7525, -3.9480]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 31.97429658234999\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0127, -1.5378, -1.4200, 13.4588, -1.3283, -0.9203, -1.6005, -1.3291,\n",
      "         -1.3821, -1.7508]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 13.458808470277646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.8886, -5.7542, -4.6178, 44.0233, -4.8902, -3.7090, -5.0973, -5.1550,\n",
      "         -5.1329, -5.9212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 44.023257955758545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3721, -2.0198, -1.5202, 15.4317, -1.8378, -1.3019, -1.7799, -1.7707,\n",
      "         -1.7951, -2.2255]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 15.431700906960884\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8604, -3.9256, -3.2723, 30.5347, -3.3082, -2.3801, -3.7349, -3.7135,\n",
      "         -3.6616, -4.2154]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 30.534682397935423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2110, -1.6600, -1.3596, 13.6117, -1.5607, -1.1302, -1.5028, -1.5745,\n",
      "         -1.4699, -1.6523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 13.611661349219183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7752, -2.4768, -1.8944, 18.2895, -2.0685, -1.7041, -2.4541, -2.1507,\n",
      "         -2.1388, -2.4068]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 18.289474244750746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4817, -3.6085, -2.8057, 27.3536, -3.1632, -2.3864, -3.1758, -3.1400,\n",
      "         -3.1528, -3.9111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 27.35355938540678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4908, -3.5870, -3.3359, 30.0380, -3.3757, -2.6414, -3.3891, -3.4751,\n",
      "         -3.3519, -3.8424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 30.037956075818336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9802, -4.0916, -3.4932, 33.0490, -3.7018, -2.7324, -3.7913, -3.8498,\n",
      "         -3.5983, -4.4545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 33.04899338751564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5572, -2.1420, -1.6644, 17.6184, -2.0223, -1.8276, -1.7683, -1.8492,\n",
      "         -1.8991, -2.4417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.618428507097562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6549, -2.1655, -1.5536, 16.9650, -1.9727, -1.5579, -1.8842, -2.1022,\n",
      "         -1.9653, -2.2051]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 16.964993880706885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0175, -2.7632, -2.1818, 20.6593, -2.3686, -1.8337, -2.6623, -2.4938,\n",
      "         -2.4268, -2.6494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 20.65926101601252\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0426, -3.5772, -2.9138, 28.3968, -3.2191, -2.1518, -3.2514, -3.3062,\n",
      "         -3.0988, -3.7987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 28.396846141368737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7854, -2.6599, -2.1760, 20.8130, -2.3640, -1.9782, -2.2090, -2.2097,\n",
      "         -2.3670, -2.9871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 20.812956128489777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6741, -2.2266, -1.9111, 17.6580, -1.9926, -1.5958, -1.8930, -2.1341,\n",
      "         -1.9308, -2.3643]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 17.65803277121314\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8278, -2.4640, -1.9776, 18.2084, -1.9903, -1.5913, -2.5298, -2.2614,\n",
      "         -2.1649, -2.3843]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 18.208416822967546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9726, -2.6658, -1.9981, 19.5304, -2.3176, -1.9319, -2.2901, -2.4335,\n",
      "         -2.1287, -2.5830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 19.530403769989324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1228, -2.7891, -2.2191, 21.3987, -2.3909, -1.9239, -2.8186, -2.6026,\n",
      "         -2.5445, -2.8091]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 21.398661091659708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3841, -1.7891, -1.6402, 14.6331, -1.5934, -1.3693, -1.7074, -1.6867,\n",
      "         -1.7949, -2.0134]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 14.633124335830168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6591, -2.7442, -2.1842, 22.0252, -2.5933, -1.4141, -2.2625, -2.1633,\n",
      "         -2.4864, -3.0395]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 22.02516215957761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7061, -2.3970, -1.7948, 17.9708, -1.7905, -1.5452, -2.1416, -2.2788,\n",
      "         -2.1287, -2.1604]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 17.970824932238838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.6378, -5.3676, -4.2514, 40.0894, -4.5457, -3.5940, -4.4408, -4.8510,\n",
      "         -4.6556, -5.5797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 40.08944801594845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3479, -2.0670, -1.6009, 16.4062, -2.1261, -1.4012, -1.8395, -1.8727,\n",
      "         -1.9625, -2.2752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 16.40621595022858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6611, -2.3416, -1.7976, 17.5763, -1.9963, -1.5258, -2.1101, -2.0398,\n",
      "         -1.9717, -2.2120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 17.576280712143845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0768, -1.6487, -1.3115, 12.5258, -1.4233, -1.1409, -1.3911, -1.5026,\n",
      "         -1.5291, -1.6600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 12.525775553820544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2662, -3.8596, -3.1679, 28.8034, -3.2805, -2.4693, -3.1587, -3.5132,\n",
      "         -3.3139, -3.6403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 28.803364196502606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2338, -1.4806, -1.3400, 12.3931, -1.1050, -1.0251, -1.6166, -1.4542,\n",
      "         -1.3895, -1.7601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 12.393146381326336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2715, -1.8782, -1.8990, 17.7729, -1.6438, -1.4567, -1.9240, -1.7784,\n",
      "         -1.7905, -2.3532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 17.77285504559077\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5341, -3.0938, -2.6503, 25.1272, -2.7633, -2.0791, -2.8735, -3.1715,\n",
      "         -3.0118, -3.3312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 25.12724272478941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7041, -2.4948, -2.0286, 19.7636, -2.2958, -1.5702, -2.0619, -2.2543,\n",
      "         -2.2822, -2.5527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 19.7635972170966\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5417, -2.0376, -1.7109, 16.1466, -1.7907, -1.5378, -1.8597, -1.9924,\n",
      "         -1.8904, -2.2982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 16.146571170933086\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3215, -2.2193, -1.7831, 17.8009, -1.9356, -1.7380, -1.6959, -1.8608,\n",
      "         -1.7679, -2.4892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.800890622563085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2650, -1.8433, -1.3068, 13.8333, -1.5903, -1.3574, -1.5587, -1.5794,\n",
      "         -1.5342, -1.6827]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 13.833280284499079\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5219, -1.9506, -1.6103, 16.0970, -1.9020, -1.2982, -1.6710, -1.8562,\n",
      "         -1.8400, -2.0808]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 16.097034895373316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1073, -2.8568, -2.3251, 22.2918, -2.3834, -1.8800, -2.5194, -2.5407,\n",
      "         -2.4448, -2.9501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 22.291784600548485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6184, -3.8933, -3.7741, 31.3897, -3.4661, -2.5742, -3.4000, -3.6923,\n",
      "         -3.6977, -3.9642]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 31.389652729822\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6702, -2.3330, -2.0844, 20.8059, -2.3627, -1.7819, -2.1277, -2.3419,\n",
      "         -2.2316, -2.9684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 20.805906239273767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7963, -2.7020, -2.2244, 21.8462, -2.5116, -2.1805, -2.1954, -2.2763,\n",
      "         -2.3522, -3.1162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 21.846164438986936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7752, -2.6030, -1.8885, 20.1309, -2.2739, -1.7786, -2.3177, -2.3849,\n",
      "         -2.2145, -2.3273]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 20.13089993670017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6453, -2.3300, -1.7082, 17.6453, -1.9195, -1.4344, -1.9380, -1.9488,\n",
      "         -1.9888, -2.2456]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 17.645250282317104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9488, -1.4879, -1.0486, 11.1443, -1.3804, -0.9184, -1.2902, -1.0993,\n",
      "         -1.1754, -1.3280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 11.144300379368879\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5303, -3.8344, -3.3770, 30.7863, -3.3498, -2.5539, -3.5297, -3.4687,\n",
      "         -3.6645, -4.0216]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 30.786251772240156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6272, -2.1877, -2.0628, 18.4064, -1.7619, -1.6383, -2.1957, -2.2577,\n",
      "         -2.1740, -2.6727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 18.40643712816777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9331, -2.4120, -2.0521, 20.3741, -2.2385, -1.8501, -2.1759, -2.2117,\n",
      "         -2.2914, -2.7032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 20.37405194433386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2913, -2.0102, -1.3020, 13.9499, -1.6594, -1.2565, -1.7295, -1.7279,\n",
      "         -1.5028, -1.7518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 13.94987009653773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.2889, -4.6956, -4.2810, 37.5826, -4.1804, -3.0980, -4.1419, -4.5552,\n",
      "         -4.6165, -4.8092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 37.58262000694499\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3356, -2.3504, -1.7368, 18.5283, -2.0746, -1.5827, -2.1827, -2.1915,\n",
      "         -1.6888, -2.2641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 18.528340811241474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5962, -2.4401, -1.9421, 19.0126, -2.1446, -1.8132, -2.1156, -1.9982,\n",
      "         -2.1754, -2.6478]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 19.012570387287717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7698, -1.2774, -1.0586, 10.3249, -1.0472, -0.9850, -1.2247, -1.0335,\n",
      "         -1.0695, -1.3923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 10.324921673646106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7484, -2.4793, -1.8761, 19.7598, -2.2762, -1.7144, -2.1865, -2.1549,\n",
      "         -2.3033, -2.7525]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 19.75975184075914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1499, -3.2824, -2.5267, 25.8870, -2.7978, -2.1193, -3.1057, -3.0303,\n",
      "         -2.7697, -3.3025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 25.887001804113662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6306, -3.6310, -3.4284, 28.8653, -3.3298, -2.4265, -3.3385, -3.1182,\n",
      "         -3.2165, -3.8436]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 28.865305425902378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8453, -2.6026, -1.8376, 19.3043, -2.1995, -1.8008, -2.3820, -2.2620,\n",
      "         -2.1539, -2.5430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 19.304345404863373\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5473, -3.6575, -2.8553, 27.6105, -2.8682, -2.0840, -3.3201, -3.2650,\n",
      "         -3.4312, -3.8559]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 27.610532071132376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2282, -1.7971, -1.5209, 13.5890, -1.3536, -1.2096, -1.6851, -1.5195,\n",
      "         -1.5538, -1.8399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 13.58895889540187\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1808, -1.7271, -1.6999, 16.7516, -1.6520, -1.2461, -1.8075, -1.6795,\n",
      "         -1.7543, -2.2668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.751628534988885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3011, -2.0350, -1.6115, 15.9961, -1.7305, -1.0614, -1.7535, -1.6685,\n",
      "         -1.7849, -2.3504]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 15.9961184484624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5773, -2.1458, -1.7667, 16.3161, -1.8892, -1.4697, -2.2126, -2.0352,\n",
      "         -1.9131, -2.1409]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 16.316103571308915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1195, -1.5294, -1.3555, 12.4664, -1.1352, -1.0434, -1.5231, -1.5419,\n",
      "         -1.4758, -1.7695]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 12.466447805314548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6869, -3.8610, -3.4469, 33.3057, -3.6658, -2.3495, -3.5546, -3.5657,\n",
      "         -3.6640, -4.5420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 33.305709972541024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4823, -2.6233, -1.8924, 19.1198, -1.9462, -1.5643, -2.2276, -2.1243,\n",
      "         -2.2719, -2.2601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 19.119792966330248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1938, -1.6397, -1.4933, 14.9856, -1.5549, -1.0288, -1.6427, -1.5487,\n",
      "         -1.5804, -2.0307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 14.98558116013849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3878, -1.9231, -1.7145, 16.1723, -1.8221, -1.1256, -1.6468, -1.8254,\n",
      "         -1.7554, -2.2119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 16.172252300982173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8164, -2.4816, -2.2775, 20.8704, -2.2307, -1.5565, -2.3908, -2.1501,\n",
      "         -2.3872, -3.0031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 20.870449464690918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7693, -2.7172, -2.1238, 21.0791, -2.3599, -1.8184, -2.6730, -2.1571,\n",
      "         -2.1285, -2.7537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 21.079072323319988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1342, -4.9015, -3.8985, 35.9598, -3.9426, -2.9529, -4.1823, -4.2148,\n",
      "         -4.1430, -4.8778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 35.95984656669701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4343, -1.8683, -1.7008, 15.0005, -1.5818, -1.2535, -1.8222, -1.7577,\n",
      "         -1.7938, -2.0491]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 15.000494438471573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8468, -2.5070, -2.2659, 20.8757, -2.2569, -1.6232, -2.3408, -2.1259,\n",
      "         -2.3108, -2.8432]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 20.87573695900674\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0104, -1.1610, -1.0044,  9.8599, -0.9334, -0.8754, -1.1829, -1.2656,\n",
      "         -1.1427, -1.3904]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 9.859851732159296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6556, -2.3410, -1.8308, 18.7146, -2.0641, -1.5645, -2.1234, -2.0126,\n",
      "         -2.1682, -2.5714]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 18.71459090545806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0644, -2.7870, -2.2942, 22.3662, -2.3732, -1.8606, -2.9259, -2.4159,\n",
      "         -2.4865, -2.8472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 22.3662377892211\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5261, -2.4061, -1.8848, 17.8365, -1.9575, -1.7028, -2.0225, -1.9768,\n",
      "         -2.1720, -2.4119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.83649370636884\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2163, -1.5346, -1.3851, 11.9717, -1.2988, -1.1536, -1.2934, -1.4192,\n",
      "         -1.4230, -1.6373]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 11.971725932247793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2592, -1.9941, -1.5814, 15.8098, -1.9053, -1.0898, -1.6614, -1.7322,\n",
      "         -1.8216, -2.0716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 15.80975245200758\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5829, -2.2472, -1.8943, 18.2441, -1.8676, -1.2823, -2.1612, -2.0241,\n",
      "         -2.1866, -2.3038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 18.24410828148831\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3194, -3.1818, -2.7867, 24.5652, -2.6301, -2.1677, -2.8486, -2.8471,\n",
      "         -2.9349, -3.3595]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 24.56520597644941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9633, -2.3993, -1.9573, 19.4886, -2.0701, -1.7562, -2.5516, -2.3213,\n",
      "         -2.2535, -2.5878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 19.488622456409285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6398, -1.8210, -1.7424, 15.7222, -1.7435, -1.3532, -1.6060, -1.8350,\n",
      "         -1.7882, -2.0796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 15.722153468622093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8700, -1.1847, -0.9744,  8.6694, -0.8574, -0.7274, -0.9176, -0.9830,\n",
      "         -1.0859, -1.1024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 8.669384120569756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9258, -2.6479, -2.2071, 21.3618, -2.4886, -1.7728, -2.3735, -2.3268,\n",
      "         -2.3590, -3.1247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 21.361811629206823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7404, -2.3895, -1.9811, 19.6679, -2.3377, -1.6514, -2.2345, -2.1416,\n",
      "         -2.1543, -2.9174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 19.66786186201553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4610, -2.0056, -1.9520, 19.0348, -1.8445, -1.4576, -2.0519, -1.9833,\n",
      "         -2.0679, -2.4879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 19.034794987810553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2135, -1.6049, -1.3179, 12.6476, -1.3374, -1.3074, -1.3715, -1.4236,\n",
      "         -1.5997, -1.6040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 12.647624478865215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7447, -2.3765, -1.9902, 18.8453, -2.1350, -1.6274, -2.1279, -2.0442,\n",
      "         -2.2253, -2.8333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 18.845330176753958\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9413, -2.2883, -2.1865, 21.1176, -2.3622, -1.8084, -2.1940, -2.3528,\n",
      "         -2.1994, -2.7882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 21.117616221908047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5740, -3.7310, -2.9766, 28.6053, -3.1543, -2.4739, -3.1885, -3.2542,\n",
      "         -3.2334, -3.9413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 28.60531147607798\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2743, -3.0772, -2.3266, 24.2459, -2.8289, -1.8230, -2.5491, -2.8540,\n",
      "         -2.5657, -3.1781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 24.245913653818427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7666, -4.0725, -3.5395, 34.6926, -3.8458, -2.4991, -3.5643, -3.6134,\n",
      "         -3.7936, -4.7328]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 34.69261516034818\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8567, -2.5339, -1.8223, 18.9793, -2.1812, -1.6797, -2.1130, -2.1840,\n",
      "         -2.0456, -2.4110]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 18.979281986581494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8626, -3.2331, -2.5395, 25.2674, -2.9862, -2.1024, -2.4710, -2.6993,\n",
      "         -2.5528, -3.3460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 25.26739164152782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8393, -1.6533, -1.3563, 13.7360, -1.4316, -0.8254, -1.5720, -1.4852,\n",
      "         -1.3701, -1.8858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 13.735993193115302\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3348, -2.0231, -1.7676, 17.5589, -1.6392, -1.3639, -1.9200, -1.8956,\n",
      "         -2.0246, -2.2398]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 17.558903625424136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3766, -2.2316, -1.6251, 16.9217, -2.0107, -1.3377, -2.1191, -1.8339,\n",
      "         -1.9940, -2.1161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 16.92170325397313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.5135, -5.0583, -4.1337, 39.0765, -4.4398, -3.2474, -4.5334, -4.6266,\n",
      "         -4.4172, -5.3553]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 39.07646428100248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9096, -1.1760, -0.8060,  9.2463, -1.1300, -0.7486, -1.0898, -0.8774,\n",
      "         -0.9328, -0.9354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 9.246259872948123\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6186, -2.5551, -2.1001, 20.7099, -2.3840, -1.6500, -1.9458, -2.2300,\n",
      "         -2.0833, -2.7126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 20.70990372167142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7793, -1.3438, -1.0045, 10.2097, -1.0026, -0.8274, -1.3589, -1.1179,\n",
      "         -1.1851, -1.4204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 10.20973309263502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3986, -1.7991, -1.7684, 15.5881, -1.7436, -1.3434, -1.7210, -1.6709,\n",
      "         -1.6923, -2.1204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 15.588116886123565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7614, -2.6352, -2.0311, 20.5415, -2.3542, -1.8115, -2.3532, -2.2830,\n",
      "         -2.2054, -2.5392]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 20.54154132967292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5678, -3.3952, -2.6506, 25.7559, -2.7840, -2.1730, -3.0810, -3.0624,\n",
      "         -3.0707, -3.4330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 25.75591784640229\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3606, -2.5077, -1.8873, 20.8474, -2.5342, -1.5810, -2.2254, -2.2797,\n",
      "         -2.1890, -2.8317]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 20.84739740823439\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7425, -2.2955, -1.8622, 18.7160, -2.1834, -1.6120, -2.0854, -2.1916,\n",
      "         -2.1294, -2.6919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 18.716044368316364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2421, -2.0147, -1.6078, 15.5289, -1.7156, -1.5139, -1.6159, -1.8120,\n",
      "         -1.6733, -1.9929]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 15.528886213275907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5417, -2.1231, -1.7178, 16.1505, -1.8859, -1.4595, -2.2160, -1.9529,\n",
      "         -1.9477, -2.0945]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 16.150493669498292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3607, -1.6485, -1.4881, 12.4848, -1.3268, -1.2382, -1.4144, -1.4393,\n",
      "         -1.4911, -1.6101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 12.48483238236733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8728, -4.0560, -3.3334, 30.9504, -3.4703, -2.6017, -3.4518, -3.7472,\n",
      "         -3.7541, -4.2619]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 30.95036432964168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4713, -0.8081, -0.7925,  7.5821, -0.7521, -0.5888, -0.8439, -0.5680,\n",
      "         -0.8324, -0.7698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 7.582135867198146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6184, -2.1438, -1.7617, 16.3270, -1.8350, -1.4044, -2.1925, -2.0558,\n",
      "         -1.8850, -2.1324]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 16.32697571201621\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2938, -3.4695, -2.8428, 25.6168, -2.7316, -2.0241, -3.1979, -3.2204,\n",
      "         -3.1695, -3.1626]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 25.616787850230654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1092, -1.8355, -1.8376, 16.4012, -1.5368, -1.2970, -1.8045, -1.5686,\n",
      "         -1.8213, -2.2677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.401243729173718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3243, -1.7316, -1.4510, 14.7284, -1.4357, -1.3012, -1.7776, -1.7535,\n",
      "         -1.6678, -2.1274]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 14.728424616465183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9612, -2.8892, -2.5260, 24.9892, -2.5117, -1.7989, -2.9025, -2.5277,\n",
      "         -2.8742, -3.2922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 24.989238525037955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1047, -3.3351, -2.6359, 25.9869, -2.8761, -2.0830, -2.8533, -2.9365,\n",
      "         -2.7528, -3.0957]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 25.986884336073704\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7452, -2.4482, -2.3821, 21.8219, -2.1007, -1.6691, -2.4730, -2.0974,\n",
      "         -2.3068, -2.9692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 21.82189190787985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8848, -1.1364, -1.0694,  9.1539, -0.8544, -0.7411, -1.1015, -1.2089,\n",
      "         -1.0766, -1.2652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 9.15391163922726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4863, -2.0060, -1.5235, 15.2099, -1.6226, -1.5035, -2.0390, -1.8112,\n",
      "         -1.8340, -2.0979]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 15.209902951536563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5924, -2.4541, -1.8968, 18.1790, -2.1626, -1.4178, -2.1482, -2.2319,\n",
      "         -2.1096, -2.4889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 18.17904091323054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3517, -3.6349, -2.9684, 27.6978, -3.0694, -2.4747, -3.2075, -3.2421,\n",
      "         -3.1142, -3.6585]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 27.6977954843533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4904, -2.7254, -2.0916, 21.0205, -2.5486, -1.7476, -2.0401, -2.4051,\n",
      "         -2.1772, -2.7475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 21.02051153124609\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8952, -2.8063, -2.2254, 21.6404, -2.6170, -1.9612, -2.3076, -2.5660,\n",
      "         -2.4076, -2.8745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 21.6403924865939\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8320, -1.2263, -1.1260,  9.3962, -0.9652, -0.6527, -1.1382, -1.0470,\n",
      "         -1.2412, -1.1843]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 9.396175735881119\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4382, -1.9483, -1.5309, 16.7817, -1.8770, -1.4546, -1.7329, -1.8806,\n",
      "         -1.7561, -2.2674]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 16.78174941727945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7344, -2.6768, -2.1339, 22.5055, -2.6324, -1.6148, -2.0938, -2.0790,\n",
      "         -2.3142, -2.9756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 22.505475188229827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1561, -1.5693, -1.4201, 12.8612, -1.3884, -0.9021, -1.3248, -1.4847,\n",
      "         -1.4100, -1.7487]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 12.861160074421619\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4187, -2.1944, -1.5289, 17.9969, -2.3827, -1.4661, -1.5647, -1.9388,\n",
      "         -1.8815, -2.2934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 17.996889432246153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1987, -1.7830, -1.7857, 16.9819, -1.7110, -1.3255, -1.8556, -1.6025,\n",
      "         -1.9001, -1.8722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 16.98189185901172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9695, -1.3233, -0.9611,  9.8756, -0.9913, -0.9346, -1.5123, -1.0736,\n",
      "         -1.0586, -1.3240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 9.875593793105562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6386, -2.3431, -1.8601, 19.8518, -2.3304, -1.8932, -2.2081, -2.1599,\n",
      "         -2.1930, -2.7812]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 19.85175299047334\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.1631, -0.3614, -0.1627,  2.7764, -0.4105, -0.2220, -0.2939, -0.2579,\n",
      "         -0.3665, -0.4686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 2.776386208502543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8459, -2.9918, -2.2745, 22.1171, -2.3933, -1.7585, -2.4961, -2.4983,\n",
      "         -2.6748, -3.1692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 22.117118555191794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0462, -1.5234, -1.2107, 11.6338, -1.1914, -0.8963, -1.3973, -1.2444,\n",
      "         -1.2857, -1.6248]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 11.633752216274967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9694, -2.7164, -2.2283, 21.6849, -2.5438, -1.8123, -2.3513, -2.3671,\n",
      "         -2.5656, -3.1382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 21.684920578165016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1456, -1.6731, -1.2882, 13.8215, -1.3790, -1.2980, -1.6678, -1.8518,\n",
      "         -1.4836, -1.7108]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 13.821514793031934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2180, -3.1426, -2.6501, 25.6706, -2.6953, -2.1761, -2.6513, -2.7845,\n",
      "         -2.7595, -3.4500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 25.670634776769713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5834, -2.3421, -2.1956, 19.9076, -2.0161, -1.4478, -2.1703, -1.9742,\n",
      "         -2.0128, -2.8789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 19.90762751145449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4076, -1.9676, -1.5778, 14.5179, -1.6527, -1.2108, -1.8609, -1.7913,\n",
      "         -1.7134, -1.9105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 14.517870201325593\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6841, -1.0457, -1.1553,  9.4708, -1.0138, -0.6886, -1.2227, -0.7581,\n",
      "         -1.0782, -1.0126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 9.470829267652515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4501, -3.3806, -2.7084, 27.3595, -2.9523, -2.5556, -2.9181, -3.2478,\n",
      "         -3.1533, -3.5003]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 27.35950859634721\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7984, -2.2970, -1.7371, 18.5105, -1.8920, -1.8478, -2.2264, -2.1037,\n",
      "         -2.0999, -2.3149]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 18.510534900376978\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5943, -4.0763, -3.2264, 30.7331, -3.5242, -2.5714, -3.5523, -3.4973,\n",
      "         -3.2506, -4.2140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 30.733090738904988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6118, -3.9418, -3.1982, 31.1718, -3.7353, -2.7429, -3.1628, -3.7655,\n",
      "         -3.3777, -4.4913]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 31.171756741667547\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0275, -1.1386, -0.9851, 10.3760, -1.0279, -0.6961, -1.2436, -1.0924,\n",
      "         -0.9221, -1.5069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 10.375988884136145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3285, -2.1204, -1.5585, 16.1658, -2.0192, -1.3491, -1.9332, -1.9441,\n",
      "         -1.8903, -2.1830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 16.165812834463168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5626, -2.2629, -1.8621, 17.8125, -2.0997, -1.7734, -2.0247, -1.9504,\n",
      "         -2.0108, -2.4451]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 17.812512729007757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9136, -1.2615, -1.1555, 10.2960, -0.9067, -0.8608, -1.2403, -1.3009,\n",
      "         -1.2154, -1.4701]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 10.295959369614398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7669, -2.6368, -2.0822, 19.6274, -2.0700, -1.5509, -2.3108, -2.1543,\n",
      "         -2.4053, -2.6436]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 19.627396144223543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3018, -2.1090, -1.8240, 17.9989, -1.9197, -1.4241, -1.9628, -1.8692,\n",
      "         -1.8950, -2.3399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 17.998933464764576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1651, -1.9841, -1.6294, 14.6212, -1.8093, -1.2020, -1.5523, -1.5127,\n",
      "         -1.8059, -1.9311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 14.621215083484369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7265, -2.5184, -1.8473, 18.1231, -1.9838, -1.5745, -1.9713, -2.0438,\n",
      "         -2.0664, -2.1196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 18.12314521229115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9531, -1.2844, -1.2824, 11.7712, -1.0198, -1.0443, -1.1393, -1.1229,\n",
      "         -1.3114, -1.7670]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 11.771204498148407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1378, -3.3075, -2.6764, 26.5347, -2.9956, -2.2083, -3.2434, -2.8148,\n",
      "         -2.7350, -3.4229]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 26.5346693704911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5797, -2.3096, -1.9157, 17.1042, -1.7739, -1.3382, -2.1740, -2.2174,\n",
      "         -2.1026, -2.1420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 17.104153043223288\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8995, -2.6569, -2.0435, 19.3801, -2.0905, -1.7445, -2.6205, -2.3154,\n",
      "         -2.2396, -2.5088]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 19.3801037550434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5457, -2.2387, -1.8921, 17.2427, -1.8574, -1.5751, -1.7798, -2.3298,\n",
      "         -2.0768, -2.1345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 17.242736333505473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8042, -1.7225, -1.2732, 13.2197, -1.5548, -1.0014, -1.1926, -1.2247,\n",
      "         -1.5701, -1.5880]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 13.219718847144755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7572, -4.2441, -3.2319, 32.7549, -3.7868, -2.7917, -3.7376, -3.4482,\n",
      "         -3.6879, -4.2312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 32.754891035617106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9103, -3.0249, -2.6966, 24.5184, -2.6801, -1.7398, -2.8852, -2.6581,\n",
      "         -2.5335, -3.3814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 24.518367816192782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1489, -1.7432, -1.5513, 13.4416, -1.6695, -1.3648, -1.4890, -1.5671,\n",
      "         -1.7161, -1.7244]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 13.441612773314613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0756, -1.4742, -1.2499, 12.4708, -1.0736, -0.7716, -1.4829, -1.4162,\n",
      "         -1.2571, -1.4905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 12.470759280508908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6090, -3.6507, -2.7987, 27.5651, -3.1301, -2.1166, -3.2595, -3.4151,\n",
      "         -3.2286, -3.8403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 27.565084943031167\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8730, -1.6635, -1.0246, 11.3744, -1.2063, -1.0736, -1.3571, -1.0987,\n",
      "         -1.5428, -1.4348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.374447598136232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1387, -1.8230, -1.3673, 13.3507, -1.5268, -1.1053, -1.3500, -1.5020,\n",
      "         -1.5607, -1.7174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 13.350735750569022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1382, -1.7085, -1.3978, 13.3456, -1.6535, -1.1623, -1.3791, -1.6497,\n",
      "         -1.3617, -1.9370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 13.345600398108036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1066, -2.8888, -2.4095, 22.1163, -2.3197, -1.7896, -2.7617, -2.5717,\n",
      "         -2.6852, -2.9284]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 22.116255294692973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4496, -4.0728, -3.2321, 30.8401, -3.4584, -2.5862, -3.3619, -3.3117,\n",
      "         -3.2571, -4.0025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 30.840129470193816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4574, -2.0634, -1.6860, 16.7218, -1.9691, -1.5266, -1.7318, -1.7620,\n",
      "         -1.7224, -2.2840]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 16.721771110398027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1800, -1.7805, -1.4698, 14.3674, -1.4964, -1.4336, -1.6613, -1.4651,\n",
      "         -1.4479, -1.7933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 14.367419872800415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5558, -2.2230, -1.7397, 16.2630, -1.8463, -1.4273, -2.1115, -2.0073,\n",
      "         -1.8834, -2.0888]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 16.26303760518322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7971, -2.3694, -2.0433, 17.8567, -2.0817, -1.4828, -2.1912, -2.3258,\n",
      "         -2.1800, -2.2820]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 17.856696174013337\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5323, -3.2095, -2.5988, 27.2521, -2.9388, -2.3338, -3.1170, -3.2209,\n",
      "         -3.2930, -3.7797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 27.252075607907468\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1004, -1.3945, -1.1327, 11.3083, -1.1450, -1.0067, -1.6784, -1.3074,\n",
      "         -1.2042, -1.5480]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 11.308305598193417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3339, -2.1361, -1.6049, 16.2536, -1.7743, -1.4508, -1.9935, -1.9934,\n",
      "         -2.0783, -1.9397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 16.253565446349278\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [2]: loss = 18.972, accuracy = 8.59\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327, -0.0425, -0.0239, -0.0287, -0.0659,  0.4636,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327, -0.0425, -0.0239, -0.0287, -0.0659,  0.4636,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-2.3243, -3.5179, -2.8524,  7.7773, -3.0737, -2.4436, -2.8394, 16.4597,\n",
      "         -2.9621, -3.9215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 16.459661187474822\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6209, -2.2154, -1.9957,  4.4199, -1.9786, -1.5380, -1.9036, 12.3456,\n",
      "         -2.0621, -2.5972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 12.345605792609739\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6055, -2.3595, -1.9728, 12.1775, -2.0892, -1.6227, -2.2160,  4.4893,\n",
      "         -1.9098, -2.4392]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 12.177489356420743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1667, -3.0111, -2.8651,  6.0220, -2.5787, -2.1266, -2.5060, 15.2487,\n",
      "         -2.6910, -3.0854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 15.248744257656716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0117, -1.5328, -1.3113,  5.2294, -1.8511, -1.1306, -1.6338,  7.0585,\n",
      "         -1.2819, -1.9561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 7.058462678713386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4632, -3.5865, -3.2851, 13.3238, -3.1741, -2.3668, -3.3081, 12.2486,\n",
      "         -3.2520, -4.0147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 13.323817438287952\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2849, -1.8238, -1.1386, -3.3810, -1.2941, -1.2429, -1.8170, 15.2960,\n",
      "         -1.5021, -1.7160]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.295962246226699\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3051, -3.1883, -2.8935,  6.5228, -2.9130, -2.2068, -2.9316, 18.5832,\n",
      "         -2.9997, -3.7348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 18.583225283075294\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7448, -2.5966, -1.9233,  3.8130, -2.3426, -1.7457, -2.2015, 13.8152,\n",
      "         -2.1312, -2.4967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.815224689903236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9391, -2.4503, -2.2082,  3.9875, -2.4068, -1.9642, -2.2642, 15.3422,\n",
      "         -2.1877, -3.0903]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.34220827419487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7400, -2.5436, -1.9945,  3.0159, -2.4266, -1.9801, -2.2680, 15.3639,\n",
      "         -2.2688, -2.7982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.363932870017257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4164, -1.9629, -1.8448,  1.8163, -1.6013, -1.2169, -1.5531, 11.6760,\n",
      "         -1.7096, -2.2416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 11.67602995557797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5314, -2.8841, -2.2395, 13.8558, -2.7289, -1.8407, -2.4893,  6.2926,\n",
      "         -2.2975, -2.8544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 13.855834534162966\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6069, -2.1299, -1.8345, -3.4949, -2.0508, -1.5185, -2.0266, 18.9432,\n",
      "         -1.9738, -2.3424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.943175451036034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5629, -2.8096, -2.1888,  7.1452, -2.7217, -1.7709, -2.1313, 12.5510,\n",
      "         -2.1891, -3.0439]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 12.550998813178065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2847, -1.8524, -2.0242,  0.4171, -1.8921, -1.1604, -1.8377, 14.8448,\n",
      "         -1.8779, -2.1627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.844775148371449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1175, -2.9782, -2.3994,  5.0993, -2.6683, -2.0020, -2.7383, 17.6646,\n",
      "         -2.5373, -3.3528]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 17.664625584613947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6401,  -2.5664,  -1.9278, -10.0435,  -2.2262,  -1.5814,  -2.1245,\n",
      "          27.1101,  -2.3273,  -2.4999]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 27.11005561783437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4602, -2.1658, -1.8289,  3.0171, -1.9784, -1.6569, -2.0179, 12.4095,\n",
      "         -2.0362, -2.3486]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.409488139369413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4751, -0.8051, -0.6067, -8.5415, -0.7166, -0.4071, -0.7982, 15.1610,\n",
      "         -0.8040, -0.9529]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.16101144823297\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0817, -2.8143, -2.3689,  5.7794, -2.5804, -2.0309, -2.6352, 14.0752,\n",
      "         -2.3548, -3.1488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 14.07522908024975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5683, -2.1540, -1.7086, -5.4026, -1.4937, -1.2786, -2.1255, 18.8148,\n",
      "         -1.8934, -1.9916]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.814781181185925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0893, -1.7310, -1.2777,  3.7112, -1.4538, -1.1085, -1.6376,  9.2075,\n",
      "         -1.4217, -1.5344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 9.207529129991858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7089, -2.5656, -2.1023, -4.4557, -2.0808, -1.5117, -2.2923, 20.9277,\n",
      "         -2.2633, -2.4399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 20.92769813395294\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8357, -1.3285, -0.9916,  3.7456, -1.0384, -0.9738, -1.0375,  5.5990,\n",
      "         -1.1730, -1.4033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 5.599016371951839\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8087, -2.3661, -2.2881,  2.6548, -2.3392, -1.5198, -2.4675, 15.6935,\n",
      "         -2.2458, -3.0531]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 15.693454003096862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1002, -1.3982, -1.1293, -0.2103, -1.1141, -1.0350, -1.6623,  9.9535,\n",
      "         -1.1950, -1.5219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 9.953481957991691\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9330, -4.2224, -3.5432,  5.6036, -3.7371, -2.9171, -3.7742, 24.0183,\n",
      "         -3.6152, -4.7537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 24.018304543157498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0857, -1.7332, -1.3488,  6.5684, -1.8204, -1.1777, -1.5429,  6.0129,\n",
      "         -1.4380, -2.0479]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 6.5684079897927266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5105, -1.9789, -1.5586, -0.2518, -1.6218, -1.3541, -1.9092, 14.5194,\n",
      "         -1.8534, -2.2364]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.519367983242661\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2266, -3.7836, -3.1209, 17.1224, -3.5485, -2.2374, -3.3592, 10.2228,\n",
      "         -3.2782, -4.2680]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 17.122396134755828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7095, -2.2944, -2.0956,  4.9263, -2.1328, -1.5422, -2.2044, 11.9832,\n",
      "         -2.1712, -2.8202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 11.983203589753181\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0532, -3.5746, -2.6626, 12.6388, -3.1493, -2.5828, -3.1492, 12.0572,\n",
      "         -2.8481, -3.5495]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 12.638781740167106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6826, -3.9734, -3.3303,  6.7246, -3.5909, -2.5478, -3.5450, 20.6322,\n",
      "         -3.6590, -4.2949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 20.632189963248624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7004, -2.5178, -2.1870, 10.2370, -2.0659, -1.5479, -2.4209,  8.0709,\n",
      "         -2.1299, -2.5009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 10.23696135003652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2556, -1.9184, -1.6608, -2.2941, -1.5954, -1.0601, -1.8996, 16.0327,\n",
      "         -1.8691, -2.0334]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 16.032744129759635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8010, -4.2476, -3.5168, 16.5245, -3.8065, -3.2219, -3.8907, 14.9348,\n",
      "         -3.7928, -4.5466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 16.524474206468266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7735, -4.1823, -3.2275, 13.5757, -3.6415, -2.8634, -3.6576, 15.2924,\n",
      "         -3.6347, -4.4231]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 15.292365202806014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5071, -2.0266, -1.4454,  0.9134, -1.6161, -1.2822, -1.8294, 12.8560,\n",
      "         -1.7665, -1.9376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.855980399835866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6354, -3.8043, -3.0487, 18.2363, -3.2567, -2.7080, -3.3640,  8.8892,\n",
      "         -3.3877, -3.9097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 18.236277514889803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9693, -2.4663, -2.1279,  5.6174, -2.1949, -1.7233, -2.5113, 12.8674,\n",
      "         -2.3505, -3.0085]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 12.867370644194496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5078, -1.9652, -1.6888, -3.5435, -1.6930, -1.2733, -1.9714, 16.9356,\n",
      "         -1.8075, -2.0785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 16.935619897493915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8789, -3.0028, -2.2194, 10.3574, -2.6317, -1.9766, -2.6019, 10.8225,\n",
      "         -2.4823, -3.0355]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 10.822487214172735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3453, -3.6149, -2.9124,  8.8596, -3.1457, -2.3763, -3.1379, 15.5155,\n",
      "         -3.1525, -3.6922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 15.515527301739146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8961, -2.3037, -2.0616,  5.2206, -2.1161, -1.7242, -2.2842, 11.6508,\n",
      "         -2.1707, -2.8072]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 11.650750476770256\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9307, -4.4913, -3.3880, 15.5545, -3.8972, -3.0571, -4.0089, 15.4522,\n",
      "         -4.0384, -4.7781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 15.554496926776656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5452, -0.7257, -0.4477,  0.1764, -0.7194, -0.6038, -0.8137,  5.8539,\n",
      "         -0.5412, -0.8248]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 5.8539047057937355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9579, -3.9626, -3.2396, 11.6576, -3.3878, -2.6082, -3.7907, 16.3667,\n",
      "         -3.6630, -4.4215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 16.3666543484588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5494, -2.2905, -1.6318,  3.1770, -1.7503, -1.7344, -1.9270, 11.2347,\n",
      "         -1.8194, -2.2350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.23471767420157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1701, -3.3770, -2.7703,  9.9900, -2.8723, -2.0865, -3.2908, 13.6531,\n",
      "         -3.1029, -3.7106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 13.653071129857555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7079, -1.3197, -1.0296, -0.6093, -1.1614, -1.0448, -1.2101, 10.1410,\n",
      "         -1.1731, -1.2870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.140990727703436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2141, -3.3455, -2.7998,  9.8196, -2.7140, -2.2035, -2.9705, 12.0044,\n",
      "         -2.7820, -3.2537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.004372051785602\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7046, -2.7276, -2.0680,  6.0305, -2.4506, -1.9549, -2.0688, 11.8551,\n",
      "         -2.2341, -2.5645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.855112516556211\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9941, -2.6073, -2.4474,  1.8199, -2.2783, -1.7257, -2.7907, 18.2905,\n",
      "         -2.5650, -2.9370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 18.29046344777644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6887, -2.2618, -1.5743,  5.4692, -2.1435, -1.4919, -1.9965, 10.0309,\n",
      "         -1.9504, -2.2778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 10.030932453243462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1632, -1.9128, -1.6197, -4.7528, -1.8971, -1.5109, -1.7601, 18.3329,\n",
      "         -1.8452, -2.1656]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 18.33288273769098\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1194, -3.1555, -2.6536,  5.0523, -2.8879, -2.0491, -2.9597, 16.4577,\n",
      "         -2.8510, -3.0849]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.457749649756817\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3479, -2.1463, -1.8936, -2.8608, -1.6952, -1.2655, -2.1410, 17.9993,\n",
      "         -1.9553, -2.2257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 17.999306528276026\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7592, -2.9363, -2.3384, -1.7846, -2.6266, -2.0855, -2.9635, 23.5334,\n",
      "         -2.6693, -3.1496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 23.533375903957868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4497, -3.6120, -2.8663,  3.2185, -3.0609, -2.0808, -2.9053, 20.0881,\n",
      "         -3.1902, -3.6983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 20.088119567764657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4004, -1.7749, -1.5600,  4.6660, -1.4468, -1.2554, -1.7475,  8.0812,\n",
      "         -1.7686, -2.0679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 8.08121671535945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6571, -2.3353, -1.8222, -3.3428, -1.8466, -1.5571, -2.2168, 18.2655,\n",
      "         -2.0499, -2.2305]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.265468311325805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6467, -2.3250, -1.9396, 10.3400, -2.0614, -1.7357, -2.0853,  5.5332,\n",
      "         -1.9744, -2.6042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 10.33995919508927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9006, -2.6977, -2.3014,  2.5968, -2.1200, -1.7342, -2.6031, 15.7111,\n",
      "         -2.4966, -2.7765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 15.711057492220153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3054, -1.8314, -1.3682,  7.3451, -1.6584, -1.1692, -1.6754,  5.0647,\n",
      "         -1.3713, -1.8247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 7.345134370996767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3458, -3.2982, -2.8987,  8.2681, -2.9540, -2.2238, -2.8385, 16.7113,\n",
      "         -3.1062, -3.7546]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 16.71128466002506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8895, -1.6054, -1.4501,  4.5065, -1.3004, -0.8882, -1.4595,  7.1308,\n",
      "         -1.6238, -1.8835]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 7.130759939829872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9755, -1.6144, -1.3724, -1.2856, -1.3953, -0.9616, -1.5772, 13.2515,\n",
      "         -1.4312, -1.8724]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 13.25150585451026\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6519, -2.0811, -1.5507,  4.1733, -2.1116, -1.4040, -1.8381, 10.4168,\n",
      "         -1.9279, -2.1497]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 10.416795672277033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9996, -3.9894, -3.2105, 14.9004, -3.6380, -2.7566, -3.7488, 14.0153,\n",
      "         -3.5725, -4.5585]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.900404128105436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7283, -1.5277, -1.4671, -1.3650, -1.5938, -0.7685, -1.5010, 14.1837,\n",
      "         -1.5973, -1.9314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.18371778633389\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5009, -2.3468, -1.8208, -6.8081, -2.1750, -1.4984, -1.9770, 22.3001,\n",
      "         -2.1825, -2.3551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 22.3001247176718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8576, -1.1808, -0.7342,  1.9510, -1.0973, -0.8753, -1.1916,  7.1605,\n",
      "         -1.1794, -1.2075]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 7.16052858956617\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9596, -1.0680, -0.9777, -2.2098, -1.0105, -0.8948, -1.0368, 10.9547,\n",
      "         -1.1074, -1.3013]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.954686126325367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9607, -1.6708, -1.2011,  1.1395, -1.6009, -1.1813, -1.4498, 10.0257,\n",
      "         -1.4665, -1.8651]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.025731852629612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6129, -2.2108, -1.8572, -2.8866, -1.8589, -1.3076, -2.0894, 17.4681,\n",
      "         -2.0086, -2.2108]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.468145490082943\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4253, -2.1080, -1.5530,  2.0853, -1.8908, -1.5148, -2.1212, 11.9272,\n",
      "         -1.7433, -2.1489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 11.927183269239851\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6968, -2.3418, -1.9542,  0.6683, -2.1695, -1.5635, -2.1225, 16.3221,\n",
      "         -2.1288, -2.6039]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 16.322101979816107\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1598, -1.4319, -1.2229,  1.5760, -1.2793, -0.9473, -1.3987,  9.1208,\n",
      "         -1.4246, -1.5532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.120803642233133\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2201, -3.5696, -3.0785,  8.0885, -3.1665, -2.5359, -3.2120, 17.2064,\n",
      "         -3.1422, -3.8307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 17.206380854504786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6090, -1.1020, -0.8135,  0.7195, -0.7891, -0.7432, -1.0561,  7.1670,\n",
      "         -0.7932, -0.8792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 7.1669760013465575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5470, -2.2025, -1.8205, -5.4631, -1.8279, -1.4109, -1.9960, 19.5614,\n",
      "         -1.9147, -2.1281]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 19.56135466896213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8745, -2.9696, -2.4845,  4.1903, -2.5699, -1.7504, -2.8803, 16.4056,\n",
      "         -2.5435, -3.1111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 16.405639898895803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4924, -2.2425, -1.7017, -3.7030, -1.9618, -1.5538, -1.9415, 18.3353,\n",
      "         -1.9352, -2.2742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.335336180891446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0411, -2.1073, -1.6415,  0.6398, -2.0581, -1.4030, -1.5868, 14.2958,\n",
      "         -1.9093, -2.2206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.295844451317869\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0512, -2.9420, -2.4814,  5.2138, -2.4610, -1.9177, -3.0271, 16.9611,\n",
      "         -2.8113, -3.0914]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 16.961069512406407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9677, -1.4236, -1.4755,  3.2928, -1.4253, -0.8643, -1.5952,  9.4089,\n",
      "         -1.3605, -1.9219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 9.408931214699187\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0574,  -1.8343,  -1.4806, -12.0718,  -1.7629,  -1.4432,  -1.5884,\n",
      "          24.5692,  -1.8068,  -1.9274]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.569240017412504\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6129, -1.8871, -1.7403,  3.7444, -1.6704, -1.3297, -1.6389,  9.8403,\n",
      "         -1.8781, -2.1872]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 9.840301947218599\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8972, -1.5757, -1.0116, -7.8222, -1.4414, -1.0220, -1.1878, 18.1978,\n",
      "         -1.5006, -1.5296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.197791835466443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4181, -2.3462, -1.9419,  7.5911, -2.2259, -1.3592, -2.3099,  9.4538,\n",
      "         -1.9386, -2.6295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 9.453818194772248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3354, -3.5784, -3.0205, 12.1844, -3.2163, -2.3062, -3.1061, 14.0385,\n",
      "         -3.1246, -3.6987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.038548252209932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8074, -0.8115, -0.6503, -0.3162, -0.6773, -0.6803, -0.9847,  6.2283,\n",
      "         -0.7782, -0.8770]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 6.228316679016764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9552, -1.5056, -1.4023, -6.9285, -1.1240, -0.7443, -1.5434, 17.6826,\n",
      "         -1.3238, -1.5532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 17.6826342612857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2142, -1.5963, -1.0634, -2.6231, -1.3726, -1.0715, -1.7354, 14.3684,\n",
      "         -1.4704, -1.4026]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.368409644654005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0179, -2.9751, -2.6104,  8.7475, -2.5668, -1.9121, -2.8804, 13.4671,\n",
      "         -2.7750, -3.1307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.467059222570128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9082, -1.3913, -1.0314, -1.2313, -1.2672, -1.0083, -1.2334, 11.7251,\n",
      "         -1.3811, -1.4845]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.72514022617603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8328, -2.5717, -2.0956, -2.3302, -2.1191, -1.7276, -2.3765, 18.7604,\n",
      "         -2.3192, -2.4805]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.760376142802166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6721, -0.7777, -0.7994, -6.3745, -0.8948, -0.7725, -0.8485, 13.9139,\n",
      "         -0.7631, -1.2302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 13.91387900507643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4200, -1.9820, -1.6412, -8.7886, -1.7648, -1.2346, -1.8593, 22.3873,\n",
      "         -1.9909, -2.0905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.387347120489892\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9363, -1.8685, -1.6974,  2.7153, -1.8121, -1.2844, -1.5692, 11.7406,\n",
      "         -1.7383, -2.1099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 11.740571723702352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4873, -3.0913, -2.6259, 10.2869, -2.9350, -2.1736, -3.0209, 12.9056,\n",
      "         -2.9873, -3.5848]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 12.905623220842907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5275, -1.8537, -1.9788,  0.1871, -1.6447, -1.2535, -1.7878, 14.8016,\n",
      "         -1.8556, -2.3482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.80160812056501\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6880, -2.3414, -1.9450, -0.0311, -1.9977, -1.4299, -1.9402, 15.8372,\n",
      "         -2.0199, -2.5250]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 15.837228197046162\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5733, -2.4769, -2.1708,  0.7602, -2.2176, -1.6406, -2.1664, 16.6820,\n",
      "         -2.2138, -2.3042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 16.681998802932377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2790, -2.1078, -1.6543, -7.9078, -2.0161, -1.7057, -1.8465, 22.3811,\n",
      "         -1.9987, -2.3277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.38109544439652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9905, -1.4142, -1.1896,  3.3451, -1.0662, -1.0096, -1.4184,  6.2591,\n",
      "         -1.3691, -1.6442]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 6.25907942819945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3347, -2.1028, -1.7519,  0.1402, -1.7340, -1.4322, -1.6852, 13.9535,\n",
      "         -1.9429, -1.9751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 13.953465652931193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4637, -3.9057, -2.9349, 14.7081, -3.5172, -2.6288, -3.3330, 12.7191,\n",
      "         -3.0957, -4.0448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 14.708117177757599\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4465, -1.7739, -1.5908,  0.9055, -1.6363, -1.2098, -1.6771, 12.1825,\n",
      "         -1.7241, -2.0021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.182515031456841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9510, -3.0452, -2.4992,  4.1201, -2.7279, -1.8337, -2.6422, 16.8976,\n",
      "         -2.7718, -3.1420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 16.89757208943125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8949, -2.7357, -2.6005, -0.4809, -2.4159, -1.6778, -2.6818, 20.3647,\n",
      "         -2.6257, -2.8853]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 20.364725789618177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5183, -2.2578, -1.7523,  4.0072, -1.9528, -1.6988, -1.9648, 11.6315,\n",
      "         -2.0283, -2.3690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.631549432311767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3428, -3.3176, -2.9022, 16.3817, -3.1595, -2.1987, -2.8854,  7.9387,\n",
      "         -2.9643, -3.8559]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.381710148092793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8996, -2.3060, -1.8608,  1.5826, -2.1777, -1.6800, -1.8380, 15.8606,\n",
      "         -1.9595, -2.5173]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 15.860596176874298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2014, -1.3901, -1.0113, -3.4709, -1.1555, -0.9886, -1.2485, 13.8296,\n",
      "         -1.3051, -1.5661]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 13.829618342282382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1663, -1.7975, -1.5011,  5.1785, -1.6610, -1.0373, -1.8736,  7.1767,\n",
      "         -1.2996, -2.0175]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 7.17673039259193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5261, -3.5945, -2.6970,  3.8292, -3.1027, -2.4190, -3.3057, 21.3209,\n",
      "         -3.4566, -3.8489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 21.32093093800082\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8675, -1.3822, -1.2027,  3.4802, -1.0881, -0.7681, -1.3566,  6.5271,\n",
      "         -1.0921, -1.4965]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 6.5270940191881825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1715,  -1.8622,  -1.4166, -10.2207,  -1.6819,  -1.2206,  -1.5706,\n",
      "          22.7242,  -1.7174,  -1.7956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 22.724168360666628\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4553, -2.1971, -1.8799,  5.1966, -1.9420, -1.4080, -1.6490,  9.9637,\n",
      "         -1.7396, -2.2567]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.963710686856812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5504, -3.7739, -3.3324, 12.8457, -3.4894, -2.4198, -3.3861, 15.0445,\n",
      "         -3.3581, -4.1101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.04452034772596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2806, -1.6749, -1.2822,  2.5840, -1.3785, -1.2818, -1.4263,  8.6901,\n",
      "         -1.5494, -1.7770]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 8.690070951870407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9523, -2.6745, -2.5115, -1.1198, -2.3184, -1.8892, -2.7570, 21.5245,\n",
      "         -2.6971, -3.0077]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 21.524471120640634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0830, -1.5721, -1.2486, -1.4488, -1.4058, -1.1957, -1.3315, 12.4368,\n",
      "         -1.4568, -1.6533]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 12.436820301234228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6305, -2.1345, -1.7555,  0.1052, -1.8671, -1.2529, -2.0040, 14.1563,\n",
      "         -1.8762, -2.1386]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.156293983582454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2103, -1.5484, -1.5120,  4.8836, -1.2937, -1.1411, -1.5697,  6.4786,\n",
      "         -1.5618, -1.8551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 6.478634336285267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0814, -3.1760, -2.8404,  9.1682, -2.8923, -1.9910, -2.8680, 14.9380,\n",
      "         -2.8532, -3.5655]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.93800881679999\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9128, -1.4794, -1.0564,  0.4250, -1.2477, -0.7358, -1.2782,  9.6953,\n",
      "         -1.1665, -1.3657]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.695276088861391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6780, -2.4306, -1.8576, -7.0331, -2.1618, -1.4845, -2.3495, 23.8417,\n",
      "         -2.3243, -2.4693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 23.84167438695905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6573, -4.2902, -3.4475,  9.7198, -3.8270, -2.9148, -3.8293, 19.2245,\n",
      "         -3.7287, -4.2597]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 19.22449513704692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0371, -4.2195, -3.3661, 14.8160, -3.6044, -2.7745, -3.9409, 15.1722,\n",
      "         -3.8480, -4.4700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 15.172199111586284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2523, -1.7516, -1.4543, -3.4256, -1.3019, -1.3221, -1.8321, 15.3642,\n",
      "         -1.5770, -1.9049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.364229825548332\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6264, -3.7029, -2.9836,  8.5973, -3.3194, -2.5765, -3.4206, 18.4581,\n",
      "         -3.3944, -4.1276]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 18.45808280042083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7033, -2.5447, -1.9408,  4.2378, -2.2042, -1.6856, -2.4406, 12.7258,\n",
      "         -2.1445, -2.5449]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.72581495230095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3760, -0.8920, -0.6239, -8.7946, -0.6021, -0.4044, -0.6978, 14.5986,\n",
      "         -0.8414, -0.8818]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.598556018324457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0159, -1.2292, -0.9378, -1.9180, -0.7801, -0.9523, -1.3355, 10.3827,\n",
      "         -1.0726, -1.3652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 10.382690586520118\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4263, -2.3116, -2.0590,  2.0389, -1.9514, -1.4989, -2.3324, 15.6544,\n",
      "         -2.1780, -2.4970]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 15.654389029838816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2478, -1.7269, -1.0862, -3.3340, -1.2012, -1.2458, -1.6035, 14.8440,\n",
      "         -1.3906, -1.5014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 14.844020000610634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3970, -2.2016, -1.8166, -8.5629, -2.1373, -1.7623, -1.9294, 23.7951,\n",
      "         -2.1303, -2.4235]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 23.795117060947824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3516, -3.3413, -2.8753, 16.2130, -3.1750, -2.1711, -3.0969,  7.9723,\n",
      "         -2.8024, -3.9141]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.213006503074613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9416, -2.6390, -2.2699,  8.5032, -2.2815, -1.6983, -2.2218, 10.0560,\n",
      "         -2.2661, -3.0301]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 10.055983254205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6321, -2.3640, -1.7452, -0.1278, -2.1463, -1.7531, -1.9493, 16.0492,\n",
      "         -2.1408, -2.3427]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.049246838503265\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1859, -1.5331, -1.3637, -3.2604, -1.2659, -1.1799, -1.6486, 15.4547,\n",
      "         -1.5886, -1.9193]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.45474313389487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0851, -3.1943, -2.7766,  9.0722, -3.0822, -1.8982, -2.9791, 15.6122,\n",
      "         -3.0080, -3.7001]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.612156354596275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7941, -3.0996, -2.5997, -0.4429, -2.5720, -2.1141, -2.6606, 21.0469,\n",
      "         -2.7066, -3.0327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 21.046917885332956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1161, -1.9029, -1.3332,  4.5708, -1.3213, -1.3389, -1.4564,  8.4032,\n",
      "         -1.4300, -1.6330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 8.40319599308987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6281, -3.6538, -2.8375,  6.5595, -3.1155, -2.5841, -3.2826, 19.1646,\n",
      "         -3.5938, -3.9652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 19.164550358302968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0427, -1.5728, -1.3363,  4.8412, -1.3531, -0.8227, -1.5776,  7.1729,\n",
      "         -1.3194, -1.8478]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 7.172872312610099\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3671, -2.0098, -1.6648, -7.3048, -1.6370, -1.0713, -1.9248, 21.6785,\n",
      "         -1.8611, -2.0492]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 21.67849781439384\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9112, -1.7079, -1.5768, -0.0850, -1.6436, -0.9537, -1.6134, 12.9146,\n",
      "         -1.7116, -2.0920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 12.914645330636674\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8578, -1.1205, -0.9984, -1.4344, -0.8744, -0.7540, -1.1419, 10.3423,\n",
      "         -0.9900, -1.2151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.342323384137586\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2418, -1.8628, -1.4606, -3.4222, -1.6376, -1.4554, -1.8473, 17.5952,\n",
      "         -1.6955, -2.0485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 17.595220490702445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1763, -2.9597, -2.8499,  0.0229, -2.6062, -1.7345, -3.1136, 21.8442,\n",
      "         -2.7334, -3.0694]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 21.844190258120523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6310, -2.3807, -2.1359,  9.1885, -2.4129, -1.5851, -2.6054,  9.7962,\n",
      "         -2.2392, -2.9451]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 9.796210000307145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0025, -2.6668, -2.5794,  5.4925, -2.5219, -1.8542, -2.6340, 15.6065,\n",
      "         -2.5122, -3.0731]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.606515118125554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7408, -1.6319, -1.4208,  2.0056, -1.8142, -1.2047, -1.4594, 10.6792,\n",
      "         -1.4145, -1.8985]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 10.679185367029625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1301, -3.5182, -3.0610, 11.4415, -3.2413, -2.1281, -3.0540, 14.6477,\n",
      "         -3.1533, -3.8054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.647737291209785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5135, -2.6699, -2.1403,  3.6889, -1.9279, -1.6683, -2.2964, 14.5964,\n",
      "         -2.3276, -2.4258]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 14.59635294443849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1956, -2.9374, -2.4741, -2.3961, -2.3297, -1.8868, -2.8149, 21.5455,\n",
      "         -2.6604, -2.8737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 21.54548837564179\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9978, -2.8442, -2.5444,  8.1930, -2.6660, -1.8304, -2.8022, 13.8900,\n",
      "         -2.6028, -3.2494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.889955582492766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1205, -3.3942, -3.0314,  4.2527, -2.8985, -2.1647, -3.1370, 18.9623,\n",
      "         -3.0807, -3.2601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 18.96228479979375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1344, -1.4286, -1.1708,  4.9006, -1.1879, -1.0781, -1.5326,  6.1358,\n",
      "         -1.4380, -1.6630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 6.135792529035937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1600, -4.7187, -3.7310, 22.3162, -4.1438, -3.0186, -4.3916,  9.9041,\n",
      "         -3.8548, -4.9765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 22.316221193135988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3893, -1.7018, -1.3404,  4.2203, -1.3744, -1.2012, -1.7795,  7.9086,\n",
      "         -1.5257, -1.9360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 7.908615136010571\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2681, -2.9458, -2.5499, 12.9660, -2.9305, -2.3064, -2.3524,  9.2070,\n",
      "         -2.4341, -3.5720]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 12.96599207228264\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4653, -1.7775, -1.6621,  5.5205, -1.4333, -1.3278, -1.7438,  7.4779,\n",
      "         -1.7756, -2.0667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 7.477862903141145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3873, -3.5795, -3.1565, 18.4233, -3.0749, -2.2227, -3.4005,  7.9118,\n",
      "         -3.0086, -3.9233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 18.423308909452427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3509, -2.0034, -1.8372,  6.4464, -1.9423, -1.2506, -1.8764,  8.8763,\n",
      "         -2.0092, -2.4492]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 8.876274227370896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6292, -2.2845, -2.3378,  9.3138, -2.2591, -1.7257, -2.3171, 10.3660,\n",
      "         -2.2343, -2.6958]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 10.36597161704478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6324, -0.7644, -0.4535,  0.3749, -0.5161, -0.5613, -0.7935,  5.4029,\n",
      "         -0.7817, -0.6523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 5.4029257419509635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7396, -2.7415, -2.1832, -3.5920, -2.5965, -2.1259, -2.3202, 22.7616,\n",
      "         -2.4783, -2.8990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.761632010466087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9145, -3.1792, -2.4555,  4.5872, -2.9025, -1.9987, -2.8862, 16.8114,\n",
      "         -2.6977, -3.1215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.811356411405765\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6413, -3.6287, -2.9545,  5.7037, -3.0257, -2.2720, -3.4235, 18.8243,\n",
      "         -3.4000, -3.9302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.82433261777572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6631, -1.0342, -0.5863, -3.1564, -0.7229, -0.7770, -1.1585, 10.5330,\n",
      "         -0.9688, -0.9470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.53301565137148\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8637, -2.3732, -1.9339,  1.8117, -2.2111, -1.7325, -2.0182, 15.5675,\n",
      "         -2.1911, -2.6325]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 15.56753473197266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5424, -2.3684, -1.5974,  4.2109, -1.7911, -1.7586, -1.9347, 11.3883,\n",
      "         -1.8785, -2.1352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 11.388301009123932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1467, -3.5028, -3.1756, 12.4512, -3.1047, -2.1271, -3.1661, 14.0537,\n",
      "         -3.1585, -4.0053]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.053722394504558\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8874, -1.7712, -1.3325,  3.8697, -1.3528, -0.9531, -1.6161,  8.3055,\n",
      "         -1.3654, -1.8775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 8.305527297462406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1528, -2.9602, -2.4516, -2.8819, -2.4334, -1.9842, -2.7784, 22.2969,\n",
      "         -2.7115, -2.8607]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 22.29693120726602\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6183, -2.2432, -1.7702,  4.9820, -2.2272, -1.5340, -1.9521, 11.1281,\n",
      "         -1.9566, -2.2477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.128086640172885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5410, -2.4079, -1.9633, -2.1621, -2.0070, -1.3571, -2.2698, 18.4825,\n",
      "         -2.2519, -2.1126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 18.48250876608077\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6916, -2.4727, -2.0658,  7.5785, -2.1978, -1.7707, -2.2461,  9.3342,\n",
      "         -2.1467, -2.7982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 9.33418892252258\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.7306, -5.3975, -4.4063, 26.9075, -4.8190, -3.4625, -4.7969,  9.8851,\n",
      "         -4.5982, -5.6490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 26.907502544287286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8138, -2.8784, -2.1463,  2.1901, -2.3716, -1.6664, -2.6144, 16.5329,\n",
      "         -2.5709, -2.6961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.532939407208065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1940, -2.7984, -2.4032, 12.3205, -2.5561, -2.1573, -2.3498,  8.6097,\n",
      "         -2.2090, -3.3782]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 12.320489723710772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6139, -2.0561, -1.7635, -1.0553, -1.8407, -1.4406, -2.2708, 15.5222,\n",
      "         -1.7990, -2.1711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 15.522223842603593\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4272, -3.7529, -3.1374, 18.9938, -3.1128, -2.3521, -3.4486,  7.9265,\n",
      "         -3.1032, -4.1160]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 18.99376867686551\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1563, -1.8254, -1.5890,  3.9873, -1.7753, -1.0692, -1.6341,  9.8980,\n",
      "         -1.8423, -2.2174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.897952570879605\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5797, -2.1299, -2.1609,  6.2633, -1.9781, -1.7355, -2.2184, 11.9983,\n",
      "         -2.1037, -2.4668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.998252009181009\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4896, -2.4933, -1.9183,  9.4227, -2.4823, -1.7441, -2.0197,  9.3484,\n",
      "         -2.0779, -2.7311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 9.4226910954678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6574, -2.2530, -1.8940,  1.6554, -2.1219, -1.7888, -1.8154, 15.2281,\n",
      "         -2.0144, -2.6566]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.228087827575731\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0977, -1.6448, -1.5157, -6.7893, -1.2513, -1.0561, -1.4959, 18.6726,\n",
      "         -1.6620, -1.3727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.672592740175595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3160, -3.2396, -2.4868,  0.7387, -2.2759, -1.8250, -3.0045, 19.8692,\n",
      "         -2.9068, -3.1382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 19.869220369258606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3964, -1.5589, -1.0844,  1.8455, -1.4168, -1.0490, -1.6621,  9.6012,\n",
      "         -1.3207, -1.4014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.60120171481002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0604, -2.6102, -2.1805,  5.2552, -2.4834, -1.9409, -2.4543, 13.9092,\n",
      "         -2.4318, -3.0138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.90920408290474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5814, -2.0767, -1.7817,  3.8674, -1.8743, -1.5723, -2.0182, 11.4305,\n",
      "         -1.8081, -2.5013]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 11.430507724850946\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9767, -2.9081, -2.5248,  6.6907, -2.6458, -1.8732, -2.5130, 15.0778,\n",
      "         -2.5218, -3.4055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.077802882000238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1691, -1.5338, -1.3923,  4.1648, -1.2526, -1.0999, -1.5690,  7.1412,\n",
      "         -1.5080, -1.8462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 7.141189432433049\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8864, -2.5356, -2.2015, -2.8296, -2.1751, -1.6704, -2.4505, 19.7832,\n",
      "         -2.2996, -2.5940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 19.783214085983218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9004, -4.3272, -3.8135,  8.2654, -4.0511, -2.7494, -3.9619, 23.0572,\n",
      "         -4.1797, -4.8199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 23.05719981319828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6974, -4.2288, -3.4708,  6.1120, -3.5608, -2.7221, -3.8565, 22.6905,\n",
      "         -3.8117, -4.1557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.690469689291838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5383, -2.0205, -1.4980,  1.0082, -1.4827, -1.1396, -1.8750, 12.4287,\n",
      "         -1.9124, -1.9898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.428668403822156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.7430, -5.2259, -4.2968, 24.7795, -4.7586, -3.5057, -4.8507, 11.7441,\n",
      "         -4.4530, -5.5761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 24.779536147140274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0628, -4.2810, -3.7720, 14.3848, -3.9476, -2.8125, -4.2250, 17.1818,\n",
      "         -3.9988, -4.7892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 17.181842776830873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6436, -2.3384, -1.9902,  5.6548, -2.0245, -1.5370, -2.2480, 12.2738,\n",
      "         -2.0687, -2.8468]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 12.273795540557039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0586, -1.6490, -1.2895,  7.4756, -1.6065, -0.9905, -1.4810,  4.0047,\n",
      "         -1.1937, -1.6657]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 7.4755640630264235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1636, -3.6186, -2.9757, 14.5716, -3.1030, -2.0636, -3.5006, 11.2690,\n",
      "         -2.9365, -4.0380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 14.571617818174083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8391, -2.6135, -2.1441,  7.8256, -2.5009, -1.8548, -2.2852, 10.3422,\n",
      "         -2.2927, -2.9049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 10.342238928541988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4161, -1.8418, -2.0963,  5.8458, -2.0079, -1.4263, -2.1376, 11.6642,\n",
      "         -2.0113, -2.3612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.664199957478772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6344, -1.3842, -1.1342,  2.8910, -1.4515, -1.1178, -1.2907,  7.7580,\n",
      "         -1.1398, -1.5894]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 7.757990345216226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7085, -2.4672, -2.1096, -5.3613, -2.3959, -1.9814, -2.0696, 22.9519,\n",
      "         -2.3574, -2.7587]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.95185701211466\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4166, -2.3096, -1.6156,  0.7880, -2.1528, -1.7376, -2.0822, 15.4292,\n",
      "         -2.0608, -2.4024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.429185136026167\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5199, -3.4661, -2.8057,  2.1982, -2.7642, -2.0929, -3.3538, 21.6251,\n",
      "         -3.2437, -3.7697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 21.625117789695274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4120, -2.0802, -1.8321,  7.0706, -1.9485, -1.3810, -2.0613,  8.1315,\n",
      "         -1.5008, -2.4229]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 8.131529762075614\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9416, -2.5244, -2.1186,  4.7148, -2.3770, -1.8353, -2.1676, 13.6066,\n",
      "         -2.3130, -2.8117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.606632489606262\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3476, -1.9895, -1.4355,  2.4575, -1.5051, -1.4017, -1.7635, 10.3141,\n",
      "         -1.7235, -2.0103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.314147834393006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8176, -2.5294, -2.1271, 11.1634, -2.3431, -1.7804, -2.1175,  7.0402,\n",
      "         -1.8643, -2.8190]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 11.16341184309632\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3900, -2.2297, -1.4861, -1.5108, -1.8983, -1.7200, -1.8558, 16.6389,\n",
      "         -1.9822, -2.0843]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.63887947341347\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.7103, -5.2037, -4.3311, 25.6456, -4.7466, -3.4412, -4.7637, 10.5035,\n",
      "         -4.4538, -5.5550]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 25.645593033190124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4078, -3.5388, -2.6217,  7.5300, -2.9270, -2.3324, -3.1460, 16.0586,\n",
      "         -2.9737, -3.2668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.05860241887873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7510, -2.8910, -2.5807, 12.2188, -2.3479, -1.6970, -2.6826,  9.6487,\n",
      "         -2.6355, -3.1852]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 12.218795667528758\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2480, -3.1595, -2.5093,  2.9809, -3.0334, -2.3098, -2.7220, 18.6402,\n",
      "         -2.7902, -3.3037]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.640236540180407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0937, -1.5940, -1.7690,  3.3826, -1.7124, -1.2182, -1.8491, 11.6410,\n",
      "         -1.8500, -1.9388]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.641041743940495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2319, -1.6620, -1.4207,  3.5241, -1.4740, -1.0750, -1.6914,  8.2424,\n",
      "         -1.3207, -1.7112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 8.242421846431938\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6578, -2.6794, -2.3923,  5.4850, -2.5240, -1.7122, -2.5820, 15.0075,\n",
      "         -2.4560, -2.8862]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 15.007496343165318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0200, -1.2860, -1.2339,  4.3748, -1.0921, -0.9770, -1.2823,  4.9094,\n",
      "         -1.2697, -1.5089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 4.909374526446759\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5957, -2.2226, -2.2186,  0.4502, -1.9907, -1.5374, -2.1861, 17.6971,\n",
      "         -2.1942, -2.3209]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 17.697112335230905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7536, -2.5205, -2.1101,  9.0254, -2.4142, -1.5470, -2.2578,  9.2936,\n",
      "         -2.2266, -3.0639]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 9.293621825192911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3774, -1.9833, -1.6655,  3.5812, -1.9422, -1.5122, -1.7201, 11.4324,\n",
      "         -1.7534, -2.3046]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 11.43243506019807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6810, -0.7796, -0.7819,  0.9612, -0.7193, -0.5745, -0.7473,  6.1612,\n",
      "         -0.7755, -0.9216]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 6.161160675836485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6256, -3.8028, -3.4166, 15.0913, -3.3404, -2.5703, -3.3625, 13.3523,\n",
      "         -3.3068, -4.2381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 15.091286568823728\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3843, -2.0553, -1.6223,  1.6089, -1.5706, -1.4529, -1.7779, 12.0114,\n",
      "         -1.8921, -2.0067]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.01135304984283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7424, -3.8532, -3.3836, 14.9421, -3.3920, -2.6399, -3.5117, 13.8159,\n",
      "         -3.4501, -4.2731]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 14.942113522391962\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6859, -2.2189, -1.9579,  7.5417, -2.0245, -1.4732, -2.1552,  8.4656,\n",
      "         -2.0109, -2.4422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 8.465564973084428\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6365, -2.3767, -2.0098, -3.6125, -1.9819, -1.5348, -2.2024, 18.7371,\n",
      "         -2.0692, -2.2353]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.737128204821534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7973, -2.6515, -2.3779, 12.4118, -2.4682, -1.8079, -2.4847,  7.1748,\n",
      "         -2.1085, -3.0496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 12.411775592195074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0077, -2.3995, -2.1352,  7.9595, -2.3199, -1.9140, -2.0596, 10.6476,\n",
      "         -2.1608, -2.9686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.647581303667131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3358, -1.9737, -1.2409,  0.2390, -1.8138, -1.4725, -1.6565, 12.7700,\n",
      "         -1.6163, -1.9394]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 12.769958643955022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5930, -3.8682, -3.3688, 17.5640, -3.3003, -2.3319, -3.6841, 10.1925,\n",
      "         -3.2347, -4.3219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 17.56398363987608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3632, -3.4228, -2.8251, 13.5154, -3.0141, -2.2271, -3.3091, 10.2419,\n",
      "         -2.7213, -3.5664]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 13.515448241554331\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5428, -2.3267, -1.9250, -9.3792, -2.1440, -1.8103, -2.0496, 25.8138,\n",
      "         -2.1865, -2.5476]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 25.81384573914382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1098, -1.5503, -1.0892,  2.9559, -1.2284, -0.9073, -1.2231,  6.9176,\n",
      "         -1.3398, -1.5465]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 6.9175559110174065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0349, -2.5468, -2.0967,  2.6578, -2.2884, -1.9747, -2.2283, 16.4876,\n",
      "         -2.3884, -2.9601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 16.487646207063914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4770, -4.8966, -3.9498,  3.4101, -4.3213, -3.1944, -4.3081, 30.7055,\n",
      "         -4.1966, -5.3095]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 30.70549174385217\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4601, -3.5490, -3.2163, 16.0425, -3.1959, -2.2235, -3.5031, 10.9506,\n",
      "         -3.1112, -4.0687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.042478379871177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2973, -3.3128, -2.8120,  4.6058, -2.9420, -2.1553, -3.0483, 18.2262,\n",
      "         -2.9872, -3.7262]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.22621429814968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5705, -2.2082, -2.3002,  4.4545, -2.0298, -1.5133, -2.1718, 13.3657,\n",
      "         -2.2730, -2.3923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.365719823487797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9055, -1.3713, -1.1296,  3.1578, -1.1872, -0.9692, -1.3461,  7.0603,\n",
      "         -1.2256, -1.7860]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 7.06028961558183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5026, -3.5497, -2.7322,  4.1876, -2.9746, -2.2803, -3.0448, 19.2943,\n",
      "         -3.1664, -3.8032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 19.29425860723815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6415, -1.2586, -1.0776,  4.3627, -1.0072, -0.8552, -1.0945,  5.1231,\n",
      "         -1.0902, -1.2523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 5.123142695708245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1797, -2.8898, -2.3282,  2.2390, -2.8170, -2.0815, -2.3857, 18.8854,\n",
      "         -2.5910, -3.3136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.88537764412365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2622, -1.5081, -1.2538, -3.0768, -1.4079, -0.8916, -1.5683, 15.1939,\n",
      "         -1.5998, -1.6753]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 15.193921736769777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8484, -2.4694, -2.0559, -1.1727, -2.0964, -1.5811, -2.6019, 17.9966,\n",
      "         -2.1907, -2.6086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.99656908582638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8159, -4.4192, -3.5716,  6.6583, -3.9942, -2.7700, -3.7619, 22.5441,\n",
      "         -3.8555, -4.7261]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 22.544124878330727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9797, -4.1965, -3.4511, 20.1719, -3.8046, -2.7717, -4.0858,  9.6143,\n",
      "         -3.5364, -4.5413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 20.171882248238223\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [3]: loss = 13.520, accuracy = 15.23\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327, -0.0425, -0.0239, -0.0287, -0.0659,  0.4636,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0083, -0.0853, -0.0327, -0.0425, -0.0239, -0.0287, -0.0659,  0.4636,\n",
      "        -0.0427, -0.0324], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.5897, -2.6639, -2.3880, 14.3093, -2.2758, -1.6126, -2.5499,  4.5973,\n",
      "         -2.0496, -3.0042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 14.309340474103877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6228, -3.8890, -3.0002,  4.4207, -3.1044, -2.4062, -3.5248, 22.3034,\n",
      "         -3.5155, -4.3798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 22.303410234891572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5588, -0.7290, -0.4339,  0.0923, -0.7658, -0.5831, -0.7547,  5.6267,\n",
      "         -0.7810, -0.8556]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 5.626666599957331\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8018, -3.8881, -3.4133, 19.8031, -3.5321, -2.5281, -3.6385,  8.8090,\n",
      "         -3.4216, -4.5327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 19.80305214247948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5771, -3.6204, -2.8587,  1.8507, -3.1763, -2.6276, -3.1765, 23.5156,\n",
      "         -3.1226, -3.8773]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 23.51560723653416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5554, -2.6041, -1.9744,  1.9046, -2.0705, -1.9036, -2.2272, 15.4212,\n",
      "         -2.2295, -2.7005]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.421210714488964\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1754, -3.5182, -2.9518, 14.7301, -3.1550, -2.4212, -3.2556, 10.5043,\n",
      "         -2.9632, -3.8008]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 14.730103751144346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3359, -1.7243, -1.6294,  4.6192, -1.6353, -1.0016, -1.7003,  8.4766,\n",
      "         -1.6734, -2.0410]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 8.476602823191685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9647, -3.2136, -2.6068,  6.5188, -2.9710, -1.9549, -2.9741, 16.9602,\n",
      "         -2.9337, -3.6186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 16.960214475612474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9094, -3.9724, -3.1916,  8.6404, -3.3775, -2.5136, -3.4747, 18.4033,\n",
      "         -3.6085, -4.2884]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.403338627149807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7646, -0.9973, -0.8693,  1.9881, -0.7656, -0.5688, -0.8417,  4.7288,\n",
      "         -0.6910, -0.9655]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 4.728765096864103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6742, -2.4141, -2.0006, -3.0620, -2.0793, -1.5306, -2.4465, 18.7702,\n",
      "         -2.0226, -2.3689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.77023578822687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5382, -2.0085, -1.8407,  6.4307, -1.5379, -1.4954, -1.9430,  7.8604,\n",
      "         -1.9710, -2.2519]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 7.8604476401465275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4238, -3.5235, -3.1099, 13.3083, -3.0301, -2.3673, -3.2393, 13.0160,\n",
      "         -3.0760, -3.8657]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 13.308330161978585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9623, -1.3678, -1.3448,  3.3818, -1.4503, -0.9966, -1.1930,  7.2801,\n",
      "         -1.3291, -1.7524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 7.280099511185829\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7409, -2.3447, -1.9830, -2.9983, -2.0546, -1.5071, -2.4903, 18.6483,\n",
      "         -2.1048, -2.3576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.648325104391468\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5928, -3.5966, -3.0537, 11.2531, -3.2215, -2.5432, -3.3163, 13.9766,\n",
      "         -3.2426, -3.7652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 13.976551699351388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1104, -1.8855, -1.7700,  2.8669, -1.7876, -1.2566, -1.7926, 12.2800,\n",
      "         -1.7696, -2.0564]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 12.27997966557326\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9492, -1.4370, -0.9016,  0.3936, -1.1873, -1.0192, -1.0959,  8.6863,\n",
      "         -1.1942, -1.3711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 8.686270644481993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3095, -3.3613, -2.8879, 13.9894, -2.9357, -2.1704, -2.8702, 10.9494,\n",
      "         -3.0248, -3.6967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 13.989364728935099\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4407, -2.3102, -1.9130,  2.9049, -2.3228, -1.4455, -2.1619, 13.8219,\n",
      "         -2.2659, -2.5546]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.821888647491166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9602, -4.2852, -3.4754, 19.6325, -3.7670, -2.7459, -4.1761, 10.6354,\n",
      "         -3.5989, -4.6316]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 19.632471151634675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0430, -3.6019, -2.5656, 19.6424, -3.1305, -2.3904, -2.9511,  5.0220,\n",
      "         -2.7219, -3.7565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 19.64240028734059\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0508, -4.4230, -3.4183,  7.0554, -3.7184, -2.6758, -3.8346, 22.0384,\n",
      "         -4.0917, -4.7292]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 22.038448525166643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4338, -2.2320, -1.8918, 10.5696, -2.4117, -1.6119, -2.3923,  7.2486,\n",
      "         -1.8878, -2.5696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  8\n",
      "activation[3] = 10.569578412493101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8736, -2.5164, -2.1888,  6.3332, -2.3529, -1.9467, -2.0749, 11.9502,\n",
      "         -2.2492, -2.8368]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 11.950185298972224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5415, -2.1963, -2.0098,  5.1304, -2.1261, -1.5519, -2.0773, 12.8882,\n",
      "         -2.0051, -2.4011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 12.888248040566614\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7760, -2.9486, -2.1938, -5.0144, -2.5207, -2.1117, -2.4483, 24.2894,\n",
      "         -2.6448, -3.0709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.289372666083732\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5993, -2.4902, -1.9060,  3.1886, -2.2607, -1.5722, -2.1997, 13.2408,\n",
      "         -2.2015, -2.5952]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 13.240765817400165\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3002, -3.1104, -2.6169,  5.6039, -2.7950, -2.1454, -2.6164, 16.2423,\n",
      "         -2.7210, -3.3504]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 16.24233584954473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3892, -2.1250, -1.5817,  5.1168, -1.9475, -1.5058, -1.7987,  9.5582,\n",
      "         -1.8853, -2.2635]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.558234756820328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5015, -3.6435, -3.1238, 17.1540, -3.1727, -2.4280, -3.4940,  9.3627,\n",
      "         -3.1559, -4.0600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 17.153974799925408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9244, -3.0059, -2.2971,  2.6161, -2.7797, -1.8811, -2.5850, 17.4272,\n",
      "         -2.7390, -3.0875]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 17.42718414206842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0950, -2.7672, -2.3728,  5.8663, -2.3669, -1.6415, -2.6298, 13.2036,\n",
      "         -2.4164, -2.4069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 13.20358309178969\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8415, -2.8643, -2.3697,  9.0788, -2.4055, -1.9280, -2.5512, 11.9782,\n",
      "         -2.6053, -3.1144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.978203785205846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7755, -2.9282, -2.2609, -7.6729, -2.5395, -2.0622, -2.4845, 26.9834,\n",
      "         -2.7051, -3.0765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 26.983447502744507\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1210, -1.4093, -1.1297, -0.2891, -1.5437, -1.0045, -1.3245, 11.1944,\n",
      "         -1.3832, -1.4915]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.194420130635688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6069, -3.7122, -3.2014, 18.9261, -3.3499, -2.3226, -3.4948,  7.8770,\n",
      "         -3.1965, -4.1522]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 18.92606320151169\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0974, -2.8643, -2.2318,  3.5924, -2.6923, -1.9623, -2.4421, 16.2055,\n",
      "         -2.5921, -2.9932]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 16.205533925167504\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5913, -2.1250, -1.8442,  3.2276, -1.8316, -1.4405, -2.1008, 12.1993,\n",
      "         -1.7751, -2.0251]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.19928462818187\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5460, -2.2066, -1.8976, 10.9150, -1.8719, -1.5652, -1.7647,  4.2492,\n",
      "         -1.7524, -2.4522]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 10.914989442956673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5207, -1.9790, -1.6745, -2.1132, -1.7606, -1.2932, -2.1511, 15.7601,\n",
      "         -1.8020, -2.0853]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 15.760112423535526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7768, -2.7584, -2.1708,  5.8830, -2.1968, -1.7693, -2.4302, 13.2573,\n",
      "         -2.2860, -2.6302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.25726450132113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.6841, -4.9656, -4.1952, 23.9111, -4.4796, -3.2340, -4.5245, 10.9047,\n",
      "         -4.3018, -5.3760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 23.91108986703325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5418, -1.8304, -1.3607, -0.4583, -1.6666, -1.0908, -1.6378, 13.4113,\n",
      "         -1.6826, -1.7787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.411293471678304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6201, -2.5303, -1.9342, -5.9624, -1.9526, -1.5787, -2.3083, 22.6723,\n",
      "         -2.3976, -2.2676]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.672304460450498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6678, -4.2050, -2.9427,  6.1116, -3.4076, -2.6422, -3.5332, 21.2113,\n",
      "         -3.5852, -3.7089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 21.211299268793653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2624, -3.6931, -3.1285, 16.7102, -3.0875, -2.1385, -3.4753,  9.3322,\n",
      "         -3.0654, -3.8652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 16.710230633244365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3646, -2.1816, -1.8952,  7.7679, -1.9737, -1.2667, -2.0705,  9.2348,\n",
      "         -2.0133, -2.5609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 9.234760745930682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.2976, -4.4576, -3.8147,  8.8019, -3.9514, -2.9235, -4.1086, 21.9243,\n",
      "         -4.2693, -4.9044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 21.924295370187195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1768, -1.9388, -1.5797,  3.6851, -1.5630, -1.0435, -1.4331,  9.6112,\n",
      "         -1.6111, -2.1344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 9.611180131581326\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9263, -2.9667, -2.2701,  4.8861, -2.6072, -2.2628, -2.2975, 15.1661,\n",
      "         -2.6154, -3.2172]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.16607009692308\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8557, -1.4636, -0.8536, -0.6025, -1.2663, -0.9012, -1.3938, 10.6095,\n",
      "         -1.1419, -1.3410]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.609488957744324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1318, -3.0717, -2.5160, -3.2834, -2.4677, -1.8897, -2.7972, 22.6789,\n",
      "         -2.7475, -2.9159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 22.67894986365878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4425, -1.7293, -1.4843,  5.2157, -1.5117, -1.2346, -1.4768,  7.2297,\n",
      "         -1.6027, -2.1745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 7.2296540577668855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6800, -3.7419, -3.0134,  7.1618, -3.1691, -2.2334, -3.1405, 17.6919,\n",
      "         -3.4875, -4.0273]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 17.691943176564834\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1856, -1.5803, -1.1411, -0.3524, -1.3842, -1.2573, -1.3933, 11.2021,\n",
      "         -1.5529, -1.6883]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.202111314039511\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2545, -3.2021, -3.0393, 11.6650, -3.0808, -2.0827, -3.0339, 14.0184,\n",
      "         -3.0797, -3.9199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.01838033575089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8771, -1.2902, -1.0399, -4.3361, -1.4578, -1.0144, -1.3008, 14.9844,\n",
      "         -1.0724, -1.7271]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 14.984436837234647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5706, -2.1625, -1.6017,  0.6412, -1.7794, -1.4914, -1.7916, 14.4728,\n",
      "         -1.9089, -2.3711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 14.472807097247513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3000, -0.4464, -0.2331, -1.1690, -0.5898, -0.2008, -0.4811,  4.4344,\n",
      "         -0.3638, -0.3813]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 4.434414058890361\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5529, -2.4143, -2.2500,  1.0412, -2.1241, -1.5359, -2.4880, 17.9434,\n",
      "         -2.3642, -2.5941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 17.943350969997542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2774, -3.1607, -2.2556, 10.1881, -2.8153, -2.2284, -2.9170, 11.8291,\n",
      "         -2.6783, -3.2055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 11.829053155817268\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1183, -4.6864, -3.5801,  9.7662, -3.8670, -2.8860, -3.6655, 20.2397,\n",
      "         -4.0566, -4.7587]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 20.239676544478144\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2557, -3.0622, -2.6170, 13.9266, -2.8027, -1.9514, -3.0583,  8.2718,\n",
      "         -2.6054, -3.3986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 13.92655109150969\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7572, -2.3215, -1.9437, -1.4269, -2.0087, -1.5056, -2.4635, 17.2378,\n",
      "         -2.0332, -2.4194]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.237766239606707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4993, -2.2235, -1.6531,  4.4143, -2.0401, -1.4773, -1.9736, 10.6079,\n",
      "         -1.8196, -2.1715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.607900183322327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5600, -2.0826, -1.8698, -3.2694, -1.8617, -1.3279, -2.2490, 17.5605,\n",
      "         -1.8602, -2.1630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.560493111621582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4512, -2.5257, -1.8011,  8.3246, -1.8663, -1.5382, -2.0840,  8.3048,\n",
      "         -1.8615, -2.5287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 8.324643906846289\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4954, -3.7504, -3.2111, 18.7428, -3.1329, -2.3176, -3.7395,  8.6423,\n",
      "         -3.2512, -4.0734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 18.742781720700467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3138, -1.5611, -1.3416,  3.0231, -1.2086, -1.1620, -1.5448,  7.8500,\n",
      "         -1.4874, -1.6935]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 7.849975842110764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6470, -2.6502, -2.0252, -3.9738, -2.3074, -1.9928, -2.2479, 21.8787,\n",
      "         -2.3767, -2.7389]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 21.878731464692034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6298, -3.5709, -3.0771, 17.4196, -3.3476, -2.5278, -3.4029,  8.8555,\n",
      "         -3.1877, -3.9272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 17.419586782939387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3633, -2.0621, -2.2255,  6.5438, -2.2407, -1.5010, -2.2670, 11.9307,\n",
      "         -2.0946, -2.4962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.930732599997292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3163, -1.9455, -1.8013,  4.7598, -1.6255, -1.1628, -1.9759,  9.4204,\n",
      "         -1.8174, -1.8223]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.420352614053296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1196, -4.3398, -3.7273, 18.8289, -3.9905, -2.9507, -3.9009, 11.8129,\n",
      "         -4.0550, -4.6413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 18.828881245446155\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1846, -3.4503, -2.8532, 13.8836, -3.1119, -1.9821, -2.9451, 10.2334,\n",
      "         -3.0644, -3.7127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 13.883571847428911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9103, -4.2641, -3.6694, 23.1389, -3.8563, -2.7752, -4.0028,  7.7806,\n",
      "         -3.6636, -4.6962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 23.138856034562817\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3372, -2.2485, -2.0278,  6.2818, -2.0292, -1.5074, -2.0964, 10.8293,\n",
      "         -1.9395, -2.7299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 10.82927408310213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3600, -1.8457, -1.2452,  1.8023, -1.7387, -1.3981, -1.6027, 12.0557,\n",
      "         -1.5716, -2.1649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 12.055712223135382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9993, -1.4095, -0.8530,  0.3962, -1.4026, -0.8955, -1.4575, 10.5493,\n",
      "         -1.1368, -1.4009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.549331648251245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5393, -3.9861, -3.6441, 13.7199, -3.7070, -2.5534, -3.7840, 16.6491,\n",
      "         -3.7008, -4.4120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 16.649112451193453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0331, -1.7124, -1.5564,  2.3650, -1.3308, -1.0546, -1.6750,  9.8263,\n",
      "         -1.5693, -1.7412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.826278741119964\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3775, -1.8980, -1.4414,  5.0609, -1.8908, -1.5332, -1.5307,  9.0639,\n",
      "         -1.4839, -2.2066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.06386172963447\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6644, -2.2055, -2.0828,  6.6197, -2.1979, -1.4798, -2.2819, 11.3448,\n",
      "         -2.1693, -2.7645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.344812875092432\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5928, -2.4077, -1.9580, -2.7111, -2.1727, -1.7681, -1.9922, 19.4736,\n",
      "         -2.2471, -2.6350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 19.473609026906413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4304, -1.9086, -1.6513,  1.6195, -1.9281, -1.3532, -1.7168, 13.1618,\n",
      "         -1.8098, -2.0722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 13.161799011064538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8130, -2.3291, -1.8310,  7.1782, -2.2512, -1.8381, -1.9939, 10.4532,\n",
      "         -1.8284, -2.7961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.45318099594468\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2226, -3.0225, -2.5262, 14.3455, -2.7354, -2.1705, -2.6121,  5.9603,\n",
      "         -2.5090, -3.3015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.345509710767535\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0900, -4.6806, -3.7902, 20.2914, -4.1760, -3.1079, -4.3115, 12.5157,\n",
      "         -3.9973, -4.8555]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 20.291358320361304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7027, -2.9312, -2.2213,  4.0892, -2.3315, -1.7584, -2.2006, 13.8591,\n",
      "         -2.4148, -2.8115]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 13.85911696766919\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9668, -4.1765, -3.7992, 14.6926, -3.8012, -2.9148, -3.8603, 17.0029,\n",
      "         -3.7734, -4.8186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 17.002889716077846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9817, -2.9992, -2.4607, 11.5516, -2.8405, -1.9034, -2.7367, 11.6873,\n",
      "         -2.9110, -3.4882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 11.687344255454322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.5295, -4.9107, -4.2341, 24.2517, -4.4568, -3.2974, -4.3616, 10.3578,\n",
      "         -4.1284, -5.4277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 24.251718859728566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9748, -2.7661, -2.1946,  5.3343, -2.3749, -2.2628, -2.7386, 14.4576,\n",
      "         -2.4727, -2.8156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 14.457605655093799\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3508, -1.4406, -1.4338,  2.3981, -1.3363, -1.1329, -1.6392,  9.3303,\n",
      "         -1.4443, -1.6226]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 9.330302378135363\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2737, -1.5507, -1.2377,  3.6357, -1.2657, -1.0669, -1.5641,  7.2722,\n",
      "         -1.4118, -1.7485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 7.2721701562291745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8850, -3.9134, -3.1309,  8.4125, -3.4181, -2.4564, -3.3792, 19.0455,\n",
      "         -3.8105, -4.2314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 19.045532055469238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7589, -2.6265, -2.1398,  9.0193, -2.5618, -2.0394, -2.3062,  9.4602,\n",
      "         -2.3307, -3.0325]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 9.460212239055842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.6744, -5.2718, -4.2935, 25.4157, -4.6845, -3.3939, -4.8280, 11.2983,\n",
      "         -4.5122, -5.6478]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 25.415707621841545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0241, -1.4361, -1.0839,  5.6800, -1.4783, -1.2308, -1.3298,  5.2737,\n",
      "         -1.3757, -1.7076]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 5.679989587275664\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9938, -3.1572, -2.5559, 14.2006, -2.7475, -1.8778, -2.6583,  8.8158,\n",
      "         -2.9121, -3.3168]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 14.200649218865653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8550, -2.3497, -2.2671, 10.6016, -2.1614, -1.7443, -2.2253,  6.3490,\n",
      "         -2.2451, -2.6137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 10.601551668247874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5048, -2.1040, -1.7345, -3.2481, -1.8595, -1.4335, -2.1996, 17.2982,\n",
      "         -1.8275, -2.1341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.298193007850475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1894, -2.0940, -1.7627, -0.1007, -1.9169, -1.4724, -1.7338, 15.6508,\n",
      "         -1.9075, -2.0878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.650841128351567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5536, -3.9690, -3.2234, 17.8264, -3.5250, -2.6801, -3.5441,  9.8058,\n",
      "         -3.3609, -3.9992]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 17.826373260016222\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0509, -4.5357, -3.8778, 16.7202, -4.0005, -3.1251, -4.1064, 15.5865,\n",
      "         -3.8556, -4.8361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 16.72016929757424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1729, -3.3941, -2.4647,  7.7670, -2.7743, -2.3402, -3.2471, 14.6341,\n",
      "         -2.8140, -3.2533]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 14.634074844421164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4941, -2.1496, -1.7017,  7.2983, -1.9114, -1.7945, -1.9582,  7.7024,\n",
      "         -1.8811, -2.3921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 7.702362751431619\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6813, -2.2744, -1.9849,  6.6569, -2.2464, -1.3934, -1.8623, 10.0602,\n",
      "         -1.9409, -2.5183]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.060156836671007\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6228, -2.2711, -1.9303, 11.9948, -2.2242, -1.6593, -2.0615,  4.4094,\n",
      "         -1.9385, -2.6871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.994817692271337\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4383, -1.7648, -1.6242,  2.9241, -1.4403, -1.0529, -1.6283, 10.0191,\n",
      "         -1.6534, -1.8646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 10.019080257867756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6489, -2.4043, -1.8197, -5.5393, -2.0405, -1.9231, -2.0885, 21.9977,\n",
      "         -2.2302, -2.5628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 21.997683455775725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7185, -2.3581, -2.0693,  1.5212, -1.9941, -1.4820, -2.4632, 16.6476,\n",
      "         -2.4083, -2.6380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 16.647596857351843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5888, -0.8831, -0.7670, -2.0369, -0.8239, -0.7204, -0.7711,  9.4548,\n",
      "         -0.6713, -0.6915]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.454813676418832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5347, -2.4614, -1.9582,  1.4023, -2.2358, -1.7326, -1.8793, 15.8693,\n",
      "         -1.9279, -2.7360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.869328071458101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8255, -2.2853, -1.8819,  4.1352, -1.9164, -1.7085, -2.2574, 11.4075,\n",
      "         -1.8670, -2.4252]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.407490804572193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0910, -4.4437, -3.5890,  1.0071, -3.8094, -2.7722, -3.9822, 29.3003,\n",
      "         -4.0966, -4.7761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 29.300324790606528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6978, -2.7360, -2.2687, 14.3346, -2.3370, -1.9622, -2.5599,  5.8482,\n",
      "         -2.1193, -2.9402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 14.334646897631764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2830, -2.9704, -2.2217,  1.4278, -2.7159, -2.1944, -2.4445, 19.8531,\n",
      "         -2.6774, -3.3291]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 19.853081692153104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5113, -2.2010, -1.7867,  2.9520, -1.9163, -1.6093, -1.8062, 12.2065,\n",
      "         -2.0136, -2.4076]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 12.206544793955342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7542, -2.3532, -2.2504,  4.0636, -2.0442, -1.6179, -2.0943, 13.2917,\n",
      "         -2.0774, -2.6947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 13.29168647464016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4527, -3.6820, -2.9839, 11.1069, -3.1743, -2.3741, -3.4862, 14.5163,\n",
      "         -3.0611, -3.9461]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 14.516255395751147\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5768, -2.1945, -1.8520, -3.9208, -1.9487, -1.5180, -2.2756, 18.6164,\n",
      "         -1.9404, -2.1728]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.616448114508913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2809, -1.5129, -1.5340, -0.8225, -1.1816, -0.8888, -1.7500, 11.6263,\n",
      "         -1.3670, -1.6604]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.626262424945558\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4141, -3.7720, -2.9293,  8.6469, -3.1407, -2.7370, -3.2699, 17.5117,\n",
      "         -3.3720, -3.8902]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 17.51172059818702\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9856, -2.6969, -2.1310,  2.3528, -2.2024, -1.8721, -2.5305, 16.6110,\n",
      "         -2.1725, -2.8333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 16.61099748027089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0849, -5.1358, -3.9399, 15.7672, -4.2271, -3.1060, -4.3690, 18.4039,\n",
      "         -4.2947, -5.1303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 18.403871375583112\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0933, -2.9466, -2.3158,  4.6068, -2.2606, -1.9797, -2.2724, 15.3199,\n",
      "         -2.3545, -3.0186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.319922263581875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1700, -1.4128, -1.3605,  3.8754, -1.3453, -1.1282, -1.4182,  8.2240,\n",
      "         -1.2406, -1.7153]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 8.224003649972653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4105, -2.0419, -1.4324, -3.3153, -1.6664, -1.4397, -1.7133, 16.5450,\n",
      "         -1.7617, -1.9257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.54497477235191\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2846, -1.5557, -1.6815, -2.2719, -1.5472, -1.0159, -1.5403, 14.4641,\n",
      "         -1.6252, -1.7527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.464063543316145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2784, -1.5607, -1.2869,  4.2711, -1.4622, -1.0701, -1.4706,  6.7970,\n",
      "         -1.4606, -1.8747]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 6.796998765916812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0748, -1.6716, -1.6406,  2.7650, -1.6615, -1.2312, -1.6868, 11.6110,\n",
      "         -1.8822, -1.9560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.610963066965137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4463, -2.3085, -2.1407,  9.6750, -2.2357, -1.5107, -2.1057,  8.7023,\n",
      "         -2.0178, -2.7033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  9\n",
      "activation[3] = 9.67495888278932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7447, -2.5704, -2.4472,  4.6277, -2.3631, -1.8368, -2.4338, 15.2742,\n",
      "         -2.5002, -3.0089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.274238213619492\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3500, -2.0626, -1.5527,  0.9010, -1.9294, -1.4165, -1.7583, 13.2401,\n",
      "         -1.8984, -2.1687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.24008422626649\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8098, -2.7635, -2.2276, -3.9253, -2.2765, -1.7980, -2.4189, 21.1541,\n",
      "         -2.3240, -2.4811]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 21.154083008831098\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3803, -1.7781, -1.2995,  1.7698, -1.6295, -1.2870, -1.7287, 10.5445,\n",
      "         -1.4418, -1.5019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.544452900108594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1086, -4.5028, -3.8104, 16.7071, -4.0636, -3.1084, -4.0920, 15.5887,\n",
      "         -4.2019, -4.8797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 16.707080916700168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8986, -1.4546, -1.0258, -0.3338, -1.0414, -0.6628, -1.3146,  9.8636,\n",
      "         -1.0777, -1.2096]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.86363723163865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.2931, -5.5826, -4.3950, 22.6925, -4.7446, -3.4341, -4.8657, 15.0714,\n",
      "         -4.7390, -5.5909]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 22.69246537590713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8683, -1.6368, -1.4471, 10.2032, -1.5849, -1.2372, -1.4942,  2.6988,\n",
      "         -1.2625, -1.8189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 10.203204577047035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5462, -2.3887, -1.9545, -8.2811, -2.3030, -1.8380, -2.1261, 25.2071,\n",
      "         -2.1749, -2.6591]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 25.207093823492325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7687, -2.5683, -2.3484, 12.8436, -2.2776, -1.7903, -2.2250,  5.1814,\n",
      "         -2.3264, -3.0837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 12.843609047003035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1639, -3.3722, -2.6509, -6.9312, -2.6099, -1.9899, -2.9473, 28.8494,\n",
      "         -3.0611, -3.3353]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 28.84942459603669\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3919, -2.0235, -1.5113,  0.8909, -1.6766, -1.2559, -1.7431, 13.1469,\n",
      "         -1.6478, -1.8768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 13.146893060030932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7667, -2.1713, -1.8754,  4.5532, -1.8853, -1.3989, -2.0478, 11.3606,\n",
      "         -2.0108, -2.4415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 11.360550743030277\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9226, -3.1299, -2.5556,  7.9743, -2.8647, -2.0209, -2.8633, 14.9498,\n",
      "         -2.6643, -3.2921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.94981233163121\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1140, -2.9187, -2.8587,  5.2130, -2.6616, -1.9643, -2.7545, 16.8305,\n",
      "         -2.8604, -3.2126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.83053518972566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8617, -2.8634, -2.3540, -3.5378, -2.4021, -1.9300, -2.6577, 22.8301,\n",
      "         -2.5609, -2.8660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.830091657907463\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6047, -2.2458, -1.9230, -2.8624, -1.9748, -1.4717, -2.2844, 17.7499,\n",
      "         -1.9135, -2.2544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.74990290316054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8526, -2.3378, -2.1191,  3.2328, -2.0379, -1.7157, -2.4769, 14.1845,\n",
      "         -2.2736, -2.8007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.184505316775583\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7737, -2.2730, -2.0229,  3.0351, -1.9642, -1.3906, -2.0341, 14.3692,\n",
      "         -2.2094, -2.5861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.36922639829021\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0979, -1.4645, -1.2417,  4.2087, -1.2247, -1.0805, -1.3783,  6.7990,\n",
      "         -1.1824, -1.5809]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 6.798950326937231\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7819, -3.8163, -3.0438,  2.7618, -3.2895, -2.3082, -3.1252, 22.6142,\n",
      "         -3.4561, -4.0885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 22.61415287120238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3865, -2.3964, -1.7512, 11.1747, -2.3478, -1.5949, -2.2742,  5.4291,\n",
      "         -1.9196, -2.8319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 11.174691618964356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0565, -4.4749, -3.5829,  4.3197, -3.7711, -2.7600, -3.6911, 25.3448,\n",
      "         -3.9517, -4.8670]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 25.344841986589422\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0769, -1.6577, -1.4427,  0.6684, -1.4619, -1.0976, -1.5164, 11.8831,\n",
      "         -1.3295, -1.5920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.883128074175236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0959, -3.5160, -3.0925, 11.7857, -3.1953, -2.1447, -3.0722, 14.4257,\n",
      "         -3.1871, -3.7318]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.425722610951802\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1683, -1.6469, -1.2989,  0.4471, -1.5149, -1.3521, -1.2931, 11.3780,\n",
      "         -1.4104, -1.9193]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.378046791418578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5914, -2.0822, -1.6775,  1.0540, -2.0195, -1.6894, -1.7979, 14.4497,\n",
      "         -1.9591, -2.3341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 14.449667534276259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7912, -2.7128, -2.1113,  6.1387, -2.2692, -2.0062, -2.3651, 13.5439,\n",
      "         -2.2137, -3.0428]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.543873012107866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9489, -2.4420, -2.6205,  0.5879, -2.2969, -1.7486, -2.3861, 18.3224,\n",
      "         -2.4419, -2.8119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 18.322366993135624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4186, -1.4710, -1.3168,  2.1923, -1.2218, -1.0703, -1.4691,  9.2654,\n",
      "         -1.4470, -1.5905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 9.265353251989524\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4379, -1.8630, -1.6502,  7.4062, -1.6006, -1.1491, -1.8244,  6.1162,\n",
      "         -1.6077, -2.0702]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 7.406170329279767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5796, -2.3589, -1.8362,  7.3678, -2.0232, -1.9689, -2.1669,  9.8885,\n",
      "         -2.1491, -2.5854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.88852026927333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5458, -2.1308, -1.5465, -5.4197, -1.5379, -1.2565, -1.7317, 18.5391,\n",
      "         -1.8685, -1.8474]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.539093922994667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5403, -2.0682, -1.5800,  3.0177, -1.8649, -1.6590, -1.7999, 11.2936,\n",
      "         -2.0540, -2.3045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 11.293573072245104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0455, -1.3246, -1.1639,  1.2323, -1.1960, -0.8706, -1.3604,  9.0362,\n",
      "         -1.1111, -1.5330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.036176846799124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8311, -2.9506, -2.1866,  8.4458, -2.6113, -1.9141, -2.6903, 11.2450,\n",
      "         -2.3310, -2.9187]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 11.245033313977427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0492, -1.7620, -1.4578, -1.1598, -1.3782, -1.0214, -1.5794, 12.1895,\n",
      "         -1.4212, -1.5927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 12.189475280266025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1967, -1.6195, -1.6086, -1.3547, -1.4601, -1.0597, -1.4449, 13.2389,\n",
      "         -1.6676, -1.6458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 13.238929737366902\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9864, -1.5163, -1.2323, -3.2661, -1.3483, -0.9697, -1.5587, 13.1360,\n",
      "         -1.3027, -1.4773]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 13.135972255821232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2057, -2.9439, -2.3062,  5.8699, -2.6559, -2.1264, -2.6450, 16.2563,\n",
      "         -2.5288, -3.3032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.256322795372377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5912, -2.4530, -2.2578,  2.1364, -2.4247, -1.5966, -2.4451, 16.4670,\n",
      "         -2.4105, -2.6891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 16.467033213284164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0965, -2.7353, -2.3290,  6.7947, -2.4060, -2.0205, -2.8118, 13.9362,\n",
      "         -2.3823, -2.8087]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.936161913692645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4147, -2.0926, -1.6248,  2.8991, -1.8062, -1.1608, -1.7897, 11.8019,\n",
      "         -1.9579, -2.1636]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.801879008304988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8899, -4.6718, -3.6431,  2.3996, -3.7747, -2.9766, -3.8873, 28.2982,\n",
      "         -3.9035, -4.7563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 28.29820973649241\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8519, -1.1841, -1.1191, -0.9922, -0.8890, -0.6462, -1.0925,  9.6709,\n",
      "         -1.1727, -1.1419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 9.670936583563806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2305, -3.2606, -2.5517, -2.4212, -2.6787, -2.1871, -2.9779, 24.2750,\n",
      "         -2.9305, -3.4054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.274971438377708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5852, -3.7216, -3.4603, 14.3509, -3.5380, -2.4708, -3.5452, 14.3369,\n",
      "         -3.5190, -4.4363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 14.350862017088113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4646e+00, -3.5914e+00, -2.6156e+00,  1.9858e-02, -2.9834e+00,\n",
      "         -2.5693e+00, -3.3980e+00,  2.4424e+01, -3.0936e+00, -3.8514e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.42438255750782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5970, -2.2346, -1.9194, -2.5834, -1.9921, -1.4337, -2.0829, 17.1942,\n",
      "         -1.9834, -2.1761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.194193695954727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1915, -2.3352, -1.9471,  4.7726, -2.0576, -1.4149, -1.9778, 11.4472,\n",
      "         -1.9975, -2.7142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 11.447239640025746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2100, -3.2190, -2.5018, 11.0627, -2.8230, -2.4827, -3.0363, 11.4888,\n",
      "         -2.7460, -3.6330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 11.488756090044891\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5323, -2.2723, -1.6340, -4.4354, -1.9469, -1.7562, -1.9306, 20.5306,\n",
      "         -2.0754, -2.4152]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 20.530614471427576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9965, -1.4577, -1.4359, -1.0432, -1.4599, -1.0318, -1.5262, 12.7358,\n",
      "         -1.4068, -1.5673]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 12.735839608881399\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2797, -3.5833, -3.0954, 17.7333, -3.0940, -2.3113, -3.2363,  7.9766,\n",
      "         -2.9366, -3.8509]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 17.733254610924522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9569, -3.0172, -2.5829, 13.4849, -2.6995, -1.8685, -2.5239,  8.4852,\n",
      "         -2.8780, -3.2623]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 13.484863610014097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0468, -3.1778, -2.7474, 14.6908, -2.8474, -1.9300, -3.0089,  9.0892,\n",
      "         -2.7788, -3.6333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 14.690783664625686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3202, -3.4038, -2.7801, -2.0790, -2.8079, -2.1924, -3.2393, 23.8859,\n",
      "         -2.9292, -3.2057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 23.885889859766607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2402, -3.3618, -2.9113, 15.6087, -2.9205, -2.1142, -3.0164,  7.9144,\n",
      "         -2.6003, -3.8024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 15.608742543315145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1384, -1.6244, -1.4353, -3.2310, -1.4988, -0.9765, -1.7324, 14.1145,\n",
      "         -1.4023, -1.6312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.114490433519157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1323, -1.5809, -1.2720, -0.1352, -1.5440, -1.1296, -1.4154, 12.0070,\n",
      "         -1.4923, -1.7038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 12.00696302982116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6382, -3.5169, -2.8481,  1.4026, -2.9866, -2.1727, -3.1457, 22.6087,\n",
      "         -3.3081, -3.8419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 22.60867380663528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3332, -3.0203, -2.6006, 11.8578, -2.6254, -2.0362, -2.8686, 10.1956,\n",
      "         -2.8520, -3.4532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 11.857783333542175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6607, -2.4322, -1.9984, 10.3460, -2.0698, -1.5573, -2.1731,  8.2341,\n",
      "         -2.2557, -2.6621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 10.345977389626384\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7484, -1.3263, -0.8050,  2.6423, -0.9602, -0.8634, -1.2657,  6.6935,\n",
      "         -1.0389, -1.2156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 6.693521860806679\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2898, -1.4906, -1.5065,  4.2620, -1.4860, -1.2107, -1.5165,  9.1724,\n",
      "         -1.5301, -2.0170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.172352025100897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2900, -1.8522, -1.3713,  2.9720, -1.5425, -1.4022, -1.5250,  9.1719,\n",
      "         -1.5811, -1.8367]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 9.171867676278763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7367, -2.5344, -2.0287,  5.2117, -2.4333, -1.8547, -2.3302, 13.9807,\n",
      "         -2.3011, -3.1138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.980705807625064\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2975, -2.4714, -1.9751, 10.8493, -2.2594, -1.5327, -2.1389,  6.1524,\n",
      "         -1.8795, -2.5557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 10.849289040074643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8305, -1.3252, -1.2220, -4.3400, -1.1652, -1.0095, -1.2400, 13.3337,\n",
      "         -1.0658, -1.2562]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.333705931801841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6261, -3.8523, -2.9969,  1.5685, -3.8876, -2.4561, -3.0540, 24.9534,\n",
      "         -3.4842, -4.3170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 24.953394066659463\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3680, -2.0333, -1.8668,  2.8671, -1.8798, -1.4334, -2.0807, 13.4920,\n",
      "         -1.9206, -2.2525]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.49195019574038\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1140, -3.0029, -2.6531,  7.5993, -2.3055, -1.9443, -2.7387, 12.9515,\n",
      "         -2.4559, -3.0352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.951454865892542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8459, -4.5892, -3.5737, 19.8669, -3.9660, -2.8871, -4.0790, 11.0878,\n",
      "         -3.6766, -4.4918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 19.86687385578323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0297, -2.7815, -2.3364,  3.8698, -2.7448, -1.8025, -2.5457, 15.8595,\n",
      "         -2.4994, -3.2041]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 15.85945269097367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2101, -1.8641, -1.6194,  2.2387, -1.6292, -1.3430, -1.7538, 11.8907,\n",
      "         -1.6898, -1.9258]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.890698765445643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0068, -1.3867, -1.2989,  5.0125, -1.2749, -1.0644, -1.2967,  4.8705,\n",
      "         -1.4351, -1.5560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 5.01249997845985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0638, -3.2281, -2.8552, 11.6115, -3.0661, -2.0870, -2.9150, 12.6011,\n",
      "         -3.0199, -3.6334]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 12.601099231712666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9885, -2.6916, -2.0920,  5.6149, -2.4780, -1.7368, -2.3074, 12.7245,\n",
      "         -2.5541, -2.9021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.724463733542748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9480, -2.8619, -2.2738, -1.6748, -2.6589, -2.2766, -2.3817, 22.4714,\n",
      "         -2.4921, -3.2381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.4713575718039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7139, -2.3934, -2.0951,  8.7713, -2.0508, -1.5769, -2.4026,  8.4355,\n",
      "         -2.3264, -2.8865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 8.77132151653858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4741, -3.4793, -2.6008, 10.1912, -2.9145, -2.4486, -2.9850, 13.5752,\n",
      "         -2.9969, -3.7825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 13.575191042004034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8821, -1.3700, -1.2679,  1.2976, -1.4903, -0.9009, -1.1238,  8.3169,\n",
      "         -1.1008, -1.4457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 8.316932814913837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5828, -2.0534, -1.9619,  0.9042, -1.8177, -1.3693, -1.9559, 14.6841,\n",
      "         -2.0008, -2.4807]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.684087338847412\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6471, -2.3100, -1.7913,  5.7230, -1.9463, -1.8948, -2.1507, 11.7384,\n",
      "         -1.9404, -2.0742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 11.738432333937434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6995, -1.9924, -1.8391,  5.5560, -1.9100, -1.4542, -1.9680, 10.6499,\n",
      "         -1.9420, -2.5879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.649900577624232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5305, -2.4570, -1.9639,  3.1047, -2.0956, -1.6472, -2.0213, 13.2066,\n",
      "         -1.9979, -2.2739]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 13.20662732533796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3573, -3.3022, -3.1626,  6.5549, -2.9761, -2.4476, -3.1154, 18.0555,\n",
      "         -3.1079, -3.6445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 18.055523908599408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1840, -1.5227, -1.5582, -1.0711, -1.6000, -0.9269, -1.3590, 13.5786,\n",
      "         -1.2867, -1.6668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 13.578600188281204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9443, -2.5784, -2.2415, 12.0745, -2.2903, -1.7949, -2.1663,  6.8320,\n",
      "         -2.1115, -2.9400]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 12.074548617341945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0016, -2.8670, -2.4120, 12.1736, -2.4623, -1.9254, -2.8028,  8.8752,\n",
      "         -2.5584, -2.9681]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.173614916668052\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9931, -1.5213, -1.2425, -3.3436, -1.3793, -0.9338, -1.5918, 13.3457,\n",
      "         -1.3000, -1.5111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 13.345743136079129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3519, -1.9627, -1.6744,  0.8184, -1.7367, -1.4629, -1.6320, 13.1618,\n",
      "         -1.7264, -2.1623]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.161756259444013\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1883, -2.5485, -2.0995,  8.9466, -2.4051, -1.7454, -2.4069, 10.0892,\n",
      "         -2.0023, -2.9002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.089169674893027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3966, -2.0685, -1.7823,  7.8878, -1.7017, -1.2135, -1.9464,  7.4801,\n",
      "         -1.6727, -2.2872]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 7.887809850750787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9722, -2.9901, -2.8330,  6.5196, -2.8081, -2.0549, -2.6139, 15.8064,\n",
      "         -2.7041, -3.2972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.806370089404753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2686, -2.1834, -1.7310,  6.6606, -1.7352, -1.2955, -2.3040,  8.6991,\n",
      "         -1.8301, -2.1096]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 8.699104493147473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4062, -2.2196, -1.8925,  1.2526, -1.9857, -1.5151, -2.1668, 14.7811,\n",
      "         -1.9726, -2.2056]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 14.781052480488645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9709, -1.9534, -1.6213,  4.2025, -1.7652, -1.1882, -1.6208,  9.7661,\n",
      "         -1.6655, -2.3457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 9.766121434398345\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2346, -3.0049, -2.4909,  0.4346, -2.6860, -2.3266, -2.7963, 21.5214,\n",
      "         -2.7284, -3.3376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 21.52137687262612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7993, -1.1843, -1.0580,  4.4759, -0.9217, -0.7908, -1.1616,  3.8761,\n",
      "         -1.1595, -1.3647]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  1\n",
      "activation[3] = 4.475854942003081\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4275, -1.8909, -1.5979, -1.8601, -1.6191, -1.1434, -1.7922, 14.1723,\n",
      "         -1.6100, -1.8548]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.172261489529523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3618, -1.4556, -1.3104,  6.5589, -1.5307, -1.0198, -1.4038,  4.6389,\n",
      "         -1.3018, -1.6376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  4\n",
      "activation[3] = 6.55894847932128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1834, -2.6272, -2.0808,  3.1722, -2.4939, -1.8213, -2.2712, 16.7268,\n",
      "         -2.4570, -3.1286]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 16.726822547348522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1604, -1.9733, -1.3656,  1.6407, -1.7672, -1.3187, -1.8340, 11.2226,\n",
      "         -1.4562, -1.7799]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.222606622146538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3354, -3.1024, -2.6006,  6.2839, -2.7958, -2.2556, -2.8354, 15.9674,\n",
      "         -2.7951, -3.4097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 15.967390017978092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8518, -2.5597, -1.7963,  2.9962, -2.2645, -1.8448, -2.0086, 14.2073,\n",
      "         -2.2786, -2.5760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.20730757389311\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6370, -2.1991, -1.6930, -4.1603, -1.5346, -1.2954, -2.0095, 18.3026,\n",
      "         -2.0920, -2.1197]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.302563196619893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5062, -3.9763, -3.3776, 14.7046, -3.4488, -2.6859, -3.5985, 13.2220,\n",
      "         -3.6054, -4.1686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  2\n",
      "activation[3] = 14.704614173296369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5905, -2.2786, -1.9479,  0.3095, -1.9110, -1.5948, -2.1564, 16.1017,\n",
      "         -2.1499, -2.4923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 16.10171678871648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1578, -1.3452, -1.1983, -1.1872, -1.0477, -1.0310, -1.5061, 11.3219,\n",
      "         -1.2635, -1.6117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 11.321942886651266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4074,  -2.3969,  -1.8133, -10.1666,  -1.7920,  -1.2792,  -1.9017,\n",
      "          24.6651,  -1.9400,  -2.0484]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 24.665107069364407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7632, -2.5261, -1.8681,  3.3225, -2.3095, -1.6230, -2.1020, 13.9240,\n",
      "         -1.9840, -2.3540]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.924009243152566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6473, -2.3391, -2.0291,  8.4594, -2.0402, -1.2957, -2.2023,  8.9216,\n",
      "         -1.9854, -2.6465]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 8.921597246735578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9920, -2.8873, -2.3440,  6.8633, -2.8574, -1.7997, -2.2841, 12.7989,\n",
      "         -2.5348, -2.9147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 12.798948737265993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8638, -1.2223, -0.9578, -3.2585, -1.0651, -0.8020, -1.3312, 11.5600,\n",
      "         -1.0932, -1.2222]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 11.559972138942266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1720, -2.3216, -1.8901,  2.6284, -1.9755, -1.5131, -2.0938, 14.3884,\n",
      "         -2.1062, -2.3962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.38835403777084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8540, -2.5068, -2.4023,  9.7571, -2.5162, -1.7773, -2.1542,  9.7317,\n",
      "         -2.2070, -3.0233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 9.757067129651658\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7718, -2.4228, -2.1589,  9.6666, -2.1655, -1.5073, -2.2108,  9.1422,\n",
      "         -2.2729, -2.9216]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  6\n",
      "activation[3] = 9.666589011006403\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2738, -3.3904, -2.8594, 13.1688, -2.8605, -2.2560, -3.2223, 10.1008,\n",
      "         -2.9097, -3.5232]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 13.168824862874631\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9723, -1.5466, -1.1244,  3.4411, -1.1721, -1.0991, -1.3742,  6.6629,\n",
      "         -1.3052, -1.6545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 6.662880337630383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1295, -1.4084, -1.2579,  6.1555, -1.2112, -0.8934, -1.5562,  4.5292,\n",
      "         -1.2317, -1.7142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  7\n",
      "activation[3] = 6.155458224188832\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [4]: loss = 12.427, accuracy = 19.92\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086, -0.0855, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.8818,\n",
      "        -0.0429, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086, -0.0855, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.8818,\n",
      "        -0.0429, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-0.4621, -1.0538, -0.9258, -0.3176, -0.9916, -0.6853, -1.0276,  8.2471,\n",
      "         -0.7600, -1.0099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 8.247096546502267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0646, -2.8744, -2.2404, -0.8172, -2.3348, -1.5072, -2.7558, 19.6164,\n",
      "         -2.5791, -2.9922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 19.61639473174355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0431, -2.8888, -2.5050, -7.2590, -2.7412, -1.8158, -2.6955, 27.5237,\n",
      "         -2.5401, -3.2711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 27.52372302750623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4000, -1.7589, -1.2772, -7.5519, -1.3177, -1.1777, -1.5816, 19.5453,\n",
      "         -1.5959, -1.8239]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 19.545278867615703\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9780, -2.1006, -1.4470,  3.7849, -1.7170, -1.1532, -1.1726,  9.5662,\n",
      "         -1.3708, -2.0689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 9.56615598119382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6720, -2.5848, -2.2412,  1.4127, -2.0885, -1.5361, -2.5991, 17.5281,\n",
      "         -2.1624, -2.9034]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 17.52814514353279\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0288,  -3.0471,  -3.0988, -13.8501,  -2.7604,  -1.7896,  -2.9365,\n",
      "          36.7341,  -2.9454,  -3.2741]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 36.734080144005226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9871, -1.5625, -1.0871, -5.6345, -1.1016, -1.1226, -1.3560, 14.7788,\n",
      "         -1.2690, -1.2866]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.778839040315662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1921, -3.4336, -2.8939, -1.6088, -3.1864, -2.2204, -2.9336, 24.6952,\n",
      "         -2.9225, -3.7014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 24.69518368667726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5429, -2.5081, -1.9943, -4.3947, -2.0478, -1.6957, -2.2189, 22.0607,\n",
      "         -2.3571, -2.6830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.060652542008146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1129, -1.5466, -1.3464,  1.2840, -1.4322, -0.9510, -1.5596, 10.5520,\n",
      "         -1.4294, -1.7089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 10.551980027260122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2583,  -2.2047,  -1.6452, -11.0442,  -1.6052,  -1.2344,  -1.8597,\n",
      "          24.8638,  -1.7979,  -2.1574]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 24.8638230015404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5006,  -2.2190,  -1.8957, -19.7437,  -2.1335,  -1.4148,  -1.8447,\n",
      "          35.0345,  -2.0122,  -2.2820]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 35.034520737521284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9730, -1.5020, -1.1496, -8.6644, -1.3157, -0.7915, -1.4994, 19.3425,\n",
      "         -1.5175, -1.6041]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 19.342478160064523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0536, -1.7455, -1.1062, -4.9277, -1.4709, -1.0833, -1.3092, 16.2577,\n",
      "         -1.4113, -1.4569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 16.257651191813792\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8219, -2.7022, -2.3317, -0.7737, -2.4669, -1.6923, -2.6178, 20.5866,\n",
      "         -2.3882, -3.0225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 20.586569106688806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6884, -2.9921, -2.2824,  5.2903, -2.8302, -1.9494, -2.2015, 15.0938,\n",
      "         -2.3753, -3.1345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 15.093846234239823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5628, -1.9767, -1.8770, -4.8499, -1.6080, -1.2535, -2.1051, 20.4816,\n",
      "         -1.9866, -2.0969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 20.481572821407948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4774, -2.1452, -1.4994, -3.7062, -1.8879, -1.6016, -1.8340, 17.7378,\n",
      "         -2.0409, -2.2547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 17.737768657445955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8203, -2.2171, -1.9451, -7.2012, -1.9093, -1.6316, -1.8172, 24.1749,\n",
      "         -1.8229, -2.7263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.174865475741225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5643, -1.8682, -1.4244, -5.2134, -1.4722, -1.4283, -1.8416, 18.0022,\n",
      "         -1.6587, -2.0194]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.0021748041317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5931, -4.0511, -3.2047,  5.9550, -3.5536, -2.4260, -3.7346, 21.9484,\n",
      "         -3.4631, -4.2894]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 21.94839446810762\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5972, -1.2108, -1.0940,  0.7131, -1.1795, -0.8601, -1.0330,  7.4211,\n",
      "         -1.0438, -1.2795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 7.4211232432702285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3468, -3.0876, -2.8786, -8.2818, -2.8231, -2.4315, -3.0952, 31.8308,\n",
      "         -3.0563, -3.6396]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 31.830767629375813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7835, -2.4007, -2.0213, -1.2071, -2.2711, -1.9025, -2.3816, 20.1147,\n",
      "         -2.2598, -2.3781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 20.11469780365121\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8335, -1.4091, -1.0124, -4.7787, -1.2179, -0.6778, -1.0588, 14.8878,\n",
      "         -1.2825, -1.3049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.887846306074202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7810, -1.4837, -1.4218, -5.7689, -1.1825, -0.9228, -1.5048, 16.3108,\n",
      "         -1.2735, -1.2035]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 16.310800104279444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5342, -2.2922, -1.8397, -7.3346, -1.9257, -1.5512, -2.1602, 21.9168,\n",
      "         -1.9382, -2.1163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 21.916755827085005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0703, -1.5388, -1.3844, -2.5033, -1.1353, -1.0600, -1.5964, 13.4317,\n",
      "         -1.3664, -1.8135]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 13.431742013939079\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8662,  -1.4276,  -1.1447, -13.0889,  -1.2520,  -0.7972,  -1.3754,\n",
      "          23.4315,  -1.4308,  -1.5094]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 23.431476723560927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1637, -1.5780, -1.3930, -7.3638, -1.5989, -1.2553, -1.3953, 19.5839,\n",
      "         -1.4792, -1.8757]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 19.583912457673183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8552, -2.7892, -2.2996, -1.4794, -2.4108, -1.7152, -2.6110, 21.5083,\n",
      "         -2.5903, -2.9470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 21.50831805011849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5109, -1.9743, -1.4919, -5.0570, -1.6788, -1.3453, -1.6040, 18.5009,\n",
      "         -1.9109, -2.0864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.500857849034194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8452,  -1.6677,  -1.3951, -17.4368,  -1.4588,  -1.1881,  -1.5072,\n",
      "          28.8262,  -1.6419,  -1.6580]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 28.82618754989585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1461, -1.7462, -1.4554,  1.3952, -1.7900, -1.0977, -1.8063, 11.1659,\n",
      "         -1.6282, -1.9696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 11.165941714480981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4368, -3.1563, -2.6719,  3.7404, -2.6019, -1.8873, -2.9237, 17.3205,\n",
      "         -2.6908, -3.2795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 17.320456463421937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3457, -1.6364, -1.4561, -1.0643, -1.2946, -1.1240, -1.6078, 12.9134,\n",
      "         -1.5915, -1.9486]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 12.913355135939254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9110, -2.5442, -2.1080, -8.9057, -2.1787, -1.8313, -2.3455, 26.5476,\n",
      "         -2.3804, -2.7683]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 26.547594592691595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3467, -3.3283, -2.7649,  7.2143, -2.8137, -2.1036, -2.9469, 16.0254,\n",
      "         -2.9060, -3.7079]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 16.02541575237722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8308, -2.8165, -2.3261, -0.0490, -2.5344, -1.6761, -2.5019, 18.9985,\n",
      "         -2.4431, -3.0484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 18.998531795495907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3457, -1.8957, -1.7215, -3.4768, -1.8014, -1.4446, -2.0789, 17.5736,\n",
      "         -1.5012, -2.0777]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 17.573557497537724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9476, -1.2843, -0.9665, -5.4531, -0.9674, -0.8796, -1.5277, 14.1650,\n",
      "         -1.0735, -1.3310]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.165045270841263\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2667,  -2.0323,  -1.3748, -16.4569,  -1.6563,  -1.2492,  -1.8425,\n",
      "          30.1217,  -1.8507,  -1.9338]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 30.121718450284526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0083, -4.6417, -3.5243,  6.2043, -3.9082, -2.8876, -3.9922, 24.3253,\n",
      "         -3.6878, -4.5903]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 24.325302585471498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2867, -3.1317, -2.6945,  7.5956, -2.8492, -2.1709, -2.9480, 15.4680,\n",
      "         -2.6858, -3.5328]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 15.467968115758522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9222, -2.8101, -2.3199, -7.0825, -2.2820, -1.7015, -2.5729, 24.9896,\n",
      "         -2.5188, -2.5962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 24.989639647566626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0449, -2.6457, -2.4277,  2.2072, -2.6079, -1.7893, -2.4664, 17.5361,\n",
      "         -2.2724, -3.1466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 17.536062382469474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0784, -2.9954, -2.4854,  0.7502, -2.7262, -1.7910, -2.9075, 21.2147,\n",
      "         -2.7048, -3.4231]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 21.214735017727634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3316, -2.2292, -1.5787, -9.5661, -2.1233, -1.4394, -1.7412, 24.1607,\n",
      "         -2.0446, -2.3245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 24.160672892332315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9602,  -1.5372,  -1.2312, -10.7580,  -1.3274,  -0.8549,  -1.5576,\n",
      "          22.2258,  -1.4167,  -1.8100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 22.225794361353987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6238, -2.8219, -2.1745, -3.6859, -2.3906, -1.7535, -2.6068, 22.1009,\n",
      "         -2.5469, -2.7400]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.10092826307315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4991, -1.8096, -1.5285, -2.6568, -1.5883, -1.0212, -1.7387, 15.9900,\n",
      "         -1.6074, -1.6749]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.990043085101643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1024, -2.2659, -1.8956, -5.5798, -2.0720, -1.5049, -2.0708, 21.8928,\n",
      "         -2.0158, -2.4679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 21.892777267139124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3723, -3.6287, -2.8156, -2.8195, -2.8588, -2.2467, -3.2439, 26.7870,\n",
      "         -3.2047, -3.6304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 26.78695275093869\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9899, -3.5514, -2.7351, 11.2189, -3.1452, -2.2845, -2.7538, 12.9782,\n",
      "         -2.8489, -3.6676]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 12.978236420851847\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2156, -1.5211, -1.2001, -7.8991, -1.1427, -1.1706, -1.4591, 17.9727,\n",
      "         -1.3938, -1.4055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 17.97269450748591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6816, -1.0475, -0.7352, -3.9028, -0.8938, -0.8722, -0.9516, 10.6633,\n",
      "         -0.9660, -1.0102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 10.663306969290462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0566, -1.4481, -1.0733, -7.9604, -0.9715, -1.1141, -1.5473, 16.9945,\n",
      "         -1.2510, -1.3006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 16.99453626556108\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0647,  -1.6360,  -1.2182, -16.7773,  -1.3791,  -1.4966,  -1.3864,\n",
      "          27.9421,  -1.5359,  -1.6798]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 27.942126397911487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5102, -2.2740, -1.9613, -3.6741, -2.2494, -1.8164, -1.8843, 20.3359,\n",
      "         -1.9636, -2.5315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 20.335852035381215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2264, -1.5528, -1.4582, -4.5548, -1.2804, -1.1301, -1.7607, 16.5415,\n",
      "         -1.5293, -1.9421]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 16.541475629333796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1628, -1.6853, -1.3387, -8.3002, -1.4149, -1.1261, -1.6380, 19.3100,\n",
      "         -1.4895, -1.6644]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 19.31004037839495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4167, -2.2975, -2.0283,  1.9535, -2.2587, -1.6035, -2.2600, 15.3769,\n",
      "         -1.8000, -2.7396]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 15.376866964605567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8507, -2.8011, -2.5050,  3.7556, -2.4327, -1.7824, -2.6903, 16.9144,\n",
      "         -2.5077, -3.1869]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 16.914447232636526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0655, -1.5228, -1.1226, -0.7201, -1.2661, -1.0595, -1.2749, 10.7453,\n",
      "         -1.1811, -1.4715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 10.745259030650782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3182, -1.7049, -1.7039, -8.8595, -1.6797, -1.1616, -1.7980, 22.2426,\n",
      "         -1.7394, -1.9875]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 22.242577070992194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4454, -2.2634, -1.9473,  8.2015, -1.9961, -1.4376, -2.0612,  8.7646,\n",
      "         -1.8900, -2.5196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 8.764643493910325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5630, -2.2148, -2.0431, -3.2495, -1.9213, -1.3956, -2.2452, 21.3324,\n",
      "         -2.2588, -2.1489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 21.3323514214087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8528, -2.9496, -2.4498, -2.5414, -2.5189, -1.8216, -2.9003, 24.4453,\n",
      "         -2.4388, -3.2841]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 24.44534315414251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6886, -2.6707, -2.1658,  4.7890, -2.2892, -1.6960, -2.1712, 13.8069,\n",
      "         -2.2720, -2.8113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 13.806943349468664\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4519, -1.7816, -1.4467, -1.6909, -1.6026, -1.0907, -1.6908, 14.9194,\n",
      "         -1.6496, -1.9757]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.919363468356089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0089, -1.5169, -0.9977, -7.1229, -1.0963, -1.1018, -1.4971, 16.3374,\n",
      "         -1.2458, -1.3635]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 16.337431497000445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5153, -3.4708, -2.8247, -0.9546, -3.0142, -2.1352, -3.3068, 24.9308,\n",
      "         -3.2710, -3.3776]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 24.930802200005388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5682, -4.2332, -3.6676,  5.0024, -3.6545, -2.9434, -3.8819, 25.6955,\n",
      "         -3.8204, -4.4130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 25.695518836739783\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1335, -1.6800, -1.1674, -0.2791, -1.6669, -1.0151, -1.5010, 11.9609,\n",
      "         -1.3162, -1.5658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 11.960869574225327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2398,  -2.1278,  -1.7575, -14.4602,  -1.6820,  -1.1502,  -2.0344,\n",
      "          29.0574,  -2.0202,  -2.0510]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 29.057370976659918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9527, -2.4444, -2.0991,  1.9363, -2.1026, -1.7667, -2.3053, 16.3128,\n",
      "         -2.1717, -2.7861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 16.312775803848005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1853, -3.3180, -2.8780, -0.7966, -3.1636, -2.0343, -2.8650, 23.5527,\n",
      "         -3.0235, -3.7047]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 23.552742475752908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0159, -1.7689, -1.3940,  8.5057, -1.3386, -1.0730, -1.5820,  3.4193,\n",
      "         -1.1671, -1.8500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 8.505742427970654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4012, -3.1496, -2.5388, -8.0553, -2.8943, -2.3827, -2.6868, 30.6877,\n",
      "         -2.7974, -3.4102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 30.68767780683115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0492, -3.2856, -2.6171,  5.1617, -2.8171, -1.7328, -2.9492, 17.0874,\n",
      "         -2.8100, -3.4218]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 17.08736624961687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4529, -3.5667, -2.8278, -1.6116, -3.0476, -2.2859, -2.9959, 24.7917,\n",
      "         -2.9605, -3.7426]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 24.79168879096828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6415, -2.2742, -1.7476, -5.4816, -1.8167, -1.7785, -2.2457, 20.7843,\n",
      "         -1.8914, -2.4477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 20.784335749713442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8252, -2.8225, -2.4362,  4.7374, -2.5131, -1.7050, -2.6392, 17.3692,\n",
      "         -2.7517, -3.2939]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 17.3691839937351\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7956, -3.0592, -2.2705, -0.8155, -2.6064, -2.0418, -2.6963, 20.8491,\n",
      "         -2.6404, -3.0797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 20.84908240378164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8684, -2.7013, -2.4868, -2.1016, -2.3780, -1.6437, -2.8284, 22.3907,\n",
      "         -2.4272, -3.1255]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 22.39067316468686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4363, -2.0124, -1.4493, -1.0658, -1.7461, -1.3013, -1.7486, 14.7589,\n",
      "         -1.6466, -1.9831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.758883154006735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9625, -1.3429, -1.3047, -5.2904, -1.2338, -0.8814, -1.6283, 15.7092,\n",
      "         -1.3126, -1.4302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 15.70920232974039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8892, -2.7313, -2.1878, -0.6929, -2.5999, -1.8385, -2.1715, 19.3282,\n",
      "         -2.3638, -2.8933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 19.328246949436572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3520, -1.5481, -1.4403, -8.4030, -1.3849, -1.0239, -1.6066, 20.4868,\n",
      "         -1.5262, -1.6857]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 20.48683935239514\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2576, -1.9084, -1.6153, -2.1047, -1.7269, -1.4481, -1.5886, 15.8700,\n",
      "         -1.6437, -2.0962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.86997480237374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6509, -2.4398, -2.0110, -6.6306, -2.0773, -1.5749, -2.3954, 22.2987,\n",
      "         -2.0138, -2.2912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 22.298668321922033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2499, -3.2449, -2.3117, -4.9730, -2.7824, -2.1719, -2.7070, 26.3087,\n",
      "         -2.8745, -3.0751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 26.308727037358928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0170, -1.6874, -1.5512, -3.9122, -1.4578, -1.0731, -1.8067, 16.2143,\n",
      "         -1.4153, -1.5444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 16.214279690219797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1275, -1.3546, -1.1699, -5.9739, -0.9436, -0.9739, -1.5509, 15.7693,\n",
      "         -1.2720, -1.5086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 15.769262300043126\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3123, -3.4607, -2.7996,  2.6559, -2.6987, -2.1864, -3.1822, 21.2579,\n",
      "         -3.2178, -3.6247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 21.257910706982102\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7994, -1.3228, -0.7008, -2.0685, -0.8331, -0.7892, -0.8816,  9.1972,\n",
      "         -0.9193, -0.8795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 9.197221571266507\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8370, -2.4834, -2.3440, -8.1004, -2.0904, -1.6702, -2.2483, 26.1722,\n",
      "         -2.3381, -2.6692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 26.172175590807228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1557, -2.7470, -2.3796, -4.4436, -2.6415, -1.8422, -2.4519, 24.6260,\n",
      "         -2.5466, -2.9679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 24.625955719540844\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3337, -1.8169, -1.4907, -2.5197, -1.4330, -1.1036, -1.6501, 13.8808,\n",
      "         -1.5099, -1.6137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 13.880780276784868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7431, -2.4149, -2.2715,  5.2160, -2.2415, -1.5979, -2.2188, 12.6642,\n",
      "         -2.2048, -2.6540]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 12.664203694629364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6169,  -1.9615,  -1.7141, -14.2361,  -1.8349,  -1.4470,  -1.8853,\n",
      "          29.3375,  -1.8498,  -2.3205]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 29.337542780900254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2040,  -3.0664,  -2.3079, -12.0233,  -2.5523,  -2.2113,  -2.8777,\n",
      "          32.8758,  -2.7678,  -3.2184]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 32.87583539253931\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4230, -1.9532, -1.7157,  1.3080, -1.7322, -1.0894, -1.8385, 13.4427,\n",
      "         -1.7105, -1.9928]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.442698695097665\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9098, -1.7763, -1.5347, -1.8923, -1.7060, -1.0661, -1.7545, 14.6680,\n",
      "         -1.6933, -1.9929]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 14.668042131460044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3945, -2.1965, -2.0787, -2.7279, -1.8685, -1.3432, -2.1555, 18.8804,\n",
      "         -2.3659, -2.3586]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 18.880365431776063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2590, -3.3852, -2.8384,  5.5990, -3.0137, -2.2958, -3.1863, 17.4875,\n",
      "         -2.7454, -3.5669]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 17.48751547543258\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9342, -1.4461, -1.1793, -5.7118, -1.3456, -0.9690, -1.3899, 15.2036,\n",
      "         -1.2240, -1.3957]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 15.203588719212346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0021, -1.2400, -1.1039, -5.1466, -0.8880, -0.8581, -1.4040, 14.3223,\n",
      "         -1.1431, -1.4712]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.322318353666425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1218, -1.5963, -1.2500, -9.4955, -1.1637, -0.9455, -1.5512, 21.0992,\n",
      "         -1.6557, -1.8239]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 21.099234574845863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5536, -3.3805, -2.7640,  2.4178, -3.2870, -2.5733, -3.1714, 22.9668,\n",
      "         -3.0877, -3.7252]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.966833070455905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8967, -1.2036, -1.2191, -7.9730, -1.2107, -0.7884, -1.3720, 17.9554,\n",
      "         -1.2628, -1.4618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 17.955382323076904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3063, -3.1731, -2.7449, -4.5490, -2.7926, -1.9396, -3.2557, 28.1595,\n",
      "         -2.9339, -3.6067]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 28.15954494985271\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8033, -2.8818, -2.2633,  2.5157, -2.2657, -1.9685, -2.5695, 16.4269,\n",
      "         -2.4747, -2.9541]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 16.426860998628936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4303, -1.7213, -1.6782, -5.5038, -1.4329, -1.2328, -1.4720, 18.2547,\n",
      "         -1.7049, -1.9828]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 18.25469360317875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4623, -1.8938, -1.6580, -2.3166, -1.5677, -1.1805, -1.7690, 17.1722,\n",
      "         -1.8991, -1.9870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 17.172204727405024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0200,  -1.2767,  -1.1398, -13.4534,  -0.9829,  -0.8248,  -1.0664,\n",
      "          22.0985,  -1.0307,  -1.1782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.098526574045152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8872, -3.0905, -2.1224, -0.5494, -2.4232, -1.8590, -2.5346, 19.9824,\n",
      "         -2.2575, -3.0247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 19.982408798336664\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6419, -1.9575, -1.6881, -5.2508, -1.9600, -1.5143, -1.4879, 19.4915,\n",
      "         -2.0244, -2.2020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 19.49153354489835\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6658, -2.5657, -2.0847,  7.1033, -2.4161, -1.6044, -2.4870, 10.2183,\n",
      "         -2.2538, -2.7209]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 10.218262811379189\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0694, -2.8416, -2.5230,  4.5384, -2.6247, -2.0532, -2.7346, 15.6079,\n",
      "         -2.4640, -3.2394]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 15.607900674028713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2915, -3.6332, -3.0751,  9.9908, -3.2469, -2.3594, -3.4632, 14.9245,\n",
      "         -2.9439, -3.9025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 14.924485247109647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4233, -2.2428, -2.0198,  3.4094, -1.9388, -1.2957, -2.1149, 13.9527,\n",
      "         -2.0133, -2.6821]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.952667434212442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7281, -2.2848, -1.7244, -3.6025, -2.1471, -1.7982, -1.8432, 20.6103,\n",
      "         -1.9904, -2.5615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 20.61025165089564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7387, -2.1760, -1.9227, -2.8412, -2.0122, -1.5888, -2.1823, 18.5649,\n",
      "         -2.0481, -2.3535]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.564928278438853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4107, -1.8702, -1.5985,  0.4326, -1.6081, -1.2854, -1.5899, 13.2776,\n",
      "         -1.6011, -2.0300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 13.277607076548435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5668, -1.9904, -1.9485,  2.3008, -1.9131, -1.4151, -2.1252, 12.9486,\n",
      "         -1.7108, -2.3558]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 12.948618048338767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2026, -3.4369, -2.6931,  4.4778, -2.8509, -2.1260, -3.1968, 18.4978,\n",
      "         -2.8212, -3.5783]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 18.497787370049245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3114, -2.4506, -1.9971,  4.8262, -2.3435, -1.5854, -2.0687, 13.1796,\n",
      "         -2.0768, -2.8232]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 13.179629420053134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9609,  -1.6309,  -1.2969, -16.5208,  -1.4765,  -1.1840,  -1.3970,\n",
      "          27.8768,  -1.5058,  -1.6980]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 27.876844118026764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7157,  -2.5256,  -1.8252, -10.0663,  -2.1941,  -1.9270,  -2.2549,\n",
      "          27.3801,  -2.4438,  -2.6131]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 27.38011977997153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3300, -1.6734, -1.4042, -3.1261, -1.4336, -0.9658, -1.5740, 14.0263,\n",
      "         -1.4515, -1.6399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 14.026336795197178\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3104, -1.9202, -1.3700, -1.4411, -1.7496, -1.5178, -1.6621, 14.6658,\n",
      "         -1.8371, -1.9583]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 14.665753067550213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4282,  -1.9248,  -1.6022, -12.2809,  -1.5179,  -1.2715,  -1.7568,\n",
      "          26.3099,  -1.7447,  -2.2217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 26.309939469150127\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4632, -2.0846, -1.7542, -2.3610, -1.8217, -1.6831, -1.9990, 17.9507,\n",
      "         -1.8244, -2.4023]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 17.95067860655548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9512, -1.4149, -1.2953, -7.7689, -1.1355, -0.8893, -1.4680, 19.0625,\n",
      "         -1.4387, -1.4082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 19.062540528930793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7338, -0.9164, -0.6844, -4.9336, -0.9054, -0.5115, -0.9290, 12.3305,\n",
      "         -0.9847, -0.7764]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 12.330482221932343\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5443,  -2.1067,  -1.7534, -10.9855,  -1.8186,  -1.5959,  -1.7481,\n",
      "          26.1324,  -1.8625,  -2.2589]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 26.132405129016067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5471, -2.8707, -2.0489,  5.9963, -2.0602, -1.4937, -2.2731, 11.0244,\n",
      "         -2.1336, -2.3341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 11.02442466176825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7472,  -1.3566,  -1.1001, -12.2818,  -0.9319,  -0.8057,  -1.4757,\n",
      "          21.8621,  -1.2462,  -1.5274]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 21.86209092074477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1459, -1.4827, -0.8853,  0.8022, -1.2820, -1.0338, -1.3792,  9.3797,\n",
      "         -1.0112, -1.3155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 9.379674289772133\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7205,  -1.0213,  -0.7213, -10.8312,  -0.8265,  -0.8742,  -1.0102,\n",
      "          17.4828,  -0.8965,  -1.0001]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 17.482828025500815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2435, -1.6319, -1.3459, -2.2447, -1.4381, -1.2536, -1.3763, 13.4537,\n",
      "         -1.6229, -1.8540]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 13.453738143564111\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0186, -2.5034, -1.9864, -7.4119, -2.2873, -1.7902, -2.3080, 26.0314,\n",
      "         -2.3778, -2.8683]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 26.031398602250547\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9990, -1.6498, -1.3493,  3.0018, -1.5074, -1.0428, -1.5062,  8.8118,\n",
      "         -1.4536, -1.9500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 8.811846802061122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8281, -2.3794, -1.9340, -3.2346, -2.2131, -1.6878, -2.0852, 20.5520,\n",
      "         -2.1047, -2.7032]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 20.55202829438346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3221, -2.0393, -1.8108, -0.2318, -1.9982, -1.4121, -1.9774, 15.0182,\n",
      "         -1.8039, -2.3169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 15.01823778194833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0340,  -1.5616,  -1.1179, -10.2979,  -1.0085,  -0.9712,  -1.5279,\n",
      "          20.9378,  -1.4876,  -1.7988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 20.93776448114228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8644, -1.4194, -0.9106, -6.8619, -1.1510, -0.9820, -1.1641, 15.5741,\n",
      "         -1.0601, -0.9537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.57406429343824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7368, -2.1334, -1.8596, -9.5160, -1.8736, -1.6291, -2.0991, 25.3831,\n",
      "         -2.1989, -2.3912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 25.38311895501404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5526, -1.8516, -1.6474, -6.0875, -1.6674, -1.4377, -1.9339, 19.8229,\n",
      "         -1.7088, -2.2569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 19.822926885242055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7411, -2.6848, -2.3091, -4.3437, -2.1722, -1.6647, -2.3802, 22.4586,\n",
      "         -2.6274, -2.6986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.458573863965384\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6699, -2.3459, -1.7805, -5.1831, -2.0306, -1.6629, -1.7491, 21.9809,\n",
      "         -1.8021, -2.0834]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 21.980904742395794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0410, -2.9338, -2.2692,  0.6252, -2.5294, -2.1378, -2.4485, 19.3011,\n",
      "         -2.4670, -2.9240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 19.301075022172782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5647, -1.9863, -1.6530,  4.6548, -1.9105, -1.5034, -1.8384, 10.0534,\n",
      "         -1.8418, -2.4061]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 10.053419553829471\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0479, -4.6789, -4.2429, -2.6963, -4.4504, -3.0775, -4.3899, 37.9647,\n",
      "         -4.4282, -5.3424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 37.96465182610857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9489, -2.9055, -2.3357, -5.5427, -2.4721, -1.6643, -2.6054, 25.4444,\n",
      "         -2.5951, -2.8157]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 25.444382115204192\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9551, -2.4821, -1.9957, -8.9096, -2.1260, -1.7030, -2.5982, 26.3275,\n",
      "         -2.2081, -2.6330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 26.327528050522094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9542, -1.4902, -1.3287,  3.6050, -1.6446, -1.1375, -1.4432,  8.2155,\n",
      "         -1.4709, -1.9124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 8.215475475290585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0657, -4.2581, -3.6621, -2.4965, -3.7850, -2.8500, -4.0720, 33.2974,\n",
      "         -4.0034, -4.5137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 33.29736265022449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1931, -2.0431, -1.9682,  1.2997, -2.0006, -1.4523, -2.0640, 15.4146,\n",
      "         -1.7775, -2.3322]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 15.41456173486662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.8617, -5.5611, -4.7943,  5.0745, -4.8520, -3.7447, -5.2156, 33.9343,\n",
      "         -5.0738, -5.9890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 33.93430257310413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0098, -1.6652, -1.0898, -5.5691, -1.4493, -0.8960, -1.4717, 15.9852,\n",
      "         -1.2135, -1.4919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 15.98520557984487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9702, -2.9040, -2.3342, -4.2227, -2.5469, -1.9745, -2.4037, 24.8932,\n",
      "         -2.4294, -2.9747]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 24.893218705505163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7440, -2.3251, -1.8870, -4.8042, -1.9059, -1.8236, -2.2867, 21.0884,\n",
      "         -2.2657, -2.2161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 21.088379699905683\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5303, -2.6236, -2.2804, -4.3758, -2.2162, -1.7489, -2.3333, 24.2082,\n",
      "         -2.3487, -2.7167]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 24.20821882837811\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5926, -1.1337, -0.8633, -5.3815, -0.7854, -0.7791, -0.8713, 12.1346,\n",
      "         -0.8143, -0.8694]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 12.134628563820298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0697,  -3.1370,  -2.5827, -10.3317,  -2.6272,  -2.2607,  -2.7754,\n",
      "          31.9536,  -2.6134,  -3.2227]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 31.953617186861685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7783, -2.2231, -2.0461, -0.6865, -1.8457, -1.5560, -2.1342, 16.3602,\n",
      "         -2.1002, -2.5143]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 16.360155121504526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.5633, -5.2825, -4.4498, -5.7470, -4.6824, -3.6227, -4.4210, 42.1235,\n",
      "         -4.6742, -5.6484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 42.12347784974087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2203, -1.5615, -1.0699, -6.4453, -1.4214, -1.2662, -1.4232, 17.5502,\n",
      "         -1.2125, -1.3297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 17.55022610091921\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7911, -4.1463, -3.8847, -5.6814, -3.9221, -2.6841, -3.9713, 37.2106,\n",
      "         -3.9424, -4.9130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 37.210641854200425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7138, -0.9082, -0.5710, -2.8857, -0.7280, -0.6784, -0.9676, 10.3382,\n",
      "         -0.7311, -0.8104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 10.338237208075778\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9373, -2.3669, -1.9489, -8.6856, -1.9756, -1.6161, -2.4705, 25.4367,\n",
      "         -2.2518, -2.6112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 25.436744156303014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2479, -1.5411, -1.1239, -2.2167, -1.2874, -1.1675, -1.3788, 13.3180,\n",
      "         -1.3452, -1.4482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 13.318014421663388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9684, -4.5138, -3.8229, -1.4885, -3.8564, -3.0602, -4.3871, 33.6645,\n",
      "         -4.0450, -4.6287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 33.66445803329341\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3474, -1.6879, -1.3839, -5.3032, -1.2467, -1.2332, -1.6725, 17.0098,\n",
      "         -1.5545, -1.8630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 17.009817162785897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4387, -5.0391, -4.2872, -7.0963, -4.4213, -3.3345, -4.6642, 42.1572,\n",
      "         -4.5013, -5.5029]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 42.15719164694364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8147, -1.6181, -1.4767, -2.3740, -1.4188, -0.9746, -1.6340, 15.1218,\n",
      "         -1.5215, -1.7940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 15.121781867208199\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6232, -3.5985, -2.8950, -7.5593, -3.1733, -2.3868, -3.2253, 32.7399,\n",
      "         -3.0588, -3.7250]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 32.73985998765452\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6035, -2.3956, -1.9985, -0.8859, -2.0749, -1.4332, -2.0891, 18.1852,\n",
      "         -2.0684, -2.6658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 18.185207446005705\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9450,  -2.8877,  -2.3676, -21.4774,  -2.4859,  -2.1549,  -2.4640,\n",
      "          41.7110,  -2.5696,  -3.0868]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 41.71104746878718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3527, -3.9378, -3.1003,  8.7894, -3.3977, -2.5829, -3.4650, 17.9508,\n",
      "         -2.9793, -4.1883]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 17.950847552978935\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.9266, -5.4812, -4.5461, -9.1105, -5.0606, -3.5573, -4.8738, 47.7579,\n",
      "         -4.9934, -5.9956]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 47.757916479022676\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6921, -2.4939, -2.1279, -7.3381, -2.3663, -1.7711, -2.1093, 25.1932,\n",
      "         -2.2036, -2.6640]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 25.193238725786053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0093, -4.6201, -3.9987, -3.7593, -3.9699, -3.0329, -4.2052, 37.1424,\n",
      "         -3.8976, -5.2570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 37.14237563284528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3984, -2.4342, -1.9115,  3.3378, -2.2720, -1.5293, -2.3394, 13.1907,\n",
      "         -1.8314, -2.6406]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 13.19071651444223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9173,  -2.5872,  -2.1128, -10.7336,  -2.0925,  -1.8202,  -2.5639,\n",
      "          27.8876,  -2.3058,  -2.5616]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 27.887558427380682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2843, -1.7057, -1.4860, -4.2698, -1.5343, -1.3052, -1.6073, 17.1526,\n",
      "         -1.4450, -1.6557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 17.15256933984731\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2990, -2.7630, -2.6572,  1.9679, -2.6674, -1.9696, -3.0001, 20.2758,\n",
      "         -2.7690, -3.1360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 20.27577019962427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6998, -4.1590, -3.4327, -2.3810, -3.1826, -2.8760, -3.4918, 29.0063,\n",
      "         -3.3340, -3.9265]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 29.006315792430875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2377, -3.0390, -2.4756, -7.2584, -2.4974, -2.0888, -2.7065, 29.3678,\n",
      "         -2.4495, -3.4847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 29.36782817914657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1002, -1.8768, -1.3571, -4.3242, -1.7935, -1.3425, -1.4371, 16.8652,\n",
      "         -1.5156, -1.8885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.86523892367027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2339,  -3.4668,  -2.9779, -14.5703,  -2.9812,  -2.5777,  -3.1084,\n",
      "          39.1419,  -3.0192,  -3.8359]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 39.14188752764414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1090, -2.9345, -2.5550,  7.2979, -2.6432, -2.0078, -2.7344, 13.7087,\n",
      "         -2.4402, -3.3135]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 13.708682750520879\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8326,  -3.8117,  -3.3984, -13.8471,  -3.5126,  -2.3941,  -3.5994,\n",
      "          42.0708,  -3.6468,  -4.2015]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 42.070808917329074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0990, -1.7264, -1.4542, -6.8356, -1.5120, -1.2094, -1.7880, 19.5520,\n",
      "         -1.4530, -1.5804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 19.55200145490442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7077,  -3.7492,  -2.9942, -11.2013,  -3.0803,  -2.6818,  -3.3558,\n",
      "          37.7882,  -3.1468,  -4.0037]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 37.78820624812436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1288, -2.1130, -1.5971,  4.8097, -1.5757, -1.4291, -2.1624,  9.9272,\n",
      "         -1.7074, -2.1687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 9.927223793020303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7588,  -4.1075,  -3.2331, -13.3940,  -3.7447,  -2.5641,  -3.3587,\n",
      "          41.3375,  -3.3707,  -4.2750]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 41.337501772958234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6210, -1.0867, -0.9228, -5.4117, -0.7660, -0.7742, -1.1448, 13.7995,\n",
      "         -0.8931, -1.1089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.799459460810244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2475, -3.3268, -2.5291, -6.6473, -3.0246, -2.4469, -2.7958, 29.3903,\n",
      "         -2.8821, -3.4987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 29.39025519637031\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7206, -3.6860, -3.1061,  8.9776, -3.5132, -2.7028, -3.4875, 17.3045,\n",
      "         -3.1879, -4.1148]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 17.30452415910291\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1351,  -2.9110,  -2.3801, -11.7817,  -2.5952,  -2.0092,  -2.9251,\n",
      "          33.0245,  -2.4721,  -3.1809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 33.02451225521393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4390, -2.0139, -1.7233,  2.2945, -1.9327, -1.2407, -1.9425, 13.3645,\n",
      "         -1.8268, -2.2612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 13.364508352216456\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1077, -3.1979, -2.5119, -9.2363, -2.6588, -2.4424, -2.8158, 30.6934,\n",
      "         -2.7885, -3.2895]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 30.69339877076743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7465, -2.0717, -1.8279, -3.2049, -1.6987, -1.5258, -2.0545, 18.1876,\n",
      "         -2.0538, -2.4280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 18.187601722321144\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3684, -3.4034, -2.7931, -8.0148, -3.0043, -2.3577, -2.9978, 31.6550,\n",
      "         -2.9467, -3.5028]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 31.655031740683256\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0146, -1.6666, -1.2754, -4.1085, -1.4469, -1.1183, -1.5068, 15.4605,\n",
      "         -1.3871, -1.4441]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.46053356295873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.9651, -5.5384, -4.8241, -1.0848, -4.9930, -3.7945, -5.1148, 40.6504,\n",
      "         -5.1217, -5.9650]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 40.650424107600415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9121, -2.3996, -1.9288,  0.3501, -2.2853, -1.6732, -2.4308, 18.0079,\n",
      "         -2.1756, -2.7641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 18.007947006668093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6683,  -3.6693,  -2.8945, -10.3282,  -3.3291,  -2.5752,  -3.2757,\n",
      "          35.7711,  -3.3008,  -4.1026]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 35.771132102437434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1774, -3.2965, -2.7102,  6.4336, -2.9384, -2.1100, -3.2820, 17.0220,\n",
      "         -2.7418, -3.7023]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 17.021990029197823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4163, -5.0720, -4.0929,  0.0574, -4.5143, -3.2730, -4.3881, 34.3668,\n",
      "         -4.2984, -5.4756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 34.366814519952726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2253, -1.5815, -1.4680, -0.8496, -1.2024, -1.1269, -1.5678, 12.3316,\n",
      "         -1.5595, -1.8424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 12.331574670923853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6413, -2.5851, -1.9326, -9.5176, -2.4971, -1.8734, -2.0438, 28.1589,\n",
      "         -2.1404, -2.7949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 28.15888523110958\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4869, -1.7198, -1.4709, -1.8819, -1.6055, -1.3245, -1.6904, 14.7428,\n",
      "         -1.4669, -1.7659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 14.742844689423098\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.2262, -4.7794, -4.1211, -2.0073, -4.0457, -3.0341, -4.4058, 36.0857,\n",
      "         -4.3274, -4.9489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 36.085709386198346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8959, -1.0801, -1.0064, -1.7849, -0.9069, -0.8429, -1.0913, 10.0598,\n",
      "         -1.1484, -1.3354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 10.0597762346218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4734, -3.3171, -2.6307, -4.5591, -2.9296, -2.3144, -3.2169, 27.6075,\n",
      "         -2.8637, -3.6987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 27.60752353466809\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2574, -3.1966, -2.2463, -2.8858, -2.5104, -2.0604, -2.7241, 23.7051,\n",
      "         -2.5529, -3.1313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 23.705054275396712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9749, -4.1390, -3.6493, -4.9712, -3.6546, -2.8169, -3.5911, 34.9422,\n",
      "         -3.8342, -4.7891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 34.94223146212196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6848, -2.3783, -1.8350, -4.7266, -1.8126, -1.4571, -2.3074, 19.7629,\n",
      "         -1.9590, -2.1767]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 19.76294490902307\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4396, -5.0545, -4.1082, -7.5606, -4.4360, -3.3590, -4.4347, 42.4942,\n",
      "         -4.4716, -5.6202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 42.494166477074295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1645, -1.9374, -1.7379, -5.9251, -1.5800, -1.2426, -1.5267, 20.0040,\n",
      "         -1.7349, -1.9608]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 20.004031291051113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3292, -3.1981, -2.8719,  0.7020, -2.6458, -2.3442, -2.9494, 22.2870,\n",
      "         -3.0455, -3.1059]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 22.286993957359527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0677, -2.7457, -2.1986, -2.9355, -2.5145, -1.9810, -2.3931, 22.3263,\n",
      "         -2.4764, -3.1453]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 22.326276405417254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4828, -3.4404, -2.6134, -7.2948, -3.1603, -2.5652, -3.1580, 30.8584,\n",
      "         -3.0905, -3.5540]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 30.858368055800618\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6962, -2.0564, -1.8812,  0.1795, -1.7509, -1.5005, -2.0316, 15.0288,\n",
      "         -2.0896, -2.4299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 15.028830294102736\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6897, -3.5501, -2.5000, -4.5982, -3.4719, -2.4634, -3.1284, 29.8188,\n",
      "         -3.0137, -3.7172]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 29.81876552148084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8105, -2.7749, -2.2237, -1.3284, -2.4092, -1.7630, -2.9192, 20.9760,\n",
      "         -2.2922, -2.9631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 20.976039199927143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4664, -3.3551, -2.9604, -2.5613, -2.8446, -2.2823, -3.3397, 26.8635,\n",
      "         -3.2357, -3.3087]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 26.863539296087172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9670, -1.6071, -1.0725, -3.5430, -1.6382, -1.0780, -1.4261, 14.1020,\n",
      "         -1.4848, -1.6218]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 14.102044474355411\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5495, -2.3155, -2.1773,  1.0014, -2.0670, -1.4403, -2.1995, 18.2181,\n",
      "         -2.0905, -2.9707]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 18.21809913762071\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5342, -2.3328, -1.6638,  1.2307, -2.2268, -1.7349, -1.9267, 15.1678,\n",
      "         -1.9640, -2.2739]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 15.16781898731017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7409, -3.7215, -3.0514, -8.0463, -3.3401, -2.5183, -3.7304, 34.4989,\n",
      "         -3.4365, -4.0295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 34.49891974663077\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9233, -1.0960, -1.0175, -2.2820, -1.2263, -0.9948, -1.3326, 12.4306,\n",
      "         -1.0669, -1.4817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  3\n",
      "activation[7] = 12.430578528262863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3775, -3.2377, -2.3307, -4.2282, -3.0367, -2.3519, -2.8823, 26.9590,\n",
      "         -2.6504, -3.1832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 26.958956701745365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5902, -3.6640, -3.3894,  0.1591, -3.2628, -2.4755, -3.4251, 27.2155,\n",
      "         -3.5231, -4.1446]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 27.21553338427777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1581, -4.2399, -3.8775, -1.3256, -3.9539, -2.7261, -3.9816, 32.7351,\n",
      "         -3.9223, -5.1460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 32.73509395993743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3130, -2.1270, -1.6641, -3.2555, -2.0066, -1.4703, -2.1035, 19.1211,\n",
      "         -1.8841, -2.2134]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 19.121120255843433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7058, -3.7439, -3.3679, -6.0773, -3.4444, -2.4515, -3.3884, 33.7099,\n",
      "         -3.4573, -4.5663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 33.709868412228936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1438, -3.2405, -2.5778, -3.3911, -2.6059, -2.0205, -2.7953, 25.9477,\n",
      "         -2.8412, -3.2380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 25.947732985513827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.9294, -5.9537, -4.8785, -3.3159, -5.0562, -3.7304, -4.9814, 43.7863,\n",
      "         -5.1975, -6.3326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 43.78629035736399\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4297, -3.6533, -3.1378, -0.1043, -3.5133, -2.2310, -3.3898, 27.5647,\n",
      "         -3.3925, -4.3589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 27.56470915529296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0695, -4.3346, -3.5980, -7.4353, -3.8789, -2.8376, -4.2518, 40.0305,\n",
      "         -3.7830, -4.7060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 40.03048555097735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2885, -2.0925, -1.7563, -1.4108, -1.5642, -1.4306, -1.9450, 15.3293,\n",
      "         -1.7679, -2.2228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 15.329254373678387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.3542, -4.7018, -3.9036, -7.5014, -4.3071, -3.2348, -4.4620, 41.6349,\n",
      "         -4.0573, -5.1282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 41.634897497907545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2047, -1.8409, -1.4784,  0.5556, -1.6737, -1.3664, -1.3897, 12.1545,\n",
      "         -1.3516, -1.9403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 12.154457863163474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0954, -4.2607, -3.3334, -4.9016, -3.9775, -2.8468, -3.9113, 35.2052,\n",
      "         -3.6738, -4.5950]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 35.20523987731066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1827,  -2.7035,  -2.3122, -10.7462,  -2.6721,  -1.9766,  -2.3968,\n",
      "          30.8905,  -2.5169,  -3.2532]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 30.890545210733773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0741, -4.2139, -3.2522, -6.4307, -3.9384, -2.9144, -3.5476, 35.8369,\n",
      "         -3.5678, -4.4085]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 35.83687604660812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2303, -1.9178, -1.5761, -5.2911, -1.7774, -1.1120, -1.5715, 20.2258,\n",
      "         -1.4832, -2.1162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 20.225801223207355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4896, -3.2891, -2.6422, -9.8627, -2.8532, -2.1716, -3.3353, 32.7668,\n",
      "         -3.0453, -3.5133]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 32.76680438866463\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5364, -2.4407, -1.9465,  6.9763, -2.3078, -1.5000, -2.2407, 10.8342,\n",
      "         -2.0987, -2.5717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 10.834182095087824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6731, -4.0879, -3.4063, -7.7326, -3.7881, -2.6729, -3.3226, 35.2028,\n",
      "         -3.3493, -4.3078]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  8\n",
      "activation[7] = 35.202805599485266\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [5]: loss = 20.605, accuracy = 10.94\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086, -0.0855, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "         0.4571, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086, -0.0855, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "         0.4571, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.3866, -2.1207, -1.6995, -3.9771, -1.8143, -1.2651, -1.7791, -5.3459,\n",
      "         21.8232, -2.2028]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.823174845064216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5700,  -3.7514,  -2.8057,  -4.5284,  -3.2060,  -2.9442,  -3.3548,\n",
      "         -11.3727,  38.0124,  -4.0177]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 38.0124425110831\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8814,  -2.8107,  -2.4632,  -0.4692,  -2.5234,  -1.9376,  -2.5776,\n",
      "         -12.9142,  31.5710,  -3.2624]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 31.571006662667568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5912,  -2.1567,  -2.0016, -13.5492,  -1.8240,  -1.4420,  -1.8810,\n",
      "           2.0740,  25.4368,  -2.4580]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 25.436791381398123\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1975, -1.5345, -1.1685, -4.7939, -1.1629, -1.0539, -1.3205, -0.2276,\n",
      "         14.1126, -1.7069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.112578136708116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2500, -2.7269, -2.5949, -9.8381, -2.4242, -1.8783, -2.4328,  1.5829,\n",
      "         26.1588, -3.1295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.15881182321067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6945, -2.1343, -1.6130, -3.0889, -1.8638, -1.5023, -1.7428, -7.1515,\n",
      "         22.8731, -2.1870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.87312300472246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9847, -3.9807, -3.1847, -7.0409, -3.6122, -2.6691, -3.9321, -3.7069,\n",
      "         35.1079, -4.2774]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 35.10794431449895\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0506,  -1.5963,  -1.6094,  -0.4381,  -1.4433,  -1.3105,  -1.2900,\n",
      "         -14.6421,  25.2491,  -2.0513]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 25.249075769519102\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.9140e+00, -5.6484e+00, -4.8834e+00, -3.8712e-02, -5.2087e+00,\n",
      "         -3.6174e+00, -5.3177e+00, -1.8512e+01,  5.3639e+01, -6.2033e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 53.63913920700958\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8605,  -3.0513,  -2.3623,  -1.8301,  -2.7934,  -2.0609,  -2.9211,\n",
      "         -17.2522,  38.6454,  -3.2718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 38.64536014161318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8344,  -3.9713,  -3.0704,  -8.3822,  -3.5521,  -2.8579,  -3.2943,\n",
      "         -19.1255,  51.5053,  -4.1694]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 51.505299185300174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1649, -2.9718, -2.4605, -8.3399, -2.7372, -1.9756, -2.7187, -5.0718,\n",
      "         31.4993, -3.3483]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 31.49934210745838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6112, -3.3393, -2.7961, -4.3359, -3.0599, -2.3309, -3.3702, -4.6889,\n",
      "         30.2929, -3.8220]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 30.292862215760778\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6527,  -2.2886,  -2.0664,  -6.2283,  -2.1525,  -1.4616,  -2.0803,\n",
      "         -11.1222,  30.8577,  -2.2922]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.857664109776266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.8623,  -5.6469,  -4.6999,  12.2194,  -4.8032,  -3.7819,  -5.4236,\n",
      "         -11.3983,  34.1260,  -6.0703]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 34.126019219426475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7125,  -4.0987,  -3.1343,   0.1271,  -3.5594,  -2.4797,  -3.4179,\n",
      "         -26.3113,  49.9464,  -4.3317]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 49.94639805558735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7164,  -2.5415,  -2.4781,  -3.5705,  -2.3440,  -1.8431,  -2.6071,\n",
      "         -20.6707,  42.7878,  -3.0415]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 42.787831580951675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2879,  -3.4030,  -2.6550,   3.3306,  -2.8636,  -2.1905,  -2.8838,\n",
      "         -22.2828,  39.1128,  -3.7793]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 39.11280287340303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4649,  -2.2097,  -1.8919, -10.8283,  -1.7988,  -1.2619,  -2.2064,\n",
      "          -6.7107,  30.8899,  -1.9703]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 30.889936353235893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9933, -3.0054, -2.2238, -5.1535, -2.4818, -2.3102, -2.6594, -6.9687,\n",
      "         29.6747, -3.1112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 29.674710509788476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0072,  -4.7826,  -3.8603,  -6.8671,  -4.1735,  -3.3204,  -4.3144,\n",
      "         -18.9258,  54.6360,  -4.8688]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 54.63601440413411\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9814,  -1.5207,  -1.3034, -15.1923,  -1.1903,  -0.9653,  -1.4623,\n",
      "          -1.5542,  25.7600,  -1.3486]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 25.759981009370296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5826,  -2.2111,  -2.2323,  -1.8475,  -2.2637,  -1.5677,  -2.4578,\n",
      "         -16.7396,  35.8844,  -2.7310]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 35.88444350607042\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4177, -3.7118, -3.1828, -0.5065, -3.3131, -2.2554, -3.4977, -6.6103,\n",
      "         31.2045, -3.9621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 31.20447026020629\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1433,  -2.9910,  -2.4529, -10.0225,  -2.7457,  -2.0662,  -2.6323,\n",
      "         -16.4868,  44.9542,  -3.1061]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 44.95420652158263\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9317,  -1.5292,  -1.1031,  -3.4361,  -1.4929,  -1.1412,  -1.0273,\n",
      "         -12.3136,  25.6451,  -1.6952]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 25.64505520767223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4688, -3.1935, -2.6860, -9.3518, -2.9821, -2.3049, -3.0475, -9.6707,\n",
      "         39.3896, -3.5996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 39.38958068886366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5757,  -1.0727,  -0.7898,  -5.2298,  -0.8325,  -0.7869,  -1.1344,\n",
      "         -11.0618,  23.1910,  -0.7518]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 23.190980891284042\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3364,  -2.8498,  -2.7240,  -8.7616,  -2.5959,  -1.9159,  -3.1303,\n",
      "         -12.3389,  41.2261,  -3.3722]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 41.22612399563408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0696,  -3.1601,  -2.6321,   1.6049,  -2.6888,  -1.8901,  -2.4069,\n",
      "         -11.3825,  27.8538,  -3.3036]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.85379175777675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9708,  -2.6652,  -2.2864, -10.5664,  -2.2222,  -1.7336,  -2.4755,\n",
      "          -0.4256,  27.9927,  -2.7295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.992711648078753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9774, -3.0685, -2.4239,  5.6015, -2.6361, -1.8754, -3.2153, -6.3657,\n",
      "         19.8427, -3.1982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.84274223828737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4033, -3.2993, -2.9267, -6.7910, -2.9697, -2.1539, -2.8039, -4.4925,\n",
      "         32.4320, -3.9537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 32.431958740828485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9473,  -1.4646,  -1.0988, -10.2017,  -1.4852,  -0.8701,  -1.4976,\n",
      "          -6.0563,  26.0829,  -1.4772]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.082861826274623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.2085,  -5.9519,  -4.9436,   3.2279,  -5.4576,  -4.1104,  -5.3622,\n",
      "         -18.3347,  51.6877,  -6.3833]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 51.6877083091981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8032, -2.3071, -1.6898, -7.8692, -1.8826, -1.5449, -1.8929,  0.0516,\n",
      "         21.2264, -2.3469]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.226416013647068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5927,  -5.2518,  -4.4149,   1.6068,  -4.6231,  -3.6373,  -4.6220,\n",
      "         -18.5802,  48.5738,  -5.4794]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 48.57382955319953\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3593,  -2.2146,  -1.8547,  -0.8853,  -1.7237,  -1.2082,  -2.0141,\n",
      "         -14.7615,  29.5839,  -2.2280]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 29.583916840451913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9332,  -4.4314,  -3.7933,  -1.0619,  -4.0957,  -2.8635,  -3.7051,\n",
      "         -31.6672,  60.1984,  -4.7828]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 60.198371848127564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2761,  -3.0886,  -2.3378,   7.0745,  -2.7393,  -2.1926,  -2.8096,\n",
      "         -20.0532,  31.3650,  -3.2407]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 31.36500951910493\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4806, -1.9418, -1.5462, -8.6655, -1.5949, -1.4888, -2.1689,  0.6269,\n",
      "         19.6903, -2.0511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 19.690291140621635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5073, -2.1343, -1.6450, -8.2191, -1.9383, -1.4549, -1.8811, -4.8034,\n",
      "         25.8423, -2.1035]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 25.84230387473734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5430,  -2.2552,  -1.9559,  -6.3555,  -1.9383,  -1.4163,  -2.2109,\n",
      "         -13.5959,  35.6284,  -2.2766]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 35.628384766929656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7542,  -4.1829,  -3.6203,  14.6454,  -3.4786,  -2.7378,  -3.8504,\n",
      "         -17.6137,  29.4022,  -4.4498]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 29.40216681206268\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1165, -2.6256, -2.4766, -9.5968, -2.4115, -1.8149, -2.5676,  3.6921,\n",
      "         23.6294, -3.0444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 23.6294194455454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6158, -2.1916, -1.8533, -5.5767, -1.8718, -1.6282, -1.8916, -0.3331,\n",
      "         19.0049, -2.2922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.00493901413251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8292,  -2.4211,  -2.4597,  -8.1530,  -2.2143,  -1.7255,  -2.7072,\n",
      "         -14.6623,  41.1830,  -2.6999]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 41.18300341111594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9209,  -1.6285,  -1.4920,  -5.6782,  -1.4439,  -0.8261,  -1.3420,\n",
      "         -11.5404,  26.8557,  -1.9510]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.8557370294589\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1721,  -4.6401,  -3.7722, -13.5167,  -4.0337,  -2.9949,  -4.1877,\n",
      "          -7.7254,  49.1334,  -5.1362]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 49.13340918320937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2860, -2.1598, -1.3924,  2.9509, -1.9646, -1.2389, -1.8457, -4.7418,\n",
      "         14.6211, -2.1989]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.621091107577977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1919,  -2.8631,  -2.2805, -10.4779,  -2.3992,  -1.8599,  -2.9683,\n",
      "          -0.1787,  27.5916,  -2.9849]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 27.59160446056105\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2025,  -1.7528,  -1.3555, -12.9396,  -1.5319,  -1.4129,  -1.5672,\n",
      "          -0.0697,  24.0650,  -1.9357]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 24.06499899758889\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0807,  -4.2240,  -3.2842,  -4.2630,  -3.6430,  -3.0618,  -3.6170,\n",
      "         -19.1327,  48.9631,  -4.4446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 48.963113884652515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0995, -3.0124, -2.2738, -1.3783, -2.5350, -2.2794, -2.8160, -7.9738,\n",
      "         27.2794, -3.0921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 27.279433362550687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1286,  -3.1732,  -2.4822, -13.9585,  -2.9274,  -2.3278,  -2.9417,\n",
      "          -5.3941,  38.8953,  -3.5380]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 38.89529696578343\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3167, -1.6802, -1.6489,  2.9937, -1.5875, -1.3506, -1.6912, -9.3299,\n",
      "         17.6375, -1.9454]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.637462997166928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1501,  -2.8410,  -2.6154,  -5.5599,  -2.6508,  -1.8698,  -2.9050,\n",
      "         -13.8524,  39.1257,  -3.4158]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 39.1256806712405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8388, -2.2412, -1.5995, -8.2290, -2.0063, -1.8466, -2.2147, -4.5496,\n",
      "         26.5555, -2.2471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.55552705904727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3612,  -4.8449,  -3.9881, -11.4662,  -4.4616,  -3.0395,  -4.3528,\n",
      "         -10.2553,  51.0076,  -5.2612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 51.00758829756805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5723,  -2.5253,  -2.2416,   8.8263,  -2.2635,  -1.6039,  -2.0151,\n",
      "         -23.6928,  30.0082,  -2.8494]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 30.00819855445264\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.7772, -3.7685, -3.3103, -9.4939, -3.3061, -2.5149, -3.6657,  2.6319,\n",
      "         29.9503, -4.0992]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 29.950331329176322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5809, -1.8814, -1.6210, -4.7593, -1.5898, -1.4821, -1.7174, -3.7946,\n",
      "         20.1770, -2.0717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.1770432639861\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0588,  -3.1019,  -2.5392, -10.1518,  -2.6828,  -2.1176,  -2.6706,\n",
      "          -7.2152,  36.6543,  -3.2908]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 36.654290929450646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7702,  -2.3379,  -1.9622,  -1.1675,  -2.1642,  -1.8310,  -2.1429,\n",
      "         -16.1432,  32.0787,  -2.4625]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 32.07867127810701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3606,  -3.2416,  -2.4808,  -4.9561,  -2.9298,  -2.1639,  -2.8198,\n",
      "         -14.1121,  39.1370,  -3.3226]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 39.13696988915928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3591,  -1.6982,  -2.0059,  -4.8230,  -1.7300,  -1.1630,  -1.8480,\n",
      "         -13.2002,  32.1088,  -2.4264]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 32.108799124219125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9743,  -2.9500,  -2.3325, -13.2061,  -2.4627,  -2.2547,  -2.6324,\n",
      "          -2.5830,  33.2854,  -3.1155]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 33.285444974488556\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9674,  -2.6043,  -2.1915,   5.7848,  -2.5839,  -2.0290,  -2.3855,\n",
      "         -14.0913,  25.1852,  -2.9910]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 25.185241759483677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9227,  -4.2256,  -3.7657,  -4.0188,  -4.0434,  -2.7021,  -4.0345,\n",
      "         -10.2646,  42.0974,  -4.9600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 42.097376454222356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7640,  -2.4239,  -2.0823,   1.4713,  -1.9016,  -1.4350,  -2.3229,\n",
      "         -12.2302,  26.4214,  -2.6745]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 26.421448420738653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.7366, -5.2354, -4.3861,  2.3261, -4.5509, -3.4216, -4.8674, -9.3499,\n",
      "         38.8756, -5.6906]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 38.875582866978455\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8022,  -3.0587,  -2.4554,  -0.7589,  -2.6773,  -1.9370,  -3.0802,\n",
      "         -14.5123,  34.9547,  -3.2160]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 34.9546864078549\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8859,  -2.9051,  -2.2699, -14.1739,  -2.3439,  -2.1202,  -2.4624,\n",
      "          -0.5212,  31.6511,  -3.1155]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 31.65114849213661\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4165, -1.7850, -1.6378,  0.9088, -1.4731, -1.3329, -1.7767, -3.2103,\n",
      "         13.6041, -2.1034]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 13.604057452662266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4549,  -3.1676,  -2.6210,  -7.0908,  -2.9997,  -2.1748,  -2.8972,\n",
      "         -10.6829,  37.8921,  -3.5789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 37.8921376292878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5568,  -2.9755,  -2.3394,  -7.9293,  -2.6374,  -1.8823,  -2.7432,\n",
      "         -12.7390,  38.7241,  -3.0376]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 38.72413541223148\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0138, -4.0843, -3.3692,  0.5837, -3.5147, -2.8128, -3.9788, -8.3052,\n",
      "         32.7046, -4.5800]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 32.704587670952506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4917,  -2.1978,  -1.9521,  -4.7860,  -1.9350,  -1.3874,  -2.1333,\n",
      "         -10.7757,  30.7977,  -2.5121]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 30.7976761051649\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9546,  -4.4217,  -4.0499,  -4.2888,  -4.1764,  -2.7853,  -4.0656,\n",
      "         -11.4307,  44.5626,  -5.1312]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 44.56263544260274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8462,  -1.1164,  -1.2259,  -4.5773,  -1.2999,  -0.8815,  -1.0996,\n",
      "         -16.3738,  29.3452,  -1.4317]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 29.34520827393987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0467, -2.5704, -2.2490, -4.2857, -2.0834, -1.7193, -2.6634, -7.6084,\n",
      "         28.8652, -2.8263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 28.865213568157316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7419,  -2.6482,  -2.2564,  -1.0044,  -2.4548,  -1.9419,  -2.4001,\n",
      "         -17.7621,  34.9055,  -3.0583]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 34.90548895755182\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4587,  -2.1166,  -1.9239,  -4.7470,  -1.8051,  -1.4551,  -1.9388,\n",
      "         -16.8539,  36.7673,  -2.4740]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 36.76726487336333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6451e+00, -4.0760e+00, -3.2057e+00, -1.1948e-02, -3.4240e+00,\n",
      "         -2.8221e+00, -3.7225e+00, -2.6908e+01,  5.1484e+01, -4.0665e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 51.483521149379335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8999,  -3.7969,  -3.1435, -10.2118,  -3.4272,  -2.5339,  -3.7012,\n",
      "           0.6202,  32.1721,  -3.9838]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 32.1721082059715\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0395,  -1.5778,  -1.0295,  -0.8266,  -1.2071,  -1.1282,  -1.0072,\n",
      "         -11.6026,  21.7795,  -1.1348]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.77952825370244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2528,  -4.8125,  -4.1631,  -0.5071,  -4.2779,  -2.9444,  -4.0789,\n",
      "         -20.3272,  51.6826,  -5.2521]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 51.682637540435046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6961,  -2.9387,  -2.4223,  -0.1558,  -2.3661,  -1.7409,  -2.4099,\n",
      "         -15.7059,  33.8745,  -3.0068]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 33.874546919530395\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2535,  -2.8400,  -2.3030, -10.4297,  -2.4736,  -1.8913,  -2.9302,\n",
      "          -0.4970,  28.4311,  -3.1110]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 28.431132791104655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7957,  -2.5606,  -2.1973,  -1.3622,  -2.2301,  -1.7518,  -2.3555,\n",
      "         -19.5769,  36.7197,  -2.6782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 36.71970848753471\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3629,  -4.9893,  -4.4842,  -0.9111,  -4.7842,  -3.1784,  -4.7024,\n",
      "         -20.2066,  53.9450,  -5.7612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 53.94500390058474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9228,  -3.3854,  -2.5523,  -4.7097,  -3.0179,  -2.1332,  -2.7552,\n",
      "         -20.8443,  46.7572,  -3.5999]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 46.75717749811761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4836,  -3.5391,  -2.6191,  -7.1742,  -2.9964,  -2.2787,  -3.1759,\n",
      "         -11.0784,  39.1054,  -3.4968]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 39.1053706117756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9374, -1.4722, -1.2936, -3.5626, -1.2975, -1.0336, -1.5292, -3.6638,\n",
      "         17.5142, -1.7879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.514190430628098\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7277,  -3.7373,  -3.0522, -12.1992,  -3.2674,  -2.5577,  -3.5832,\n",
      "          -1.9819,  36.5220,  -4.0217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 36.522015437708546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2453, -0.4892, -0.3583, -7.2491, -0.3257, -0.2113, -0.4689, -2.0169,\n",
      "         12.9942, -0.5200]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 12.994229045538978\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1156,  -4.3583,  -3.8298,  -6.5292,  -4.1151,  -2.6954,  -4.2503,\n",
      "         -13.0373,  48.0909,  -5.0068]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 48.090852279590806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5504,  -2.5181,  -2.2203,   6.2432,  -1.9409,  -1.8099,  -2.0861,\n",
      "         -19.9582,  29.2666,  -2.7506]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 29.26659466599868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1364,  -2.9696,  -2.4688,  -3.0125,  -2.7439,  -1.9552,  -2.4533,\n",
      "         -13.6293,  35.1591,  -3.1709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 35.15907941569579\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8001,  -1.4219,  -0.9926, -10.0271,  -1.3203,  -0.7088,  -1.4950,\n",
      "          -3.8191,  22.3768,  -1.2876]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 22.376786254535453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9979,  -3.1550,  -2.4882, -15.7344,  -2.4904,  -2.3220,  -2.6999,\n",
      "          -1.4059,  35.2008,  -3.1785]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 35.2008099614331\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6397,  -2.1672,  -1.9781,  -1.1000,  -2.0910,  -1.7152,  -2.1004,\n",
      "         -19.4415,  36.0024,  -2.7160]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 36.00240411747968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7147,  -3.6038,  -2.9512,  -8.6289,  -3.2459,  -2.5130,  -3.2796,\n",
      "         -11.1148,  41.8813,  -3.8645]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 41.881291362875814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1339,  -3.1432,  -2.4834,  -0.4769,  -2.7727,  -2.0967,  -2.6914,\n",
      "         -14.8241,  34.2990,  -3.2645]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 34.29895022135389\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9963,  -2.9007,  -2.6624,  -9.0400,  -2.6567,  -2.1183,  -2.8174,\n",
      "         -15.9326,  43.0352,  -2.9933]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 43.035225492238354\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6388,  -2.5119,  -2.1658,  -0.2966,  -2.3412,  -1.6281,  -1.8271,\n",
      "         -19.1058,  34.5433,  -2.6803]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 34.54329482063735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1985,  -4.4293,  -3.9026,  -9.0601,  -4.0568,  -2.7899,  -4.4204,\n",
      "         -10.5133,  48.4716,  -5.0506]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 48.47156425311996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6374,  -3.8029,  -3.1689,  -2.7866,  -3.5641,  -2.5072,  -3.3027,\n",
      "         -22.8305,  48.8083,  -4.2980]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 48.808302249521375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6907,  -3.5761,  -3.0991,  -4.5707,  -3.2246,  -2.2411,  -3.5814,\n",
      "         -13.2632,  41.1739,  -4.0889]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 41.17394245904204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9098, -1.3488, -0.9224, -5.7468, -0.8640, -1.0779, -1.3414,  0.9147,\n",
      "         12.7314, -1.2100]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 12.73139578389096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5076,  -3.6165,  -3.1506,  -5.7619,  -3.2424,  -2.3477,  -3.3056,\n",
      "         -16.2965,  44.2310,  -3.8298]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 44.23096938698663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0646,  -3.2172,  -2.3997,   0.5763,  -2.9506,  -2.4176,  -2.6716,\n",
      "         -16.0312,  35.0516,  -3.5181]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 35.0516165120698\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2610,  -2.8512,  -2.6181,  -8.3691,  -2.5666,  -1.9358,  -3.0376,\n",
      "         -16.0072,  44.1585,  -3.1706]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 44.15847679259523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6906, -2.1402, -1.9869, -1.6708, -1.6392, -1.6230, -2.1109,  0.5262,\n",
      "         14.2878, -2.4093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 14.287801087043901\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6403,  -3.7184,  -3.1564,  -6.2325,  -3.2955,  -2.6902,  -3.7091,\n",
      "         -15.8871,  45.9244,  -3.8888]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 45.924359148383814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5921, -2.0091, -1.5132, -2.1905, -1.7817, -1.4734, -1.6397, -7.6872,\n",
      "         21.7256, -2.2151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.7256344382957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8323,  -3.9779,  -3.2571,  -2.3622,  -3.5187,  -2.8515,  -3.8874,\n",
      "         -15.4340,  42.4515,  -4.0072]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 42.45149015588218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9604,  -2.7864,  -2.5245,  -1.2009,  -2.6259,  -1.8640,  -2.6637,\n",
      "         -12.9336,  33.2275,  -3.2851]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 33.227457685704934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3016,  -3.2649,  -2.6442,  -6.3529,  -3.0148,  -2.1756,  -2.7722,\n",
      "         -18.7759,  45.1118,  -3.4123]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 45.11181758721002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5455, -3.4282, -2.6214, -6.8525, -2.8012, -2.6026, -3.1580, -7.8120,\n",
      "         35.3226, -3.7320]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 35.32261142926059\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2709,  -3.3599,  -2.6917,  -9.5483,  -2.9355,  -2.2764,  -3.0725,\n",
      "         -19.7764,  50.1470,  -3.4322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 50.146984590549046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3933, -1.5189, -1.2516, -6.0158, -1.4411, -1.2710, -1.5715, -7.5394,\n",
      "         23.5948, -1.6889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 23.594774339663097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3111, -3.1871, -2.8266, -2.8815, -2.7882, -2.1314, -2.8202, -9.5439,\n",
      "         33.9110, -3.7118]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 33.911016979731656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1707,  -3.0415,  -2.8060,  -1.5538,  -2.9590,  -2.0721,  -2.7841,\n",
      "         -18.5181,  41.3102,  -3.7608]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 41.31020366779151\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0028, -2.8217, -2.2435, -9.7788, -2.5016, -1.8469, -2.7896,  0.5741,\n",
      "         25.2599, -2.6847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 25.259883840674185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0064,  -2.9447,  -2.5607,   0.8841,  -2.8993,  -2.1665,  -2.5480,\n",
      "         -21.8141,  39.4399,  -3.4138]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 39.4398526475701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8557,  -2.5991,  -2.6265,  -6.2536,  -2.4120,  -1.9815,  -2.4652,\n",
      "         -14.6653,  38.2027,  -2.8864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 38.202650258518645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0945,  -1.4345,  -0.8831,  -1.9721,  -1.2132,  -0.9201,  -1.0221,\n",
      "         -18.0037,  28.3564,  -1.0913]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 28.35636582373083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0738,  -4.4641,  -3.7549,   9.4708,  -4.0662,  -2.9268,  -4.5083,\n",
      "         -16.8628,  36.4381,  -4.8290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 36.43808659400131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2578, -1.9401, -1.5811, -6.6621, -1.6759, -1.2701, -1.7786, -8.7784,\n",
      "         27.3748, -2.2699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 27.374845291808704\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4879,  -2.1068,  -1.8476, -10.2480,  -1.8385,  -1.2941,  -2.0381,\n",
      "          -0.5513,  24.4215,  -2.1410]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 24.421523999104227\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3687, -2.2869, -1.7570, -2.8655, -2.1118, -1.5114, -1.6779, -5.7291,\n",
      "         21.6375, -2.4257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.637455916393712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7889, -2.3101, -2.4153, -4.6913, -2.2379, -1.7079, -2.0005, -5.4196,\n",
      "         26.1260, -2.9967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.126000584245645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7882,  -2.6810,  -1.9923,  -3.0375,  -2.1732,  -1.8513,  -2.2737,\n",
      "         -10.9700,  30.7486,  -2.4471]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 30.74861586339099\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3870, -1.8422, -1.7468,  1.0817, -1.9386, -1.2689, -1.9283, -9.3417,\n",
      "         22.2706, -2.2420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.27064302133764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.2253,  -0.4622,  -0.4136, -10.9078,  -0.2577,  -0.1038,  -0.5832,\n",
      "           3.4862,  10.6579,  -0.3275]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.65790093184747\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6928,  -2.4520,  -1.8762, -12.6641,  -2.0908,  -1.7840,  -2.0444,\n",
      "          -3.3817,  30.9487,  -2.4837]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 30.948699702328422\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2637,  -1.9371,  -1.5270,  -2.7522,  -1.4222,  -1.0283,  -1.7938,\n",
      "         -11.2795,  26.0869,  -1.8740]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 26.08691579207312\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5162, -3.4848, -3.0533, -3.0875, -2.9939, -2.1634, -3.2223,  0.6713,\n",
      "         22.9465, -3.6697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 22.946535651724552\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8562,  -3.3173,  -2.3141,   3.0472,  -2.8482,  -1.9848,  -2.9702,\n",
      "         -16.4665,  33.4939,  -3.2391]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 33.49386371859285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4379,  -2.0891,  -1.6889, -12.8268,  -1.6571,  -1.4264,  -1.8381,\n",
      "           2.4535,  22.2316,  -2.1111]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.23159834870751\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5184, -2.1613, -1.7330, -6.1981, -1.9379, -1.7215, -1.8473, -3.6495,\n",
      "         22.7975, -2.3922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.797522848633612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9791,  -2.5970,  -2.6495, -15.5298,  -2.3688,  -1.6863,  -2.5189,\n",
      "           2.3292,  30.8888,  -2.9939]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.88878206028252\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8213,  -1.3442,  -0.9316,   1.1946,  -1.2258,  -0.9531,  -0.9252,\n",
      "         -12.9502,  20.5766,  -1.1829]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 20.57661239301028\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0891, -2.9273, -2.3979, -8.9050, -2.3331, -1.8050, -2.7562,  0.3634,\n",
      "         24.5741, -2.8300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 24.574117146810107\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6751, -2.1632, -1.7220, -2.2751, -1.8927, -1.4653, -1.9806, -4.6950,\n",
      "         19.7801, -2.3323]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 19.780096442410425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8429,  -2.4298,  -2.4830,  -9.0509,  -2.1864,  -1.6896,  -2.2839,\n",
      "         -10.4295,  35.5127,  -2.6339]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 35.51271724421915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0704, -1.9039, -1.5922, -2.1284, -1.4289, -1.1764, -1.7686, -8.5277,\n",
      "         21.7701, -1.9396]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 21.77008263291407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2756,  -4.8476,  -3.9260,  10.8464,  -4.1562,  -3.1249,  -4.1352,\n",
      "         -13.5874,  31.2513,  -5.0957]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 31.25129019222253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0216, -2.6147, -2.2179, -2.5047, -2.4814, -1.7693, -2.1029, -8.0216,\n",
      "         27.6426, -3.0871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.642591454384174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4935, -1.7778, -1.4011, -7.8871, -1.6273, -1.2777, -1.8403, -5.4331,\n",
      "         25.3183, -2.1383]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 25.318333333718996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1291,  -4.4006,  -3.4587,  -1.0394,  -3.7643,  -3.0341,  -3.9416,\n",
      "         -10.9028,  39.2123,  -4.8142]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 39.212336446420665\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2500, -1.6852, -1.5565, -7.7112, -1.4440, -0.9969, -1.3995, -0.6949,\n",
      "         18.6686, -1.8315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 18.668569903308907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4521,  -2.2413,  -1.7892,  -3.6505,  -1.8320,  -1.4461,  -1.9635,\n",
      "         -11.6675,  28.1128,  -2.3538]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 28.112768230845308\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2538, -1.8567, -1.6030, -0.5685, -1.7941, -1.2988, -1.7574, -3.0351,\n",
      "         16.1369, -2.1777]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.13686047964875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7436,  -3.7050,  -2.9774,   8.0408,  -3.3698,  -2.7460,  -3.3787,\n",
      "         -17.6894,  32.3903,  -4.0784]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 32.390298033960484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6488,  -2.2048,  -1.7378,  -5.8445,  -2.0820,  -1.6989,  -1.7923,\n",
      "         -13.1957,  33.1763,  -2.5169]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 33.176315211353554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7241, -3.1912, -2.3586, -1.7582, -2.6981, -1.9314, -2.6783, -7.5014,\n",
      "         27.0650, -2.9663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 27.06497337693157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1052, -2.9434, -2.5543, -5.5390, -2.2614, -1.9251, -2.6076, -9.2405,\n",
      "         31.6871, -2.8953]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 31.687066070908713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2502, -0.6027, -0.4373, -6.0953, -0.7323, -0.2931, -0.5300, -1.9066,\n",
      "         12.4021, -0.7326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.40206766164992\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5004,  -2.0444,  -1.6462, -11.9251,  -1.7557,  -1.5056,  -1.9876,\n",
      "           2.2456,  21.8635,  -2.1717]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.86351737173626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2236, -2.9290, -2.5598, -2.3677, -2.7800, -2.0103, -2.8786, -0.2497,\n",
      "         21.6674, -3.3547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 21.667444255854512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6338, -3.6256, -3.2957, -1.9117, -3.2142, -2.3460, -3.4052, -4.5128,\n",
      "         30.8531, -4.2019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.853059970996725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0817,  -1.7831,  -1.3405,  -1.1680,  -1.5929,  -1.0862,  -1.5745,\n",
      "         -12.1839,  24.6613,  -1.6130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 24.661318797884157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7880, -2.3170, -1.8656, -8.2625, -1.9378, -1.7796, -2.3524,  1.0259,\n",
      "         21.2228, -2.4715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 21.222818154845044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5405,  -1.9004,  -1.2815,  -5.3303,  -1.5852,  -1.2946,  -1.7437,\n",
      "         -11.6406,  28.2211,  -1.7431]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 28.221068191675855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6067, -2.2298, -1.9437, -9.0616, -1.9176, -1.3366, -1.7864, -7.3444,\n",
      "         29.3670, -1.9177]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 29.367011003423194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8825,  -0.8545,  -0.4448,  -5.3036,  -0.9250,  -0.6962,  -0.8855,\n",
      "         -14.8410,  27.1254,  -0.6822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 27.12542109097658\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6350, -4.0281, -3.2256,  2.1725, -3.4474, -2.7370, -3.6477, -7.2338,\n",
      "         29.8933, -4.2456]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 29.89334511771067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5666, -2.1368, -1.9702, -3.1265, -1.6800, -1.6290, -2.1640, -0.8404,\n",
      "         17.3658, -2.5309]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 17.365821685011866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2534,  -1.9107,  -1.5417, -16.1605,  -1.8087,  -1.5195,  -1.5474,\n",
      "          -4.0365,  31.5313,  -2.0353]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 31.531267627538035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1775, -1.5242, -1.4484,  1.5510, -1.2769, -1.1062, -1.5581, -4.2772,\n",
      "         12.3619, -1.6898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 12.361873625627068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1242,  -3.2816,  -2.7915, -12.1000,  -2.4870,  -2.1143,  -3.0484,\n",
      "          -5.9135,  37.1835,  -3.5462]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 37.18349933578513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6185,  -1.4911,  -1.2546,  -3.4035,  -1.4270,  -0.9345,  -1.3606,\n",
      "         -15.9435,  29.7538,  -1.5547]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 29.753776726092806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2998,  -2.0650,  -1.7332, -16.4916,  -1.9179,  -1.1528,  -1.7155,\n",
      "           5.0492,  23.3946,  -1.9802]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.394616953561023\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4868,  -2.2794,  -2.0503,  -2.5440,  -2.0519,  -1.6568,  -2.2977,\n",
      "         -16.4640,  35.3407,  -2.5969]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 35.340732787069236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9249, -2.7559, -2.3187, -9.1031, -2.3562, -1.6840, -2.3968, -4.0496,\n",
      "         29.3345, -3.0417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 29.334490581140297\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1592, -1.3920, -1.1535, -6.3651, -0.9207, -0.9783, -1.4495,  1.7250,\n",
      "         13.2064, -1.5791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 13.206440518251359\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3143,  -2.0820,  -1.6198, -18.3531,  -1.9090,  -1.4388,  -1.7745,\n",
      "          -0.8460,  31.3362,  -2.1301]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 31.336218851448532\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7075, -0.8664, -0.6119, -6.2673, -1.1133, -0.6607, -1.1827, -4.5045,\n",
      "         17.6558, -0.8814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.655824015740457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5418, -1.9225, -1.7572, -6.6044, -1.7442, -1.2937, -1.9128, -2.3981,\n",
      "         21.7295, -2.0460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.729537153018065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0521,  -1.2440,  -1.0884,  -8.9733,  -1.1410,  -0.9407,  -1.2643,\n",
      "         -14.8080,  32.6122,  -1.3981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 32.612222527448935\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0777, -1.5153, -1.1587, -5.7686, -1.1094, -1.1196, -1.5562,  2.1868,\n",
      "         11.8647, -1.4619]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 11.86469007422494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0002,  -2.6690,  -2.1524,   1.0640,  -2.4716,  -1.7195,  -2.6434,\n",
      "         -10.4825,  25.8549,  -3.0604]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 25.854895820207112\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7896,  -2.6617,  -2.1781, -13.1449,  -2.3543,  -1.7872,  -2.3397,\n",
      "           0.4331,  27.9861,  -2.7966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 27.98609139491721\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8095,  -2.4085,  -1.8056,  -8.2776,  -2.1055,  -1.8518,  -2.0116,\n",
      "         -19.2237,  42.9520,  -1.8633]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 42.95202616722409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2689, -1.7794, -1.9033, -8.4475, -1.6093, -1.0735, -1.6626,  0.3440,\n",
      "         19.9105, -2.0599]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.910542232189613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6344,  -2.3507,  -1.9544,   1.7000,  -2.2122,  -1.7612,  -2.1556,\n",
      "         -13.8802,  27.6484,  -2.8368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.648416485234286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8679,  -4.2375,  -3.5743,   8.4673,  -3.7402,  -2.7250,  -3.7866,\n",
      "         -11.2157,  28.9740,  -4.4646]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 28.973977539421497\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0086,  -2.6177,  -2.0469,   5.2257,  -2.2576,  -1.8549,  -2.2729,\n",
      "         -14.2151,  23.9261,  -2.5877]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 23.926060621446542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8108,  -4.1747,  -3.6785,   3.2467,  -3.7219,  -2.7345,  -3.6566,\n",
      "         -11.1786,  35.1573,  -4.5754]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 35.15733867885006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9492, -2.6189, -2.3739,  1.5597, -2.2660, -1.8962, -2.5293, -5.9671,\n",
      "         20.9250, -3.0306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 20.925046563517515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1743, -1.8169, -1.5187, -6.6553, -1.6075, -1.0527, -1.7783, -3.2401,\n",
      "         20.8012, -1.7542]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.801225429097528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2362,  -1.8738,  -1.5834,   3.6211,  -1.5947,  -1.3472,  -1.8491,\n",
      "         -11.4728,  19.5863,  -1.9650]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.58630094463832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6081, -2.4343, -2.0010, -9.8989, -1.8988, -1.4410, -2.1752, -6.0505,\n",
      "         30.4088, -2.6823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.408820705055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1014, -2.9907, -2.4311,  6.5787, -2.6176, -2.1258, -2.6724, -5.6403,\n",
      "         17.0272, -3.1679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.02719476568489\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6393,  -2.2877,  -2.0602, -12.7179,  -2.0341,  -1.4296,  -2.3215,\n",
      "          -0.7024,  27.7371,  -2.2283]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 27.737109053921202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4200, -2.1999, -2.0266, -2.3476, -2.0512, -1.5406, -1.9689, -7.0133,\n",
      "         23.2859, -2.3619]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 23.285883378812983\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3550,  -3.5498,  -3.1343,  -4.3196,  -2.9397,  -2.1263,  -3.1428,\n",
      "         -12.7575,  40.2552,  -3.9989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 40.25515747848369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3816,  -3.5469,  -2.7707,  -7.9598,  -3.0180,  -2.6277,  -3.4558,\n",
      "         -10.6445,  41.5903,  -3.7988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 41.590335246410504\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7415,  -1.1345,  -0.7747, -11.9208,  -0.7567,  -0.5252,  -1.1385,\n",
      "           3.2859,  15.3682,  -0.9163]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 15.368241582886794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2999,  -3.2266,  -2.7027,   8.8616,  -2.8771,  -2.2979,  -2.6877,\n",
      "         -20.7796,  32.3939,  -3.8234]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 32.39386649000095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1777, -1.5811, -1.2576, -7.5065, -1.3367, -1.1409, -1.6333,  0.3725,\n",
      "         16.2227, -1.5215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 16.222689202761085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2019,  -3.5159,  -2.8535,   1.8998,  -3.3353,  -2.3490,  -2.9323,\n",
      "         -24.5962,  43.9568,  -3.8171]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 43.95682478319742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7608, -2.1889, -2.1679, -4.8243, -2.1290, -1.6119, -2.0914, -2.3756,\n",
      "         22.5882, -2.8979]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 22.58815629701588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6367, -2.1773, -1.7345,  4.3884, -1.9471, -1.4763, -2.1691, -6.6234,\n",
      "         16.4375, -2.2923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 16.437513105352725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5943, -1.8896, -1.5973, -9.0922, -1.6131, -1.4154, -1.8459, -4.6161,\n",
      "         25.8543, -2.1217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 25.85425684588069\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0519,  -1.8573,  -1.3274,  -4.7929,  -1.2560,  -1.4181,  -1.5588,\n",
      "         -10.1684,  25.9911,  -1.4493]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 25.99108611793471\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2515,  -3.0003,  -2.7460, -10.2321,  -2.6355,  -1.9401,  -2.7964,\n",
      "          -9.5217,  40.4876,  -3.5868]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 40.487625434087406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1020,  -3.3765,  -2.7722,   7.5406,  -2.9213,  -2.0991,  -2.8982,\n",
      "         -26.2201,  39.2718,  -3.7127]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 39.27180577204274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0856,  -1.7502,  -1.2485, -10.0569,  -1.2710,  -1.1909,  -1.4537,\n",
      "           5.0321,  14.3573,  -1.6113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.35731132869079\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5464, -1.9148, -1.7259, -1.5622, -1.6351, -1.3043, -1.9322, -3.6709,\n",
      "         18.1018, -2.0425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 18.101833854018675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1844,  -1.7117,  -1.5521,  -1.4247,  -1.6495,  -1.1345,  -1.7294,\n",
      "         -13.4945,  27.4528,  -2.1623]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 27.4527504692176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2344, -1.5869, -1.1059, -3.2969, -1.2270, -1.2727, -1.1682, -9.6911,\n",
      "         22.5761, -1.1653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.576126032869855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3594,  -4.9552,  -4.2118,  -3.0998,  -4.3263,  -3.1068,  -4.4641,\n",
      "         -16.0753,  50.7910,  -5.1369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 50.79099210489642\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2272, -1.5668, -1.2884, -7.8264, -1.2631, -1.1789, -1.7799,  0.8416,\n",
      "         16.7960, -1.8282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 16.795980808383554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9715,  -2.5938,  -2.0771, -13.2579,  -2.1117,  -1.6557,  -2.5750,\n",
      "           2.4890,  25.6568,  -2.4499]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 25.656812802207135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4469,  -1.8691,  -1.6062,   0.9694,  -1.5785,  -1.4029,  -1.7958,\n",
      "         -10.6431,  21.3952,  -1.7980]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.395204009942553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6380,  -2.3261,  -1.8466, -16.0156,  -1.9683,  -1.6659,  -2.0921,\n",
      "           1.7099,  28.3288,  -2.4723]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 28.328814854627453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2412, -1.7189, -1.4866, -2.1287, -1.6511, -1.1281, -1.4934, -4.5364,\n",
      "         16.7496, -1.9370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.749623258409173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2306,  -3.0672,  -2.7614,  -3.7663,  -2.8350,  -2.0937,  -2.6430,\n",
      "         -12.3032,  36.7647,  -3.6586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 36.764679696343926\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3998,  -2.4824,  -2.1103,   0.0722,  -2.4420,  -1.7229,  -2.1668,\n",
      "         -19.6684,  36.2485,  -2.7275]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 36.24847227541646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7673, -2.2246, -2.2155, -1.4783, -2.2780, -1.5876, -2.3030, -7.9795,\n",
      "         25.2345, -2.7369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 25.23450246759498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2711,  -2.0127,  -1.2941,  -8.7355,  -1.5813,  -1.4261,  -1.6521,\n",
      "         -11.8656,  32.5749,  -1.4445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 32.57494598248807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0519,  -3.4051,  -2.7718,  -7.6968,  -2.5419,  -2.0441,  -2.9658,\n",
      "         -13.8457,  40.9805,  -3.4968]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 40.98045574752741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5156, -2.1583, -1.8043,  3.1650, -1.7945, -1.3567, -2.0746, -9.8508,\n",
      "         20.8342, -2.4893]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 20.834152244686756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5374,  -2.1078,  -1.6730, -12.5840,  -1.7968,  -1.4772,  -2.0166,\n",
      "          -4.8819,  30.2138,  -2.3608]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 30.213778552773494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5262,  -2.1330,  -1.9789,  -4.3364,  -1.8610,  -1.4015,  -1.9763,\n",
      "         -15.5914,  33.9302,  -2.1169]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 33.93022391825569\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8655, -2.2902, -2.2574, -5.2689, -2.3721, -1.6596, -2.1600, -7.9878,\n",
      "         28.9191, -2.8367]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 28.91909624652434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6529, -2.6391, -2.0444, -0.6877, -2.3430, -1.6159, -2.4679, -5.0346,\n",
      "         20.3809, -2.6387]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 20.380948405789766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7380, -1.9905, -1.7930, -7.1956, -1.9309, -1.3921, -2.0637, -5.4702,\n",
      "         26.2746, -2.3016]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 26.27459638217517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4693, -3.2578, -2.7773, -1.8888, -3.0403, -2.1589, -3.1800, -6.3897,\n",
      "         29.6238, -3.8634]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 29.623819638796235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2494,  -1.9016,  -1.4716, -15.5595,  -1.8101,  -1.3496,  -1.6264,\n",
      "          -0.0626,  27.1212,  -1.9461]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 27.12124773242101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5737,  -2.4288,  -1.8370,   5.9609,  -2.0939,  -1.6608,  -2.0239,\n",
      "         -18.5349,  27.0345,  -2.7244]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.034528721197795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3903, -1.8526, -1.7259, -0.4142, -1.9081, -1.2812, -1.8588, -5.4013,\n",
      "         18.7169, -2.2561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.71689446291099\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4974,  -3.7261,  -3.1642,  10.8837,  -3.3424,  -2.4446,  -3.2495,\n",
      "         -20.7959,  32.7726,  -4.2877]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 32.772615769436484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6984,  -3.9634,  -3.6252,  -2.8620,  -3.6803,  -2.5939,  -3.7540,\n",
      "         -13.4252,  42.9611,  -4.7079]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 42.9611368682891\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9739, -1.0512, -0.6821, -8.1347, -0.7907, -0.6775, -1.3461, -1.2952,\n",
      "         16.9144, -1.0526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.914441615860177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1707, -3.3712, -2.5975, -7.1573, -2.4593, -2.0872, -3.2751,  0.9234,\n",
      "         24.9701, -3.3667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 24.97007536217405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0329,  -1.7039,  -1.2039,  -2.2717,  -1.2905,  -1.0612,  -1.5183,\n",
      "         -11.7478,  24.2781,  -1.5011]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.27805805788109\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1989, -1.7747, -1.3048, -6.6546, -1.3188, -1.2413, -1.6854,  1.6803,\n",
      "         14.3538, -1.6272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 14.353846299394796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4250, -0.9632, -0.5660, -9.3886, -0.6285, -0.4939, -0.7148, -0.2238,\n",
      "         14.6059, -0.7455]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.605894791130591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1242,  -1.9084,  -1.5274, -15.5992,  -1.7148,  -1.3873,  -1.6454,\n",
      "           3.6654,  23.0929,  -1.9275]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 23.092906654931973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7039,  -2.6502,  -2.3565,   9.2881,  -2.5694,  -1.6607,  -2.3105,\n",
      "         -22.7669,  29.6733,  -3.1696]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 29.67334991845203\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2756,  -1.8902,  -1.6202, -14.9797,  -1.7007,  -1.4377,  -1.5900,\n",
      "           3.3577,  23.2989,  -2.0779]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 23.298876525787236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5614,  -2.6971,  -2.0444,  -1.7506,  -2.4706,  -1.6610,  -2.4598,\n",
      "         -16.9760,  34.9755,  -2.9655]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 34.97550216786202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5941, -2.2779, -1.9086, -7.8622, -1.9210, -1.4834, -2.0932,  2.7605,\n",
      "         17.6093, -2.1674]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 17.609349944653427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7887, -2.2460, -2.0240, -0.7398, -1.9202, -1.6236, -2.1284, -4.6484,\n",
      "         18.8631, -2.5718]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 18.863078220537798\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4825, -3.3134, -2.9487, -3.4333, -3.0149, -2.2766, -3.2589, -6.1393,\n",
      "         30.4952, -3.8060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 30.495225751603385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3914,  -2.5304,  -2.0638,   9.0993,  -2.1939,  -1.5821,  -1.9609,\n",
      "         -18.9291,  25.0772,  -2.5568]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.077157335854785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1742, -1.4061, -1.0680, -7.8760, -1.0546, -0.9454, -1.3950,  1.9519,\n",
      "         14.2798, -1.1781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.279787142441869\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3189,  -2.1592,  -1.5139,   3.2168,  -2.1898,  -1.3959,  -1.7080,\n",
      "         -22.7377,  32.5194,  -2.1568]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 32.51942855334285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5718, -3.7428, -2.9112,  6.1860, -3.3969, -2.4774, -3.4421, -8.4433,\n",
      "         25.3164, -4.0829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 25.316365162449607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5860,  -2.2476,  -1.8580,  -8.1961,  -2.2893,  -1.6705,  -2.1018,\n",
      "         -12.2170,  34.6411,  -2.4906]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 34.6411188055373\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7364, -2.3250, -2.0122, -4.6214, -1.9647, -1.3534, -2.2155,  2.6006,\n",
      "         15.4035, -2.2147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 15.403538715801272\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [6]: loss = 28.512, accuracy = 8.59\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4145, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0429, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4145, -0.0329, -0.4586, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0429, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -1.0180,   3.0596,  -1.5198,   1.8260,  -1.5018,  -1.1976,  -1.5290,\n",
      "         -14.2947,  19.4513,  -2.0316]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.45133400410331\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7774,  18.0438,  -2.0483, -12.0824,  -2.1400,  -1.5135,  -2.1788,\n",
      "          -4.1286,  10.9603,  -2.5108]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 18.04383661407295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1191, 19.0292, -2.3078, -3.3691, -2.4520, -1.9905, -2.6095, -9.7757,\n",
      "          8.9502, -2.8283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 19.029224902693848\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3532, 15.9731, -1.7511, -9.4296, -1.6711, -1.1864, -1.7956, -7.2070,\n",
      "         10.8005, -1.9255]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.973089398059257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3444,   3.7079,  -1.7811,   2.3536,  -1.7847,  -1.4296,  -1.8734,\n",
      "         -15.6953,  21.1895,  -2.1655]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.189511677366976\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6129, 20.4538, -1.8202, -6.7829, -1.5992, -1.2734, -2.1407, -1.1896,\n",
      "         -1.6190, -2.1385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 20.45375335506394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9680,  10.4380,  -2.3649,  -7.3445,  -2.7275,  -1.9863,  -2.5132,\n",
      "         -13.0151,  24.3652,  -3.1689]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 24.365207913022957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2958,  12.3149,  -2.8483,  -5.2912,  -2.9928,  -2.1732,  -2.9696,\n",
      "         -10.7647,  20.6983,  -3.7425]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 20.69830378282248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1594,  4.4213, -1.4163,  0.7807, -1.3011, -1.1067, -1.5068, -3.9376,\n",
      "          6.5391, -1.8293]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 6.539092450706391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1316, 11.9777, -1.3696, -8.8386, -1.2797, -0.9566, -1.7078, -4.4227,\n",
      "          9.6844, -1.6922]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 11.977728515149863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0893,   9.1940,  -1.3644,  -6.1866,  -1.4407,  -1.2352,  -1.3190,\n",
      "         -15.3579,  21.4150,  -1.4438]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.41499124181293\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0709,   7.8401,  -1.2897, -12.4307,  -1.3043,  -1.3346,  -1.5659,\n",
      "           4.2936,   8.0252,  -1.6273]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 8.025238475755117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4392,  4.3643, -1.7291,  2.6176, -1.6200, -1.3972, -1.8559, -5.0585,\n",
      "          8.2719, -2.2772]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 8.271935366270874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2641, 13.8360, -1.6278, -9.3238, -1.5292, -1.1246, -1.3832, -7.0866,\n",
      "         11.0330, -1.6688]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.836034938633192\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.8525,  25.7429,  -4.7609,   6.9857,  -5.0088,  -3.8722,  -5.2815,\n",
      "         -13.4530,   9.6128,  -5.9956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 25.7429338228355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6223, 14.8582, -3.0021,  7.2439, -3.3773, -2.4283, -3.6297, -7.5839,\n",
      "          5.2145, -3.9951]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.858186467418541\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5792,  7.9661, -1.8548,  0.2389, -1.8344, -1.2564, -1.8899, -9.9242,\n",
      "         12.2552, -2.2375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 12.255248864809843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3783,  5.8417, -1.5681,  0.5358, -1.6645, -1.0534, -1.6054, -8.0243,\n",
      "         11.9566, -1.8891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 11.956593454826146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3103,  8.7454, -1.5796, -1.3231, -1.6547, -1.0528, -1.6858, -6.0973,\n",
      "          7.8341, -1.9304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 8.745402879181022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5975,   6.6347,  -1.8789, -10.2147,  -1.9409,  -1.4157,  -1.8086,\n",
      "          -0.9171,  15.5078,  -2.4935]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.507789797727407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6210,   7.0285,  -3.1011,   8.7763,  -3.5118,  -2.7339,  -3.1836,\n",
      "         -27.0973,  32.3519,  -4.4275]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 32.351876930017234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9264,  8.4997, -1.3131, -5.3568, -1.3585, -0.8992, -1.5024, -2.6972,\n",
      "          7.9687, -1.5943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 8.499733820649164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9965,  11.2683,  -2.8407,   2.7305,  -3.1012,  -2.1401,  -2.7360,\n",
      "         -18.9768,  21.7668,  -3.3569]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 21.7667682074902\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1183, 10.9314, -2.5880, -1.1010, -2.7515, -1.9389, -2.9637,  0.1211,\n",
      "          6.4925, -3.2514]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 10.931412903543182\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3725,   7.5902,  -1.5602,  -8.0984,  -1.7140,  -1.5160,  -1.8282,\n",
      "         -14.0494,  24.5234,  -1.8726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.523433747118812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2903,  14.8681,  -1.8197,  -7.7365,  -1.5432,  -1.0429,  -1.5575,\n",
      "         -10.5559,  12.1662,  -1.4235]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 14.868128539219484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8829,  7.7727, -0.9778, -0.8053, -0.9516, -0.8326, -1.1105, -6.3846,\n",
      "          6.3957, -1.1753]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 7.772729358880088\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6577,  16.2048,  -2.2350,  -4.3234,  -2.0426,  -1.3552,  -1.8920,\n",
      "         -13.7644,  13.6182,  -2.2201]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.20475277942031\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6705,  5.1396, -1.8657, -3.9039, -2.1223, -1.8154, -2.1677, -4.0987,\n",
      "         14.7831, -2.5467]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.783085441265216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0311,  10.0952,  -1.0673, -12.7935,  -1.0039,  -1.0348,  -1.5449,\n",
      "          -0.4501,  10.7881,  -1.5368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.78814429766177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0650,  15.6842,  -3.6414,   1.5125,  -3.8763,  -2.8932,  -3.8947,\n",
      "         -21.6826,  26.1497,  -4.6698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 26.14970158051219\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9949, 11.2950, -1.4624, -4.8517, -1.3983, -0.9579, -1.5720, -9.2015,\n",
      "         13.0819, -1.7729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.081858945142564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1567,   9.7601,  -1.5915,  -7.4368,  -1.6715,  -1.3769,  -1.8050,\n",
      "         -12.1121,  20.2033,  -1.9401]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.203331352508993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7386,  12.0992,  -2.0921, -18.0963,  -2.4186,  -1.6295,  -2.3489,\n",
      "          -1.7096,  20.6418,  -2.7170]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 20.64184243174393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5816,  3.2658, -1.6082, -4.4687, -1.8981, -1.6976, -2.0170, -4.7647,\n",
      "         17.3369, -2.4645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 17.336898277534235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9698, 10.1259, -2.5683, -9.3417, -2.4475, -1.7486, -2.4401, -7.1085,\n",
      "         22.1468, -3.2544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.146786400355673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9871,  8.0818, -1.4722, -1.1689, -1.3548, -1.1240, -1.6612, -7.3723,\n",
      "          9.0091, -1.8972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 9.009107170231015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8643, 10.7979, -0.8234, -9.0145, -0.8258, -0.6452, -1.1252, -0.8882,\n",
      "          4.5694, -0.9725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 10.79788591528189\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1268,   9.7050,  -1.9401,  -4.7209,  -2.7470,  -2.0036,  -2.2131,\n",
      "         -21.0355,  30.4580,  -3.1225]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 30.457991523460652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7961, 11.6879, -2.1823, -3.3603, -2.1427, -1.5424, -2.2332,  0.5603,\n",
      "          4.3436, -2.8682]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 11.687874525448283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0616,  6.8757, -0.9457,  0.0349, -1.0910, -1.0484, -1.0344, -8.2670,\n",
      "          7.9898, -1.1510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 7.989763321049385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5286, 10.3412, -2.0275, -3.1860, -1.8451, -1.5041, -1.8726, -5.7411,\n",
      "         10.3029, -2.5202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 10.341204120397865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2833,  12.8856,  -2.1419, -10.8716,  -2.3425,  -1.5168,  -2.4404,\n",
      "         -20.2418,  32.1365,  -2.9408]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 32.13652431637775\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9047, 14.1723, -2.1731, -7.7239, -2.2458, -1.7733, -2.4273,  2.0147,\n",
      "          3.6335, -2.5744]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.17234763834512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0914,   7.9425,  -1.0862,  -6.2332,  -1.2497,  -0.9637,  -1.2995,\n",
      "         -11.5880,  18.1440,  -1.4692]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.143962836046352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5626,  12.3451,  -3.1529,   2.8852,  -3.2927,  -2.4831,  -3.4413,\n",
      "         -15.5234,  19.3472,  -3.9856]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.347206413195206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2539,   3.5714,  -1.7434,   3.2284,  -1.8063,  -1.4055,  -1.8736,\n",
      "         -19.4550,  24.4374,  -2.3002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.437383651271816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8884,  12.8072,  -3.4703,   9.4872,  -3.9261,  -2.9317,  -3.9425,\n",
      "         -14.3141,  14.4869,  -4.6033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.48685076630604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3798,  5.8600, -1.8596, -1.3560, -1.9508, -1.7474, -1.9865, -4.7714,\n",
      "         11.3903, -2.2814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 11.390300747556585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5385,  8.0301, -1.6729, -9.9041, -1.7757, -1.3895, -1.8713,  1.2381,\n",
      "         10.7044, -2.1912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 10.704423418949649\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5561, 14.9137, -2.7788, -9.7942, -3.0436, -2.6824, -3.4712, -9.2693,\n",
      "         23.0221, -3.8357]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 23.022134023403243\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3867, 14.9935, -1.9458, -9.1192, -1.6576, -1.2327, -1.9885, -1.3261,\n",
      "          6.1323, -2.2799]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 14.993451368869934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7634,   6.1962,  -2.0301,   4.9799,  -2.1351,  -1.8681,  -2.2315,\n",
      "         -20.3728,  22.1395,  -2.6529]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 22.13946554879739\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5674,   3.6442,  -2.0289, -13.7782,  -2.2001,  -1.7591,  -2.0376,\n",
      "          -6.1361,  28.6711,  -2.7250]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 28.671086034964357\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3063,   2.9963,  -1.9150,   9.5487,  -2.0482,  -1.4458,  -1.9938,\n",
      "         -18.4780,  17.7073,  -2.5372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 17.707317544520553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1013,  7.9052, -2.2888, -9.0128, -2.5703, -1.8523, -2.4059, -8.3622,\n",
      "         23.8025, -3.1031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.80251969518604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2502,   7.0459,  -2.8608,   8.0135,  -2.9323,  -2.0946,  -2.9653,\n",
      "         -15.5246,  17.3062,  -3.6981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.306178136957584\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7188,  14.2048,  -2.0339, -10.0219,  -1.7319,  -1.3998,  -2.3498,\n",
      "          -2.3130,   9.5378,  -2.4177]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 14.20479537776055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2212,  3.3161, -2.2923,  6.8384, -2.6941, -2.1164, -2.8221, -7.3273,\n",
      "         12.9432, -3.2339]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.943181257210307\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2996, 12.3496, -1.4959, -7.2410, -1.5854, -1.1573, -1.6157, -7.0750,\n",
      "         10.9294, -1.5627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.349623842316333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9352,   7.6405,  -1.3327,   1.8653,  -1.9960,  -1.2794,  -1.4756,\n",
      "         -17.5768,  17.8292,  -1.9256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 17.82921866861402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7287,  17.0323,  -1.9429, -10.8625,  -2.0304,  -1.5302,  -2.1230,\n",
      "           3.0878,   1.6047,  -2.2035]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.03232279168528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2300,  13.0621,  -2.7084,  -2.6878,  -2.7600,  -2.3060,  -2.7904,\n",
      "         -10.1992,  15.6148,  -3.4013]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 15.61482421059478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0490,  9.7582, -3.5269,  6.5793, -3.9360, -2.8875, -4.0337, -6.4238,\n",
      "         12.5964, -4.9348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.596428771093596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1999,   8.2246,  -1.9395,  -1.3361,  -2.1242,  -1.3208,  -1.9736,\n",
      "         -16.9431,  21.4858,  -2.3785]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 21.485801871698143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7972e+00,  1.8533e+01, -2.1074e+00, -8.6336e+00, -2.1041e+00,\n",
      "         -1.6462e+00, -2.3529e+00,  1.5075e+00, -2.5076e-03, -2.4171e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 18.53261714211237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1738,  14.4356,  -2.5675,  -5.3231,  -2.8722,  -2.2044,  -3.0836,\n",
      "         -12.8695,  19.1903,  -3.3487]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.190345243733407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.7583,  12.0806,  -4.3415,  17.0448,  -4.6740,  -3.4088,  -4.7420,\n",
      "         -11.5544,   9.1655,  -5.7639]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 17.044841145850622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9903,   7.2845,  -1.0203,  -5.6328,  -1.3130,  -0.9461,  -1.4534,\n",
      "         -13.3397,  19.5651,  -1.2833]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 19.565131843780552\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8726,   7.5303,  -2.5173,   1.9908,  -2.5853,  -1.7503,  -2.5099,\n",
      "         -16.5469,  23.0577,  -3.1981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 23.05774255511996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0193,   7.9473,  -1.6545,  -6.5659,  -1.6219,  -1.0659,  -1.6322,\n",
      "         -16.3913,  24.6201,  -2.0765]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 24.620117351053196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4038,  7.1239, -1.2552, -4.5951, -1.3133, -1.2108, -1.5323,  0.0667,\n",
      "          5.3154, -1.7345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.123949237113877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5681,  5.8699, -0.8493, -9.8213, -0.6088, -0.5344, -0.8350, -3.0525,\n",
      "         12.3738, -0.7764]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 12.373771745967503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6183, 14.6841, -1.6861,  3.1523, -2.0930, -1.4517, -2.1526, -9.0751,\n",
      "          3.3935, -2.3074]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 14.684145083346845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0058,  11.2681,  -2.3481, -17.6834,  -2.7237,  -1.8743,  -2.5645,\n",
      "          -0.1709,  20.9386,  -3.1845]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 20.93860305594578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2462,  12.1634,  -3.0297,   6.3457,  -3.0538,  -2.1708,  -3.4817,\n",
      "         -11.0519,  10.7112,  -3.6220]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.163428856385309\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3086,  3.7431, -1.3956, -4.6991, -1.6220, -1.1505, -1.5601, -4.8790,\n",
      "         14.4355, -1.9312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.435463522197374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5458,  8.9630, -1.8670, -0.5221, -2.0747, -1.7702, -1.9844, -9.2907,\n",
      "         12.6504, -2.4482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.650385823060585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1129,  3.6779, -1.2248,  0.1304, -1.4365, -1.4296, -1.5853, -5.7942,\n",
      "         10.0061, -1.6512]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 10.00612742314496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6003,  8.6946, -2.1509,  0.0536, -2.2575, -1.4571, -2.1203, -8.7710,\n",
      "         12.3705, -2.8696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.370491575038834\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7639,   9.6747,  -2.1009,  -2.2305,  -2.5535,  -1.6884,  -2.1862,\n",
      "         -23.7118,  30.0675,  -2.7766]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.06751656115857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4076,   4.1091,  -1.7202,   2.7474,  -1.8173,  -1.1828,  -1.7101,\n",
      "         -11.3265,  15.7719,  -2.2712]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.771863402310782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9819,  17.9591,  -3.1278, -10.0470,  -3.4195,  -2.7699,  -3.7671,\n",
      "         -15.4661,  28.6282,  -4.2373]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 28.628200025305684\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1618,  2.3833, -1.3338, -5.6651, -1.5706, -1.2717, -1.5055, -7.0485,\n",
      "         19.4219, -1.8538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.42194259212292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0816,  7.9406, -1.0238, -6.8394, -1.5132, -0.9897, -1.2892, -8.9973,\n",
      "         16.1640, -1.4011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.163980277700272\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4136, 18.9694, -2.7412, -4.1377, -2.7019, -2.0406, -2.8684, -7.3958,\n",
      "          8.2557, -3.5972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 18.969444132120696\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0226,   9.1437,  -1.0968,  -8.8767,  -1.4841,  -0.9563,  -1.6855,\n",
      "         -16.4085,  24.9445,  -1.4547]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.94448515532942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5575,  6.6802, -1.5913, -3.2593, -1.6290, -1.5290, -1.5776, -7.8083,\n",
      "         14.7122, -2.0786]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.712217605194398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1820, 12.4161, -2.9844,  1.2958, -3.0871, -2.4118, -3.0153, -5.1764,\n",
      "          8.6904, -3.3676]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.416120341110304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4426,   4.6299,  -1.9970,   6.9080,  -1.8338,  -1.3131,  -1.9710,\n",
      "         -14.9402,  15.8003,  -2.5614]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.800268257530213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4112,   9.1262,  -1.9380,  -1.2922,  -1.9894,  -1.3813,  -1.8418,\n",
      "         -14.6013,  18.3672,  -2.4224]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.367151876558136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3540,  9.9245, -1.3247, -7.7678, -1.3888, -1.3792, -1.9896,  2.3885,\n",
      "          4.0489, -1.7776]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.92450932251362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0032,  12.2977,  -2.0026,  -3.6229,  -2.4576,  -1.7349,  -2.3769,\n",
      "         -13.1793,  17.8091,  -2.5312]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.80909767336907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8289, 18.7926, -1.9620, -4.1557, -2.0069, -1.7207, -2.4589, -6.3405,\n",
      "          4.1198, -2.3924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.792599345412913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1209,   8.0962,  -1.2786,  -2.4977,  -1.4494,  -1.0387,  -1.2411,\n",
      "         -12.2844,  14.6929,  -1.4882]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.69288365594398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1500,  11.1102,  -2.6507,   4.5231,  -2.8176,  -2.1236,  -3.2330,\n",
      "         -13.7239,  15.0427,  -3.4826]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 15.04268458408276\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3934,   8.5430,  -1.4228,  -3.5379,  -1.6350,  -1.3226,  -1.7036,\n",
      "         -14.2452,  18.7813,  -1.7383]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 18.781320939046584\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6788,  9.6677, -1.9710,  0.6894, -2.3133, -1.7667, -2.2272, -9.1298,\n",
      "         11.2834, -2.4926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.283445244115608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9450,   7.2135,  -3.6846,   3.9566,  -3.8788,  -3.1312,  -3.9793,\n",
      "         -14.4068,  25.9111,  -4.9189]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 25.911125989973414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9562,  9.9403, -1.3236, -5.4333, -1.3987, -1.0307, -1.2665, -0.1541,\n",
      "          4.0631, -1.6690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.940295799590023\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7131,   5.5661,  -1.9419, -10.4326,  -2.3234,  -1.8203,  -1.9891,\n",
      "          -3.4378,  20.1167,  -2.5538]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.116707024128903\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8445,   9.2057,  -1.2160,  -4.2977,  -1.1574,  -0.9098,  -1.4640,\n",
      "         -10.6585,  14.8031,  -1.7013]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.80308135675034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4333,  8.9061, -1.5838, -2.7988, -1.8723, -1.3601, -1.7820, -3.6340,\n",
      "          8.9510, -2.4099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 8.95099703055382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1504,  3.0171, -1.1861, -7.4071, -1.3966, -1.1695, -1.4841, -2.1067,\n",
      "         14.7897, -1.7702]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.789743721823172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0648,  6.1120, -1.2495, -2.0749, -1.0649, -0.9888, -1.4168, -2.1934,\n",
      "          5.6501, -1.6380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.11203502008329\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9953,  13.5494,  -2.2690,  -3.7777,  -2.3784,  -1.8029,  -2.5480,\n",
      "         -12.3120,  16.0158,  -3.1010]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 16.015830258169057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5507, 10.4635, -2.0993, -0.9096, -2.3277, -1.4451, -2.5030, -5.7221,\n",
      "         10.1370, -2.4832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 10.46352001572663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5284,  8.9529, -1.4142, -6.3981, -1.5991, -1.4219, -1.6796, -5.5738,\n",
      "         12.6108, -1.9768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 12.610799993923585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4468,   6.9917,  -1.6730,   1.7340,  -1.6430,  -1.4340,  -1.6751,\n",
      "         -13.2670,  14.2816,  -2.0835]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.281557326683007\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9146,   7.8186,  -2.5962,   0.2194,  -2.6210,  -1.8461,  -2.3258,\n",
      "         -13.4562,  20.6454,  -3.2634]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 20.645374615306352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4110,  12.2561,  -1.5712,  -4.1418,  -2.0273,  -1.3939,  -1.8821,\n",
      "         -15.7395,  18.9097,  -2.0103]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.909660882638004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0644,  9.0925, -1.0823, -7.4697, -1.0758, -1.0571, -1.5182,  0.3740,\n",
      "          4.7895, -1.5006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.092522875770833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9596,   4.9010,  -2.6701,  -1.7973,  -3.2078,  -2.4234,  -2.7373,\n",
      "         -15.7871,  29.7856,  -3.6945]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 29.78555943025383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0326, 17.6966, -2.1654, -3.6171, -2.3404, -1.9416, -2.7742, -7.3922,\n",
      "          6.4662, -2.5619]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.696627654432035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0466,   6.0218,  -1.5313,  -2.1984,  -1.5807,  -1.0792,  -1.4218,\n",
      "         -14.2433,  19.7270,  -1.9421]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.726987570377307\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6642, 14.9023, -3.5298,  8.4832, -3.3960, -2.4710, -3.8369, -7.5099,\n",
      "          5.0760, -4.0908]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.902295469384452\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7793,  5.6104, -1.1129, -4.9105, -1.1539, -0.7468, -1.3196, -7.7069,\n",
      "         14.5784, -1.3560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.578359979138034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2766,   6.6260,  -1.6295,  -1.9943,  -2.0179,  -1.5258,  -1.5059,\n",
      "         -11.9407,  17.6694,  -2.0726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.669447956420345\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0684,  3.9863, -1.2166,  0.8691, -1.1066, -1.0445, -1.3642, -1.3400,\n",
      "          3.7615, -1.5996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 3.9863361428388036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1651,   2.7863,  -1.5321,  -3.9550,  -1.7558,  -1.5931,  -1.4912,\n",
      "         -10.8803,  21.8963,  -2.1209]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.89629708898859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3375,  7.7533, -1.5565, -5.5067, -1.6027, -1.3439, -1.7339, -1.5362,\n",
      "          7.9648, -1.9354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 7.964752044862588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2959,  20.4580,  -3.8769,   4.1741,  -4.2638,  -2.9826,  -4.1863,\n",
      "         -12.8341,  11.3641,  -5.0961]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 20.458027850066134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2633,  8.7197, -1.1281, -6.0711, -1.1565, -1.0440, -1.6849,  2.1914,\n",
      "          2.7247, -1.6630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.719701692286623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6841,  8.2303, -1.5954, -4.6153, -1.8931, -1.5015, -1.8901, -6.7815,\n",
      "         14.0377, -2.3059]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.03770530491709\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5684,  10.2781,  -2.6194,   2.2206,  -2.7426,  -1.9982,  -2.9581,\n",
      "         -12.1387,  14.1931,  -3.1896]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.19305960961638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9539, 14.2881, -2.6326,  1.7195, -2.5823, -2.0033, -3.2558, -3.6495,\n",
      "          4.2222, -3.1297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.288148061416047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1130,  7.3796, -1.1925, -2.3526, -1.2974, -1.3460, -1.3230, -4.6885,\n",
      "          8.3291, -1.6615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 8.329076111158631\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2875,  9.0675, -1.3683, -3.6981, -1.5510, -1.3679, -1.5438, -3.5945,\n",
      "          6.5636, -1.8506]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 9.067519789672815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1177,  10.4181,  -2.5843,  -3.2245,  -2.8807,  -1.9526,  -2.4114,\n",
      "         -12.4796,  22.3830,  -3.2633]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.382950289170896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8715,  7.8374, -0.9115, -5.6601, -0.9400, -0.7864, -1.3425,  0.6366,\n",
      "          2.8651, -1.1812]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.837404121562269\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2683,   8.8005,  -1.4416,  -3.1388,  -1.6036,  -1.0945,  -1.4053,\n",
      "         -11.6942,  14.9194,  -1.7331]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 14.919357936264804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2986,  8.4764, -1.4257, -3.7504, -1.5430, -1.1926, -1.4999, -1.4805,\n",
      "          5.0635, -1.7369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 8.476359980585134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3689,   8.7061,  -2.6779,  11.7219,  -2.9578,  -2.4165,  -2.7586,\n",
      "         -13.5730,   9.7088,  -3.5213]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.72193400176848\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8464,  5.4333, -1.1961, -3.7169, -1.2144, -1.0370, -1.5099, -8.5211,\n",
      "         15.7570, -1.7545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.75701465940226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8853,   3.9283,  -1.4866,   3.1288,  -1.5591,  -0.9394,  -1.4762,\n",
      "         -12.9449,  14.7794,  -1.8684]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 14.779442570550414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0840,  3.6252, -1.2658,  1.8800, -1.4120, -0.8821, -1.4171, -9.0614,\n",
      "         12.3720, -1.7113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.371963285762355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9367,  7.6767, -1.0424, -2.8073, -1.4389, -0.9708, -1.4497, -7.4185,\n",
      "         10.5926, -1.2008]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.592614705173887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2220,  2.9438, -1.4414, -7.3157, -1.7586, -1.3987, -1.6880, -4.8798,\n",
      "         18.8256, -2.0255]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.82560572775898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0898,   8.3354,  -2.5754,   0.4163,  -3.1217,  -2.1856,  -2.8404,\n",
      "         -19.9320,  29.4878,  -3.8288]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 29.487768191179885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8472,  13.4994,  -3.6801,   9.6685,  -3.9335,  -2.6150,  -3.8814,\n",
      "         -19.4797,  18.1791,  -4.7673]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 18.17913612209544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8989,  5.8718, -2.3371,  1.2499, -2.2328, -1.6789, -2.3772, -7.3918,\n",
      "         13.0838, -2.6360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 13.083761213584957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6605,  11.9741,  -3.0225,   7.5276,  -3.2323,  -2.3781,  -3.3976,\n",
      "         -14.9472,  14.2083,  -3.9865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.208340847222393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5179,  11.8244,  -3.2157,  -2.1887,  -3.1941,  -2.4882,  -3.1184,\n",
      "         -17.4995,  27.8230,  -4.1979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.823031412601498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3951, 13.5882, -2.0999, -4.1675, -2.0233, -1.5519, -2.2002, -5.2034,\n",
      "          8.0101, -2.3660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.588231627366866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4660,  9.2088, -1.3548, -7.5089, -1.4008, -1.3587, -1.9218,  2.6737,\n",
      "          4.4746, -1.9050]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.20882097994655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5562, 10.0752, -1.4585, -7.4258, -1.5288, -1.4903, -2.0073,  1.4903,\n",
      "          5.2699, -2.0019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 10.075220776328536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5129,   7.9786,  -2.2860,   4.6587,  -2.4800,  -1.6694,  -2.6135,\n",
      "         -23.3685,  25.1736,  -2.9880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.17355291335721\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5267,   7.5033,  -2.1540,  -8.9613,  -2.2125,  -1.5250,  -1.8395,\n",
      "         -14.3052,  27.9932,  -2.6188]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 27.993204636841117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8327,  13.4077,  -2.0594, -11.4233,  -2.1709,  -1.6746,  -2.2021,\n",
      "         -15.1275,  25.4731,  -2.3040]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 25.47308115874503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1240,  7.1594, -1.4817, -2.7013, -1.6878, -1.1679, -1.7226, -9.6926,\n",
      "         15.1486, -2.0414]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.148641320989723\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6046,  7.4669, -1.9457,  4.5503, -2.1486, -1.4258, -1.8750, -9.4043,\n",
      "         10.1835, -2.6202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 10.18352249558295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1573,   4.6506,  -1.4120, -10.0583,  -1.7799,  -1.3725,  -1.5881,\n",
      "          -1.0988,  16.1200,  -2.0628]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 16.119979208306773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1225, 12.7500, -1.3340, -3.0192, -1.6153, -0.8619, -1.3766, -4.7108,\n",
      "          3.8610, -1.5506]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 12.749954160321757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3345, 10.3458, -2.6384, 10.3926, -2.9242, -2.1290, -3.1958, -8.2692,\n",
      "          4.2733, -3.4860]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 10.392574999736079\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9978, 10.2096, -2.2821, -0.2998, -2.3932, -1.8290, -2.3366, -8.2506,\n",
      "         12.4825, -2.8800]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.482521061129757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7970,  9.9595, -2.3137,  1.1314, -2.2876, -1.6031, -2.3865, -4.9417,\n",
      "          7.3666, -3.0112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.959491629375938\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2645,   9.9418,  -1.2370,  -6.7880,  -1.4950,  -1.2647,  -1.6637,\n",
      "         -16.2211,  21.9334,  -1.4364]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.933351462973153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0868,  7.2479, -1.4986, -4.4430, -1.7926, -1.3391, -1.4646, -7.1191,\n",
      "         13.4750, -1.7816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.475014552774457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4915,   8.6168,  -1.7645,   0.2895,  -1.7936,  -1.5043,  -2.0140,\n",
      "         -13.0921,  15.9171,  -2.3290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.917073616649645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4995,   8.0953,  -1.7681,  -8.3222,  -2.0393,  -1.5574,  -1.7368,\n",
      "         -11.6523,  22.4683,  -2.2109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.46826294636247\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7029,  5.7114, -2.0336,  2.3294, -1.8906, -1.5576, -2.0812, -5.5801,\n",
      "          8.9716, -2.4482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 8.971609052973056\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0387,  7.1300, -1.0223, -5.0605, -0.9981, -0.9029, -1.5719,  1.8381,\n",
      "          2.7008, -1.4044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.1300008968893565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2370,  12.1796,  -2.8135,   6.4455,  -2.9236,  -2.1462,  -3.1182,\n",
      "         -16.5568,  14.6852,  -3.6697]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.685210811601316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9937,  6.8435, -0.8831, -5.9381, -0.8048, -0.8377, -1.2170,  0.4281,\n",
      "          4.6271, -1.2921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.843462856044367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1838,  5.5843, -1.3531, -1.4989, -1.1427, -1.0904, -1.5033, -1.0912,\n",
      "          4.5941, -1.7009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 5.584323526330859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1284,   7.1185,  -2.9040,   7.1708,  -3.0808,  -2.1272,  -2.9040,\n",
      "         -22.0641,  26.4883,  -3.8336]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.48825964294968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4728,  16.0645,  -2.8096,  -6.3240,  -3.0663,  -2.2260,  -3.0630,\n",
      "         -18.1435,  26.7481,  -3.9060]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.74809991393608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2726,  8.6857, -1.1203, -6.1737, -1.1221, -1.1267, -1.7310,  2.0836,\n",
      "          2.8371, -1.5811]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.68567439915573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3304,  8.9408, -1.4001, -1.8349, -1.4305, -1.1281, -1.5437, -2.6090,\n",
      "          4.5621, -1.8320]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 8.940793512172997\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5521, 10.1046, -1.6452, -2.6482, -1.8730, -1.5856, -1.8389, -5.7978,\n",
      "          8.8273, -2.0428]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 10.10459457061878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0299,  6.3641, -1.2456, -2.2503, -1.1620, -0.9621, -1.6343, -8.3754,\n",
      "         13.0257, -1.7080]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.025728610334564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1771,  8.3012, -1.3713, -3.4137, -1.3961, -1.1170, -1.6892, -9.4260,\n",
      "         14.8127, -2.0302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.812727332593122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0840,   9.4697,  -1.2763,  -2.0191,  -1.4246,  -1.0462,  -1.5632,\n",
      "         -11.9569,  13.6319,  -1.6758]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.63191638423975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8776,   9.4393,  -2.9669,   2.6623,  -3.2374,  -2.1467,  -2.9995,\n",
      "         -23.1907,  30.0520,  -3.9003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.05196455243784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6144,  5.9090, -1.9002,  0.4535, -1.6831, -1.4747, -1.9747, -2.7567,\n",
      "          7.2137, -2.3600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 7.213650394603103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6566, 19.4528, -1.6175, -3.6071, -1.6848, -1.2519, -2.0815, -5.1304,\n",
      "         -0.4774, -1.9493]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 19.45283387105919\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4262,  13.3531,  -3.1656,  -5.5750,  -3.2382,  -2.4372,  -3.2438,\n",
      "         -14.9369,  27.2248,  -4.1982]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.224769379144867\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0974,  15.1475,  -2.6273,  -6.9639,  -2.8098,  -2.0486,  -2.8655,\n",
      "         -14.6620,  21.9539,  -3.5720]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.953909329693534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9383,  2.8933, -2.1191,  2.9810, -2.4973, -1.9685, -2.4273, -5.4186,\n",
      "         13.4845, -2.9138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 13.484511363172874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0632, 19.9456, -2.7361, -0.6085, -2.6276, -2.1197, -2.9139, -5.8446,\n",
      "          1.4746, -2.9206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 19.945599951107116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5986,  3.1770, -0.7620, -0.2710, -0.7886, -0.7259, -0.9200, -2.0193,\n",
      "          3.8389, -1.0729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 3.838864948660205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1123,  9.3655, -1.1989, -7.3660, -1.1311, -1.1066, -1.6557, -1.1614,\n",
      "          6.6240, -1.6527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.365462353549205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6065,  2.2414, -1.6901,  3.2106, -1.8168, -1.3113, -1.9748, -5.7193,\n",
      "         11.9379, -2.1459]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.937855977551866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0184,  4.1322, -1.4579, -7.5769, -1.5207, -1.1933, -1.3165, -7.0777,\n",
      "         19.3213, -1.6812]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.3212904044192\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8736,   5.2568,  -0.9497,  -5.2869,  -1.3241,  -0.9065,  -1.2788,\n",
      "         -12.9072,  19.5828,  -1.2356]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 19.582842132623853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1206,  8.8337, -1.4744, -6.2336, -1.5250, -1.3852, -1.4791, -5.4785,\n",
      "         12.2113, -1.9495]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.21133965220787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.9897, 12.1384, -3.5233,  6.6795, -4.0795, -3.0265, -3.8742, -8.7043,\n",
      "         11.2986, -4.5044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.138443806020963\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9108,   8.0519,  -2.5922,   5.1658,  -2.7042,  -2.0399,  -2.4571,\n",
      "         -23.7476,  26.6541,  -3.3023]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.654140937214574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3803,  17.1293,  -4.0544,   4.7057,  -4.4551,  -3.1765,  -4.4023,\n",
      "         -15.3568,  19.5564,  -5.1973]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.55644629562237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6542,   8.0252,  -2.0790,   2.3002,  -2.5528,  -1.6667,  -1.9988,\n",
      "         -18.8078,  22.8748,  -2.8591]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.874780685013985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7277,   5.8247,  -2.3713,   1.1366,  -2.3785,  -1.8203,  -2.5041,\n",
      "         -19.1799,  28.0067,  -3.1377]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 28.006734385191763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1408,  19.0733,  -2.3292,   3.6640,  -2.6569,  -1.9585,  -2.9323,\n",
      "         -10.1433,   3.1832,  -3.1520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 19.073305426198143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6833,  9.7209, -1.7744, -6.7984, -1.8702, -1.5097, -2.0317, -0.8115,\n",
      "          9.0470, -2.3679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 9.720922282372115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6387,   8.6575,  -2.0790,  -1.6601,  -2.6068,  -1.5371,  -2.0469,\n",
      "         -13.8885,  20.8066,  -2.9894]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 20.806576270427843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3219,  3.0759, -1.5911, -2.6598, -1.7180, -1.6208, -1.8354, -1.3091,\n",
      "         11.2317, -2.1892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 11.231732408064623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9623,   7.8715,  -1.3387,  -4.2293,  -1.1544,  -0.9525,  -1.5293,\n",
      "         -10.9531,  16.7076,  -1.6588]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.70762635258519\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8286,   2.8393,  -0.9469,  -1.5968,  -1.2894,  -0.7523,  -0.9807,\n",
      "         -12.7486,  17.6808,  -1.2024]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 17.6807524530494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4083,  8.2783, -1.4637, -7.0310, -1.6381, -1.3249, -1.6602, -6.0315,\n",
      "         13.8936, -1.7339]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 13.893634580456657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2812, 11.3872, -1.2483, -7.2257, -1.2640, -1.1012, -1.7290,  0.1917,\n",
      "          3.7681, -1.7021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.387235984433369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9834,  10.2633,  -2.4190,  -2.1596,  -2.7380,  -2.0637,  -2.8393,\n",
      "         -10.9600,  17.4489,  -2.9295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.448927711570768\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5280,  8.4369, -1.5273, -1.9903, -1.9888, -1.3855, -1.8588, -5.3784,\n",
      "          9.3265, -2.2005]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 9.326488724422369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9866,  7.5510, -2.4321,  3.4684, -2.5493, -1.9182, -3.0039, -8.8984,\n",
      "         13.2406, -2.9479]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.240605611735914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3088,   8.0602,  -1.5606,  -2.9239,  -2.0332,  -1.3935,  -1.7046,\n",
      "         -12.5205,  17.9331,  -2.0061]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.933096431896875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0290,  3.8032, -1.2149, -8.2587, -1.5429, -1.2261, -1.4562, -0.8222,\n",
      "         13.7089, -1.7486]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 13.708917182786168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1609,  5.7643, -1.7246, -4.1145, -1.3436, -1.3385, -1.4640, -7.5534,\n",
      "         14.9522, -1.8944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.952184838601324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5352,  10.0232,  -2.1139,  -2.4959,  -2.2285,  -1.4044,  -2.2681,\n",
      "         -10.9629,  17.0458,  -2.6533]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 17.04575295933981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1750,   8.8545,  -2.0323,   0.6007,  -2.4447,  -1.5629,  -2.0822,\n",
      "         -23.0666,  26.7276,  -2.8617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.727590639035537\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1528,  6.5390, -1.3368, -9.2977, -1.4021, -1.0904, -1.4387, -8.3586,\n",
      "         19.0126, -1.5299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 19.012567772106838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5055,  6.6477, -1.6255,  0.4148, -1.4691, -1.2627, -1.7207, -8.3515,\n",
      "         10.9309, -1.8704]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.930915938713996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5944,  21.3378,  -3.0593,  -3.3046,  -3.2195,  -2.5154,  -3.3547,\n",
      "         -11.7879,  12.1845,  -4.1876]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 21.33783162950623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4810,  7.3503, -1.6915, -8.9237, -1.9270, -1.5878, -1.7816,  2.3739,\n",
      "          9.4881, -2.2117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 9.488060735205757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1697,  3.2755, -1.3990, -7.9133, -1.5982, -1.2795, -1.4560, -4.1304,\n",
      "         17.8352, -1.8697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 17.835209426160937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0083,   8.5908,  -1.1872, -12.0257,  -1.2623,  -0.9776,  -1.3230,\n",
      "         -10.4977,  21.4903,  -1.3050]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.49028252245034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5239, 19.1306, -2.9940, -3.2673, -2.9921, -2.1388, -3.0484, -9.8876,\n",
      "         10.6127, -3.8341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.13057966627454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2185, 13.3896, -2.4327, -3.1009, -2.6139, -1.8709, -2.7240, -3.6331,\n",
      "          8.6569, -3.0498]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 13.389595156444575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2355,  7.8227, -1.4392, -8.6866, -1.4369, -1.2354, -1.3779, -7.4835,\n",
      "         16.5958, -1.5988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.595754867805322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0576,   2.4618,  -1.4620,   2.3288,  -1.5923,  -1.1224,  -1.7561,\n",
      "         -19.1332,  23.9274,  -1.8681]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 23.92739418739701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0529,  12.9918,  -2.7865,   0.5868,  -3.2742,  -2.3931,  -3.2747,\n",
      "         -14.4152,  17.8102,  -3.5661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.81019795660731\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0135, 12.9522, -1.3802, -8.1788, -1.4721, -1.0927, -1.4640, -7.5801,\n",
      "         11.9475, -1.6261]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.952152515516978\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3096,  16.1831,  -2.8444,   5.3295,  -3.2647,  -2.3319,  -3.4106,\n",
      "         -13.8050,   9.9670,  -3.6508]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.183116431197575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6630,  15.6114,  -3.1809,   7.9830,  -3.5868,  -2.6479,  -3.4780,\n",
      "         -16.0514,  11.7788,  -4.0526]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 15.611386737343459\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3420,   9.6433,  -1.5312, -11.6000,  -1.5794,  -1.2219,  -1.5154,\n",
      "         -12.6918,  23.9752,  -1.8047]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.97516123030482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1144, 24.0081, -2.2832, -8.9613, -2.2466, -1.9587, -3.0403,  4.5990,\n",
      "         -5.4549, -2.9199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 24.008076831770786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4683,  18.0797,  -1.8032, -19.0340,  -1.7696,  -1.5548,  -1.8841,\n",
      "          -6.8436,  18.8503,  -2.4924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 18.850294570110616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3884,  13.7160,  -3.0767,  -0.8868,  -3.3968,  -2.3328,  -3.4257,\n",
      "         -19.6063,  26.2553,  -3.9079]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 26.25532550986934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9134,  6.4121, -1.2064, -5.9659, -1.1948, -1.0031, -1.4308, -5.2400,\n",
      "         13.5492, -1.4412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.54924703494903\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1245,  7.9308, -1.2501, -2.7392, -1.5440, -1.1022, -1.5503, -8.2785,\n",
      "         11.9068, -1.7538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.906760587630986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2402,  7.1379, -1.3825, -4.4744, -1.4263, -1.1037, -1.4584, -1.8906,\n",
      "          7.9400, -1.7171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 7.940035587750103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9270,   7.6244,  -1.4691,  -4.3950,  -1.5229,  -1.2571,  -1.4943,\n",
      "         -16.8753,  22.7395,  -1.5584]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 22.739535812091646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5207,  9.0292, -1.6253, -5.3934, -1.7442, -1.5388, -1.8527, -4.3245,\n",
      "         11.2040, -2.0433]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.203950582579477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0759,  13.5689,  -2.7422,   5.9081,  -3.1847,  -2.3889,  -3.1876,\n",
      "         -23.2856,  22.2109,  -3.5415]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 22.21089060121105\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3174,  8.6473, -1.4928, -6.1551, -1.6144, -1.1064, -1.4882,  0.0611,\n",
      "          6.5617, -1.9224]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 8.64729416838032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7819,   9.1107,  -2.2833,  -0.5596,  -2.2679,  -1.9151,  -2.4956,\n",
      "         -20.7084,  27.3862,  -2.7286]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 27.3861638454085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5558,   5.4236,  -2.1577,   9.6112,  -2.3716,  -1.6105,  -2.2456,\n",
      "         -20.1341,  19.2087,  -2.7821]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 19.20868383086511\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0850,  2.4071, -1.1281, -2.2884, -1.5135, -1.2322, -1.4140, -2.2013,\n",
      "         10.5098, -1.8084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.509769950192048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0568,   5.3062,  -2.7321,  11.2586,  -3.0737,  -1.9604,  -2.6294,\n",
      "         -21.6882,  22.2852,  -3.5812]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.285200801273987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0801, 11.3065, -2.1697, -4.7833, -2.3427, -1.9980, -2.7112, -7.2661,\n",
      "         15.5631, -2.8283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 15.563095773356686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4218, 18.2988, -2.8008, -1.8193, -3.0445, -2.1797, -3.0924, -7.4120,\n",
      "          7.4800, -3.6145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 18.298849476299004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0451,   9.3600,  -2.3590,   7.7244,  -2.6027,  -2.1192,  -2.6082,\n",
      "         -15.3749,  14.3227,  -2.9899]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.322682925066744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9546,   6.4956,  -2.6463,   6.9932,  -2.7960,  -1.9263,  -2.4345,\n",
      "         -19.0513,  22.0490,  -3.3243]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.04896232715352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2857, 17.3643, -2.5208, -6.2536, -2.6585, -1.8931, -2.8026, -2.7710,\n",
      "          7.1306, -3.4742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 17.364330853434087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3240,  16.6262,  -2.7721,  -3.7694,  -2.9045,  -2.1215,  -2.9008,\n",
      "         -11.3581,  13.9034,  -3.5619]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 16.626194649078435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3077,  12.3595,  -3.0591,   3.7111,  -3.0097,  -2.1761,  -3.1806,\n",
      "         -11.0795,  12.8514,  -3.8877]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.851369093643845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9359,  5.9772, -1.0933, -3.8961, -1.1280, -0.7708, -1.1783, -6.8447,\n",
      "         12.5575, -1.3850]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.557461325544292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6175e+00,  1.7210e+01, -3.1767e+00, -1.2019e-02, -3.7447e+00,\n",
      "         -2.5933e+00, -3.4021e+00, -2.1813e+01,  2.3956e+01, -4.3952e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 23.956424836082174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0123,   6.2489,  -1.3977,  -5.6117,  -1.1315,  -1.0092,  -1.4491,\n",
      "         -10.2413,  18.0398,  -1.7002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.039767840132356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1637,  9.1041, -1.1443, -3.0903, -1.3533, -1.2621, -1.4668, -4.7507,\n",
      "          6.9795, -1.4658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 9.10410131282718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1717,  19.7063,  -3.6870,   3.5680,  -3.7151,  -2.7890,  -3.9376,\n",
      "         -12.2692,  10.3138,  -4.7102]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.706265047769612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1719,  17.2007,  -2.6617,  -0.7598,  -2.6362,  -1.7474,  -2.8922,\n",
      "         -14.2487,  14.5869,  -3.5835]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 17.200724353148246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2955,  9.7814, -1.6492, -3.4095, -1.6160, -1.1263, -1.6527,  3.2896,\n",
      "          0.3497, -2.1639]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.781411012218875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9143,  2.6537, -1.1652,  0.6040, -1.1100, -0.9546, -1.1697, -2.1881,\n",
      "          4.8897, -1.3988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 4.889737788184492\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3919,  9.1871, -1.3118, -5.0534, -1.3980, -1.2540, -1.9060, -0.0104,\n",
      "          4.4679, -1.8877]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.187058493451499\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2649,  12.6141,  -2.8348,  -1.7366,  -3.2323,  -2.3200,  -2.9880,\n",
      "         -17.5723,  23.7324,  -3.7833]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 23.732429528783666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1074,  2.3246, -1.3836, -5.1631, -1.5602, -1.3293, -1.3503, -6.7559,\n",
      "         18.6156, -1.9419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.615617782566787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3236,  17.8404,  -2.7115,   3.3319,  -3.2955,  -2.2808,  -3.2323,\n",
      "         -18.1201,  14.7266,  -3.9512]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 17.84041215404579\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.1248,  8.6906, -3.8391, 15.5276, -4.0047, -3.0441, -4.2501, -8.2876,\n",
      "          7.2422, -4.7647]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 15.527635898806862\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [7]: loss = 15.137, accuracy = 13.28\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4139, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0431, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4139, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0431, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.6594, 10.8083, -1.6968, -3.3599, -1.6850, -1.3225, -2.1178, -8.4419,\n",
      "         12.0870, -2.0428]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.087022606020662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0075,   9.8956,  -2.3269,  -8.0631,  -2.5388,  -2.0583,  -2.3847,\n",
      "         -16.8770,  29.4935,  -3.1849]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 29.49352035283565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5065,  12.4407,  -1.8829, -15.3424,  -1.7704,  -1.3779,  -2.0204,\n",
      "          -7.8144,  21.2112,  -2.0586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.211166994691904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0194, 11.9730, -1.5287, -7.8221, -1.4001, -1.0095, -1.7639,  1.4655,\n",
      "          3.8844, -2.0778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 11.97297106341518\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3287,   5.1826,  -2.0126,   3.3982,  -2.0527,  -1.5435,  -1.9757,\n",
      "         -19.2117,  22.8250,  -2.4337]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.824990159807918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6796,  6.2178, -1.8896,  0.8866, -2.0814, -1.6148, -1.8687, -7.7457,\n",
      "         13.2453, -2.5116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 13.2452698423999\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0337,   6.1011,  -1.5381,   4.3734,  -1.7320,  -1.2556,  -1.4340,\n",
      "         -15.8242,  15.1767,  -1.7681]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.176691354335803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0166, 12.1804, -3.5571, 12.9783, -3.7164, -2.7038, -3.9951, -6.9304,\n",
      "          3.6382, -4.5118]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.978274739606016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8875,   9.8040,  -1.9322,   1.8336,  -2.4315,  -1.9542,  -2.6795,\n",
      "         -11.4364,  13.7052,  -2.7035]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 13.705231195605712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3648,  9.7065, -1.6033, -2.3604, -1.7021, -1.1944, -1.7102, -7.9788,\n",
      "         11.5565, -2.0002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 11.556519938178626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1302,  6.3394, -1.3493, -3.7505, -1.3361, -1.2102, -1.5252, -7.9585,\n",
      "         13.7838, -1.5734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.78375736261907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2636,  2.7481, -1.4795, -6.9354, -1.6488, -1.3523, -1.4951, -5.7098,\n",
      "         19.6866, -2.0755]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.686561911603388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0733,  9.1427, -1.1585, -4.2673, -1.2397, -1.1455, -1.3815, -6.5764,\n",
      "          9.1530, -1.7277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 9.153029555822503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0846,  12.6284,  -3.5631,  13.2666,  -3.8292,  -2.7327,  -3.7782,\n",
      "         -10.6282,   6.6814,  -4.6237]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 13.266626868639484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1127,   5.5446,  -1.3504,   1.5653,  -1.5377,  -1.1473,  -1.3158,\n",
      "         -12.8511,  13.6141,  -2.0909]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 13.614110280397846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3463,  8.9603, -1.3139, -6.1277, -1.3266, -1.2320, -1.9192,  1.2579,\n",
      "          4.4036, -1.8534]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.960268462188383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4611,  11.0268,  -1.8116,  -4.2455,  -2.0741,  -1.5010,  -2.2421,\n",
      "         -11.4955,  16.6352,  -2.3522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.635222145956526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7563,  12.5581,  -3.3143,  10.6818,  -3.5120,  -2.6608,  -3.6634,\n",
      "         -17.1038,  13.8259,  -4.2156]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.82585306682899\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0355,  9.1031, -1.3555, -5.8146, -1.4684, -0.9869, -1.3761, -0.1633,\n",
      "          6.0430, -1.7645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.103102995766713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4437,   8.3341,  -1.6328, -11.1935,  -1.7919,  -1.5268,  -1.7116,\n",
      "          -4.7770,  17.6552,  -1.9324]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 17.655201860044595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1240,  11.9404,  -2.4468,   0.9222,  -2.3684,  -1.6337,  -2.7453,\n",
      "         -12.1278,  13.8352,  -2.9700]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.835164511712101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4959,  8.5180, -1.7886, -3.2415, -1.8376, -1.2594, -1.9131,  2.8747,\n",
      "          2.6400, -2.3990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 8.517957751106833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2737, 16.5920, -2.1436, -7.7295, -1.7708, -1.0434, -1.8745, -1.5457,\n",
      "          3.5315, -1.9358]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 16.59201628299498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9736, 10.7470, -1.2089, -5.3023, -1.2647, -0.8425, -1.5048,  0.7114,\n",
      "          0.6721, -1.4464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 10.747014641772102\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6848,  6.6059, -1.9346, -0.3432, -1.8213, -1.5621, -1.9532, -2.0923,\n",
      "          6.5846, -2.4095]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.605850743526878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0212,  9.3155, -1.4662, -5.3499, -1.4873, -1.1603, -1.7325, -3.0920,\n",
      "          7.8794, -2.0413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.315459106615084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3734, 11.0647, -1.6839, -7.4238, -1.5389, -1.2797, -1.7024, -1.3894,\n",
      "          7.8476, -2.0331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 11.064713993450157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8806,   3.2905,  -2.5721,  12.1959,  -2.4023,  -1.9498,  -2.5990,\n",
      "         -17.3884,  17.9619,  -3.2936]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 17.96186256054317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4577,  10.5045,  -1.8784,  -5.1072,  -1.7944,  -1.5478,  -1.9816,\n",
      "         -16.3608,  22.2086,  -1.9872]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.208582449335378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3076,  3.0246, -1.5129, -3.4947, -1.7510, -1.5219, -1.7644, -6.0852,\n",
      "         16.2343, -2.1368]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 16.234344837085214\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2110,  6.1181, -1.4526, -1.3130, -1.2429, -1.1742, -1.6468, -1.5575,\n",
      "          5.3531, -1.9051]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.118101659671122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1117,   9.5818,  -2.7323,  -2.5176,  -3.3289,  -2.3254,  -3.0316,\n",
      "         -14.4654,  24.3013,  -3.6260]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 24.301312648432148\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4453,   4.4824,  -2.1871,   8.0699,  -2.2352,  -1.6235,  -2.1347,\n",
      "         -20.5136,  21.3166,  -2.8203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 21.316570991983543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0706,  3.1397, -1.3481, -6.2227, -1.6124, -1.4191, -1.3261, -8.4430,\n",
      "         20.4492, -1.8336]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.449225835638586\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0672,  15.8495,  -2.2522, -11.3953,  -2.2281,  -1.7799,  -2.6940,\n",
      "         -10.9942,  21.4255,  -2.5616]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.4255414772255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2039,  7.8008, -1.4386, -4.8710, -1.4689, -1.0097, -1.4966, -4.1717,\n",
      "         10.1086, -1.8136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.108637482514084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5228,  12.1220,  -2.0491,  -7.8923,  -2.2551,  -1.6318,  -2.0706,\n",
      "         -13.7126,  23.6411,  -2.6286]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 23.64109186728226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9294,  10.7713,  -3.3975,   9.8107,  -3.8306,  -2.8516,  -3.6537,\n",
      "         -12.1226,  12.6380,  -4.5347]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.638045783453855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2022,   4.9084,  -1.6769,   0.5271,  -1.6022,  -1.1666,  -1.6992,\n",
      "         -13.6183,  19.3158,  -2.2810]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.315779969035912\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1740, 11.0389, -1.2465, -6.6568, -1.2588, -1.1246, -1.6739, -0.8077,\n",
      "          4.1449, -1.6616]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.038939966583152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2114,  6.2497, -1.3010, -7.0176, -1.1890, -1.3299, -1.4442,  2.5058,\n",
      "          5.9458, -1.5968]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  7\n",
      "activation[1] = 6.249721485610941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4051,   3.5817,  -1.5636, -10.5797,  -1.9287,  -1.5710,  -1.6610,\n",
      "          -3.4580,  21.1007,  -2.2918]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.100716559561175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4004,   9.8224,  -2.9722,   1.1978,  -3.4656,  -2.4428,  -2.8162,\n",
      "         -27.3555,  35.1500,  -4.1918]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 35.14996744296386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1666, 10.0948, -1.3289, -2.8138, -1.3254, -0.8418, -1.5608, -5.8069,\n",
      "          7.2864, -1.4147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 10.094793961807648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3905,   9.0993,  -2.8192,   6.8181,  -2.9846,  -2.4574,  -3.0979,\n",
      "         -18.8528,  20.3379,  -3.8303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 20.337936529153666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9271,   5.4047,  -2.9035,   3.8336,  -3.1342,  -2.2121,  -2.9754,\n",
      "         -20.6379,  30.6208,  -3.8901]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.620752335998766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6000,  5.8433, -1.9372,  1.5349, -1.6939, -1.5632, -2.0286, -3.6028,\n",
      "          6.9084, -2.3583]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 6.908364829340095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1800, 12.8990, -2.3262, -5.0569, -2.4435, -2.0363, -2.7603, -3.0967,\n",
      "          9.5483, -3.1464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.898988890963048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1172, 10.6095, -1.2028, -4.8621, -1.4971, -0.8311, -1.4922, -5.3608,\n",
      "          8.1128, -1.4964]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 10.609485850495753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5940, 17.1144, -2.0962, -0.2537, -1.8229, -1.4164, -2.1219, -8.2751,\n",
      "          2.8390, -2.1130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.114437429995444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6602,   9.7771,  -1.4331,  -3.6356,  -1.6462,  -1.4839,  -1.8707,\n",
      "         -11.1154,  15.5184,  -1.9464]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.518421155943072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3040,  15.8128,  -4.0226,   0.2966,  -4.5208,  -3.4381,  -4.4890,\n",
      "         -13.7596,  23.9015,  -5.4275]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 23.90145157186289\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8895,   7.4303,  -1.3372,  -3.9517,  -1.2875,  -0.7887,  -1.2044,\n",
      "         -11.3626,  16.3180,  -1.3828]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.317990278221327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6644,  14.9732,  -2.1575,  -6.3146,  -2.4196,  -1.8154,  -2.2609,\n",
      "         -16.0203,  21.6592,  -2.5225]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.65920122133667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6606,  9.5617, -1.7955, -6.8387, -1.8213, -1.7097, -2.2164, -1.8423,\n",
      "         10.2305, -2.4840]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.23054981033128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7556,  10.2874,  -3.6532,   8.6601,  -3.8198,  -2.8095,  -3.6676,\n",
      "         -27.7622,  31.2977,  -4.8520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 31.297717195323585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8109,  6.2081, -1.9651, -7.8407, -2.3959, -1.9762, -2.2981, -1.5139,\n",
      "         16.0962, -2.7557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 16.09615953703555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6149,   6.6794,  -2.2644,  -2.9706,  -2.0433,  -1.9748,  -2.3415,\n",
      "         -17.5525,  28.5114,  -2.8340]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 28.511376740692338\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8987,  5.0872, -0.8110, -0.5237, -1.2065, -0.8339, -1.2076, -6.5020,\n",
      "          8.3483, -1.3790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 8.348301352536993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5424,   8.7098,  -1.6582, -14.0263,  -2.2241,  -1.3486,  -1.9282,\n",
      "          -9.4608,  27.1873,  -2.4920]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 27.18731506892372\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4973,  6.9597, -0.7743, -5.1295, -0.5338, -0.6051, -0.8733, -1.1315,\n",
      "          3.6419, -0.8047]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 6.959709931254456\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7109,  20.1890,  -3.2389,  -4.6962,  -3.8175,  -2.6113,  -3.5933,\n",
      "         -21.9503,  26.5760,  -4.5063]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 26.576026849072125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2853,  6.8152, -1.4997, -4.8513, -1.5576, -1.4856, -1.5042, -4.0980,\n",
      "         11.7305, -1.8880]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.730490009230033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2521,   8.9027,  -1.4718,  -9.8864,  -1.5797,  -1.2050,  -1.6579,\n",
      "         -12.7029,  23.2754,  -1.7101]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.275382082468237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9007,  14.7775,  -3.5546,   5.8185,  -3.6669,  -2.6905,  -3.7992,\n",
      "         -17.8197,  19.0200,  -4.7313]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 19.02002479538636\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8372,   7.6546,  -2.6620,   5.2958,  -2.9802,  -1.9873,  -2.6672,\n",
      "         -21.3002,  26.1415,  -3.4427]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.141549072412527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6523,  2.3547, -0.7945, -5.4328, -0.8402, -0.6938, -1.1004, -4.8673,\n",
      "         13.3903, -1.0700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 13.390282882275901\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1498, 15.0995, -2.4240, -6.3307, -2.4755, -1.8700, -2.9561, -3.3244,\n",
      "          9.5139, -3.2254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.099500643877557\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7126, 21.5936, -1.9908, -5.5113, -2.0525, -1.3921, -2.2506,  0.3340,\n",
      "         -5.5032, -2.3636]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.59356209469414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8054, 20.5309, -2.4405, -8.1949, -2.0097, -1.8784, -2.4286, -5.5893,\n",
      "          6.8261, -2.5718]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 20.530885689403522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2216,   9.3067,  -2.6330,   3.0417,  -2.7905,  -2.2811,  -3.0510,\n",
      "         -18.1621,  22.5010,  -3.5256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 22.501004592753713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5789,  16.7828,  -3.0073,  -5.7792,  -3.3895,  -2.6799,  -3.6272,\n",
      "         -19.9114,  28.8786,  -3.9217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 28.87859559730177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1751,   4.8037,  -2.5178,   8.2884,  -2.5029,  -1.8321,  -2.7487,\n",
      "         -12.8314,  14.5249,  -3.3975]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 14.524948301882802\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6760,  18.4960,  -2.7975,  -4.9627,  -3.4964,  -2.2960,  -3.1117,\n",
      "         -10.0919,  14.8772,  -3.8014]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 18.495958210983616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1448,  4.4099, -1.3929,  0.9129, -1.3913, -1.0977, -1.4742, -9.3432,\n",
      "         13.0765, -1.7458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.076460545982837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5567,  15.0146,  -1.9803, -11.5106,  -2.0641,  -1.4544,  -2.3636,\n",
      "           4.3166,   5.3586,  -2.9343]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 15.014551964804062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2496,   7.0103,  -1.7292,   0.8529,  -1.7848,  -1.2118,  -1.5545,\n",
      "         -21.8785,  24.9719,  -2.2070]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 24.971858489543607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5654,  16.1252,  -3.0486,  -4.9010,  -2.9638,  -2.3177,  -3.4391,\n",
      "         -15.6206,  24.1070,  -3.9033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.107008083167702\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6516,  4.2171, -2.1135,  3.5206, -2.1081, -1.8405, -2.4309, -6.4978,\n",
      "         12.1314, -2.7007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.131397373639519\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9975,   8.9682,  -2.3288, -10.3998,  -2.6614,  -1.8883,  -2.4151,\n",
      "          -6.9213,  23.8508,  -2.9994]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 23.850750147335862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8671,   5.9792,  -2.4775,   4.2144,  -2.5649,  -2.0246,  -2.7408,\n",
      "         -12.9360,  17.5806,  -3.0478]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.580552493337034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5645,  19.7412,  -4.6111,  -0.1002,  -4.7670,  -3.6970,  -4.7361,\n",
      "         -24.9464,  33.0339,  -5.7753]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 33.03385766653146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0855, 12.6423, -2.1258,  1.3281, -2.3068, -1.8375, -2.5585, -9.1725,\n",
      "          9.4101, -2.8690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.642294704742795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5635,  11.8127,  -1.9680, -11.5612,  -1.7526,  -1.5999,  -2.2098,\n",
      "          -2.9129,  14.4213,  -2.5335]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.421260295523416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5032,  4.8804, -0.5917, -4.0087, -0.8488, -0.5307, -0.5469, -3.7874,\n",
      "          7.9338, -0.8992]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 7.933798463055127\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4658,   8.8453,  -2.1806,  -4.5824,  -2.3426,  -1.4846,  -2.4494,\n",
      "         -16.6549,  27.7083,  -2.9864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.70826390426358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2395, 10.1119, -1.1861, -8.7541, -1.3225, -1.0800, -1.7362, -4.8626,\n",
      "         11.8141, -1.7448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 11.814067383344142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0474, 10.7299, -1.9916, -6.0100, -2.0747, -1.8831, -2.3978,  0.1602,\n",
      "          7.7087, -2.6993]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 10.729922535956709\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3772,  13.4066,  -1.8144,  -1.4281,  -1.8314,  -1.2176,  -1.9896,\n",
      "         -10.9475,   9.2651,  -2.2402]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.40661632390797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2202, 17.1092, -1.7254, -7.0240, -1.4504, -1.3403, -1.8421, -3.9744,\n",
      "          3.8268, -1.7201]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.109226025533207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1403,   5.0943,  -1.2867,  -4.7792,  -1.7874,  -1.1432,  -1.5587,\n",
      "         -14.2098,  22.1631,  -1.7100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.163093842712254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1361,  14.8822,  -4.0618,   6.9618,  -4.4554,  -3.3236,  -4.3968,\n",
      "         -18.2465,  21.6615,  -5.2794]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 21.661504359771865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0951,   8.7078,  -1.3216, -11.6181,  -1.3428,  -1.0684,  -1.4077,\n",
      "         -11.2319,  22.2161,  -1.4303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.216103863054773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9701,  12.1983,  -2.3362,  -2.1049,  -2.3854,  -1.8448,  -2.1722,\n",
      "         -12.5874,  16.6591,  -2.8081]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.65914549835744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8265,   4.0430,  -1.2673,  -1.6285,  -1.1763,  -1.1657,  -1.3246,\n",
      "         -11.1436,  17.2662,  -1.2396]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 17.266193867460988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0166,   9.6856,  -4.0046,  14.4813,  -4.3770,  -3.2037,  -4.3769,\n",
      "         -25.2940,  26.6211,  -5.1970]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.621087092211777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6459,  7.3756, -0.6791, -6.6810, -0.7890, -0.7228, -0.8116, -3.2417,\n",
      "          8.3269, -1.0910]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 8.326916889307654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6762, 10.3651, -2.3824, -0.4303, -2.5481, -1.6619, -2.4078, -9.4970,\n",
      "         14.3858, -3.1555]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.385816945355206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3108,  8.9055, -1.3407, -0.4720, -1.5258, -0.9783, -1.4406, -5.6418,\n",
      "          6.7101, -1.6801]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 8.905503870947987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7244,   6.5820,  -1.9114, -14.3723,  -2.0904,  -2.0174,  -2.2308,\n",
      "           0.1970,  20.2606,  -2.8083]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.260643538624237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2688,  9.0778, -1.5038, -6.6635, -1.6027, -1.4809, -1.6609, -9.5357,\n",
      "         16.9517, -1.5825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.951667066798112\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8410,  18.7764,  -3.3631,  -8.3007,  -3.6193,  -2.5739,  -3.4948,\n",
      "         -10.5583,  19.9252,  -4.3978]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 19.925162452204628\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5857, 14.7288, -1.8528, -4.7301, -1.9325, -1.6975, -2.4420, -5.8117,\n",
      "          6.9698, -2.1568]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 14.728846699953445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0163,  9.3496, -2.1934, -9.7470, -2.3604, -1.8633, -2.3630, -1.2639,\n",
      "         15.4367, -3.0525]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.436680907487304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4051,  9.2674, -1.8993, -2.6521, -1.9481, -1.5041, -2.0001, -7.6447,\n",
      "         12.0541, -2.2303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 12.054054051745682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2024,   9.1286,  -3.1223,   5.3114,  -3.3502,  -2.5192,  -3.3328,\n",
      "         -21.6038,  28.2914,  -4.1955]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.291367862867585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7136,   3.5580,  -1.2818,   1.6547,  -1.2965,  -0.8158,  -1.3351,\n",
      "         -10.2820,  13.1690,  -1.7246]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.168964914606116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5798,  6.7015, -1.7512, -8.0300, -1.8907, -1.5789, -2.0121, -0.9475,\n",
      "         12.9458, -2.2914]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 12.945841702448416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3944,  7.4472, -1.8070,  0.6468, -2.0249, -1.4245, -2.0349, -8.0224,\n",
      "         10.7897, -2.2506]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 10.78974875308436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2420,  11.2624,  -2.8518,  -8.6310,  -3.1490,  -2.4798,  -3.0432,\n",
      "         -13.4636,  28.7326,  -3.9369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 28.73259053747496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6075,  8.3103, -1.7720,  2.9600, -1.7783, -1.2796, -1.9270, -8.9064,\n",
      "          9.2859, -2.3171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 9.285916452170575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6857,  6.5089, -1.8650, -3.8603, -1.9966, -1.5454, -1.8680, -7.6877,\n",
      "         16.4054, -2.4092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.40543569195246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0584,   5.6221,  -1.2247,   0.9423,  -1.5908,  -0.9494,  -1.6657,\n",
      "         -11.4271,  13.7987,  -2.0813]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 13.798711340251604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5870, 15.2512, -2.9271, -9.4710, -3.1467, -2.4704, -3.0727, -4.6521,\n",
      "         16.7060, -3.7361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.70598079762257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3207,  8.9852, -1.3254, -2.2223, -1.5262, -0.9712, -1.6475, -1.1654,\n",
      "          3.1363, -1.6663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 8.985202274548646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2543,  10.8576,  -3.1521,  -0.4656,  -3.3984,  -2.0580,  -3.4404,\n",
      "         -19.8502,  30.0968,  -4.0659]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.096796594812975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2263,  3.6677, -1.3844, -0.2459, -1.4107, -1.0310, -1.7830, -2.9528,\n",
      "          9.0578, -1.8030]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 9.057775948977103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2949,  19.7151,  -2.3192, -12.0551,  -2.5331,  -1.9830,  -2.9329,\n",
      "           1.2351,   5.8022,  -2.9713]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.715127665433815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3342,  6.5762, -1.4746, -2.7167, -1.3501, -1.1862, -1.6710, -0.0617,\n",
      "          5.1133, -1.9975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.576182032900864\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8177,  12.2666,  -1.9332,  -1.7467,  -2.4663,  -1.8078,  -2.3425,\n",
      "         -12.7165,  15.5910,  -2.5874]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.590969861884487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4709,  12.3102,  -1.4063, -10.1769,  -1.5183,  -1.1614,  -1.6666,\n",
      "          -4.9165,  12.6255,  -1.8587]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 12.625472307865863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1633,   2.5701,  -2.7702,   8.3446,  -2.8345,  -2.1393,  -3.1227,\n",
      "         -10.0411,  16.9832,  -3.7019]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 16.98322675741393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4644,  15.0988,  -3.0369,   6.7302,  -3.1204,  -2.2276,  -3.1611,\n",
      "         -17.4256,  14.2419,  -3.7872]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.098829410581235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0499, 19.0699, -2.3786, -7.9666, -2.4140, -1.8565, -2.7594,  1.1790,\n",
      "          1.2095, -2.8488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.06988305311971\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7621,  6.7296, -1.0843, -7.7270, -1.0216, -0.9388, -1.2729, -1.5587,\n",
      "          9.4135, -1.2431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 9.413470419561339\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6003,   9.5813,  -2.3311,  -1.9363,  -2.4787,  -1.5975,  -2.4735,\n",
      "         -12.9314,  19.9516,  -3.0290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.951635916921543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0226,   8.5624,  -1.2237,  -7.1538,  -1.4249,  -1.2612,  -1.4636,\n",
      "         -12.6140,  20.5627,  -1.3567]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 20.562709608144175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7079,   5.6029,  -2.0451, -10.6749,  -2.2034,  -2.0101,  -2.3166,\n",
      "          -0.7463,  18.4135,  -2.7386]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.413484205026286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4771, 11.2639, -2.9780, -1.1828, -3.1376, -2.4916, -3.4652, -9.8463,\n",
      "         18.3583, -3.7911]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 18.358282048241083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8556,  10.5719,  -3.3284,   7.0547,  -3.6437,  -2.8299,  -4.0036,\n",
      "         -11.9978,  16.4313,  -4.3737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 16.431268293418032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3111,   9.7383,  -1.1491,  -3.3745,  -1.6030,  -1.2407,  -1.5329,\n",
      "         -11.0255,  13.2331,  -1.5536]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.233070249151764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9190,  11.6219,  -2.6363,   1.1931,  -2.4251,  -1.7511,  -2.4672,\n",
      "         -15.9025,  17.5614,  -2.7292]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.56140776731283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0614, 18.0698, -3.4433, -7.0293, -3.8306, -3.1116, -3.9418, -7.7898,\n",
      "         19.5387, -4.7957]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.538749973917476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4623,   7.7902,  -1.4909,  -6.0715,  -1.8011,  -1.4512,  -1.4139,\n",
      "         -13.4087,  21.6746,  -1.9656]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.674585267981954\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7591,   9.8933,  -2.1799,   0.4534,  -2.9965,  -2.0301,  -2.4216,\n",
      "         -22.5834,  28.3665,  -3.1733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.366547834265685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4511e+00,  9.4361e+00, -3.1878e+00,  4.5779e-03, -3.6225e+00,\n",
      "         -2.4791e+00, -3.1896e+00, -2.6105e+01,  3.8369e+01, -4.3855e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 38.36946217732327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4642,  8.1060, -1.6612, -1.4457, -1.9230, -1.5206, -1.7769, -5.2782,\n",
      "          8.7912, -2.1699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 8.791237369901765\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7034,  10.7406,  -3.4969,   7.9033,  -3.6589,  -2.5218,  -3.9919,\n",
      "         -15.3271,  18.9054,  -4.5144]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 18.90541689029699\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9872,  9.8048, -2.4433, -0.0702, -2.6168, -2.0656, -2.7664, -6.3307,\n",
      "         13.1896, -3.2440]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 13.18957074098323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3307, 15.4734, -2.7934, -1.2139, -2.9599, -2.1586, -2.9259, -8.9081,\n",
      "         11.5501, -3.4384]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 15.473396222857376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7954,  12.0315,  -2.1837,  -2.6445,  -2.2846,  -1.6258,  -2.2228,\n",
      "         -13.8612,  17.4940,  -2.3705]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.494016832654104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8737,   7.1304,  -2.1649, -14.9165,  -2.3029,  -2.0537,  -2.3576,\n",
      "          -0.0227,  21.6703,  -2.9233]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.6703077082944\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8959,  6.4834, -1.2277, -5.6059, -1.3266, -1.0204, -1.3732, -8.5370,\n",
      "         15.4943, -1.3781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.494338427315842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6076, 10.7287, -3.4798,  6.6188, -3.3009, -2.5511, -3.6950, -4.4993,\n",
      "          7.4937, -4.0038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 10.728662008628985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9991,  5.1536, -1.0231, -2.2258, -0.9321, -0.8784, -1.2156,  0.2761,\n",
      "          3.1987, -1.3663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 5.153576463856423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9167,  8.9415, -2.0484, -4.1274, -2.1969, -1.5760, -2.0196, -0.5031,\n",
      "          8.0382, -2.5715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 8.941512558998562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8363,  7.2843, -2.0608, -1.0909, -2.2236, -1.7812, -2.3316,  0.7880,\n",
      "          5.8475, -2.7631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 7.284322805004459\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7926, 11.0077, -1.9385, -5.4883, -2.0887, -1.6782, -2.1425, -6.0851,\n",
      "         12.9975, -2.6603]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 12.997536593815735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1595,   9.3109,  -2.3921,   0.7339,  -2.6745,  -1.9794,  -2.8104,\n",
      "         -16.6880,  22.6079,  -3.0325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.60788715059189\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3706,  8.4130, -2.8279,  6.8515, -3.0630, -2.3817, -3.5214, -7.7101,\n",
      "         11.4496, -3.7434]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.449627235312315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3460,  5.8892, -1.5701, -3.0394, -1.2416, -1.2256, -1.6694,  0.4834,\n",
      "          5.1296, -1.8772]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 5.889239158426394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8834,  19.8399,  -3.6102,  -2.5388,  -3.8407,  -2.8912,  -3.7082,\n",
      "         -18.8527,  22.5984,  -4.6761]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 22.598431498390493\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7592,   9.5802,  -1.9781, -12.3180,  -2.1547,  -1.8952,  -2.4434,\n",
      "          -3.3791,  19.1543,  -2.7446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.15433060734876\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4913,  7.3359, -1.5953, -3.7965, -1.4757, -1.3675, -1.7705,  0.4328,\n",
      "          5.4455, -2.0975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.335864633226869\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5542,  3.3728, -0.6338, -7.2579, -1.1695, -0.5965, -1.1478, -3.4895,\n",
      "         12.6136, -0.9687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 12.613599470498714\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0691, 15.4792, -2.2700, -2.8894, -2.0708, -2.2387, -2.6437, -6.2710,\n",
      "          8.0493, -2.8889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.479231941254904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6071,  12.9515,  -3.1710,  -5.7659,  -3.3382,  -2.5265,  -3.5666,\n",
      "         -20.0408,  32.4856,  -4.0773]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 32.48557402360523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0391, 10.0490, -2.2347, -4.4226, -2.3640, -1.7853, -2.3169, -6.5989,\n",
      "         14.0722, -2.7800]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.072185470302284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2428, 10.5216, -1.2204, -9.7219, -1.4627, -0.8233, -1.4193, -8.5397,\n",
      "         16.6173, -1.5627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.61734413719485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9293,  11.0179,  -2.2152,  -1.8514,  -2.2487,  -1.6612,  -2.4174,\n",
      "         -11.5599,  16.8929,  -2.8790]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.89287943194252\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9225,  11.6836,  -2.2925,   3.0883,  -2.6606,  -2.0449,  -2.6907,\n",
      "         -13.5423,  14.8780,  -2.8570]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.877992052320874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0636,  5.0809, -2.3495, -9.2331, -2.4254, -2.0417, -2.4644, -7.5727,\n",
      "         26.2146, -2.9551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.214555945771853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6390, 15.2900, -1.8546, -6.9466, -1.8185, -1.5766, -2.4610, -3.7857,\n",
      "          7.0205, -2.3941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.29004380110033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0032,  12.0878,  -3.8607,   7.7133,  -4.0826,  -2.8257,  -4.1982,\n",
      "         -20.5305,  24.8045,  -5.1156]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 24.804524964479118\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1720, 12.5259, -2.8056, -1.8863, -2.5329, -1.9150, -2.7218, -8.0311,\n",
      "         15.0714, -3.3944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.071364153947147\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4041,   5.0369,  -2.0188,  -0.5614,  -1.8782,  -1.5398,  -1.9675,\n",
      "         -15.9983,  24.3240,  -2.5349]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.323974012273673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4893,  5.0729, -1.3643, -4.1001, -1.7971, -1.5071, -1.7419, -1.7251,\n",
      "         10.5561, -2.0083]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.556141559072692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6209,  14.3589,  -3.2138,   0.5740,  -3.6516,  -2.5445,  -3.6158,\n",
      "         -20.3309,  25.0603,  -4.4014]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 25.06032049457533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8090,   7.8925,  -0.9979, -13.3490,  -0.9053,  -0.7054,  -1.1741,\n",
      "          -5.3514,  16.7765,  -1.0284]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.776468487873434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9158,   8.3062,  -2.5072,   2.7163,  -3.1180,  -2.1563,  -3.0081,\n",
      "         -21.7501,  27.9901,  -3.4082]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.99009913006324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2557,  7.8984, -1.7643, -6.3264, -1.5473, -1.3482, -1.6703, -8.0369,\n",
      "         15.9302, -1.9082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.930213848155775\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.8430,  22.3463,  -4.8954,   0.5338,  -5.1951,  -3.6892,  -5.2279,\n",
      "         -17.6062,  25.6278,  -6.1493]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.627809538268835\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1693,  15.9371,  -2.6978,  -0.7172,  -2.9784,  -2.1286,  -3.2940,\n",
      "         -12.6607,  15.2423,  -3.5256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.937134192740912\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8574,  13.4766,  -3.5268,   2.1766,  -3.5262,  -2.7106,  -3.6119,\n",
      "         -14.6078,  21.1884,  -4.7711]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 21.188372213540017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6256,  11.9544,  -2.1192,  -2.0079,  -2.2204,  -1.6370,  -2.5847,\n",
      "         -18.1259,  21.3155,  -2.6651]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.315494100878226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3527, 12.3780, -2.6931,  0.0730, -3.0073, -2.0142, -2.5484, -7.6547,\n",
      "         11.7571, -3.4981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 12.377971611156617\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0929,  3.8565, -1.0918, -5.0996, -1.2746, -1.0487, -1.3141, -2.4963,\n",
      "         11.7790, -1.5933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 11.779018372552894\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4687,  13.3875,  -3.4146,  -3.9261,  -3.5574,  -2.4684,  -3.7184,\n",
      "         -17.9267,  30.8532,  -4.4463]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.85315730568868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8196,  7.9785, -1.2752, -5.4226, -1.3490, -0.8494, -1.3064, -0.4904,\n",
      "          5.9132, -1.6869]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 7.97850461078809\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.7096,  17.0589,  -4.4107,   5.1073,  -4.6005,  -3.4667,  -4.9287,\n",
      "         -14.1188,  19.7078,  -5.6220]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.707765195114757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5079,  14.2854,  -2.6490,  -0.0895,  -3.2236,  -2.5672,  -3.5579,\n",
      "         -12.7263,  16.7990,  -3.5897]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 16.798997743266266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0655,  11.3290,  -2.3712,  -2.2880,  -2.8946,  -1.9120,  -2.5357,\n",
      "         -14.8863,  20.5662,  -3.0661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.56615678488738\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2718,  11.0546,  -1.7792,  -6.0861,  -2.2642,  -1.5357,  -2.2681,\n",
      "         -16.4587,  23.1597,  -2.3863]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 23.15971029445948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6294,  3.7776, -1.9265, -3.2155, -2.1947, -1.7578, -1.9658, -8.0993,\n",
      "         19.4989, -2.6301]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.498889056505387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2913,  8.7674, -0.8966, -5.0127, -1.5993, -1.1166, -1.5625, -8.1520,\n",
      "         12.8137, -1.6842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.813696435481983\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6561,  8.0932, -1.6237, -4.0666, -1.6708, -1.4281, -2.0143,  0.2162,\n",
      "          5.7929, -2.2512]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.09316421866484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9726,   1.7943,  -2.4020,  11.0903,  -2.5462,  -2.1258,  -2.3648,\n",
      "         -21.9371,  24.0609,  -3.2855]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 24.0609039037446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1198,  17.9623,  -2.5504,  -2.7462,  -2.9516,  -2.0787,  -2.7161,\n",
      "         -18.6029,  19.9741,  -3.0553]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 19.97414499019251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2541,   3.5358,  -1.7518,   1.1601,  -1.8543,  -1.5362,  -1.7567,\n",
      "         -18.3200,  25.7985,  -2.1741]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 25.798492170471913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9111, 11.5319, -2.4133, -3.0408, -2.5369, -1.8287, -2.9114, -7.2119,\n",
      "         15.2416, -3.1738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 15.241611443254522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7935,  2.8003, -0.7880, -3.3165, -1.1339, -0.7772, -1.0044, -7.2436,\n",
      "         13.7301, -1.2176]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 13.730136153466258\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1431,   6.8658,  -2.5874,  -9.6408,  -2.9512,  -2.2869,  -2.8977,\n",
      "         -14.1933,  34.5243,  -3.5499]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 34.52430384995697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9380,  12.8593,  -2.0858,  -5.2902,  -2.0339,  -1.7998,  -2.4311,\n",
      "         -16.5246,  22.1365,  -2.4012]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.13653519627813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0233,   8.3805,  -2.3517,  -1.0956,  -2.3607,  -1.7943,  -2.5959,\n",
      "         -15.1177,  22.6748,  -3.0489]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.674786516616532\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9184,  13.5122,  -2.3168,  -3.3243,  -2.4101,  -1.6876,  -2.6818,\n",
      "         -15.4030,  21.3653,  -3.0539]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.36525470030266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4937, 17.9388, -1.8497, -5.3964, -1.7112, -1.4576, -2.0732, -5.9650,\n",
      "          4.2940, -2.0159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.938834090111836\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9117,  9.3757, -0.8948, -4.2810, -0.9156, -0.9060, -1.1513,  0.0550,\n",
      "          0.8261, -1.1851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 9.37566505478794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2821, 14.1272, -2.4690, -6.3639, -2.6181, -2.1345, -3.0789, -0.4212,\n",
      "          8.1291, -3.3029]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.12721236976038\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0697,  8.1716, -1.0942, -3.7994, -1.0423, -0.8193, -1.4921, -6.3760,\n",
      "          9.7744, -1.2924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 9.774364984364505\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1476,  13.1945,  -3.7336,   3.0581,  -3.9932,  -2.8993,  -3.8913,\n",
      "         -10.4057,  17.2595,  -5.0838]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.25947107722831\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5910,  8.6856, -1.8106, -3.2442, -1.7928, -1.4662, -1.9815, -6.0333,\n",
      "         11.6944, -2.2741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.694358984134194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2124,  13.2855,  -4.4580,   6.8665,  -4.4218,  -3.2368,  -4.4603,\n",
      "         -17.9728,  24.6090,  -5.5167]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 24.60895114843125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8725,  11.0321,  -2.2338,   0.4587,  -2.3096,  -1.7890,  -2.3825,\n",
      "         -12.3683,  13.8181,  -2.6925]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.818088488040853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0447,  14.5146,  -2.8146,  -6.2579,  -2.9113,  -1.9610,  -2.5843,\n",
      "         -13.4561,  22.7154,  -3.4207]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.71541391834513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2901,   2.7045,  -1.6918,   4.5237,  -1.7531,  -1.2492,  -1.7288,\n",
      "         -19.7200,  22.7764,  -2.3640]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 22.776364029356802\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5803,  10.6419,  -3.5088,   4.4858,  -3.8184,  -2.6241,  -3.8462,\n",
      "         -22.8167,  30.1065,  -4.7122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 30.10650010209057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9249,   9.0459,  -1.9876,  -2.0183,  -2.4987,  -1.8816,  -2.4679,\n",
      "         -10.0869,  16.8017,  -2.7687]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 16.801737997158746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9377,  20.2343,  -3.8184,  -7.2420,  -4.1532,  -2.6187,  -4.1643,\n",
      "         -15.4918,  27.1642,  -5.0268]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.164222662429896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0559,   7.2498,  -1.7494,  -1.6349,  -1.7624,  -1.2155,  -1.7393,\n",
      "         -17.6879,  22.0005,  -2.2440]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 22.00045430716058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8769,  16.7086,  -3.4707,   1.0015,  -3.7563,  -2.7522,  -3.4103,\n",
      "         -20.0739,  22.8735,  -4.6075]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 22.87349282626378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9649,  12.9615,  -2.4316,  -3.0922,  -2.8494,  -2.1496,  -2.6073,\n",
      "         -19.9756,  25.5764,  -3.1218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 25.576448062610982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1537,  12.3412,  -2.3747,  -7.1619,  -2.7307,  -2.1734,  -2.4898,\n",
      "         -10.3535,  20.8253,  -3.1494]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.825291519980333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1639,  20.0644,  -2.8047,  -4.6299,  -2.9187,  -2.1023,  -2.8348,\n",
      "         -19.5321,  21.2809,  -3.1550]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 21.280909992938238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2691,  13.1970,  -3.0037,  -5.9404,  -2.8581,  -2.0876,  -3.2249,\n",
      "         -21.1821,  33.0310,  -3.7204]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 33.031012754232435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4570,  8.0356, -1.5685, -5.0632, -1.8300, -1.2004, -1.6113, -2.3158,\n",
      "          9.4002, -2.0971]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 9.400242501173679\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0190,   5.4613,  -2.3665,  -8.1701,  -2.7457,  -2.2116,  -2.6871,\n",
      "         -13.3557,  31.7770,  -3.1356]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 31.776971065517404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7142,  7.9458, -2.0359, -1.8863, -1.6766, -1.6036, -2.1440, -0.4832,\n",
      "          5.4471, -2.4283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.9458176391349875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9717,  17.9544,  -4.1314,   5.3066,  -4.2003,  -2.9308,  -4.0368,\n",
      "         -22.7112,  25.0264,  -5.2185]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.026370770909736\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6658,  11.3091,  -3.1833,  -4.5601,  -3.4609,  -2.7542,  -3.6647,\n",
      "         -10.6195,  24.2376,  -4.1550]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 24.237591875661867\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6651,   9.0747,  -3.3256,   4.9170,  -3.4605,  -2.5201,  -3.7391,\n",
      "         -16.4645,  23.6009,  -4.3860]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 23.600868482205737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9206,  3.3556, -1.1502,  0.3065, -0.9539, -0.8756, -1.2045, -0.6448,\n",
      "          3.2667, -1.4048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 3.3556400080412248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5465,  14.8658,  -3.0045,  -2.3416,  -3.3776,  -2.6337,  -3.1947,\n",
      "         -17.1855,  23.2505,  -4.0710]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 23.250541296258906\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7588,   5.7632,  -1.0221,  -6.2113,  -1.3958,  -0.6125,  -1.2118,\n",
      "         -14.0508,  22.8175,  -1.5076]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.81750050212613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4970,  9.3825, -1.7963, -3.4647, -1.6586, -1.4269, -2.1097, -1.9193,\n",
      "          7.1966, -2.4335]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.382483400805882\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8087,  10.3269,  -2.3319,  -0.5397,  -2.6050,  -2.0928,  -2.5715,\n",
      "         -17.7301,  22.2519,  -3.0346]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 22.25187826289996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3988, 12.6520, -2.9051, -3.1866, -2.8424, -2.5382, -3.3152, -8.9668,\n",
      "         16.8422, -3.2570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 16.84217974320101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5043,  9.8538, -1.5049, -3.3272, -1.6809, -1.6481, -2.0544, -6.6264,\n",
      "         10.6848, -2.2767]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.68475047059977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2910,  18.0835,  -2.7364,  -0.5029,  -2.9244,  -2.3568,  -3.1992,\n",
      "         -12.2163,  12.9789,  -3.3294]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.0835344571845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4391, 11.1493, -1.5334, -3.3106, -1.4898, -1.1277, -1.8890, -9.5542,\n",
      "         11.8275, -1.9002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 11.827515054981438\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7200,  10.9174,  -3.0607,   7.0465,  -3.1981,  -2.4827,  -3.4027,\n",
      "         -14.6371,  15.7917,  -3.9874]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 15.791719342834357\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1468,  7.5515, -1.3633, -6.9277, -1.6476, -1.3911, -1.6650, -6.5983,\n",
      "         15.0039, -1.9603]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 15.003927176104952\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3576,  19.2488,  -3.8267,   4.5260,  -4.1148,  -3.0274,  -4.3880,\n",
      "         -14.3396,  15.1949,  -5.1374]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 19.24877516345825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4962,  3.8756, -1.4765, -1.5990, -2.0695, -1.5801, -1.7239, -6.4570,\n",
      "         14.5898, -2.1829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.589814243866426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4155,  12.3884,  -2.8587,  -0.4388,  -2.9695,  -2.1515,  -3.0498,\n",
      "         -15.3597,  21.5562,  -3.8211]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.556240140770598\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5164,  24.2851,  -4.3531,   6.6943,  -4.5898,  -3.2758,  -4.7110,\n",
      "         -21.3430,  17.5805,  -5.5732]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 24.285124961809057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0368,   7.0942,  -2.2931, -10.5996,  -2.5838,  -2.1005,  -2.5518,\n",
      "          -7.9113,  26.2382,  -2.8932]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.238205467939235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4381,   4.5832,  -1.8595,   7.1471,  -1.8339,  -1.4753,  -2.0910,\n",
      "         -17.0257,  17.0220,  -2.4704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.022031902930312\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8527,  16.0241,  -3.2551,   2.7166,  -3.3596,  -2.5380,  -3.7507,\n",
      "         -11.3561,  13.1919,  -4.2118]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.02410510157319\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2904,   8.6358,  -2.7247,   3.0601,  -2.6211,  -2.3093,  -2.8634,\n",
      "         -13.6853,  18.1382,  -3.3720]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 18.138200510815544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0156,  13.2644,  -1.8913,  -3.4951,  -2.2268,  -1.6889,  -2.4244,\n",
      "         -15.8527,  19.0125,  -2.4022]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 19.01245678567789\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5760,  5.7040, -0.4765, -3.8949, -0.5410, -0.5122, -0.7465, -5.0544,\n",
      "          7.8399, -0.5259]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 7.839895762236168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4401,  15.2236,  -2.5442, -10.1036,  -2.8967,  -2.1441,  -2.6042,\n",
      "          -7.0488,  18.3450,  -3.3562]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 18.344966215493375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7884,  12.5580,  -2.1075,  -4.6977,  -2.2468,  -1.7915,  -2.6306,\n",
      "         -10.9617,  17.3534,  -2.6052]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.35338292317754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8315,  12.6891,  -2.2600,  -6.1403,  -2.1431,  -1.8125,  -2.4547,\n",
      "         -19.2469,  27.0408,  -2.7087]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 27.040791231968498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4646,  16.5877,  -1.3791,  -6.7666,  -1.6191,  -1.3958,  -1.8071,\n",
      "         -12.3235,  13.1001,  -1.6008]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 16.587664355799916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9955,  11.8754,  -3.8567,   7.1448,  -3.9675,  -2.8112,  -4.0448,\n",
      "         -16.0433,  20.4192,  -4.8979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.41916258358977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5695,   7.9783,  -3.2960,  12.6115,  -3.4040,  -2.4408,  -3.5466,\n",
      "         -20.5235,  20.7490,  -4.4661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.749011325945755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3146,  18.2508,  -2.3994, -11.8880,  -2.5264,  -2.0121,  -2.8832,\n",
      "           0.6442,   7.4751,  -3.0932]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 18.250772864157796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0670,   5.4525,  -2.5644,   4.2186,  -2.4758,  -1.9592,  -2.5329,\n",
      "         -13.3798,  18.3544,  -3.0790]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 18.354440346086687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2605,  6.0822, -1.5332, -6.1875, -1.6578, -1.2886, -1.5830, -7.7122,\n",
      "         17.0588, -1.8827]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 17.058843892228932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1453,   7.7947,  -2.2950,   7.4567,  -2.6212,  -1.9609,  -2.6820,\n",
      "         -10.5979,   9.6732,  -3.1303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 9.673159557267004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8705, 17.9168, -3.5259, -4.7562, -3.6543, -2.5439, -3.5795, -9.9843,\n",
      "         16.9724, -4.5193]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 17.916812274744085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8868, 11.7395, -2.0682, -2.5676, -2.2509, -1.5960, -2.4198, -6.6138,\n",
      "         10.3367, -2.8287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 11.739537494338615\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0610, 17.6579, -2.2461, -8.5089, -2.3989, -1.9079, -2.8057,  0.6278,\n",
      "          3.6063, -2.7645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.657938153135756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9359,  11.6735,  -2.3565,  -4.6017,  -2.5742,  -1.7671,  -2.4559,\n",
      "         -11.3891,  18.7205,  -2.9919]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.72054057006302\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5626, 12.5055, -1.6444, -8.8415, -1.6462, -1.6169, -2.2127,  2.2928,\n",
      "          4.0438, -2.1505]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.505487123705226\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [8]: loss = 16.204, accuracy = 16.02\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4141, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0432, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4141, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0432, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.1087,  5.3597, -1.2839, -9.9338, -1.3824, -1.2803, -1.4828,  2.1308,\n",
      "         10.7766, -1.8598]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.776572281838925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6723, 12.9855, -2.0408, -4.1331, -2.1851, -1.5253, -2.3401,  1.5156,\n",
      "          2.6382, -2.8461]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 12.9855434464317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2046,  6.1473, -1.1234, -1.5515, -1.6368, -1.0852, -1.3814, -8.2308,\n",
      "         11.8160, -1.6155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.81600497706572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7403, 12.6951, -2.2488, -7.3727, -2.2254, -1.5199, -1.9462, -5.9558,\n",
      "         14.4108, -2.4623]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 14.410819639251521\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3256,   8.5450,  -1.4162,  -2.7958,  -1.9687,  -1.4076,  -1.6232,\n",
      "         -12.4504,  16.1861,  -1.8815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.186127515842994\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2082,  13.1258,  -2.9336,   1.2728,  -2.9498,  -2.3713,  -3.0139,\n",
      "         -15.9297,  19.1310,  -3.5912]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.13101921533682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1251,  1.9471, -1.3399,  0.3829, -1.7153, -1.3700, -1.5371, -6.5211,\n",
      "         13.2079, -1.9113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 13.207912771446836\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6609,  6.3135, -1.9145, -9.2660, -2.1570, -1.7509, -2.0352, -1.9787,\n",
      "         16.7239, -2.5097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 16.72392168361469\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4717,   2.8085,  -1.9646,   6.5409,  -2.2428,  -1.6290,  -2.1558,\n",
      "         -13.8240,  17.5346,  -2.6083]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.53457605229365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0244,  16.6099,  -3.4946,   5.1363,  -3.7139,  -2.7059,  -3.9609,\n",
      "         -19.5618,  19.8091,  -4.6968]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 19.809056627019974\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3197,   5.7566,  -1.6452,   6.1665,  -2.1895,  -1.6315,  -1.8558,\n",
      "         -19.1844,  19.6578,  -2.3855]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 19.657758065985963\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5212,   8.5464,  -1.8852,  -2.4492,  -1.9952,  -1.3782,  -2.0490,\n",
      "         -15.2104,  22.0456,  -2.4886]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.045612629367017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9113,  6.0254, -1.0797, -5.3776, -1.0558, -0.9384, -1.2661, -9.6355,\n",
      "         15.3449, -1.2231]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.3448563429068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5524, 10.5803, -2.1897, -2.4661, -2.2242, -1.4935, -2.1121, -9.1772,\n",
      "         14.5441, -2.8304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.544139889944649\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8273,   5.8346,  -1.4620,   0.2778,  -1.4630,  -1.1045,  -1.3973,\n",
      "         -12.4491,  15.8570,  -1.7681]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.856951350332803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7966,  20.4258,  -3.4932,  -1.2650,  -3.8648,  -2.6612,  -3.6038,\n",
      "         -26.2972,  27.4978,  -4.5616]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 27.49780961620304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5122,   7.8249,  -1.6544,  -0.5080,  -2.1214,  -1.5080,  -2.0855,\n",
      "         -14.5273,  18.0462,  -2.1091]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.046150872189205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0311,  16.7248,  -2.6730,  -5.4407,  -2.9953,  -2.2360,  -3.1990,\n",
      "         -16.3527,  22.3851,  -3.3871]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 22.38507525918582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2429,   6.4530,  -1.7430,   1.2354,  -2.0530,  -1.2562,  -2.2668,\n",
      "         -11.8573,  15.4597,  -2.5343]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.459671034047282\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6396,  19.1174,  -3.2772,  -5.0276,  -3.6142,  -2.2613,  -3.4609,\n",
      "         -16.2963,  21.1231,  -4.2733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.123109375402645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4480,  13.0179,  -1.8111,   0.2089,  -2.2223,  -1.5452,  -2.5138,\n",
      "         -13.7396,  13.1705,  -2.5372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 13.170534147013058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9594,  13.5121,  -2.1397,  -3.2924,  -2.5713,  -1.9005,  -2.6328,\n",
      "         -13.6348,  17.7605,  -2.8710]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.76048204797649\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0888, 15.8231, -2.2662, -3.0463, -2.3869, -1.6780, -2.6183, -1.1132,\n",
      "          2.1049, -2.9920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.823077419190236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3932,  13.1688,  -2.6915,  -4.9760,  -2.8691,  -1.9947,  -2.8558,\n",
      "         -15.1585,  24.2051,  -3.5359]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 24.205121556794193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5436,  8.9248, -1.8856, -2.7311, -1.7138, -1.5307, -1.8016, -8.8440,\n",
      "         13.0636, -1.9865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.06357774011924\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2389, 21.5573, -3.0401, -0.2076, -2.8206, -2.1884, -3.0963, -9.9419,\n",
      "          6.5468, -3.1962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 21.557302378685257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8317,  3.5326, -0.9793,  1.0884, -0.9443, -0.7602, -1.0027, -9.2355,\n",
      "         11.2579, -1.2277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.257936014373755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0511, 21.2614, -3.6015, -2.4800, -3.6358, -2.9808, -4.1886, -9.4237,\n",
      "         12.3167, -4.1691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 21.261440044082708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8487,  7.4417, -2.0376, -0.3014, -2.2747, -1.6801, -2.6920, -1.9839,\n",
      "          8.4418, -2.7646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 8.441801850769501\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.8053,  25.5258,  -4.4887,  -6.6773,  -4.8033,  -3.5496,  -4.8674,\n",
      "         -22.4564,  31.0921,  -5.8995]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 31.092106688436157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4710, 14.7085, -1.7397,  1.6142, -2.1860, -1.6033, -2.0763, -9.9711,\n",
      "          3.8477, -2.2163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 14.70854449304639\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1688,  17.6179,  -2.9056, -11.6578,  -3.1243,  -2.1260,  -3.0070,\n",
      "         -14.8562,  28.4956,  -3.6774]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.495584867618543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4916,   3.3479,  -2.2115,   4.8314,  -2.4115,  -1.6766,  -2.6560,\n",
      "         -13.7333,  20.0105,  -2.9661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.010489522574638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5631,  14.2929,  -2.2646,  -4.9193,  -2.2976,  -1.5511,  -2.3617,\n",
      "         -13.9348,  18.5230,  -2.9755]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.522955000780012\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4721,   9.4103,  -2.0921,   0.7690,  -2.3430,  -1.4970,  -2.2784,\n",
      "         -14.6106,  18.5017,  -2.9265]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.50166033697779\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3588,  9.9012, -1.3059, -6.2676, -1.3685, -1.1647, -1.8408,  1.5822,\n",
      "          3.3801, -1.8303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.901179045695214\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7790,   7.8208,  -3.5949,  10.4381,  -4.1295,  -2.9218,  -3.6977,\n",
      "         -25.3267,  30.4124,  -4.8249]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 30.41240910891037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2660,  13.5475,  -2.5953,  -1.9256,  -3.0339,  -2.4539,  -3.4472,\n",
      "         -14.7517,  20.3103,  -3.5069]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 20.310292352623648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0714,  7.4304, -1.0109, -6.5829, -0.9596, -0.9278, -1.4869,  2.1162,\n",
      "          3.7263, -1.4630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.430362057920888\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6989,  10.5955,  -3.1146,   6.4333,  -3.5041,  -2.6528,  -3.6542,\n",
      "         -22.0372,  24.6923,  -4.2815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 24.692297166025284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3688,   8.9947,  -2.7642,   5.6428,  -2.7750,  -2.1636,  -3.0182,\n",
      "         -10.9890,  14.1870,  -3.5259]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.187015858378857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1725,  10.4811,  -2.5744,  -1.2907,  -2.8038,  -1.9519,  -2.3648,\n",
      "         -11.1780,  17.9130,  -3.2845]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.913039371541498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7500,  5.4900, -1.9620, -7.4413, -2.3384, -1.9026, -2.3678, -9.8916,\n",
      "         24.8834, -2.6407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 24.88337429128644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4818,   4.4774,  -3.1749,  10.8902,  -3.4604,  -2.4957,  -3.2112,\n",
      "         -22.0375,  27.1081,  -4.4867]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.108113813466932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4284,  3.1384, -0.7859, -2.2981, -0.7812, -0.6292, -1.0491, -8.5200,\n",
      "         13.4387, -0.9842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.438653095930281\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0992,   9.4221,  -1.3631,  -7.6905,  -1.2722,  -1.2561,  -1.7096,\n",
      "         -13.3807,  21.1742,  -1.7591]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.1741836612248\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7034,  6.4690, -2.0636, -1.0101, -1.8854, -1.4903, -2.1632, -4.5741,\n",
      "         10.9808, -2.6996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 10.980825391769613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3001,  3.6378, -1.3682, -5.0774, -1.5480, -1.4110, -1.7872, -7.7613,\n",
      "         19.1065, -1.8079]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.106522276486892\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2213,   5.7473,  -1.8971,   0.0597,  -1.8490,  -1.1924,  -1.8763,\n",
      "         -18.1682,  24.8386,  -2.4941]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.838580591185913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1732,  15.5323,  -2.5552,  -7.1654,  -2.9286,  -1.9697,  -2.7953,\n",
      "         -20.5612,  27.6646,  -3.3563]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 27.66461259447711\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0082,  7.6569, -2.3951, -7.2304, -2.7297, -2.3938, -2.5213, -8.1391,\n",
      "         22.7339, -3.3237]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 22.733942448758494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8055,  8.9149, -2.0224, -3.8554, -2.3882, -1.7067, -2.1728, -7.7605,\n",
      "         15.3730, -2.8036]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.37299645725367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0932,   7.1249,  -2.6815,   9.6880,  -3.0738,  -2.2796,  -2.8880,\n",
      "         -22.3962,  24.3594,  -3.5414]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 24.35939356206597\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6132,  13.1596,  -2.2981,  -7.9561,  -2.2457,  -1.6230,  -2.6753,\n",
      "         -13.4408,  22.2568,  -2.8247]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.256828655688405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6455, 11.1327, -1.6120, -6.5979, -2.1143, -1.7394, -2.3572, -7.4407,\n",
      "         14.5750, -2.4842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.574969943938244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1912,  7.2775, -1.2923, -5.6003, -1.0203, -1.0127, -1.6206,  1.8028,\n",
      "          4.1781, -1.6770]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.277463171137992\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4418,  14.5357,  -3.1945,  -4.6129,  -3.3852,  -2.7917,  -3.3910,\n",
      "         -13.8937,  23.2635,  -3.9960]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 23.263533656607134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1531,  14.8588,  -2.7241,   1.6766,  -3.2285,  -2.4896,  -3.4012,\n",
      "         -17.5098,  19.6403,  -3.5920]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.64029538212067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8244,  12.1175,  -2.1768,  -3.8528,  -2.5337,  -1.7491,  -2.2337,\n",
      "         -10.2187,  15.7710,  -2.8518]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.77101980284445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1753,  14.0047,  -2.2058,   2.0396,  -2.4167,  -2.2715,  -2.7803,\n",
      "         -19.1075,  17.3896,  -3.0759]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.38960903286565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2893,  10.4121,  -1.3348, -10.6839,  -1.1833,  -1.2527,  -1.7264,\n",
      "           8.7341,  -0.3877,  -1.6715]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  7\n",
      "activation[1] = 10.412126145995854\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7405,   8.7401,  -2.2718,  -1.4304,  -2.4247,  -1.7080,  -2.0682,\n",
      "         -18.4839,  25.2530,  -2.8537]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 25.253018060683086\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2795, 12.4876, -1.3882, -5.4073, -1.4322, -1.2356, -1.8154,  2.2813,\n",
      "         -1.0473, -1.7697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.48757636173865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3331,  10.6283,  -3.0902,   4.5098,  -2.9781,  -2.1804,  -3.3806,\n",
      "         -13.4534,  17.6180,  -3.9044]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.617980056411202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0981,   7.4300,  -1.8230,  -1.3170,  -2.0461,  -1.4836,  -1.9473,\n",
      "         -17.6567,  23.8123,  -2.2519]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 23.812305400269246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1409,   8.2546,  -1.5575,  -6.5396,  -1.3320,  -1.3510,  -1.5800,\n",
      "         -15.8849,  24.5474,  -1.6941]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.547361503615644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6235,  2.8472, -2.0672,  3.9629, -2.0905, -1.6926, -2.3836, -7.2301,\n",
      "         13.8048, -2.8529]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.804791804084067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1978,  2.5278, -1.5140, -4.0766, -1.8169, -1.4970, -1.6807, -8.5780,\n",
      "         20.0263, -1.9594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.026318577160076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7036,  9.2890, -1.6571, -6.5188, -1.8346, -1.5349, -1.8817, -6.0822,\n",
      "         14.2833, -2.3407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.283297981036409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7170,  18.1929,  -3.0648,   0.3966,  -3.3948,  -2.2827,  -3.5408,\n",
      "         -21.6193,  21.8284,  -4.2500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.828413894469232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5788,   5.9932,  -1.6195,  -0.6000,  -1.9561,  -1.2408,  -1.8699,\n",
      "         -18.3713,  24.6792,  -2.1490]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 24.67917903732415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0762,   9.5039,  -2.1139,  -3.3969,  -2.4366,  -2.0565,  -2.3072,\n",
      "         -10.7799,  18.6790,  -2.9333]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 18.67900123010563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8445,   4.5788,  -2.2700,   7.5156,  -2.3349,  -1.6961,  -2.1258,\n",
      "         -17.3768,  18.1716,  -3.1212]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 18.171583602922542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3201, 15.2600, -3.0649, -0.5534, -3.2955, -1.9659, -3.2373, -7.7514,\n",
      "         12.0175, -3.8295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 15.259960830038322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4947,  9.4294, -1.5014, -5.5273, -1.5232, -1.3370, -2.0483,  0.9999,\n",
      "          4.6362, -2.0831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.429378342554546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4252, 13.3551, -1.4164, -7.4120, -1.4509, -1.1747, -1.9098, -0.7672,\n",
      "          3.6909, -1.8796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.355119212910386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1771,  12.5733,  -2.5522,   1.5187,  -2.7139,  -2.1450,  -2.8578,\n",
      "         -17.6774,  20.5601,  -3.4606]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 20.560080258478166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6152,   8.3432,  -2.1327,  -6.4081,  -2.3276,  -1.6855,  -2.3486,\n",
      "         -14.8020,  26.2047,  -2.7373]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 26.20473180492387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2844,   5.2176,  -1.2401,  -1.5505,  -1.5420,  -1.2223,  -1.4659,\n",
      "         -15.5188,  21.7668,  -1.3600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.76681777554879\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9543,  14.7824,  -2.3866,   1.2747,  -2.5755,  -2.0969,  -2.6319,\n",
      "         -17.5746,  17.0403,  -3.1886]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.040287677338455\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3098,   3.9873,  -1.6353,   5.3392,  -1.5921,  -1.5141,  -1.6553,\n",
      "         -10.9084,  11.4337,  -2.0119]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.433728655702279\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1946,   5.8432,  -1.2591,  -6.7688,  -1.5884,  -1.2194,  -1.4501,\n",
      "         -11.7376,  22.8128,  -1.9424]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 22.812823788644135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0678,   5.5678,  -2.5998,   6.8722,  -2.6233,  -1.9694,  -2.6034,\n",
      "         -20.4065,  23.1648,  -3.3074]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 23.16477114599824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2087,   8.6750,  -2.8671,   3.4128,  -2.9371,  -1.9855,  -3.1071,\n",
      "         -13.9089,  19.7923,  -3.9453]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.79233494455953\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3003, 13.7873, -2.5132, -0.4345, -2.7843, -2.0988, -2.9292, -0.8096,\n",
      "          2.8106, -3.3397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 13.787251982526348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4990,  5.7785, -1.8327, -9.5616, -2.1330, -1.7779, -2.0218, -9.0747,\n",
      "         25.3410, -2.4861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 25.34095085718115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2949,  2.6593, -1.5344,  1.7749, -1.4723, -1.2216, -1.5938, -4.5650,\n",
      "          9.1089, -2.0176]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 9.108853557349722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9279,  14.1825,  -2.7552, -12.0167,  -2.7602,  -2.0643,  -2.5051,\n",
      "         -19.7314,  32.9362,  -3.1763]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 32.93621709798866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4256,  6.6683, -1.3809, -3.0011, -1.3509, -1.2092, -1.6319,  1.5532,\n",
      "          3.2961, -1.9015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.6683405752725875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8013,  10.9241,  -2.1470, -11.1194,  -2.5047,  -1.7332,  -2.1269,\n",
      "         -11.0572,  25.0632,  -2.7848]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 25.063156951363027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2607,   6.0912,  -1.6416,   3.4407,  -1.8292,  -1.1914,  -1.9005,\n",
      "         -10.4538,  12.5470,  -2.2442]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.54695021672418\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0406,   8.5529,  -2.4360,  -2.9606,  -2.7155,  -2.1078,  -2.6146,\n",
      "         -20.9990,  30.1983,  -3.1642]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.198336601821925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8949,  7.7420, -1.9715, -5.9223, -2.3244, -1.7104, -2.1618, -4.1584,\n",
      "         15.2556, -2.8343]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.25564602786782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9749,  7.3588, -2.2515,  1.2129, -2.4344, -1.8345, -2.0789, -9.3323,\n",
      "         13.9172, -2.9814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 13.917154074946787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0394,  4.3998, -1.1806, -9.4534, -1.3208, -1.1488, -1.3992,  1.9461,\n",
      "         10.9511, -1.6083]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.951053625099053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1586,   8.8649,  -3.0980,   6.5545,  -3.2810,  -2.2768,  -3.5511,\n",
      "         -19.4961,  23.4962,  -3.8924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 23.496153006823707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8018,  13.0386,  -2.5741,  -0.2930,  -2.8508,  -1.7217,  -2.6302,\n",
      "         -22.4013,  25.5611,  -3.5130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.56112276053264\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5878,  4.8206, -1.6775, -5.7499, -2.3349, -1.6415, -2.0515, -7.2699,\n",
      "         19.8598, -2.4107]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.859779313746838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4947,  15.7501,  -3.1287,   4.4829,  -3.4495,  -2.4784,  -3.4374,\n",
      "         -14.8433,  13.1344,  -4.0154]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 15.750055109553449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9810,   9.8030,  -2.5672,   2.6532,  -3.0951,  -2.0496,  -2.3848,\n",
      "         -20.4950,  25.0129,  -3.2738]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.01285867733409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5960,   4.2614,  -1.1442,  -0.4142,  -1.1772,  -1.0505,  -1.1776,\n",
      "         -15.2943,  18.9032,  -1.2476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.903192021979255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8627,  11.7718,  -3.4583,   7.0869,  -3.8195,  -2.9092,  -4.1059,\n",
      "         -15.8361,  19.3210,  -4.5979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.32096971081528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5311,  15.8700,  -2.9942,  -6.0265,  -3.5425,  -2.6491,  -3.2077,\n",
      "         -12.8710,  22.5472,  -4.2425]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 22.547198157897498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2799,  9.1228, -1.2751, -5.3902, -1.2755, -1.1117, -1.7111,  1.0695,\n",
      "          3.4516, -1.8297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.122837600703136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1302,   9.4251,  -1.6200,  -1.7554,  -1.6314,  -1.3272,  -1.8438,\n",
      "         -18.9744,  22.8606,  -2.3045]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.860576454797826\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4898,  11.3382,  -1.6909,  -5.9813,  -1.6058,  -1.3772,  -2.1488,\n",
      "         -13.8136,  20.4506,  -2.2509]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 20.450642335491285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3428,  8.5406, -1.4667, -4.9552, -1.2302, -1.1641, -1.6023, -0.0735,\n",
      "          4.8826, -1.8319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.540624965060161\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1377,  14.4530,  -2.7069,  -1.3863,  -2.8841,  -2.1471,  -2.6919,\n",
      "         -23.5770,  25.8672,  -3.3544]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 25.86719181200727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3016,   3.6153,  -2.0502,   2.9321,  -1.9698,  -1.4293,  -1.8599,\n",
      "         -17.1629,  22.7556,  -2.2991]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.755552724199514\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6966,   8.1594,  -2.1169,  -0.8565,  -2.4231,  -1.6917,  -1.9272,\n",
      "         -10.8169,  16.2511,  -2.5774]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.251101466188917\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7853,   5.6607,  -1.1996,  -3.0165,  -1.1920,  -1.0740,  -1.5299,\n",
      "         -12.1050,  18.3382,  -1.5071]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.3382391708278\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3445, 10.9407, -1.3664, -7.3499, -1.3256, -1.1799, -1.8862,  1.0375,\n",
      "          4.0841, -1.9024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 10.940700224541349\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8362,   5.3538,  -3.5874,  11.1814,  -3.7907,  -2.9522,  -3.6482,\n",
      "         -22.4189,  28.2336,  -4.6080]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.23358822112413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0851,  3.6428, -1.5521, -7.7323, -1.7751, -1.4268, -1.4063, -8.4971,\n",
      "         22.3521, -1.9206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.352076717816804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5396,  5.2161, -1.7505,  0.9014, -1.6331, -1.4319, -1.8687, -3.7172,\n",
      "          7.7120, -2.2530]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 7.71204380498149\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1804,  11.0862,  -1.4685,  -3.8557,  -1.4956,  -1.0333,  -1.7050,\n",
      "         -12.6544,  16.4028,  -1.8862]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.402781169011323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1044,   7.1244,  -1.6265,  -4.1576,  -1.5257,  -1.1250,  -1.4423,\n",
      "         -15.6823,  21.7547,  -1.7534]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 21.75470727902663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0022,   8.7477,  -2.6586,   0.5227,  -2.6169,  -1.9026,  -2.5453,\n",
      "         -12.7351,  18.8650,  -3.3509]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 18.864976322524253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8836, 14.8336, -1.9317, -9.5092, -1.9885, -1.7845, -2.5073,  2.5533,\n",
      "          3.8322, -2.4662]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.833601455975439\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0036,   7.7720,  -1.3646,  -8.1095,  -1.1322,  -1.1146,  -1.6692,\n",
      "         -11.7261,  21.0475,  -1.5765]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.047526162359038\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6804,  5.1587, -1.8143, -0.8040, -1.8875, -1.6455, -1.8340, -3.5387,\n",
      "          9.7846, -2.3014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 9.784626387553695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6745,  12.2188,  -2.0221, -12.0512,  -2.0701,  -1.5411,  -2.2946,\n",
      "          -0.5972,  13.5452,  -2.8346]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.545161582403093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8772,  13.8332,  -2.0730,   1.7225,  -2.2649,  -1.7853,  -2.5365,\n",
      "         -11.9133,   9.6460,  -2.5902]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 13.833225836744864\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4451,  10.1333,  -3.4805,   7.9096,  -3.8042,  -2.9749,  -3.6735,\n",
      "         -17.4165,  20.6173,  -4.2378]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 20.617294560215022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3890,   7.1161,  -1.9806,  -2.6588,  -2.0217,  -1.6113,  -2.1861,\n",
      "         -18.1384,  25.4988,  -2.3168]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 25.498772217275512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4487,  3.1995, -1.7941, -3.1449, -2.1174, -1.6951, -1.8957, -9.7244,\n",
      "         21.4050, -2.3159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.404982973106197\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9144,   8.1074,  -3.2956,   9.5155,  -3.7265,  -2.8150,  -3.6174,\n",
      "         -10.6883,  14.0622,  -4.5600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.062214414660048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5782,  19.5301,  -3.0379,  -0.9805,  -3.2154,  -2.2862,  -3.2301,\n",
      "         -18.9949,  18.3949,  -3.9543]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.530125404134928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7926,  6.1386, -0.9344, -2.5253, -1.0800, -0.9858, -1.1995, -9.3986,\n",
      "         12.0861, -0.9597]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.08614266407226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4623,  9.6256, -1.4111, -5.6410, -1.4739, -1.3166, -2.0385,  2.0301,\n",
      "          3.0550, -1.9500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 9.625615492043773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1693,   8.2143,  -1.5643,   0.5942,  -1.5373,  -1.4498,  -1.8054,\n",
      "         -10.1516,  12.5165,  -2.0615]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.516532846120812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9246,  12.3233,  -3.3439,   5.8472,  -3.6499,  -2.8986,  -3.7006,\n",
      "         -17.4556,  20.2994,  -4.5953]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 20.299369529122075\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1634,  12.9635,  -3.6497,   7.3347,  -4.2057,  -3.3332,  -4.0301,\n",
      "         -19.5861,  21.9101,  -4.6429]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 21.91013068692843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8099,   9.9064,  -1.9704,  -0.8071,  -2.4490,  -1.8450,  -2.0766,\n",
      "         -12.8553,  16.7212,  -2.4944]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.72115229584705\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3771,   7.1675,  -1.9371,   3.1113,  -2.0529,  -1.6642,  -1.7226,\n",
      "         -21.2422,  22.4278,  -2.4045]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 22.427777732600862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4684,   8.5599,  -2.9434,   7.2301,  -3.0147,  -2.4361,  -3.1910,\n",
      "         -15.6546,  18.0548,  -3.8219]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 18.054847771718872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9809,  8.8802, -1.4674,  0.6423, -1.7483, -0.9807, -1.7570, -9.2349,\n",
      "          9.6866, -2.1807]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 9.686625513789998\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0350, 10.4389, -2.6866, -3.1637, -2.7195, -1.8619, -2.5399, -8.6986,\n",
      "         16.6775, -2.9705]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.67752808995727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2367,   2.8702,  -1.6804,   2.9199,  -1.7663,  -1.1979,  -1.7252,\n",
      "         -16.3721,  20.6419,  -2.2085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.641855148122946\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6922,  4.5030, -1.8886, -2.6211, -2.3667, -1.8042, -2.1328, -8.6708,\n",
      "         18.7974, -2.5792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.79741953178117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7522,  4.8005, -0.8859, -2.8830, -0.6219, -0.6457, -1.1098,  0.8457,\n",
      "          2.5365, -1.1147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 4.800506767805703\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6014,  12.6046,  -3.2940,   2.5253,  -3.6316,  -2.8374,  -3.7958,\n",
      "         -15.3035,  20.7106,  -4.1307]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 20.710570762934125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1292,   7.4623,  -1.2170,  -3.8236,  -1.5233,  -1.1542,  -1.6029,\n",
      "         -14.8840,  20.3328,  -1.5622]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.332822744288197\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9541,  12.7706,  -2.7674,  -0.7232,  -2.9644,  -1.9841,  -2.6282,\n",
      "         -20.9051,  26.1795,  -3.5781]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.179477425140202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9630,   9.7366,  -2.4808,  -3.3416,  -2.9329,  -1.9346,  -2.8906,\n",
      "         -12.2753,  22.7823,  -3.5427]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.782342745263495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5973,   9.1045,  -3.3613,   7.4679,  -3.5443,  -2.6127,  -3.2511,\n",
      "         -25.8244,  29.4320,  -4.5956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 29.43195276487725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0548,  10.1430,  -2.4196,  -8.8008,  -3.0052,  -2.0859,  -2.6378,\n",
      "         -16.7339,  31.1231,  -3.4018]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 31.123088061192444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0975,  13.2557,  -2.8192,  -4.8849,  -3.0229,  -2.1051,  -2.7219,\n",
      "         -11.3964,  20.5631,  -3.5841]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 20.563141226419134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9431,  8.4913, -0.9969, -3.9512, -0.9120, -0.9481, -1.1982, -8.9730,\n",
      "         11.8309, -1.2104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 11.830898276534006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3369,  7.7420, -1.5084, -5.9382, -1.2537, -1.2037, -1.6649,  1.0753,\n",
      "          5.3270, -1.8128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.742000704135903\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0403,  4.2900, -1.0187, -2.0805, -1.0012, -0.8851, -1.0946,  0.7241,\n",
      "          3.1467, -1.2849]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 4.290023412418417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5976,  7.9726, -1.7396, -6.6874, -2.1979, -1.8073, -1.8594, -9.3373,\n",
      "         19.4440, -2.3471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 19.444013689647523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2148,  18.1917,  -4.2010,   1.4559,  -4.4612,  -3.3892,  -4.5270,\n",
      "         -20.8405,  27.1980,  -5.4506]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 27.198008478211726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7299, 12.1886, -2.0253, -2.9976, -2.3306, -1.7385, -2.4411, -7.5384,\n",
      "         11.7645, -2.7306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.188628831755766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5667,  9.2023, -3.1415, -1.0963, -3.1026, -2.7551, -3.5444, -6.7650,\n",
      "         17.7599, -4.0933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 17.759946876737533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1369,  10.6472,  -2.6265,   5.5399,  -2.7126,  -2.1436,  -3.0626,\n",
      "         -10.9501,  11.8184,  -3.3046]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.81838107632511\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2115, 10.6369, -1.1337, -9.2160, -1.4506, -1.1722, -1.5035, -8.8108,\n",
      "         15.8061, -1.3124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.806087511611961\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4879, 14.4417, -2.7869,  3.9743, -3.1708, -2.4238, -3.2759, -8.3990,\n",
      "          8.8816, -3.4948]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 14.441667852674344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6074,  8.6057, -1.8372, -3.0872, -1.9522, -1.5047, -1.9692, -8.7262,\n",
      "         14.8136, -2.4068]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.813599368550129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0480,  12.0824,  -2.5596,  -0.2769,  -2.8935,  -2.0923,  -3.0407,\n",
      "         -17.2266,  21.5257,  -3.3725]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 21.525697783324837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5319,  9.3662, -1.3297, -6.2176, -1.4117, -1.4810, -1.8113, -7.6470,\n",
      "         14.5942, -2.0667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.594179160731578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5719,   9.5123,  -2.4074,   3.1036,  -2.4935,  -1.9270,  -2.5920,\n",
      "         -16.3911,  19.5277,  -2.9487]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.527680487001838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2516,   8.9981,  -1.8246,  -2.7222,  -1.7541,  -1.2583,  -1.9920,\n",
      "         -15.9497,  20.2839,  -2.1443]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 20.283935562383682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5830,   6.7292,  -2.3117,   5.4895,  -2.5230,  -1.7988,  -2.4502,\n",
      "         -16.5503,  20.0066,  -3.0859]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.00660423254569\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3027,   9.1312,  -1.6805,   1.3602,  -1.6321,  -1.0221,  -1.6801,\n",
      "         -14.3686,  15.0023,  -2.1945]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.002254330272578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0373,   4.9025,  -1.1242,  -4.0483,  -1.3088,  -0.9816,  -1.3576,\n",
      "         -10.9840,  18.2896,  -1.4923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.28963954237636\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6243,  10.6057,  -1.9455,  -1.0470,  -1.7996,  -1.5926,  -2.2949,\n",
      "         -16.2337,  19.7184,  -2.5305]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.718357925146325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1696,  15.6551,  -2.4588,  -5.1510,  -2.8004,  -1.8225,  -2.7311,\n",
      "         -17.6650,  21.7783,  -3.1947]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.778301519860147\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6262,  7.5338, -1.7842, -2.5600, -1.7134, -1.4562, -1.8516, -9.9332,\n",
      "         15.4919, -2.0433]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.49193231904335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5385, 10.4257, -1.7002, -5.7578, -2.0391, -1.6168, -1.9247, -5.4849,\n",
      "         12.3376, -2.2807]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.3375735074004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5928,   9.4361,  -2.1457,   0.7447,  -2.2589,  -1.5955,  -2.4716,\n",
      "         -13.4798,  16.9542,  -2.6586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 16.95422587342839\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5663,  8.4355, -1.7483, -6.2069, -2.0714, -1.6306, -1.9026, -8.2009,\n",
      "         16.8158, -2.3104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 16.815755103656397\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8588,  4.9668, -1.1897, -0.7811, -1.2076, -0.7021, -1.2221, -7.7069,\n",
      "         10.3651, -1.2875]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.365066759254601\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8542, 11.5779, -1.8417, -5.2499, -2.1995, -1.7573, -2.1277, -8.7316,\n",
      "         14.5085, -2.5912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 14.508510584999588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4749, 11.9193, -1.4559, -4.0567, -1.7095, -1.4408, -1.7924, -7.1021,\n",
      "          9.1637, -2.1067]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 11.919317506971142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4919,  3.5883, -1.4439, -3.7757, -1.9944, -1.7583, -1.9754, -3.2054,\n",
      "         14.3633, -2.2233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.363305862106394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4779, 12.5043, -1.8244, -3.8685, -2.1310, -1.3729, -1.8677, -3.7938,\n",
      "          6.5141, -2.3787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 12.504257115893454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1502,  6.5095, -1.4335, -2.1590, -1.1948, -1.1231, -1.6220, -0.7758,\n",
      "          4.7942, -1.8452]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.509524527980506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2952,  6.3300, -1.5053,  0.6499, -1.5009, -1.0684, -1.6519, -9.4817,\n",
      "         12.5951, -1.8874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.595106007973609\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2629,  7.7678, -1.3053, -4.9342, -1.2137, -1.0979, -1.6121, -0.7620,\n",
      "          5.8742, -1.7808]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.767775881899188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8035,   7.2358,  -2.1066,   2.7002,  -2.1344,  -1.8027,  -2.4163,\n",
      "         -13.5656,  16.4318,  -2.7176]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 16.43179771770713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4689,   3.4173,  -1.8032,  -4.1741,  -2.2350,  -1.6226,  -1.9292,\n",
      "         -11.9849,  24.7579,  -2.4406]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 24.757869445731433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9167,  12.4912,  -2.5248,   7.6744,  -2.7073,  -2.2472,  -2.5568,\n",
      "         -13.7631,   9.0204,  -3.0293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.491163494832918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9299,   9.7679,  -2.5091,  -7.1047,  -2.7689,  -2.2441,  -2.7362,\n",
      "         -17.5318,  30.1932,  -3.1995]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.19322472236532\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9198,   3.0131,  -2.0904,   4.7149,  -2.1898,  -1.6885,  -2.2738,\n",
      "         -10.3615,  16.1702,  -2.8215]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 16.17024062402006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6670,  12.2998,  -3.0619,  11.1068,  -3.4061,  -2.8755,  -3.6210,\n",
      "         -16.7898,  13.0237,  -3.8997]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.023650915324522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4607, 15.2927, -1.7119, -7.7622, -1.6816, -1.4231, -1.9072, -6.5506,\n",
      "         10.1390, -1.8547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.292682818038442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8086, 12.2775, -2.0124, -3.9520, -2.5339, -1.6632, -2.2282, -9.9481,\n",
      "         14.6620, -2.6045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.66203294303411\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.4771,   5.5867,  -0.6183,  -5.7190,  -0.7701,  -0.4426,  -0.5308,\n",
      "         -10.6545,  14.9417,  -0.4648]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.941696421298904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0275,  11.9465,  -2.6269,  -9.6681,  -2.8230,  -2.2984,  -2.7193,\n",
      "         -20.3115,  33.5738,  -3.3742]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 33.57383194074249\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2158,   4.3041,  -1.4980, -13.8324,  -1.5932,  -1.2940,  -1.4698,\n",
      "           0.4792,  18.5326,  -1.9032]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 18.532597449583204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6852,   8.0283,  -1.2336,  -7.9301,  -0.9495,  -0.9362,  -1.2531,\n",
      "         -12.2391,  19.3299,  -1.2737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.32986854431528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6949,   9.8218,  -1.4109,  -3.3700,  -2.1349,  -1.6383,  -2.1080,\n",
      "         -14.0850,  18.7180,  -2.0610]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.71802887479275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3709,  12.9786,  -2.7839,   5.1776,  -3.0086,  -2.2402,  -3.1078,\n",
      "         -15.4021,  13.9949,  -3.4110]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.994904208932745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4713,   3.7061,  -2.2794,   7.1440,  -2.3586,  -1.6766,  -2.4707,\n",
      "         -18.5893,  22.3105,  -2.8667]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 22.310470020992508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6373,   8.2008,  -2.4773,  -3.6513,  -2.6357,  -1.8843,  -2.4815,\n",
      "         -21.8511,  31.6836,  -2.9581]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 31.68361527674381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7115,  4.4893, -0.8791, -5.7866, -1.0132, -0.8069, -1.2749, -4.8206,\n",
      "         12.3651, -1.0927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 12.36511698463911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6244,  10.6229,  -2.5339,  -3.3972,  -2.4524,  -1.7369,  -2.5279,\n",
      "         -20.3019,  28.1957,  -3.1085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.195660531098948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7806,  14.3829,  -2.0517, -11.7099,  -2.6794,  -2.0194,  -2.5836,\n",
      "         -16.3580,  27.8700,  -2.9321]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 27.87004855846855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6473,   9.2397,  -1.8690, -11.5929,  -2.0476,  -1.7799,  -1.9358,\n",
      "          -8.5962,  23.2899,  -2.5963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.289929948588078\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2104,   9.4212,  -1.7137,   2.9372,  -2.1005,  -1.3386,  -2.1811,\n",
      "         -14.3483,  13.4958,  -2.3071]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 13.495756683447915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1501,   9.6748,  -1.9851,  -2.6902,  -2.0358,  -1.2479,  -1.9436,\n",
      "         -12.1539,  17.8273,  -2.3501]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 17.827270595796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5093,   8.7103,  -1.9360,   2.7218,  -2.1202,  -1.4131,  -2.2369,\n",
      "         -11.7176,  12.2978,  -2.7445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.297787066654092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3814,   7.8282,  -3.0115,   9.4293,  -3.2924,  -2.3278,  -3.2168,\n",
      "         -14.1212,  15.4203,  -3.7480]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 15.420324429655343\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9238,   8.8127,  -2.0975,   2.0409,  -2.1976,  -1.9564,  -2.1650,\n",
      "         -10.1053,  11.2743,  -2.7489]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 11.274301209835812\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0035,   8.4828,  -2.6376,   1.1691,  -3.0148,  -2.0407,  -2.5642,\n",
      "         -19.6271,  27.0402,  -3.4446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.040175156794874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3835,   7.3560,  -1.5244,  -1.2508,  -2.0393,  -1.4730,  -1.9480,\n",
      "         -10.9945,  15.0482,  -2.1698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 15.048235298634204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2880,  7.0751, -1.6043, -2.7131, -1.4070, -1.2586, -1.7698, -0.4719,\n",
      "          4.9791, -2.0773]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.075131029220841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6569,  17.3521,  -2.5736,  -3.7862,  -3.1834,  -2.3681,  -3.0437,\n",
      "         -17.3245,  22.0642,  -3.6771]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 22.06415991422094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0417,   9.4331,  -2.8005,   1.5950,  -3.2074,  -2.2029,  -2.7664,\n",
      "         -20.6220,  27.7968,  -3.7684]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.79678224682426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9415,   6.1471,  -2.9650,   4.0322,  -2.7493,  -2.0875,  -3.2901,\n",
      "         -18.1844,  26.3688,  -3.6256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.368787169087224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4275, 12.8216, -1.6006, -5.1731, -1.5251, -1.5291, -2.0222, -8.9043,\n",
      "         12.1955, -1.8892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 12.821604064659534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1416,  4.0782, -1.4247,  0.6970, -1.2415, -1.0946, -1.5216, -2.3581,\n",
      "          5.5413, -1.8490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 5.541259547202686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4763, 11.6697, -1.8432, -3.7518, -2.0400, -1.7888, -2.1460, -9.9923,\n",
      "         14.3295, -2.2457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.329536792302243\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9471,  7.2109, -1.0762, -1.3548, -0.9651, -0.7064, -1.3388, -9.3420,\n",
      "         10.3368, -1.4038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 10.336806888152243\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4709,  10.3532,  -2.9900,   7.4882,  -3.2506,  -2.3750,  -3.3095,\n",
      "         -17.5065,  17.7011,  -3.8861]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 17.701110313529945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1847, 10.2848, -1.1152, -4.2206, -1.2744, -1.0609, -1.4028, -9.7847,\n",
      "         12.4112, -1.2995]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.411168879564304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1707,  13.5658,  -2.8486,  -3.5551,  -3.1346,  -2.2835,  -2.9267,\n",
      "         -23.4916,  30.4769,  -3.7097]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 30.476855248245656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3744,   4.8478,  -1.8093,   1.9315,  -1.8486,  -1.3362,  -1.9959,\n",
      "         -20.3672,  24.9727,  -2.5774]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 24.972700072789923\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0281,   8.0839,  -2.2052,  -1.4310,  -2.6628,  -2.0254,  -2.2463,\n",
      "         -15.6315,  23.3807,  -2.9964]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.380724191112204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8122,  13.9820,  -2.6845,   1.4234,  -2.8240,  -1.9790,  -2.7869,\n",
      "         -28.0543,  28.9203,  -3.5788]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 28.92030171602548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6827,   8.3651,  -2.4939,  -2.7127,  -2.6743,  -1.7632,  -2.6437,\n",
      "         -16.9297,  27.7319,  -3.2817]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.731897004398444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6227, 15.1955, -2.1179, -5.8880, -1.9421, -1.8559, -2.4733, -3.9685,\n",
      "          7.2130, -2.5594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.19554941460817\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3625,  3.2561, -1.4822, -6.5669, -1.8468, -1.5133, -1.7290, -5.6732,\n",
      "         19.3924, -2.0158]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.39238233909741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1380,  4.1555, -2.6958,  8.0773, -2.8690, -2.1152, -3.2912, -6.8114,\n",
      "         12.2630, -3.4791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.263035994024975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4047,  14.0901,  -2.6936,   1.6625,  -3.3235,  -2.7192,  -3.5025,\n",
      "         -12.1013,  15.6969,  -3.6687]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 15.696919146722388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4314, 12.5299, -1.5863, -4.2172, -1.5055, -1.1760, -1.6602, -7.4115,\n",
      "          7.9745, -1.8471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 12.52988730386735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4985,  13.2582,  -2.9274,   3.2184,  -3.1972,  -2.5264,  -3.2277,\n",
      "         -19.0448,  20.5842,  -3.9198]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 20.58421440623744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1964,  11.7224,  -2.3363,  -2.6997,  -2.9174,  -2.1458,  -2.7355,\n",
      "         -11.5827,  17.9843,  -3.2227]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.984256012332555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2716,  9.9319, -2.6039,  0.2700, -2.9243, -2.0584, -2.5968, -8.1566,\n",
      "         13.6082, -3.3370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.608177259583915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4643,  10.9056,  -2.1065,  -5.4566,  -2.3298,  -1.6052,  -2.4809,\n",
      "         -19.7744,  28.9990,  -2.9151]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 28.99898879544156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0885,  11.6373,  -3.0383,   0.7421,  -2.8587,  -2.0202,  -2.8105,\n",
      "         -14.9600,  20.4104,  -4.0403]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.410419380135984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3287,  14.5169,  -2.6906,   2.0854,  -3.0500,  -2.4929,  -3.0063,\n",
      "         -17.8052,  19.1264,  -3.4618]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.126361643624175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5568,  10.4300,  -3.2581,  11.6099,  -3.5877,  -2.5371,  -3.3806,\n",
      "         -28.7133,  27.6483,  -4.3107]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.648311095570588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2096,   4.5696,  -1.7689,   5.7046,  -1.7577,  -1.2980,  -1.7395,\n",
      "         -14.8976,  15.6591,  -2.3709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 15.659057260174137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6501,  13.0748,  -2.0538,  -1.6963,  -2.4264,  -1.9442,  -2.6084,\n",
      "         -11.5354,  14.9413,  -2.7148]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.941320742348076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5840,  9.9086, -1.6525, -4.1399, -1.7363, -1.5554, -1.8930, -7.4281,\n",
      "         12.5063, -1.8437]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 12.50629175690149\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9918,  12.8650,  -2.5513,  -2.8178,  -2.7613,  -2.0522,  -2.7904,\n",
      "         -19.1844,  24.1692,  -3.1423]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 24.169153058819145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2738,  5.1191, -1.5027,  1.7854, -1.5538, -1.1863, -1.5926, -2.4004,\n",
      "          4.8037, -2.0191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 5.119084679994068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1559,   4.6626,  -2.9542,  11.3745,  -3.1976,  -2.3115,  -3.2509,\n",
      "         -24.3155,  26.9591,  -3.8965]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.959133044252603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1066,  17.8664,  -3.0205,  -8.8702,  -2.9901,  -2.2196,  -2.7617,\n",
      "         -13.8153,  22.0993,  -3.4586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 22.09932529442476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3988,   9.3616,  -1.7390,  -4.8439,  -2.1859,  -1.3000,  -1.8705,\n",
      "         -12.5622,  19.3130,  -2.2279]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 19.313020385066576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8641,   5.6707,  -1.8806,  -1.2372,  -2.2632,  -1.7910,  -2.0519,\n",
      "         -15.5539,  24.3035,  -2.7823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 24.30350118316191\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9133,   7.9496,  -1.2597,  -7.0104,  -0.9603,  -1.1522,  -1.4750,\n",
      "         -12.1380,  19.9116,  -1.5534]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.911621106013737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5580,  6.1287, -0.4780, -9.2521, -0.8006, -0.5014, -0.8139,  3.9105,\n",
      "          4.3858, -0.8622]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  7\n",
      "activation[1] = 6.128660629275763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6028,  12.6863,  -1.8494,  -3.0171,  -1.7820,  -1.5106,  -2.3344,\n",
      "         -11.6830,  15.1851,  -2.4583]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 15.185117554620875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9593, 10.7600, -2.2775, -2.1836, -2.4595, -1.8455, -2.4603, -9.7107,\n",
      "         14.6701, -2.9019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.67005198085117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0805,   6.5241,  -1.5915,  -5.4789,  -1.3732,  -1.2705,  -1.8312,\n",
      "         -12.1122,  21.6349,  -2.0533]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.63487397618303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5779,  10.5382,  -1.6235,  -1.1359,  -1.4531,  -1.2573,  -1.8981,\n",
      "         -12.6077,  13.6085,  -1.9911]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 13.60847601982405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5576,  4.0796, -1.6952, -4.2902, -2.1618, -1.7112, -1.9075, -4.7007,\n",
      "         15.8936, -2.3391]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 15.893562568991253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3932,   7.1762,  -1.9127,   2.9764,  -2.4794,  -1.6331,  -2.0342,\n",
      "         -21.5586,  25.0750,  -2.7751]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.074987405393056\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8698,   9.7743,  -1.8656,  -4.8964,  -2.3635,  -1.7796,  -2.0200,\n",
      "         -14.6747,  22.2779,  -2.5785]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 22.277944500701505\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1701,  8.0727, -1.4631, -5.1913, -1.2855, -1.0388, -1.7842, -9.8927,\n",
      "         16.2172, -1.6806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 16.21721666060131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4670,  7.6425, -1.3533, -5.1167, -1.3261, -1.2349, -1.8692,  2.3102,\n",
      "          3.7588, -1.8919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.642516757841437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5495,  12.4622,  -2.1548,   4.6012,  -2.3673,  -1.6562,  -2.4655,\n",
      "         -12.2474,   9.1581,  -2.7575]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 12.462165053252358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0274,  13.7285,  -2.6275,  -0.0349,  -2.7217,  -1.9187,  -2.9113,\n",
      "         -17.8982,  20.1273,  -3.2691]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 20.127294303493997\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [9]: loss = 16.475, accuracy = 15.62\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4132, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0423, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4132, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.0423, -0.0325], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-0.9592,  6.6478, -0.9902, -2.4933, -1.3208, -0.9467, -1.4239, -9.3877,\n",
      "         12.8863, -1.6156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.886292484320563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1092,  12.7390,  -2.6159,   2.6058,  -3.0102,  -2.2199,  -3.0583,\n",
      "         -13.2700,  15.6906,  -3.2621]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 15.69063520038394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3091,  3.7270, -1.6449,  1.6013, -1.4737, -1.3311, -1.6123, -1.2665,\n",
      "          4.6471, -1.9330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 4.647096295145156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1960,  5.3696, -1.4711, -0.9503, -1.2945, -1.1434, -1.5055, -1.3454,\n",
      "          5.0455, -1.8606]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 5.369642982473129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4289,  8.3351, -1.6888, -4.0365, -1.6781, -1.3182, -1.7227, -6.2092,\n",
      "         12.3039, -2.4386]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 12.303852339814163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3481,  13.7612,  -2.4579,   3.7291,  -2.8836,  -2.4195,  -3.1877,\n",
      "         -11.4239,  12.2095,  -3.2867]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.761187016767305\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.4578,   5.0209,  -0.9878,  -0.9669,  -1.2582,  -0.9004,  -1.0820,\n",
      "         -11.6461,  14.0676,  -1.3858]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 14.06757052121253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4524,  12.6896,  -1.7229,  -4.4133,  -1.7172,  -1.5317,  -2.1024,\n",
      "         -13.2743,  17.1634,  -2.1864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 17.163412637778595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9220,   6.7651,  -1.0191,  -7.3884,  -1.2403,  -0.9566,  -1.2284,\n",
      "         -10.0723,  18.0906,  -1.2211]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 18.09056373474237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5676,   5.7289,  -3.4296,  10.5405,  -3.4793,  -2.6612,  -3.3910,\n",
      "         -22.7377,  26.9778,  -4.5839]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 26.977817715686793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6848,  12.4332,  -2.4988,  -1.5239,  -2.2984,  -1.6181,  -2.3465,\n",
      "         -11.4316,  13.8860,  -2.5882]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 13.886005751884948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4568,  11.1759,  -2.7184,   6.2773,  -2.8776,  -2.3391,  -3.0525,\n",
      "         -15.7149,  15.7340,  -3.7825]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 15.73397618017129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3325,  4.3371, -1.6120,  2.0665, -1.5617, -1.3334, -1.6899, -5.0975,\n",
      "          7.7754, -1.9086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 7.7754027319632115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4547, 10.2412, -1.6016, -4.2547, -2.1539, -1.5515, -1.7920, -8.5474,\n",
      "         13.6363, -2.1671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.636316906087465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8457,  4.5024, -0.9787, -0.9011, -0.8492, -0.8385, -1.1447, -1.2030,\n",
      "          3.6032, -1.2829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 4.502405674708601\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6107,  4.5733, -1.7063, -4.1110, -2.2252, -1.7676, -2.1569, -7.8138,\n",
      "         19.0597, -2.4060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 19.059678958327893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2872, 13.8803, -2.9945,  0.5649, -3.0882, -2.1121, -3.1591, -9.7845,\n",
      "         13.6012, -3.7932]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 13.880303168503124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3952,  7.5595, -1.5197, -9.8828, -1.8999, -1.5184, -1.6216, -8.5886,\n",
      "         20.7959, -1.9265]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 20.79586219465666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3018,  10.2453,  -1.6753,  -1.1438,  -1.7233,  -1.4805,  -1.7666,\n",
      "         -10.1809,  11.0715,  -1.8344]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 11.071508975643624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3806,   6.4735,  -1.8150,  -2.1687,  -2.0838,  -1.5081,  -1.8503,\n",
      "         -11.5800,  18.6718,  -2.2372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.671828177122638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7258,  3.2890, -0.7087, -1.5837, -1.0082, -0.8656, -0.8995, -4.6236,\n",
      "          9.2944, -0.9715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 9.294377160895856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7264,   8.3239,  -2.3523,  -3.2039,  -2.4318,  -1.5487,  -2.1202,\n",
      "         -17.0579,  25.6983,  -3.0249]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.698339132679518\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7608,  8.6315, -2.0662, -1.9127, -1.9435, -1.5523, -2.1030, -4.1630,\n",
      "          9.1433, -2.6804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 9.14328523696474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4271,  10.2769,  -2.2803,  -5.1297,  -2.2724,  -1.6609,  -2.4299,\n",
      "         -13.5777,  23.3220,  -3.0057]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 23.321965872321382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7859,   4.7454,  -2.5326,   6.8966,  -2.6330,  -2.0112,  -2.8072,\n",
      "         -20.5943,  24.7687,  -3.3795]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 24.768670346383878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3597,   8.6791,  -3.3274,  12.4121,  -3.2244,  -2.3663,  -3.6620,\n",
      "         -20.9408,  20.4287,  -4.1315]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 20.428721981957533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6359,   5.2087,  -1.9356,   4.7785,  -2.0098,  -1.5723,  -1.9865,\n",
      "         -14.7039,  16.6797,  -2.7083]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 16.67965889213196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7052,   7.0879,  -1.9978,  -3.7625,  -2.1885,  -1.8175,  -2.0832,\n",
      "         -11.6386,  21.0727,  -2.6187]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 21.072734018789223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7371,  7.8877, -2.1693, -2.8190, -2.5096, -1.8522, -2.3925, -8.6594,\n",
      "         16.9509, -2.8234]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 16.950933766370458\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4078,   7.7843,  -2.9198,   4.2216,  -3.2419,  -2.3184,  -3.0099,\n",
      "         -20.0014,  27.6225,  -4.0266]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 27.622537336724776\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2612, 12.2594, -2.1360,  2.2386, -2.4805, -1.8553, -2.4388, -8.0871,\n",
      "          7.7531, -3.0430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 12.259423652278981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6299, 16.4029, -1.8424, -7.5885, -1.9082, -1.5302, -2.2577,  1.0388,\n",
      "          0.6165, -2.1961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 16.402938203900423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2941,  5.5578, -1.5011, -2.5278, -1.2721, -1.2380, -1.5467,  1.8717,\n",
      "          3.0819, -1.8048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 5.557764838096803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3943,   9.4920,  -3.0631,   1.9136,  -3.1949,  -2.4553,  -3.2537,\n",
      "         -17.6445,  25.1598,  -3.9164]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 25.15979595265068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5887,   9.7118,  -1.6807,  -5.5538,  -1.8310,  -1.3056,  -1.8665,\n",
      "         -11.3771,  18.6766,  -2.1325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.67659853507982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4645, 12.5450, -3.7854,  4.9466, -4.1935, -3.4198, -4.0049, -7.8978,\n",
      "         13.7294, -5.0463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 13.729386972747523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9228,   4.6814,  -1.4754,   2.4302,  -1.9267,  -1.3219,  -1.8397,\n",
      "         -16.9417,  20.3402,  -2.0610]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 20.340227577727536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9112,  7.4682, -2.0766, -6.7129, -2.0348, -1.6514, -2.2287, -7.7960,\n",
      "         20.6586, -2.9423]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.65860984208267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3923,   7.5606,  -1.9070,  -4.1757,  -2.2054,  -1.6371,  -1.9362,\n",
      "         -14.5798,  22.2297,  -2.3953]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 22.229694179369968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2505, 12.2305, -1.7636, -8.6003, -1.5944, -1.1919, -1.5300,  1.9101,\n",
      "          4.0602, -2.1382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 12.23053227245499\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2932,  3.7961, -1.1639, -6.3604, -1.7274, -1.1879, -1.6094, -9.4091,\n",
      "         20.7241, -1.6930]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 20.724057431040574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4431, 10.1842, -2.0500, -7.7966, -2.0357, -1.5524, -2.0995, -7.4270,\n",
      "         18.2530, -2.2430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.252985654147984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3644, 13.8259, -1.3717, -5.4188, -1.5743, -1.2194, -2.0041, -5.7232,\n",
      "          6.2902, -1.8954]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.825942762797288\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6596,   4.0704,  -2.0560, -16.8793,  -2.3237,  -1.7169,  -1.9403,\n",
      "          -4.8647,  30.0743,  -2.7365]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 30.074252593960175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0095,  4.4930, -1.1065, -9.9068, -1.3369, -1.1297, -1.4057,  3.1023,\n",
      "          9.9674, -1.5832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 9.967444100998511\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8951,  19.6071,  -2.0286, -13.1752,  -2.1548,  -1.6206,  -2.3310,\n",
      "           0.1181,   6.0424,  -2.7078]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.60708853592434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6188, 10.3831, -2.2462, -0.3325, -2.3150, -1.7448, -2.8340, -8.6701,\n",
      "         12.6121, -2.8010]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 12.612070297785914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0045,   9.1864,  -2.3483, -10.0967,  -2.4801,  -1.9865,  -2.4509,\n",
      "          -8.6851,  24.0835,  -3.2146]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.083541482000385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9526,  8.0980, -1.1423, -7.5406, -1.2012, -0.9650, -1.3761,  0.3008,\n",
      "          6.9136, -1.3944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 8.09795778413529\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8043,   8.6406,  -2.5027,   2.0979,  -2.3688,  -1.7626,  -2.4593,\n",
      "         -14.0420,  19.2000,  -3.1885]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 19.200000889819716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5509, 10.6032, -1.8534, -3.6130, -2.0643, -1.5445, -2.2641, -9.7601,\n",
      "         14.4338, -2.1724]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.433791227534673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1113, 24.1899, -2.4706, -9.7363, -2.4417, -1.7912, -2.8114,  2.2828,\n",
      "         -3.1133, -2.9219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 24.189864832712857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8030,  6.9809, -0.8864, -3.4066, -0.9254, -0.6835, -1.1090, -0.7418,\n",
      "          2.8785, -1.2702]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.980874575965677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9757,  10.3603,  -3.8969,   6.5083,  -4.0865,  -3.3485,  -3.9831,\n",
      "         -21.6484,  28.9520,  -4.8344]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 28.95200196242485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4633,  14.3024,  -2.8265, -14.6458,  -3.1130,  -2.2822,  -2.9694,\n",
      "         -10.1584,  27.6630,  -3.7120]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 27.662985684164212\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.9134,  16.8391,  -4.4167,   7.7912,  -4.7767,  -3.8824,  -4.7978,\n",
      "         -12.4039,  15.0230,  -5.6236]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.83912374332963\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8310, 10.7173, -0.5314, -8.7408, -0.6589, -0.8893, -0.9751, -1.3592,\n",
      "          4.1762, -0.5243]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 10.717306538507746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3912,   7.6318,  -2.5252,  -4.8490,  -2.6950,  -2.2016,  -2.5383,\n",
      "         -12.1500,  25.8013,  -3.4616]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 25.801347704616933\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7040,  7.7707, -1.9791, -0.3209, -1.7946, -1.5498, -2.1382, -3.7121,\n",
      "          7.6785, -2.5415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.770671826115374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5490, 14.2179, -2.0068, -8.4147, -1.8740, -1.4359, -2.0120,  2.7845,\n",
      "          3.0721, -2.5483]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 14.217904285129391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3721,   9.3872,  -1.8331,  -6.7313,  -1.5677,  -1.4912,  -1.8143,\n",
      "         -10.3984,  17.9290,  -2.0145]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 17.928982859692127\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7279,  16.0023,  -2.6483,  -7.9834,  -2.4925,  -1.8910,  -2.7313,\n",
      "         -10.1459,  18.3817,  -2.8086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.381711715527818\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1267,  4.2898, -1.4051,  0.0273, -1.1629, -1.0344, -1.4347, -1.3558,\n",
      "          4.6180, -1.7399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 4.6180447859091185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3474,   3.4067,  -1.6608, -19.6068,  -1.8256,  -1.5883,  -1.5465,\n",
      "          -4.1753,  30.5775,  -2.2357]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 30.577517902848445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7407,   4.0226,  -2.3980,   4.2511,  -2.4438,  -1.8231,  -2.8525,\n",
      "         -15.1181,  22.1547,  -3.0618]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 22.15474954497265\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6046,  15.5460,  -1.8833, -12.4958,  -1.6894,  -1.3490,  -1.7137,\n",
      "          -1.5462,   8.6781,  -2.1451]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.546046215641287\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9117,  5.8585, -1.1853, -7.3253, -1.2518, -0.9700, -1.2620, -4.1661,\n",
      "         13.0616, -1.6117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 13.061580725876057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7862,   8.1209,  -2.1315, -11.9377,  -2.4983,  -1.7405,  -2.1407,\n",
      "          -6.3771,  23.0851,  -2.9231]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.085117341611415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3736,  9.6624, -1.8038,  0.7445, -1.9691, -1.2620, -1.8730, -9.2528,\n",
      "         10.8650, -2.1354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 10.865001004089166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9635,   5.2986,  -2.6008,   8.0643,  -2.2181,  -1.8246,  -2.7315,\n",
      "         -12.5908,  15.2246,  -3.2617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.224588108975318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5470, 11.4695, -1.6108, -7.4301, -1.6255, -1.3884, -2.1478,  0.6850,\n",
      "          5.6319, -2.2193]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.469537112241701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9458, 21.0865, -2.3778, -7.7778, -2.3318, -1.8485, -2.6000,  2.9715,\n",
      "         -3.2081, -2.7080]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.08648212103568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9964,  6.3236, -1.2943, -7.4352, -1.2261, -0.9183, -1.3971, -6.8914,\n",
      "         15.1863, -1.3962]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 15.186263841686086\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7297,  13.0026,  -2.3738,  -4.7651,  -2.1913,  -1.7323,  -2.2797,\n",
      "         -13.1715,  17.9788,  -2.7807]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.978778089389284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9406,  19.9361,  -3.5082,   0.6040,  -3.6848,  -2.6605,  -3.7858,\n",
      "         -23.7977,  24.5696,  -4.6376]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 24.569587169314488\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2963, 13.4519, -2.4063, -6.5353, -2.8447, -2.2185, -2.7398, -0.4772,\n",
      "          8.7939, -3.3448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 13.45189795621483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0819,   3.4286,  -1.3821,  -5.8946,  -1.4841,  -1.0984,  -1.2557,\n",
      "         -10.6644,  21.8057,  -1.6557]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 21.805737775524598\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5569,   3.0579,  -1.9132, -11.1026,  -2.0378,  -1.6389,  -2.0283,\n",
      "          -5.6562,  26.4631,  -2.6431]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.463078885308672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5794, 19.5873, -2.9830, -1.2076, -3.0389, -2.5458, -3.3293, -4.3870,\n",
      "          3.9432, -3.7756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.58725989072606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2111,  19.8960,  -2.2940, -12.8431,  -2.4649,  -1.8790,  -2.6375,\n",
      "           3.6791,   3.7565,  -3.1011]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.895952335589485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6217,  6.6239, -1.9656, -0.0501, -2.1520, -1.7597, -1.9999, -6.6172,\n",
      "         12.1415, -2.5400]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 12.141484436540491\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9274,  7.4485, -2.2578, -7.0941, -2.5203, -1.7613, -2.3066, -9.4053,\n",
      "         23.3990, -3.0918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.398952209366495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4734,  2.2350, -0.5829, -4.9100, -0.5306, -0.5064, -0.8361, -3.3063,\n",
      "         10.1031, -0.7101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 10.10312167839846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4199,   9.4630,  -1.9097,  -4.4655,  -1.9213,  -1.4808,  -2.1312,\n",
      "         -11.7486,  19.0367,  -2.4440]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.03667732624822\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4614, 14.3058, -2.4772,  1.3247, -2.8664, -1.8209, -3.0289, -6.9434,\n",
      "          7.3150, -3.4589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 14.305842905450447\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7204,  17.7083,  -3.4263,   1.8658,  -3.9193,  -2.8813,  -3.7949,\n",
      "         -10.8361,  12.2794,  -4.0653]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.708296160481474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0692,  6.2360, -0.8802, -3.8823, -1.0688, -0.8968, -1.3016, -7.6618,\n",
      "         11.9188, -1.2767]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 11.918803337596234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3220,   3.3342,  -1.4762, -13.1300,  -1.5468,  -1.3954,  -1.5777,\n",
      "          -3.1393,  22.4914,  -2.1626]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.491410225426083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5565,  7.9778, -1.6374, -3.1606, -1.7940, -1.4377, -1.8372, -3.7964,\n",
      "          9.3413, -2.0565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 9.341327288108957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4965, 14.3491, -1.7186, -7.8489, -1.7990, -1.3980, -2.1381,  1.0111,\n",
      "          2.2380, -2.0441]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.349098221976353\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4986,  11.3948,  -1.7115,   0.1476,  -1.9695,  -1.2962,  -2.0313,\n",
      "         -17.0969,  16.4286,  -2.2879]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 16.428558827758746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0787,  8.1956, -3.5518, 10.9368, -3.4977, -2.6804, -3.7977, -9.5263,\n",
      "         11.9621, -4.5752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 11.962137776022177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4463,   9.5798,  -1.8656,   1.5163,  -2.3884,  -1.5904,  -1.8404,\n",
      "         -13.3009,  15.4349,  -2.4133]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.434923559156863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4718,   8.1585,  -2.0033,  -2.5651,  -1.9915,  -1.3912,  -2.1909,\n",
      "         -13.8717,  21.5490,  -2.4734]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.548951815380242\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0540,   5.2653,  -1.0946,  -2.0422,  -1.1897,  -0.8776,  -1.2830,\n",
      "         -11.4142,  15.1886,  -1.3475]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 15.188554926988479\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9535,  21.6113,  -3.6874,   2.2380,  -3.8704,  -2.9766,  -3.9579,\n",
      "         -11.4061,   9.5893,  -4.3862]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 21.611257646268122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7645,  19.4584,  -3.2185,  -5.6700,  -3.5648,  -2.7108,  -3.5397,\n",
      "         -20.2447,  26.4057,  -4.3716]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 26.40567644056375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6125, 14.0674, -1.9688, -6.1329, -2.1267, -1.5775, -2.1912,  2.4047,\n",
      "          2.3811, -2.7491]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 14.067358289398872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6111,   1.6482,  -2.0092,   5.2198,  -2.4664,  -2.0408,  -2.2427,\n",
      "         -12.3182,  19.1271,  -2.8302]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.127098823663985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4741, 10.9984, -1.9841, -2.5073, -1.8991, -1.4770, -2.0053, -6.6772,\n",
      "         11.4129, -2.5117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 11.412855154172572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4512,   4.5531,  -2.0109,   7.7189,  -2.0570,  -1.5750,  -2.0319,\n",
      "         -13.3105,  14.1929,  -2.3886]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 14.192933530521081\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6382, 11.4430, -1.9439, -3.7218, -2.0089, -1.5062, -2.0247,  0.4264,\n",
      "          4.5835, -2.6284]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 11.443033684363959\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2011,  17.7881,  -1.6954, -10.0461,  -1.5468,  -0.9745,  -2.0181,\n",
      "          -3.4515,   5.4996,  -1.6601]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 17.788127573553687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1002,  7.5968, -2.1955, -6.1059, -2.3349, -1.7208, -2.2889, -6.4876,\n",
      "         19.7775, -3.1030]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 19.77751911472251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5746,  15.3564,  -4.1790,   6.2963,  -4.5237,  -3.3300,  -4.8039,\n",
      "         -10.2127,  14.4341,  -5.4802]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 15.35637124825467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9859,  15.9771,  -2.8064,  -2.2162,  -2.6085,  -2.1212,  -2.8324,\n",
      "         -11.2361,  13.4011,  -3.0577]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.977064749845495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6137,  4.0829, -1.8719,  3.5296, -1.9337, -1.6661, -1.9733, -3.9322,\n",
      "          8.2999, -2.3694]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 8.2998898422136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5025,   8.0523,  -3.1746,   5.6297,  -3.2096,  -2.4700,  -3.3099,\n",
      "         -19.0292,  26.5564,  -4.2226]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 26.55639471856066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0905,   8.5250,  -1.6254,  -3.0689,  -1.8784,  -1.4096,  -2.1723,\n",
      "         -12.5984,  18.8721,  -2.0905]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 18.872098103420374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4177, 13.5270, -2.6267, -3.3626, -2.8746, -2.1225, -3.0126, -7.6584,\n",
      "         13.9905, -3.6116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 13.990548165325068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2665,   4.1803,  -1.9476,   7.9746,  -2.1286,  -1.5686,  -2.3103,\n",
      "         -17.6203,  17.3556,  -2.7229]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 17.355596329551883\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8393, 21.1373, -2.1765, -8.2245, -2.2131, -1.6148, -2.3331,  2.4347,\n",
      "         -3.6613, -2.4156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.137310160343738\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9174,   8.4711,  -2.0640,  -3.2734,  -2.3859,  -1.9673,  -2.0893,\n",
      "         -15.2274,  23.8221,  -2.7824]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 23.82208558975449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5616,   4.6247,  -1.8200, -20.0976,  -2.2346,  -1.8404,  -1.9087,\n",
      "          -6.9614,  34.2361,  -2.5239]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 34.23607155844398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8821, 15.9289, -1.9760, -3.8465, -2.1155, -1.8648, -2.3412, -4.4079,\n",
      "          4.3989, -2.2756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.928922994182006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7227, 22.7954, -2.1145, -9.1888, -2.0903, -1.6108, -2.5099,  4.0749,\n",
      "         -5.8150, -2.4924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 22.795372222756093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7988,  11.4141,  -1.9396,  -2.7951,  -2.2289,  -1.3763,  -2.2776,\n",
      "         -11.6370,  16.3588,  -2.3962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.35882015392833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2179, 15.4051, -2.4538, -6.1711, -2.4898, -1.8556, -2.5603, -2.9018,\n",
      "          8.6760, -3.1366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.405082821004173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6257,  11.7602,  -1.9724,  -1.2009,  -2.2095,  -1.5242,  -1.9497,\n",
      "         -10.4601,  12.6451,  -2.4098]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 12.64513198986634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0747, 15.3402, -2.3609, -7.9988, -2.2511, -1.7510, -2.1945, -1.5971,\n",
      "          6.7680, -2.7007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 15.340197184805833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.2376,  4.4339, -0.3457, -3.9446, -0.4532, -0.3469, -0.3563, -4.5644,\n",
      "          6.8345, -0.3029]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 6.834500705823219\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9859,  15.5245,  -1.1415, -11.9547,  -0.9689,  -0.7770,  -1.2228,\n",
      "          -2.0753,   4.9529,  -1.1762]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 15.524507821392909\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8530,  15.1454,  -2.0951, -13.5965,  -2.0462,  -1.7416,  -2.4377,\n",
      "           5.4222,   5.8451,  -2.6696]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.145378349251269\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8163,   5.7661,  -2.2429, -11.7553,  -2.7538,  -2.1430,  -2.4033,\n",
      "          -8.7055,  29.3399,  -3.2206]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 29.33993922113606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7857,   3.3403,  -2.1722,  10.1582,  -2.3731,  -1.7078,  -2.2477,\n",
      "         -18.7246,  19.0511,  -2.9839]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.051053635150748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7202, 18.3666, -1.9786, -8.8598, -1.9851, -1.6395, -2.4848,  1.0449,\n",
      "          0.6682, -2.4738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 18.36662739121109\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9654,   8.1375,  -2.4886,  -0.4214,  -2.6044,  -2.0248,  -2.7152,\n",
      "         -13.0802,  20.6666,  -3.2965]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 20.66662099700589\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6086,  2.8048, -1.9991, -8.6908, -2.2327, -1.7755, -2.0315, -9.8872,\n",
      "         28.6490, -2.8614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 28.64902220165626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8960,  5.4505, -2.3933,  3.7394, -2.1424, -1.8529, -2.3902, -8.9595,\n",
      "         12.9770, -2.8024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 12.977047159910356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4289,   2.4037,  -1.6480, -11.9833,  -1.9364,  -1.5184,  -1.6625,\n",
      "          -3.0953,  23.6353,  -2.3972]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 23.635255113506428\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9976, 10.5959, -2.3879, -0.5559, -2.5969, -1.8924, -2.2207, -5.4618,\n",
      "          8.8980, -2.9216]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 10.595885019802825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2149,  15.2892,  -2.8954,  -1.4563,  -2.9815,  -1.9964,  -3.0030,\n",
      "         -14.7636,  19.3983,  -3.7042]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 19.398273702813587\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1054,   5.5671,  -1.7585,   1.8565,  -1.8895,  -1.2660,  -1.8218,\n",
      "         -15.3184,  18.1620,  -2.1809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.16204647311552\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3945, 15.2679, -1.7125, -6.5080, -1.7291, -1.2561, -1.9884, -0.9116,\n",
      "          1.3851, -1.9247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.26786236847194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9869,  3.5925, -1.0250, -1.2618, -1.3690, -1.0248, -1.2596, -6.8810,\n",
      "         11.7973, -1.5472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 11.797276503269982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6526,  12.8712,  -1.9247, -10.9938,  -1.9406,  -1.5640,  -2.2967,\n",
      "          -0.5967,  10.7537,  -2.6324]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 12.871212824528394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8043,   9.6784,  -2.1861,   0.0787,  -2.2091,  -1.5667,  -2.4832,\n",
      "         -11.1075,  16.3936,  -2.9947]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 16.393640679676277\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1932, 11.8146, -2.5337, -8.0689, -2.5524, -1.8586, -2.7886, -1.5424,\n",
      "         13.4594, -3.3889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 13.45938534041908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7140e+00,  7.7713e+00, -1.9396e+00,  7.8329e-03, -2.2354e+00,\n",
      "         -1.8668e+00, -2.2760e+00, -1.1895e+01,  1.6464e+01, -2.7353e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 16.463925718641896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9479,  8.0735, -2.1942, -8.5984, -2.2678, -1.8100, -2.3113, -2.8894,\n",
      "         17.8936, -3.1151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.89362232154686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9004, 11.2416, -2.0441, -5.1587, -2.1296, -1.6115, -2.3140, -4.4161,\n",
      "         10.7611, -2.7245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 11.241611946122825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0752, 10.8985, -2.5292, -1.1964, -2.4478, -1.9071, -2.4166, -1.7241,\n",
      "          6.7122, -3.1652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 10.898472259452774\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0260,  4.1254, -1.3500, -1.5152, -1.1819, -0.8048, -1.3396, -0.7250,\n",
      "          5.3061, -1.6730]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  1\n",
      "activation[8] = 5.306116363342453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4589,   5.1171,  -1.8213, -15.4130,  -2.1002,  -1.6993,  -1.9478,\n",
      "          -4.1458,  26.0831,  -2.6311]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 26.08313037772351\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3523,  8.1618, -1.4828, -6.8518, -1.2358, -1.2557, -1.7775,  0.6230,\n",
      "          6.8675, -1.9728]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.161810613664484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6556,  10.0700,  -1.9975, -13.4779,  -2.1129,  -1.5534,  -2.3021,\n",
      "           1.7499,  14.3101,  -2.7749]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.310101855466423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9748,  8.9736, -1.9275, -2.1350, -1.6233, -1.0870, -1.7170, -9.3190,\n",
      "         13.9594, -1.9138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 13.95939726626622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9937,  9.4475, -2.2812, -7.8884, -2.2742, -1.8040, -2.4830, -5.0403,\n",
      "         17.9184, -3.0716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 17.918360932765932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9873,   6.5196,  -1.3003,  -4.2667,  -1.7606,  -1.2774,  -1.4816,\n",
      "         -13.8948,  20.7337,  -1.5544]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 20.733655164024366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9739,   9.3742,  -2.1276, -12.7294,  -2.3109,  -1.9562,  -2.0757,\n",
      "          -7.1073,  24.0221,  -2.8374]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.02206857060655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7860,   5.9648,  -2.1889,   6.9648,  -2.3983,  -1.8361,  -2.4063,\n",
      "         -13.9067,  14.8664,  -2.6165]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 14.866430929081911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3292,   3.5002,  -1.7013, -16.2496,  -1.9381,  -1.6825,  -1.5498,\n",
      "          -6.5162,  29.6360,  -2.2313]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 29.63598897082485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6754, 12.8258, -2.9722,  8.6429, -3.3906, -2.5278, -3.1182, -9.3958,\n",
      "          6.0210, -3.9131]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.825778369313072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7803, 15.5444, -2.3938, -3.3721, -2.3377, -1.7113, -2.4324, -9.5614,\n",
      "         10.9870, -2.7689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 15.544375134678692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3262,   8.1997,  -1.0916,  -1.9690,  -1.5954,  -1.2595,  -1.4951,\n",
      "         -10.6547,  12.7269,  -1.5316]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 12.726911497063028\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3098, 11.9720, -1.8393, -9.8998, -1.6709, -1.2741, -1.9781, -9.6855,\n",
      "         19.0585, -2.0208]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.058536842811037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5866,   6.5239,  -1.7881,  -4.1139,  -1.9342,  -1.6875,  -1.7106,\n",
      "         -15.6386,  24.3095,  -2.1178]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.309452534419382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6219,  11.0017,  -0.9775, -11.0057,  -0.8489,  -0.7166,  -1.0960,\n",
      "           1.7549,   4.3202,  -1.3262]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 11.00173275888165\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1410, 12.3288, -1.2502, -5.4724, -1.3044, -0.9259, -1.7156, -1.2318,\n",
      "          2.0675, -1.5759]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.328829333771548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5463,  14.4435,  -4.2686,  13.3984,  -4.3818,  -3.5262,  -4.7775,\n",
      "         -11.1494,   9.5960,  -5.5589]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.44351079311547\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0100, 13.0685, -2.8426, -1.0776, -3.0639, -2.2999, -2.9374, -9.7193,\n",
      "         13.9617, -3.2529]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 13.961686195695215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9614,  6.9429, -2.3503, -9.3326, -2.5130, -1.9440, -2.4106, -9.5038,\n",
      "         25.9886, -3.1405]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 25.988606038012215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8028,  11.3189,  -2.0190,  -5.5078,  -2.0089,  -1.5772,  -2.1295,\n",
      "         -15.3187,  22.4444,  -2.5394]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 22.444376369420137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.4419, 15.0289, -2.6404, -6.6141, -2.7842, -1.9979, -2.7951, -2.4698,\n",
      "         10.5297, -3.5180]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 15.028897432067156\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3359,   4.6143,  -1.5912,   4.4378,  -1.5063,  -1.2846,  -1.4451,\n",
      "         -10.9358,  10.8772,  -1.8825]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 10.87717408608157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.6985,  12.7184,  -4.3304,   7.1082,  -4.5114,  -3.7921,  -4.5296,\n",
      "         -14.9799,  21.1383,  -5.5488]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 21.13832291610554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3301,   9.7197,  -1.4236,  -3.9069,  -1.5037,  -1.1913,  -1.8396,\n",
      "         -10.7307,  14.9646,  -1.7296]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.964647323146899\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2720,   9.1436,  -2.5642, -11.4215,  -2.8188,  -2.1554,  -2.6484,\n",
      "          -6.5333,  24.7723,  -3.5584]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.7723437488269\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7788, 11.7794, -2.0476, -4.7811, -1.9945, -1.7288, -2.2890, -6.4160,\n",
      "         11.4064, -2.4295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 11.779420831481485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9299,   5.5397,  -2.6231,   7.9848,  -2.4016,  -1.9558,  -2.6666,\n",
      "         -15.5313,  18.7587,  -3.3734]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.75869694919032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9009,  12.2896,  -2.3327,   0.7007,  -2.4296,  -1.7185,  -2.7324,\n",
      "         -15.2925,  18.0884,  -3.1386]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.088366338750507\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5654,  11.8322,  -3.1441,  -4.2055,  -2.9920,  -2.4433,  -3.0808,\n",
      "         -17.9726,  28.4837,  -4.0141]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 28.48373277128825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1067,  14.3639,  -2.3993,   1.3755,  -2.7700,  -2.0705,  -2.9399,\n",
      "         -19.9397,  20.1337,  -3.2665]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 20.133681924253487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5897,   3.9789,  -1.9782, -15.9064,  -2.2659,  -1.6117,  -1.8876,\n",
      "          -4.4578,  28.3548,  -2.6780]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 28.3547794478844\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2868,   6.1746,  -1.9308,   0.2191,  -2.3789,  -1.5541,  -2.3185,\n",
      "         -21.5816,  28.1285,  -2.6510]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 28.128530563912644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4049, 15.1189, -2.0033, -8.7409, -1.9427, -1.5071, -2.2379, -7.4913,\n",
      "         13.5064, -2.2017]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 15.118936209460191\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4490,  7.7111, -1.4863,  0.5131, -1.3654, -1.1828, -1.7281, -9.3325,\n",
      "         10.6652, -1.9163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 10.665184246473986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4505,  12.9416,  -3.9553,  10.7345,  -4.2627,  -3.5620,  -4.2661,\n",
      "         -17.7942,  18.8971,  -5.2160]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 18.897121902545717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2011,  17.6782,  -2.9318,  -6.6948,  -2.8342,  -2.1515,  -3.3210,\n",
      "         -15.2684,  21.6557,  -3.5994]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 21.65568639625759\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3034,   6.4816,  -3.1372,  14.2205,  -3.0545,  -2.3989,  -3.3804,\n",
      "         -24.9450,  24.6360,  -4.0249]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 24.6359776875971\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7118,  15.5195,  -2.0780, -18.9277,  -1.8712,  -1.2577,  -1.9819,\n",
      "         -11.1931,  26.7948,  -2.5388]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 26.794806916854917\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7352,  8.0479, -2.0386, -6.8574, -2.0586, -1.6310, -2.2042, -4.8958,\n",
      "         16.7268, -2.8271]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 16.726824426065804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6981,  11.5813,  -2.3091,   4.3326,  -2.3996,  -1.4177,  -2.5047,\n",
      "         -15.8384,  14.7131,  -3.1113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 14.71310359817807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5855,  10.6609,  -2.2468,  -6.2783,  -2.0614,  -1.6694,  -2.3036,\n",
      "         -11.4619,  21.2983,  -2.5719]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 21.29828738536074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1890,  4.6244, -1.4338, -3.8141, -1.6870, -1.2051, -1.6715, -9.0215,\n",
      "         17.3968, -1.9236]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 17.396757211729934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5586,  14.9658,  -3.8442,   9.0833,  -4.4381,  -3.5426,  -4.3614,\n",
      "         -10.6889,  11.8204,  -5.3670]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.965804201412809\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4751,   7.9228,  -1.4933,  -5.6632,  -1.6923,  -1.3834,  -1.6900,\n",
      "         -10.6859,  18.4590,  -1.9404]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 18.459017845946388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1031,   5.7028,  -1.4876, -18.3877,  -1.7093,  -1.4993,  -1.4774,\n",
      "          -1.1322,  22.7825,  -1.9802]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.782526061284656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9055,  2.6274, -0.9058, -3.6009, -1.0711, -0.8617, -1.0521, -1.5374,\n",
      "          8.4636, -1.2671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 8.463559676591174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8240,  11.0590,  -2.4828,   2.6082,  -2.5404,  -1.7944,  -2.5952,\n",
      "         -19.7063,  22.1213,  -3.3981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.121313082461537\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9241, 10.9823, -1.1119, -4.2200, -1.3683, -1.0372, -1.3354, -4.4787,\n",
      "          5.9508, -1.2749]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 10.982326885957432\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5748, 14.0904, -1.8603, -8.1076, -1.8234, -1.5072, -2.1542,  2.1651,\n",
      "          1.9562, -2.1500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.090418499420755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3998, 13.6504, -1.5926, -6.1247, -1.8302, -1.3391, -1.9824, -7.5402,\n",
      "         10.7880, -1.8340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 13.650407191667078\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6197, 19.8372, -1.9666, -6.9431, -2.0611, -1.4773, -2.4077,  0.6496,\n",
      "         -2.4040, -2.3417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.837182004293872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8676,   2.9402,  -1.2957,  -3.4851,  -1.0966,  -1.2102,  -1.1505,\n",
      "         -10.5890,  19.1982,  -1.4481]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 19.19817014903508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6332,  13.5994,  -3.4182,   0.2545,  -3.7573,  -2.7661,  -3.6571,\n",
      "         -12.4501,  19.4780,  -4.2305]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 19.477993996774327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4435,   7.4711,  -1.7598,   3.1081,  -2.2387,  -1.5824,  -1.8750,\n",
      "         -15.7647,  18.5390,  -2.4196]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 18.538953643759474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1309,  8.4732, -2.3480, -9.4823, -2.5548, -1.9391, -2.4393, -7.2074,\n",
      "         23.0233, -3.2846]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 23.02325120769491\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7707, 11.3687, -1.7066, -8.4167, -2.0980, -1.8417, -2.4088, -5.5087,\n",
      "         14.5948, -2.4926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 14.59483788454699\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.4624, 14.7855, -3.7589,  2.6306, -4.1394, -3.4304, -4.2063, -7.8638,\n",
      "         13.7300, -5.0822]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 14.78548862515066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5670, 12.8032, -1.7167, -2.1984, -1.8192, -1.2988, -2.1034, -8.9850,\n",
      "         11.2049, -2.4204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 12.80318479991496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8758, 19.1757, -2.2354, -7.2175, -2.2392, -1.6711, -2.4034,  1.4093,\n",
      "         -1.4840, -2.5205]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.175736967063827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9162,   9.5173,  -2.4287,   3.2900,  -2.6822,  -1.9957,  -2.8162,\n",
      "         -16.4590,  18.7399,  -3.3534]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 18.739854448401026\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1046,  15.6258,  -3.5011,   0.3285,  -3.8104,  -2.8001,  -3.8928,\n",
      "         -10.7016,  16.5235,  -4.7003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  8\n",
      "activation[8] = 16.523499605463716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3049,  24.2636,  -2.6593,  -3.4043,  -2.6739,  -2.2942,  -3.1008,\n",
      "         -11.3963,   7.1641,  -3.4856]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 24.263610109416824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8561,   5.3344,  -2.0789,  -5.9306,  -2.1901,  -1.7595,  -2.0876,\n",
      "         -10.8513,  24.4100,  -2.8763]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.410028176656528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4274,  13.5890,  -1.9913,  -5.1296,  -2.0272,  -1.6443,  -2.0406,\n",
      "         -19.9608,  23.1206,  -2.4044]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 23.12058773660166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8474, 16.4706, -3.0542, -3.1389, -3.1766, -2.5230, -3.5518, -2.6621,\n",
      "          8.4198, -4.1350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 16.470593678861064\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2313,  4.7338, -1.4375, -2.2126, -1.4422, -1.3891, -1.4889, -1.3657,\n",
      "          7.2377, -1.8555]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 7.237652135128749\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9850,  15.3255,  -2.8237,  -6.7409,  -2.6513,  -2.0849,  -2.6285,\n",
      "         -10.1260,  17.3413,  -3.2003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 17.341265626660967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4730,  9.5171, -1.4432, -4.1469, -1.6267, -1.2404, -1.6588, -4.6027,\n",
      "          8.6937, -2.0707]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 9.517137332537436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8685, 10.6169, -2.3437, -4.2298, -2.4420, -1.8543, -2.4704, -0.1150,\n",
      "          8.2992, -3.0079]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 10.616908435844396\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7688,  7.9888, -1.2447, -4.7166, -1.1571, -0.9451, -1.2270, -5.8111,\n",
      "         10.5319, -1.4369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 10.531940232024244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7482,  16.3467,  -2.4899,  -6.5929,  -2.2993,  -1.6876,  -2.3680,\n",
      "         -10.0579,  13.4129,  -2.7481]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.346659227087216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9543, 12.9676, -2.3816, -0.8710, -2.7256, -2.0161, -2.7773, -9.4750,\n",
      "         12.2785, -3.0746]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.967615559405926\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1877,   7.0878,  -1.7709,  -0.2656,  -1.7809,  -1.1738,  -1.9481,\n",
      "         -12.5649,  18.1015,  -2.2411]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 18.101463816803854\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1957, 10.8420, -1.0139, -5.9131, -1.0169, -1.1812, -1.3932, -6.4034,\n",
      "          9.3444, -1.3561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 10.841971053552536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1837,   7.3177,  -2.4748, -10.5611,  -2.8467,  -2.1555,  -2.5275,\n",
      "         -12.9065,  32.0642,  -3.4838]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 32.064212670883855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4171,  7.0375, -1.6746, -8.2677, -1.9309, -1.4990, -1.9868, -4.1580,\n",
      "         16.1672, -2.1140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 16.16722794397231\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4381,  11.3704,  -2.0401,  -6.3668,  -1.7793,  -1.4355,  -2.1065,\n",
      "         -15.9109,  24.3385,  -2.1114]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 24.338512791003932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2944,  10.4843,  -2.7539,   2.6884,  -2.9565,  -2.4492,  -3.0743,\n",
      "         -14.2414,  18.1258,  -3.6070]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 18.12576191973487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5515,  10.7148,  -3.0987,  -0.2006,  -3.1273,  -2.4922,  -3.1285,\n",
      "         -13.4308,  22.8332,  -4.0027]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 22.833153163018025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8082,   4.7062,  -1.4416,   0.6217,  -1.3803,  -1.1533,  -1.7379,\n",
      "         -11.7547,  16.1917,  -1.7741]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 16.191685291627582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6813,   8.8238,  -3.3764,   9.9781,  -3.4775,  -2.6862,  -3.6875,\n",
      "         -16.6897,  19.1253,  -4.4098]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 19.125344117954654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5400, 12.1102, -3.4013,  1.5797, -3.2166, -2.2528, -3.3045, -8.2967,\n",
      "         15.2516, -4.2145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.251622528558622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5480,  11.3163,  -3.9298,   8.1972,  -4.3934,  -3.5921,  -4.2678,\n",
      "         -14.5059,  19.5586,  -5.2508]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 19.558574533385038\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9311,  7.7553, -0.9669, -5.8696, -1.0374, -0.9272, -1.5072,  2.9733,\n",
      "          1.7719, -1.2881]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.755337742696384\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4433,  11.7694,  -3.6101,   2.3927,  -4.0679,  -3.4482,  -3.9654,\n",
      "         -13.8133,  22.9317,  -5.0332]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 22.931737731400464\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4267,   8.3124,  -2.1308,   1.1621,  -2.1081,  -1.5284,  -1.9168,\n",
      "         -16.9779,  20.6937,  -2.7367]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 20.693739974388922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4459,   7.2584,  -2.0800,  -7.3654,  -1.8399,  -1.5243,  -1.9420,\n",
      "         -13.7422,  26.2332,  -2.1909]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 26.23321960662418\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8385, 12.8208, -1.9728, -1.2674, -1.9440, -1.6426, -2.4099, -8.0721,\n",
      "          9.2866, -2.4283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.82079818608418\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6977,   8.8301,  -2.9008,  -2.4267,  -3.1423,  -2.6911,  -3.1270,\n",
      "         -10.5303,  22.6085,  -3.8925]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 22.608468613066993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5425,   5.7463,  -1.7634,   2.9487,  -1.8742,  -1.6226,  -1.8791,\n",
      "         -12.5963,  14.9316,  -2.2302]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  3\n",
      "activation[8] = 14.931620857054675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0188, 11.7131, -2.4397, -3.1213, -2.4827, -1.8788, -2.5095,  1.4743,\n",
      "          4.5982, -3.1545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 11.713076772915949\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8492,   4.5956,  -2.4683,   7.9718,  -2.7927,  -1.8781,  -2.6370,\n",
      "         -15.6930,  19.3626,  -3.5370]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 19.36259372515421\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5302,  10.0206,  -3.5598,   2.3815,  -3.5887,  -2.6235,  -3.5990,\n",
      "         -15.6593,  25.8658,  -4.5564]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 25.865811656003782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2673,  3.8320, -1.5652, -8.2069, -1.7265, -1.3555, -1.4438, -8.0619,\n",
      "         22.1086, -2.0466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 22.10856585871841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.5669, 10.5303, -4.1694, 14.9694, -4.5209, -3.4864, -4.5069, -5.6609,\n",
      "          5.3201, -5.3674]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.969439142418915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5117, 14.9169, -2.4155, -5.3763, -2.9720, -2.1863, -2.9330, -8.3560,\n",
      "         14.6375, -3.3840]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 14.91694578084748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0692,   3.3880,  -1.4498, -16.4884,  -1.6937,  -1.4517,  -1.3343,\n",
      "          -5.3559,  27.3031,  -1.9222]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 27.303086816008655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6973,   8.9474,  -3.4536,  14.2239,  -3.5524,  -2.5761,  -3.5320,\n",
      "         -23.8150,  21.7891,  -4.6210]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 21.789055309508267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5238,  11.8319,  -2.0733,  -6.5644,  -1.8367,  -1.6168,  -2.3013,\n",
      "         -15.0478,  23.3362,  -2.4820]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 23.336238652166717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8195,  8.9848, -1.9443, -2.9348, -2.0761, -1.7100, -1.9403, -4.6393,\n",
      "         10.3081, -2.5228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 10.308070696410379\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8912, 22.4794, -2.1848, -9.0846, -2.2801, -1.6515, -2.4958,  2.0583,\n",
      "         -3.4385, -2.5305]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 22.479428508819325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3282,  8.9774, -1.6609, -3.4565, -1.6511, -1.2366, -1.7734, -5.4246,\n",
      "          9.4275, -1.6632]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 9.427453414094309\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2652, 12.5197, -1.6881, -7.0844, -1.5239, -1.1032, -1.4876,  0.7880,\n",
      "          3.1648, -1.9802]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 12.51974172464321\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8641,   6.4197,  -2.3071,  -1.9460,  -2.2312,  -2.0539,  -2.2848,\n",
      "         -11.3381,  20.6417,  -2.8402]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  2\n",
      "activation[8] = 20.641725269647306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0129, 12.6142, -1.3892, -9.0154, -1.2790, -1.0144, -1.5099,  2.5653,\n",
      "          2.4055, -1.8065]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 12.614234554840348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3309, 12.6406, -1.3899, -5.6890, -1.5374, -1.2271, -1.9184, -0.3032,\n",
      "          1.8776, -1.8535]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.64056087238754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0807,  10.2442,  -2.3684, -15.0489,  -2.6154,  -1.9961,  -2.4141,\n",
      "          -9.7325,  29.2688,  -3.1412]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 29.26879928580653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4230,  14.7247,  -3.4985,  -2.1898,  -3.7379,  -2.7532,  -3.9749,\n",
      "         -17.3759,  27.2560,  -4.6024]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  5\n",
      "activation[8] = 27.256047187205752\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7116,  16.3613,  -1.8453, -13.3683,  -1.9240,  -1.4606,  -1.8550,\n",
      "          -0.2061,   8.1426,  -2.3276]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 16.361255612386657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8638,  5.0561, -1.2675,  1.2690, -1.3521, -0.9264, -1.3001, -7.8119,\n",
      "          9.4745, -1.6858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  6\n",
      "activation[8] = 9.474455372084456\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6529, 10.0027, -2.2989, -2.4031, -2.0316, -1.4971, -2.1702, -8.9147,\n",
      "         15.4417, -2.8842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 15.441689117311826\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5806,  2.5597, -0.7441, -5.4838, -0.6887, -0.5837, -0.8737, -5.0331,\n",
      "         13.0615, -0.8728]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 13.061477384974085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9731,  11.1274,  -2.4502, -16.8382,  -2.6716,  -2.1226,  -2.5016,\n",
      "          -4.1212,  24.3466,  -3.2369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 24.34657118829687\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [10]: loss = 16.297, accuracy = 13.67\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4132, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5423,  0.4675], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4132, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5423,  0.4675], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -2.2945,  11.6659,  -2.5603,  -1.9880,  -3.0641,  -2.2078,  -2.5012,\n",
      "         -14.6192,  -2.9170,  20.8701]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.870100451578743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0031,  14.9872,  -2.6305,  -0.7585,  -2.8838,  -1.9741,  -2.7865,\n",
      "         -13.2570,  -9.3629,  21.8992]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.899231116752663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8512, 10.7021, -1.8608, -5.2940, -2.1199, -1.5103, -2.1384, -9.1478,\n",
      "         -3.3868, 16.7292]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.729161021175322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5509,  11.8807,  -1.6288, -10.0638,  -1.6962,  -1.5758,  -2.2219,\n",
      "           2.2242, -13.4564,  17.2777]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.27774766737313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4081,  8.4519, -1.7037,  3.2290, -1.9169, -1.6652, -1.8534, -6.5406,\n",
      "         -5.6798,  8.4699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 8.469941428112113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2149,  17.1742,  -3.0305,  -2.5924,  -2.9237,  -2.3141,  -3.1084,\n",
      "         -13.1798, -14.4714,  27.0500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 27.049959945177648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8485,   9.1162,  -2.1772,  -3.7453,  -2.6837,  -1.9157,  -2.0698,\n",
      "         -16.4326,   1.7985,  20.0765]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.076515771965603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0205,  11.7033,  -2.2762,   5.5164,  -2.6951,  -2.1500,  -2.9662,\n",
      "         -18.2709,   1.1653,  12.4719]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.471904275831266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8040,  16.4442,  -3.5956,   5.3625,  -3.7234,  -2.7715,  -3.9808,\n",
      "         -16.6066,  -7.2026,  19.2739]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.27390774070157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7626, 10.9368, -1.8327, -0.5374, -2.3319, -1.6782, -2.3232, -7.5337,\n",
      "         -4.6285, 11.9307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 11.930677929134568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3329,  12.8545,  -2.8725,  -2.3540,  -2.8800,  -2.3769,  -3.1393,\n",
      "         -21.2800,   0.2516,  25.9955]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 25.99551555829067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7060,   8.3092,  -2.2907,  -0.1240,  -2.5265,  -2.0553,  -2.7554,\n",
      "         -14.5799,  -2.7232,  21.5329]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 21.532933294534843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1638,  7.5755, -1.1882, -6.0020, -1.0437, -1.0598, -1.5459,  2.1601,\n",
      "         -9.1643, 11.1670]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 11.166965755046478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1919,  12.3485,  -1.4121,  -5.6231,  -1.2979,  -1.1203,  -1.8019,\n",
      "         -12.4912,  -6.6492,  20.5820]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.582022318770413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5395,   7.8524,  -1.6848,  -1.1502,  -2.1494,  -1.6620,  -2.1334,\n",
      "         -11.4303,   2.4795,  11.2502]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 11.25020468557568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7440,   6.9518,  -1.9128, -10.4541,  -2.1005,  -1.6659,  -1.9192,\n",
      "           0.3024,  -4.0406,  17.0232]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.023238326433606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5228,   4.4948,  -1.8294, -10.0442,  -2.0766,  -1.7471,  -1.9782,\n",
      "         -11.1722,   4.9923,  20.6552]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.65515622346858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1605,  20.5107,  -3.8135,   2.8360,  -3.9915,  -2.9502,  -4.0957,\n",
      "         -23.2728, -10.6056,  29.0169]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 29.016851425372046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0536,  13.4893,  -2.4923, -10.3785,  -2.5348,  -1.9874,  -2.8880,\n",
      "          -8.3699,  -8.1467,  25.6400]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.639982864301096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0500,   6.5789,  -2.2149,  -5.1358,  -2.5023,  -1.9793,  -2.0571,\n",
      "         -12.7404,  -1.1407,  23.2409]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.240870067391423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8294,  5.9762, -2.0738, -0.2850, -1.9625, -1.8362, -2.3265, -4.5841,\n",
      "         -7.0739, 15.6097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.609696862395689\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9253,   6.5261,  -2.6708,   4.7835,  -2.5663,  -1.8316,  -2.7891,\n",
      "         -12.9521,  -5.8574,  20.7873]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.78726264666269\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1211,  15.3697,  -3.0855,  -5.4046,  -3.1867,  -2.1353,  -3.4648,\n",
      "         -20.5281,   1.5080,  24.6250]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 24.624987826300544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8207,  15.9810,  -2.0709,  -8.0198,  -2.1210,  -1.7780,  -2.5238,\n",
      "           2.1776, -17.6868,  16.9354]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.93537920430809\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9366,   5.9088,  -2.7582,   3.5271,  -2.9580,  -2.1618,  -2.8205,\n",
      "         -24.5549,   6.5978,  22.5230]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.522956272990587\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4085,  15.6155,  -3.4712,  -0.5096,  -3.4007,  -2.4794,  -3.3401,\n",
      "         -12.9897, -13.0119,  26.1119]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 26.111895869755454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9567,   9.0878,  -1.6316,  -5.1946,  -1.6096,  -1.2668,  -1.7274,\n",
      "         -14.1554,   5.5660,  13.7328]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 13.732835240213392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8056,  14.3016,  -3.4848,   5.9893,  -3.9499,  -2.8659,  -4.1371,\n",
      "         -11.7304,  -8.8218,  18.6829]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 18.682906536647202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5596,  3.3196, -0.9110, -3.8844, -0.8371, -0.8222, -0.8786, -7.6565,\n",
      "          2.4816,  9.7585]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.758516725974774\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7555, 11.5655, -1.7654, -4.7430, -2.1670, -1.6320, -2.1855, -4.3231,\n",
      "         -8.1289, 15.8985]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.898493274882224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3218,  9.0929, -1.3365, -0.6949, -1.4960, -1.0136, -1.5393, -5.7595,\n",
      "         -7.2618, 12.6620]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.662026270227868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4081,   6.1203,  -1.6098, -15.0110,  -1.7598,  -1.6540,  -1.9145,\n",
      "           4.0318,  -6.9525,  20.0280]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.027979750442963\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3020,  11.2973,  -3.0612,  -0.1899,  -3.2062,  -2.2319,  -3.2047,\n",
      "         -21.9783,  -1.5474,  27.9414]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 27.94140969109759\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5031,  13.2360,  -3.2019,   4.8847,  -3.4096,  -2.7917,  -3.3028,\n",
      "         -23.2389,   0.0718,  20.5864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.586368294740428\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2081,  4.8166, -1.4807,  0.0283, -1.3017, -1.1201, -1.6078, -1.5999,\n",
      "         -4.4525,  7.6909]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 7.690857859319674\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6366,   8.0149,  -1.7836, -13.5575,  -1.8720,  -1.5352,  -1.8032,\n",
      "           0.2043, -12.3013,  26.1979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.19793101960478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-9.1626e-01,  1.1014e+01, -9.5006e-01, -5.6657e+00, -1.0789e+00,\n",
      "         -1.0221e+00, -1.4558e+00, -1.0584e+01,  6.2036e-03,  1.0874e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 11.013549528811646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6919,   8.4332,  -3.5198,   9.8054,  -3.5725,  -2.5950,  -3.6078,\n",
      "         -17.1748,  -4.6375,  21.1786]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.178584779465243\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3177,  21.9114,  -4.0916,  -6.8358,  -4.5473,  -3.2429,  -4.4714,\n",
      "         -23.1257,  -4.9891,  32.5373]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 32.53725994843181\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3631,  14.1161,  -1.5030,  -6.5714,  -1.6110,  -1.1525,  -1.9888,\n",
      "          -0.7306, -13.0118,  13.4063]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.116053421132397\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6471,  6.5610, -2.0288, -1.7138, -1.9831, -1.5613, -2.0587, -5.3113,\n",
      "         -5.3926, 15.0034]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.00344852261934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8017,  15.4916,  -2.3234,  -2.7702,  -2.4946,  -1.6393,  -2.6436,\n",
      "         -17.1021,  -1.7573,  17.2662]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.266249936475443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1024,   5.3500,  -1.3503,  -1.9498,  -1.2625,  -0.9839,  -1.5711,\n",
      "         -10.4307,   0.7582,  13.7109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.710923163661358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8907,  10.6118,  -3.4347,   8.4630,  -3.9626,  -2.9399,  -4.1478,\n",
      "         -15.4126,  -2.9983,  17.4401]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.44011425123577\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4154,  16.9948,  -1.5215,  -8.0861,  -1.6634,  -1.2937,  -1.8690,\n",
      "           1.9446, -16.7927,  13.0915]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 16.99481699672561\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0841,   8.5927,  -2.7878,   8.5647,  -3.0566,  -2.2670,  -3.1775,\n",
      "         -21.7109,  -1.8232,  20.6892]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.689198832898654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3883,   4.3212,  -1.8213,   6.8259,  -1.8702,  -1.4729,  -1.6504,\n",
      "         -17.8863,   2.8825,  12.3153]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 12.315336033040177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2131,   7.1634,  -1.6969,  -6.8068,  -1.4840,  -1.2256,  -1.7883,\n",
      "         -12.1649,  -3.2809,  23.8983]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 23.89826976474772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0699,   4.8947,  -1.0234,  -2.7005,  -1.6565,  -1.0543,  -1.2611,\n",
      "         -15.4483,   9.3249,  10.3798]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 10.379849413408055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5023,  14.9333,  -1.7707, -16.1197,  -1.9040,  -1.5988,  -2.2020,\n",
      "           5.9790, -17.5272,  21.5462]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.546195055872595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6029, 13.2625, -1.7536, -6.5767, -1.9703, -1.2441, -1.8864, -4.7329,\n",
      "         -8.8762, 14.9103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 14.910346433634814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.6180,  19.3650,  -4.0910,  12.2646,  -4.2448,  -3.1551,  -4.2900,\n",
      "          -7.5565, -21.4641,  16.9304]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 19.365042276334513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.3118,   3.7489,  -0.4655, -10.6669,  -0.5531,  -0.3832,  -0.8747,\n",
      "          -2.8945,   4.4849,   8.7101]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.71005432208995\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7353,   7.2325,  -1.9380, -10.9530,  -2.0140,  -1.6792,  -2.1131,\n",
      "          -7.2303,  -7.1182,  27.5017]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.50168494681997\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7275,  8.1946, -0.9075, -1.5307, -0.9964, -0.7134, -0.9731, -8.7392,\n",
      "         -2.8168,  9.8867]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.886650074801288\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8271,   8.4815,  -2.3440,   0.3082,  -2.6298,  -1.6665,  -2.7249,\n",
      "         -14.7304,  -0.6246,  18.8795]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.879538497294533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3274,  4.6156, -1.5971,  0.9758, -1.3424, -1.2774, -1.6376, -1.2652,\n",
      "         -5.8484,  8.4582]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.458184209433034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7238,   6.6317,  -2.4742,   0.3205,  -2.4372,  -1.7197,  -2.4956,\n",
      "         -14.0437,  -1.9555,  21.5837]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.583651703458408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9962,  3.7902, -1.9832,  1.6009, -2.2458, -2.1413, -2.2899, -5.3301,\n",
      "         -0.7312, 10.8851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.885072420201409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4209,  10.5114,  -1.6060,  -4.6701,  -1.6707,  -1.2188,  -2.0714,\n",
      "          -1.7554, -10.9625,  14.5805]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.580482877940945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3225,   2.4727,  -1.7261,   6.6472,  -1.6554,  -1.3201,  -1.6067,\n",
      "         -20.4336,   7.6239,  11.5890]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.588998846542104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7022,   4.9959,  -3.3561,  11.9868,  -3.5149,  -2.6885,  -3.4545,\n",
      "         -21.1231,  -1.7374,  23.5655]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.565514479880164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2226,   6.6788,  -1.3751,   2.5526,  -1.4833,  -1.3829,  -1.5476,\n",
      "         -15.7883,   3.3402,  10.7912]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 10.791196667330462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6873,   9.9969,  -1.6764,  -6.5555,  -1.7163,  -1.5148,  -2.2575,\n",
      "           2.6125, -11.8204,  14.0329]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.032917691762837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6715,   9.1905,  -2.5643,   2.8245,  -2.7181,  -1.8670,  -2.5240,\n",
      "         -26.4378,   4.5687,  22.5053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.50527685592557\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7810,  17.7583,  -2.4223,  -7.9584,  -2.1945,  -1.6678,  -2.6225,\n",
      "          -8.4716, -12.9840,  22.5687]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.56865009775249\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8079,   7.4483,  -2.2917,  -2.9887,  -2.5535,  -2.2241,  -2.7487,\n",
      "         -10.5111,  -2.5938,  20.1867]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.186746386082017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1797,   8.9011,  -2.6784,   2.0363,  -3.0749,  -2.1989,  -3.3795,\n",
      "         -12.0844,  -1.2616,  17.3509]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.35088278669416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1043,  10.8027,  -2.5984,   1.3394,  -2.8975,  -2.1284,  -2.9353,\n",
      "         -16.7201,   0.7287,  16.5376]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 16.537600314125896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2881,   4.7912,  -3.0521,  10.0790,  -3.1662,  -2.3047,  -3.0583,\n",
      "         -19.5923,  -1.1184,  21.0033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.00329868382219\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3412,  5.2827, -1.6019, -0.8632, -1.3466, -1.2030, -1.6401,  0.2526,\n",
      "         -6.8040,  9.0524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.052442215018745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0657,  10.2968,  -1.9227,  -4.1040,  -1.9901,  -1.2143,  -2.0509,\n",
      "         -11.7454,  -4.9537,  20.7085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.708547611034312\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5712,  4.3378, -1.9316,  2.9196, -2.1324, -1.4634, -2.4200, -6.0436,\n",
      "         -1.6157, 10.8745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.87448993287119\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5384,   6.9216,  -1.8347,  -6.6516,  -1.9758,  -1.5002,  -1.7106,\n",
      "         -15.3154,  -0.9339,  25.0986]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.098583097478745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6290,  18.2257,  -1.9007, -17.4418,  -2.0346,  -1.7060,  -2.4240,\n",
      "          -2.2331, -16.1883,  27.6416]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 27.641565288873416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2494, 10.1413, -1.6202, -7.9866, -1.5122, -1.2192, -1.8774, -9.3832,\n",
      "         -6.4553, 22.9398]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 22.939823246019163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8295,  11.3885,  -2.2945,   5.8649,  -2.5176,  -1.8384,  -2.2735,\n",
      "         -12.7950,  -5.4892,  13.3984]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.39841015404922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5679,  13.6631,  -1.6972,  -2.4661,  -1.8835,  -1.3145,  -2.0480,\n",
      "          -6.6000, -11.9528,  17.3011]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.30109631300445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0819,   8.4075,  -1.3634,  -2.6553,  -1.3641,  -1.0186,  -1.7804,\n",
      "         -10.1690,  -3.8625,  16.1108]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.110787175951724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2992, 10.7013, -1.4643, -5.3226, -1.2190, -1.0736, -1.3838, -4.1518,\n",
      "         -5.0586, 11.0257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.025735242944782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8806,  10.5848,  -2.0715,  -1.6093,  -2.0936,  -1.7627,  -2.2389,\n",
      "         -13.7095,   0.6962,  14.6711]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.671089560626378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0642,  16.9539,  -2.8672,  -2.7672,  -2.9713,  -2.3765,  -3.0678,\n",
      "         -15.3613,  -7.3589,  22.9122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.912235416520726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3309,   5.2447,  -1.8673,   3.5049,  -2.0113,  -1.2280,  -1.8587,\n",
      "         -18.5536,   3.4850,  15.5931]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.593139636018417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1517,  10.5206,  -2.3675,  -6.7193,  -2.7420,  -2.0736,  -2.3224,\n",
      "          -5.0630, -10.0624,  23.0500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.04995487876284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6210,  9.4071, -1.6875,  1.4706, -1.8613, -1.4127, -2.1451, -6.8200,\n",
      "         -6.4165, 11.9102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.91018384127058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7122,  12.5308,  -1.7530,  -7.7541,  -1.8180,  -1.6268,  -2.3811,\n",
      "           2.2156, -14.1261,  15.6413]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.641276278019491\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2073,   9.5406,  -2.7234,  -2.0083,  -2.9143,  -2.2518,  -2.7906,\n",
      "          -5.7461, -17.4328,  28.5248]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 28.524797051415234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0502,  13.2270,  -2.2130,  -6.1971,  -2.2744,  -1.9242,  -2.5461,\n",
      "          -5.2358, -11.5786,  20.8578]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.857827616550647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1504,   5.4597,  -1.7548,  -2.7747,  -1.8290,  -1.4762,  -1.7026,\n",
      "         -15.6823,   7.5461,  13.2768]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 13.276814471611564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5584,  10.1667,  -1.7239, -13.2241,  -1.8122,  -1.5375,  -2.0202,\n",
      "          -1.7756,  -9.8037,  23.2010]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.200957086704037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5021,   6.8739,  -1.6504, -12.4833,  -2.1664,  -1.3236,  -1.8634,\n",
      "          -7.9596,   6.0421,  16.9914]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.991440893254776\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0266,  10.7590,  -2.5939,  -0.8292,  -2.6484,  -1.8792,  -2.7673,\n",
      "          -4.2937, -13.5438,  20.4460]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.4459705270711\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9154,  18.6877,  -3.7621,  -0.5177,  -4.3272,  -3.3215,  -4.2936,\n",
      "         -20.2064,  -9.5218,  31.5122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 31.51221535712567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6602,   6.4026,  -1.9142, -13.1844,  -2.2104,  -1.9616,  -2.1447,\n",
      "           1.7458,  -3.9032,  19.1638]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.1637912251106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7460,  5.3697, -2.0192,  2.3946, -1.9960, -1.6034, -1.9750, -5.6940,\n",
      "         -3.7647, 10.8038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.803781863410906\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8896,  10.8981,  -2.4678,  -0.0349,  -2.3268,  -1.7177,  -2.1878,\n",
      "          -9.7884, -10.0835,  20.6010]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.601043745360798\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5773,   8.0697,  -2.0152,   0.2451,  -1.9355,  -1.5182,  -2.2859,\n",
      "         -16.4205,   0.9118,  18.0207]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.020652845153492\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3924,  10.4620,  -1.5963,  -5.4034,  -1.5275,  -1.4841,  -1.8463,\n",
      "         -14.6442,  -0.8764,  19.8251]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.82510988866724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2047,  11.5968,  -2.3237,  -8.4912,  -2.7388,  -2.3623,  -2.8219,\n",
      "         -15.8596,   2.3236,  23.0112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.011230455718817\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0496,  5.7627, -1.3701, -8.4019, -1.5121, -0.9567, -1.5635, -8.8227,\n",
      "          7.8196, 11.6213]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 11.621272931314026\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1206,  3.6175, -1.5275, -0.9495, -1.6401, -1.1477, -1.6378, -9.9085,\n",
      "          2.2080, 12.9699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.969930725894223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4515,  12.4470,  -4.3860,  11.1914,  -4.8624,  -3.3674,  -4.5297,\n",
      "         -17.4466,  -8.8141,  23.4330]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 23.43299571955943\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7730,  13.0895,  -2.5229,  -0.0776,  -2.5560,  -1.5376,  -2.6522,\n",
      "         -18.2929,  -6.2166,  24.3635]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 24.363523129945534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4208,  11.5235,  -1.5405,  -6.5145,  -1.5966,  -1.4573,  -2.0750,\n",
      "           2.1926, -13.1625,  13.2387]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.238749241292547\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0360,  20.7486,  -2.4194,  -4.4107,  -2.5775,  -2.0785,  -3.1560,\n",
      "          -9.7257, -13.8370,  19.9607]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 20.748571725839117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7298,   9.7086,  -2.3965,  -2.0721,  -2.5059,  -1.7791,  -2.3767,\n",
      "         -16.4347,  -0.2438,  20.7292]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.72919464310614\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1563,  3.4787, -1.1347, -4.8865, -1.3366, -1.2983, -1.3247, -0.8481,\n",
      "         -2.7369, 11.1926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 11.192649683700324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4407,  13.2604,  -1.5157,  -8.5034,  -1.6121,  -1.3299,  -2.0428,\n",
      "           1.1330, -13.9645,  15.4095]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.409515836397205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4153, 10.0901, -1.7610, -8.1395, -1.6845, -1.2563, -1.8134, -7.6448,\n",
      "         -8.6312, 22.0697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.06972989088489\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4174,   9.4844,  -2.9044,   4.2950,  -3.3294,  -2.5116,  -3.2288,\n",
      "         -15.5894,  -5.2688,  22.3262]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 22.32618200586109\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0657,  6.6220, -2.5238,  3.9671, -2.6675, -2.2159, -2.7051, -8.5391,\n",
      "         -4.3727, 14.7528]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.752815551604197\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2996,  11.2961,  -3.0431,   2.9631,  -3.1146,  -2.1537,  -3.4253,\n",
      "         -12.8608,  -3.2203,  16.1705]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 16.170498908021525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7049,  11.6444,  -2.0817,   0.4096,  -2.3105,  -1.8089,  -2.5306,\n",
      "         -13.3733,  -0.9850,  13.5634]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.563383684213381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8687,  4.5251, -2.1279, -3.8898, -2.4366, -2.0653, -2.2126, -5.0577,\n",
      "         -2.7310, 17.6560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.65601669913582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9149,   2.0677,  -2.6301,   8.2942,  -2.5768,  -1.9689,  -2.6259,\n",
      "         -20.5727,   5.4848,  17.4057]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 17.40570926607883\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3577,  15.1574,  -4.1883,  11.1785,  -4.5802,  -3.4094,  -4.7708,\n",
      "         -10.5174, -14.4635,  20.0129]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 20.01290843942567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8184,  6.6461, -1.9232,  1.9873, -2.0962, -2.0281, -2.1456, -8.5884,\n",
      "         -1.2046, 11.7278]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 11.727833779413196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0113,   5.8706,  -2.1218,  -6.5381,  -2.2736,  -1.8241,  -2.2318,\n",
      "         -12.3590,  -3.0026,  26.7628]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.762790934749063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3485,  14.9124,  -2.6925,  -1.2355,  -3.0234,  -2.1579,  -2.9964,\n",
      "         -18.7456,  -0.4149,  19.1455]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 19.14547014648297\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0182,  16.8038,  -3.4945,   2.4805,  -3.6261,  -2.6501,  -3.9445,\n",
      "         -11.3527, -12.5691,  21.3577]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.35774176810286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5419, 10.3310, -1.9121, -4.4358, -1.6738, -1.6365, -2.0911, -9.3010,\n",
      "         -0.1282, 12.8482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.848214946266692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6860e+00,  1.7079e+01, -3.4695e+00,  2.3163e-02, -3.6534e+00,\n",
      "         -2.7276e+00, -4.1899e+00, -1.1128e+01, -1.1760e+01,  2.3635e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.63523368213761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9801, 10.4476, -1.4074, -7.0873, -1.5863, -0.9942, -1.6694, -6.7608,\n",
      "         -2.1416, 13.6491]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.649144323910383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2056,  20.0443,  -3.8325,   1.4567,  -3.7116,  -2.7432,  -4.2115,\n",
      "         -21.4416, -11.4479,  29.3183]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 29.318267004934068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1848, 12.1772, -1.8384, -7.0433, -1.8242, -1.2889, -1.6651, -8.2118,\n",
      "         -7.5439, 18.7038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.703827706532657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8469,  17.7182,  -3.3467,   1.1811,  -3.5400,  -2.6757,  -3.7158,\n",
      "         -21.4300,  -8.0308,  26.5418]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.541798918676385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9552,  11.2155,  -2.1125,  -1.7826,  -2.5274,  -2.1176,  -2.4930,\n",
      "         -11.5200,  -2.1494,  15.8962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.89618989112001\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8991,  13.2617,  -3.2329,   2.3814,  -3.4933,  -2.5662,  -3.7690,\n",
      "         -16.6692,  -5.0722,  22.4524]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.45244781506066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2013,  4.4118, -1.5153,  1.5162, -1.3280, -1.2035, -1.5563, -4.1033,\n",
      "         -3.5632,  8.1790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.179045476534476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2894,  9.0302, -1.7513, -3.6438, -1.8021, -1.3847, -1.9814, -6.4626,\n",
      "         -5.8779, 15.4920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.492036598928491\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7308,  6.0438, -0.7267, -6.5829, -0.9956, -0.7454, -0.7831, -9.5745,\n",
      "          1.3185, 13.3994]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.399355799201397\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6603,   7.9235,  -1.9407, -15.5442,  -2.0221,  -1.9524,  -2.2139,\n",
      "           4.0286,  -7.3015,  20.7719]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.771856511013954\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9592,  7.3844, -0.9284, -5.0307, -0.9199, -0.8415, -1.3431,  1.0469,\n",
      "         -7.3127,  8.8750]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.874990158931977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6719,  17.2029,  -1.7547,   0.0873,  -1.6094,  -1.5440,  -1.9966,\n",
      "          -7.7362, -10.1976,   9.0894]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.202859564206904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8529, 12.9121, -1.9354, -2.6642, -2.1235, -1.8358, -2.4780, -7.7759,\n",
      "         -6.7082, 15.2670]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.266953787929975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5516,  12.9696,  -1.7270,  -8.6643,  -1.8246,  -1.5039,  -2.2476,\n",
      "           1.2368, -14.2770,  16.8565]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.85648621510306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4017,  16.1626,  -1.6376, -14.1381,  -1.1655,  -1.1386,  -1.7849,\n",
      "          -2.4906, -11.9623,  20.4321]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.43210222888002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8815,   7.0158,  -1.9446,  -0.5956,  -2.3182,  -1.9447,  -2.0873,\n",
      "         -17.6008,   1.1537,  20.8038]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.803788937409724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0309,   3.7956,  -1.9436,   2.3733,  -1.8448,  -1.3878,  -2.1996,\n",
      "         -14.3904,   7.5702,  10.0369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 10.036919252294977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3949,  11.7480,  -2.9840,  -2.4312,  -3.2045,  -2.4721,  -3.0219,\n",
      "         -14.0706,  -9.9102,  28.2930]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 28.292971952659176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8611,  21.9525,  -3.6527,  -3.5783,  -3.5012,  -2.7483,  -3.5145,\n",
      "         -12.4932, -18.9646,  29.6911]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 29.691135654317534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7459,   6.1083,  -1.9909, -13.6047,  -2.3873,  -1.9397,  -2.3737,\n",
      "          -1.5303,  -7.7550,  27.0086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 27.00861841230891\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3110,  13.1348,  -1.3827, -10.1589,  -1.7018,  -1.1467,  -1.6093,\n",
      "          -9.0325,  -3.9337,  18.4285]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.428525393405067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2161,  11.8059,  -2.2329, -12.3367,  -2.6030,  -2.0528,  -2.4777,\n",
      "          -1.7308, -16.3796,  30.4118]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 30.41178600796805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3132,  5.3660, -1.5159, -6.3410, -1.7841, -1.3964, -1.6334, -3.6743,\n",
      "          0.8785, 11.4660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 11.46604013411259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3231,  11.7423,  -4.2410,  15.0842,  -4.4350,  -3.3168,  -4.4679,\n",
      "         -15.8097,  -7.2110,  16.1989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 16.198897392936424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2826,  6.0268, -1.3142, -6.5246, -1.5223, -1.2607, -1.6468, -9.6821,\n",
      "          2.4609, 14.9113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.911342216382941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1596,  18.2916,  -3.9389,   2.5852,  -3.9328,  -2.8657,  -4.1517,\n",
      "          -8.1174, -18.1489,  24.0649]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.064942122751816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2731,  5.0011, -1.5566,  0.2675, -1.3454, -1.2071, -1.6292, -1.6264,\n",
      "         -5.6109,  8.7298]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.72978451343627\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8523,   9.8072,  -2.4289,  -0.2084,  -2.5510,  -1.7036,  -2.3573,\n",
      "         -14.5390,  -5.3170,  23.0368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.036774721211593\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0396,  9.9382, -1.4321,  0.6106, -1.5948, -0.8992, -1.7715, -9.4593,\n",
      "         -6.2756, 13.8120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.81201883240757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6413,   8.5854,  -1.9672, -14.9426,  -2.1708,  -2.0560,  -2.2729,\n",
      "           5.1053,  -9.7948,  21.0132]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.013244257666496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0124,  9.5080, -2.2215, -5.1334, -2.6294, -1.7869, -2.3669, -5.3884,\n",
      "         -7.0340, 18.7833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.783292273726282\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5058,  8.6293, -0.5906, -9.6886, -0.5254, -0.3238, -0.7179,  0.0979,\n",
      "         -6.0666,  9.9648]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.964817182369524\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5058,  4.0380, -1.8074, -0.1343, -1.8124, -1.6856, -1.9802, -5.6285,\n",
      "         -1.1738, 10.9333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 10.933342339891736\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9273,  16.5288,  -2.5237,  -3.7383,  -2.6048,  -1.7687,  -2.6400,\n",
      "          -1.1041, -17.5496,  18.2309]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.230900337970553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0108,  5.6837, -1.2386, -2.4931, -0.9970, -0.9117, -1.3831,  0.5751,\n",
      "         -7.0324,  8.6782]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.678183889526379\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7639,  14.0977,  -1.9891,  -8.8512,  -2.0622,  -1.7004,  -2.4749,\n",
      "           2.4712, -16.4764,  17.9326]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.932649907993742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6888,  11.0884,  -2.4010,  -1.9405,  -2.6206,  -1.6711,  -2.9216,\n",
      "         -14.5800,  -2.7015,  21.0959]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.095868517929322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6202,  13.6886,  -1.6886,  -8.1148,  -1.7812,  -1.5827,  -2.3738,\n",
      "           2.2712, -14.5359,  15.0000]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.999978527056335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0116,  3.2845, -1.2667, -3.5579, -1.2155, -1.1943, -1.3541, -0.2472,\n",
      "         -3.9429,  9.9393]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.939317702788687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1788,  14.9035,  -2.1375,  -2.9270,  -2.4676,  -2.3459,  -2.9675,\n",
      "          -4.7317, -12.8328,  18.1718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.171804048177933\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6141,  6.8515, -1.7058,  0.3349, -1.8325, -1.3653, -1.8844, -7.5105,\n",
      "         -3.0879, 11.8907]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 11.89071624347334\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9210,   7.0344,  -1.3846,  -7.3552,  -1.3377,  -1.1952,  -1.5314,\n",
      "         -10.0616,  -3.2727,  21.7561]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 21.756136147010558\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4807,  6.7354, -1.7628,  0.4484, -1.8584, -1.4118, -1.7896, -5.6954,\n",
      "         -5.5861, 12.6024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 12.602357127953072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5148,  11.8473,  -1.4944,  -8.5433,  -1.4835,  -1.4439,  -2.0818,\n",
      "           0.7389, -12.2210,  15.5191]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.519058709688073\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7352,   6.5290,  -1.9524,  -4.5884,  -2.1339,  -2.0073,  -1.9232,\n",
      "         -13.1348,   0.1799,  19.7806]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.78057580192834\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9326,   5.8559,  -2.6415,   5.9905,  -2.6112,  -1.9291,  -2.5548,\n",
      "         -15.8379,  -5.1140,  21.7886]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 21.78859874417383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3806,  16.3218,  -1.3979, -22.7167,  -1.6104,  -1.1087,  -1.5101,\n",
      "           3.3018, -16.5973,  26.9411]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.941147745589657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1185,  7.8848, -1.3486, -8.7151, -1.3537, -1.0358, -1.0832, -3.1569,\n",
      "         -5.9232, 16.3521]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 16.35213296653387\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0903,  4.0859, -1.4207, -0.6184, -1.1862, -1.1561, -1.4490, -2.3917,\n",
      "         -4.2380,  9.0284]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.028418387944862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8147,  7.5263, -2.1034,  0.6889, -1.9654, -1.6616, -2.2391, -5.8340,\n",
      "         -6.1052, 13.0693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.069296398872615\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9530,  15.2996,  -1.0968, -10.5949,  -1.2972,  -1.0023,  -1.1736,\n",
      "          -9.9218,  -5.5525,  17.2832]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 17.283170301387678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8488,  11.3862,  -2.2848,  -1.4314,  -2.5771,  -2.0919,  -2.7928,\n",
      "         -17.2240,   2.8108,  17.2968]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.296812035580604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0984,  3.8475, -1.7061,  2.6488, -1.5322, -1.1142, -1.8726, -9.2264,\n",
      "          1.1737,  9.1152]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.115166049596947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8062, 11.3487, -2.2000,  1.5589, -2.2152, -1.8277, -2.4196, -8.1199,\n",
      "         -7.0329, 12.8211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.821078010146207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3366,   7.6156,  -2.0079,   1.7035,  -2.2025,  -1.5376,  -1.6210,\n",
      "         -14.5729,  -0.6708,  15.7082]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.70821932481862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8731,  9.5309, -0.8028, -9.0647, -1.0792, -0.7263, -0.9674, -9.1727,\n",
      "          1.4900, 13.0686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.068636419863973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7045,  12.2065,  -2.0132,   1.0704,  -2.4375,  -1.6602,  -2.2604,\n",
      "         -12.2343,  -3.6178,  14.2015]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.201461243158136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2839,   7.8343,  -1.6616,  -2.1576,  -2.0660,  -1.4842,  -1.7408,\n",
      "         -20.1554,   2.6887,  19.8517]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 19.851700311655392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2362,  9.3515, -1.7589, -5.5586, -1.7949, -1.3385, -2.0280, -9.9776,\n",
      "         -0.5871, 15.2165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.216514119957875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6820,  13.4608,  -1.5114,  -1.9190,  -2.0720,  -1.6640,  -2.1107,\n",
      "         -13.1642,  -3.6677,  15.4136]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.413562632460417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5955,   8.8825,  -1.7986,  -1.7896,  -2.0067,  -1.4710,  -2.1025,\n",
      "         -13.6931,  -0.9887,  16.6242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.624216139152928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3533,   8.0897,  -1.4059, -11.8554,  -1.6308,  -0.9188,  -1.6954,\n",
      "          -6.5856,   5.0152,  13.5260]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.526045750235069\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1666,   6.1081,  -2.5145,  10.8531,  -2.7962,  -1.9673,  -2.9289,\n",
      "         -15.2198,   0.2233,  10.5197]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 10.85313843915344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2669,   6.3857,  -1.7746,   1.2607,  -2.1516,  -1.5025,  -1.5130,\n",
      "         -18.9415,   1.2279,  19.8224]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.822361773545655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5061,   2.6222,  -1.8382,   9.3156,  -2.1759,  -1.6101,  -2.2345,\n",
      "         -16.5309,   8.2796,   6.8154]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 9.315559713724497\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3021,  5.4197, -1.6899, -0.2971, -1.3551, -1.0915, -1.7424, -2.2181,\n",
      "         -4.9403,  8.7879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.787909338992625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5690,   6.4813,  -2.9029,  11.7411,  -3.2688,  -2.3981,  -3.1341,\n",
      "         -11.4377,  -6.3148,  15.0876]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.087577487499642\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9129,  13.0697,  -2.3932,   2.4015,  -2.8882,  -2.1499,  -2.8496,\n",
      "         -17.6997,   0.2316,  15.4718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.47177730110449\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0494,  3.0665, -1.0828, -6.3921, -1.4237, -1.0618, -1.5201, -4.7739,\n",
      "          5.4327,  8.9196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.919613916239879\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1042,  5.8562, -1.8993, -1.7098, -1.9416, -1.2798, -2.0196, -8.0871,\n",
      "         -0.4979, 13.6037]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.603655460279782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1862,  4.8290, -1.4094, -8.2444, -1.6464, -1.2905, -1.5421,  0.0588,\n",
      "         -1.9811, 12.4268]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 12.426805120134398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4693,   9.8955,  -1.6524,  -1.7639,  -2.0345,  -1.5886,  -1.8760,\n",
      "         -14.6746,   2.7530,  13.0829]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.082886487865137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5127,   7.2943,  -1.6837, -14.4465,  -1.7355,  -1.5299,  -1.8473,\n",
      "           4.2827,  -7.0559,  18.3219]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.321895172615257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1558,  10.8074,  -1.4013,  -7.9204,  -1.7144,  -1.2249,  -1.4935,\n",
      "         -11.9227,  -1.5881,  17.3257]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 17.325711800159137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6685,  12.7908,  -1.9332,  -2.7133,  -2.2047,  -1.3665,  -2.3476,\n",
      "          -5.3348, -11.0870,  16.6630]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.662988165985585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7232,  12.1338,  -1.9781,  -1.4385,  -1.9881,  -1.5186,  -2.2154,\n",
      "         -18.4584,  -5.0587,  23.4808]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 23.480842276746785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7090,   1.9764,  -2.3142,   8.8573,  -2.4134,  -1.7779,  -2.8110,\n",
      "         -10.0056,   1.2512,   9.5653]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.56527902433541\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3927,  8.2817, -1.6206, -9.3486, -1.9282, -1.2741, -1.9136, -7.2139,\n",
      "          4.3334, 13.2973]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.297317978887406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9630,  5.6783, -1.2152,  0.6099, -1.4729, -1.0650, -1.5792, -9.0608,\n",
      "          0.1620,  8.5346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 8.53456583256251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6780,  14.3510,  -3.4009,   3.5119,  -3.3580,  -2.6207,  -3.3460,\n",
      "         -24.3483,  -3.2177,  26.0152]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.01515644502701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3799,  7.1380, -1.5190, -2.2883, -1.4088, -1.2363, -1.6130, -1.0792,\n",
      "         -7.5510, 10.5189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.518878226414722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3853,   9.8465,  -1.6428,  -7.4039,  -1.7010,  -1.4121,  -1.9127,\n",
      "         -15.3141,   5.3794,  16.8139]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.813908943025993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3905,  4.9432, -1.5277, -4.7745, -1.6861, -1.1638, -1.5837, -5.6003,\n",
      "         -1.9327, 15.5011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.501093018020464\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5587,   7.1509,  -0.7986, -10.5449,  -0.6353,  -0.4375,  -0.9918,\n",
      "           0.4230,  -3.4373,  10.6689]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 10.668886806703904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1891,  3.6077, -1.3694, -2.4922, -1.5466, -1.3881, -1.4218, -1.2504,\n",
      "         -3.5617, 10.4717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.471679913507986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7587,  12.1295,  -1.9771,  -6.1136,  -1.9308,  -1.6590,  -2.3149,\n",
      "          -0.6306, -12.2997,  16.0888]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.088793673893708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2861,  9.2027, -1.6461, -0.5944, -1.7055, -1.1526, -1.9769, -7.6208,\n",
      "         -6.6585, 12.8981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 12.898117814635764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2234,  13.1846,  -2.2784,   2.5894,  -2.7551,  -2.3056,  -2.8167,\n",
      "         -13.8595,  -3.1773,  14.1476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.147581066546033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1216,   8.1682,  -1.9805,  -0.2989,  -2.1346,  -1.2235,  -2.1396,\n",
      "         -18.1109,   0.9142,  19.3674]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.367421986301984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4557,  11.9630,  -2.9143,   0.5161,  -3.1372,  -2.3130,  -3.2946,\n",
      "         -13.9251,  -3.2215,  19.7172]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.717169825976644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0210,  6.7620, -1.1303, -5.6583, -1.4107, -0.9219, -1.5470, -7.1583,\n",
      "          0.4932, 12.1253]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 12.125278702040728\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6712,   7.8370,  -0.4831,  -6.1152,  -0.6857,  -0.5842,  -0.7320,\n",
      "         -13.8868,   7.3350,   9.2377]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 9.237672209289132\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6658,   3.4730,  -2.0632,   3.8312,  -1.9875,  -1.6938,  -2.0198,\n",
      "         -14.0292,   4.5743,  11.7364]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 11.73638092588796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1262, 13.4854, -2.4640, -5.0835, -2.7501, -2.0731, -2.6700, -6.6323,\n",
      "         -8.9805, 20.4864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.486357941110697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1634,  3.4088, -1.4154,  1.8167, -1.2539, -1.0753, -1.4740, -4.1877,\n",
      "         -2.5240,  7.5668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 7.566765389929314\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3835,  12.3438,  -1.6471,   0.2505,  -1.7929,  -1.4133,  -1.9206,\n",
      "         -20.3055,  -1.5400,  18.9114]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.91139197977405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9449,  2.3023, -1.1642, -3.4555, -1.3910, -1.1581, -1.3618, -3.3845,\n",
      "          1.9865,  8.7988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.798826894368766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7147,   5.1098,  -1.7403,   2.1521,  -2.0262,  -1.6657,  -1.8521,\n",
      "         -16.6358,   7.5279,  11.8956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 11.895629834004284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7234,   4.4207,  -2.2152,   9.9652,  -2.6384,  -1.9751,  -2.3545,\n",
      "         -22.2057,   5.8713,  13.6906]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.690599213986259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1117,  18.9521,  -3.6544,   1.8860,  -3.8586,  -2.9464,  -3.9871,\n",
      "         -12.6629, -14.7130,  25.0494]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.04939276603902\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5549, 10.8678, -2.0211, -6.7348, -2.0313, -1.5964, -2.0571, -5.3068,\n",
      "         -5.5756, 17.4489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.4488519483376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7628,  13.5810,  -3.5025,   1.8969,  -3.7552,  -2.9596,  -3.9473,\n",
      "         -13.7826,  -7.1794,  22.8458]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.84581270011145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4497,  13.5959,  -1.7082,  -6.1041,  -1.7112,  -1.3273,  -2.1846,\n",
      "           0.6286, -13.2681,  13.3810]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.595858202400178\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2105,   9.0761,  -1.1869,  -3.5310,  -1.0787,  -1.0573,  -1.3424,\n",
      "         -13.9096,  -1.0306,  16.3345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.334494195984515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3474,  5.0956, -1.5748,  2.0065, -1.4939, -1.2331, -1.7828, -9.6368,\n",
      "          2.0083,  7.3098]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 7.309835165222075\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4817,   7.3137,  -1.4457,  -1.0921,  -1.8553,  -1.2736,  -1.7776,\n",
      "         -17.7228,   4.4659,  15.7535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.753464740358304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4023,  12.9540,  -3.0268,   8.0045,  -3.2621,  -2.3186,  -3.3575,\n",
      "         -11.8961,  -6.5218,  12.0612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.954012914031503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6962,  14.9035,  -2.2377,  -3.7106,  -1.9558,  -1.4969,  -2.4673,\n",
      "         -18.9000,  -5.1318,  24.0594]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 24.059357742563954\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4810, 11.8597, -1.6907, -2.1948, -1.9119, -1.5824, -2.1484, -5.0372,\n",
      "         -9.2753, 12.7610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.761039080205238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9864,  7.4263, -0.8854, -6.9381, -0.8121, -0.9424, -1.3396,  1.7789,\n",
      "         -7.8308, 10.1480]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.148044164277696\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5440,  9.6921, -1.9462, -3.7797, -1.6168, -1.3980, -1.9249, -5.4910,\n",
      "         -5.1265, 12.7031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.703111099357567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8799,   7.9394,  -2.1105,  -5.0517,  -2.2600,  -1.9776,  -2.1270,\n",
      "         -15.3944,  -0.5999,  24.3091]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.309142484388907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5094,  7.8624, -1.5145, -4.2625, -1.4351, -1.3103, -1.8572,  0.8543,\n",
      "         -9.5953, 12.4607]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.460723078416455\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9151,  11.1402,  -2.1121,  -6.9525,  -2.4427,  -1.8979,  -2.2227,\n",
      "         -13.1090,  -3.5096,  23.9127]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.912680588394515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7162,  17.1689,  -3.2911,   0.7978,  -3.6006,  -2.7561,  -3.9343,\n",
      "         -18.8205,  -5.7996,  24.3112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.31122827404228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2349,   8.0184,  -2.6388,  -3.5850,  -2.8067,  -2.1057,  -2.6723,\n",
      "         -11.0190,  -7.4390,  26.7446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.744608785404793\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5926,   5.6085,  -1.1269,  -1.2822,  -1.2290,  -0.7769,  -0.9816,\n",
      "         -15.6604,   6.7296,  10.4717]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 10.471683266109654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0873,   5.9930,  -1.0353,  -8.0499,  -1.1006,  -0.9894,  -1.2030,\n",
      "         -11.0649,   4.0601,  15.3943]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.394256364291232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0250,   3.7480,  -1.2646,   0.5704,  -1.6381,  -0.9634,  -1.4939,\n",
      "         -15.4613,   5.6216,  11.9032]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 11.90318983334832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3768,   6.2053,  -1.8414,  -9.4842,  -1.4850,  -1.3074,  -1.6481,\n",
      "         -15.8296,   3.8884,  23.6974]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.69739700829448\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5792,  3.4871, -1.8091,  1.5266, -1.8770, -1.7888, -1.9884, -8.0907,\n",
      "          0.4920, 12.0320]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.031998968254479\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1145,  16.5990,  -2.6608,  -3.1217,  -2.9600,  -1.8930,  -3.0922,\n",
      "         -12.9121, -10.5918,  24.6572]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.657233841432372\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1033,   8.5693,  -1.2650,  -6.3094,  -1.5369,  -1.2430,  -1.4905,\n",
      "         -17.9508,   7.7530,  15.9358]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.935831101152074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1142,  17.4427,  -2.5285,  -0.6273,  -2.8327,  -1.6954,  -2.7828,\n",
      "         -10.7206, -10.9287,  17.5720]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.572006902456522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4882,   8.9121,  -2.2966,  -2.7721,  -2.3316,  -1.7228,  -2.1624,\n",
      "         -17.1035,   4.0507,  18.2885]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.288538659494392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6712,  13.8956,  -1.7859, -11.0984,  -1.7555,  -1.5431,  -2.2805,\n",
      "           1.7402, -14.6675,  18.6067]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 18.60672804014473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6076,  14.1744,  -1.4755,  -5.2716,  -1.6857,  -1.4550,  -1.9650,\n",
      "         -11.1978,  -3.3735,  14.2905]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 14.290506066885145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6452,   6.9786,  -1.9870,  -0.8945,  -2.2384,  -1.8478,  -1.8472,\n",
      "         -16.3458,   4.7865,  16.1409]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.140932875729135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5118,  12.8679,  -2.9942,  -3.3640,  -3.4359,  -2.6732,  -3.2729,\n",
      "         -19.4172,  -5.3893,  30.6410]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 30.641027960438024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4027,  17.1641,  -1.5968,  -5.9947,  -1.6389,  -1.1432,  -1.7615,\n",
      "           0.9577, -17.1958,  11.9756]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.164108061871687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5219,  12.4132,  -1.5478,  -6.6037,  -1.6151,  -1.4427,  -2.0540,\n",
      "          -2.8658, -10.8865,  15.8943]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.894302694072874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9573,  15.7294,  -2.8011,   0.6898,  -2.5752,  -2.0333,  -2.6518,\n",
      "         -18.6533,  -7.2981,  21.9505]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.950490899993767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2472,  2.6881, -1.3328, -6.3307, -1.5720, -1.1963, -1.6432, -4.6958,\n",
      "          5.1613, 10.9366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.936633761902566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3416,   8.3698,  -1.6833,  -1.9698,  -2.1900,  -1.6994,  -1.8915,\n",
      "         -19.5095,   8.5025,  14.7301]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.730126778943449\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [11]: loss = 15.497, accuracy = 12.11\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4124, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4693], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4124, -0.0329, -0.4580, -0.0242, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4693], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -3.2943,  11.9486,  -3.9020,  12.4855,  -4.2508,  -3.3425,  -4.4620,\n",
      "         -13.3401,  -7.8945,  15.9011]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.901110005303194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9911,  13.0671,  -1.4409, -12.4470,  -1.2016,  -0.6403,  -1.4543,\n",
      "          -4.0522,  -5.9274,  16.0410]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 16.040966717592422\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9008,   3.7696,  -2.4665,   7.2727,  -2.4118,  -2.1500,  -2.6115,\n",
      "         -17.8820,   8.2500,  10.9939]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.993854856643228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1952,   6.6427,  -0.9878,  -3.6640,  -1.5506,  -1.0689,  -1.3042,\n",
      "         -22.4180,  14.4316,  12.0327]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  4\n",
      "activation[8] = 14.431570499174631\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3969,  11.5344,  -2.8734,   7.0949,  -3.1279,  -2.2065,  -3.4249,\n",
      "         -15.0855,  -1.8250,  12.5823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.582317247088948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4429,   6.6985,  -1.8110,  -1.5135,  -1.9093,  -1.6329,  -1.6790,\n",
      "         -20.3510,   5.3722,  18.9476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.947568361054206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5902,   4.1053,  -0.9330,  -2.0828,  -1.1798,  -1.0053,  -1.0197,\n",
      "         -12.0493,   5.0436,  10.8310]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 10.831041486672639\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5016,  21.8004,  -2.8926,  -9.5907,  -2.9977,  -2.2643,  -3.3325,\n",
      "           2.7266, -25.6157,  23.7872]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 23.787239813581017\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3305, 11.9824, -1.4996, -4.6366, -1.7606, -1.3021, -2.0830, -5.0709,\n",
      "         -7.4479, 13.5057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 13.505724111499992\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6699,  4.6178, -1.8005, -4.5294, -2.1628, -1.7045, -2.0606, -6.0551,\n",
      "          0.0254, 14.9864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.98635897432094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5823,   8.5481,  -2.2803,  -1.9325,  -2.5609,  -1.8024,  -2.5644,\n",
      "         -26.5851,  10.8262,  20.5986]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.59859023430752\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1241,   8.4070,  -2.3800,  -1.2027,  -2.7314,  -1.9631,  -2.2227,\n",
      "         -10.3652,  -3.2261,  18.0446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.044604125544023\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0672,   3.8886,  -1.5627,   1.4106,  -1.5117,  -1.4198,  -1.5720,\n",
      "         -17.8996,   8.8065,  12.7088]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.708762393375123\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7147,  10.8739,  -1.6310,  -4.2223,  -2.1673,  -1.5540,  -2.0181,\n",
      "         -11.2370,  -0.3202,  14.0317]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 14.031680262386036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7734,  4.8894, -1.0513, -1.0109, -1.0171, -0.8863, -1.3610, -5.1597,\n",
      "         -3.0804,  9.4192]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.419204831130727\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6480,  14.2445,  -1.7179,  -7.4891,  -1.8135,  -1.6168,  -2.1723,\n",
      "           2.3204, -15.9167,  15.1004]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.100408129654484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5760,  7.3711, -1.6145, -1.2585, -2.0701, -1.4196, -1.6682, -9.6303,\n",
      "         -1.2214, 13.2336]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.233607722374426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3831,  13.5178,  -2.9431,   3.2312,  -3.0468,  -2.1903,  -3.2347,\n",
      "         -17.8193,  -7.3252,  23.5837]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.583702915736193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9529,  9.0391, -2.1292,  7.1621, -2.4335, -1.8487, -2.4893, -7.0406,\n",
      "         -7.6038,  9.3764]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.376447543278008\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0612,   6.7553,  -1.4497, -12.4066,  -1.8243,  -1.3634,  -1.6398,\n",
      "         -10.8029,   7.5433,  17.5919]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.591866937733172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8334,  11.2778,  -2.3731,  -8.8817,  -2.3214,  -1.9718,  -2.5246,\n",
      "         -18.3017,  -0.0288,  28.2544]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 28.254374172865496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4951,  12.3040,  -1.6974,   1.5253,  -1.7706,  -1.4973,  -2.1102,\n",
      "         -13.5366,  -6.9813,  16.7462]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.74621606237542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2382,  5.4506, -1.5859,  0.8736, -1.4548, -1.2283, -1.7589, -3.1585,\n",
      "         -2.9531,  7.9500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 7.9499969659440755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2414,  6.4290, -1.8067, -4.6416, -1.7668, -1.2955, -1.6934, -4.1293,\n",
      "         -4.1010, 14.8576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 14.857636223299021\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3021,  14.7653,  -2.6432,  -4.3233,  -2.9266,  -2.5475,  -3.5243,\n",
      "         -12.2626,  -5.1541,  21.3445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.3445167673712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7627,  13.9326,  -2.0396, -12.7633,  -2.2147,  -1.6425,  -2.1516,\n",
      "          -7.5819, -12.6974,  28.2229]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 28.22288837180562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8944, 10.8935, -1.2574, -8.7793, -0.9682, -1.1445, -1.4058, -6.2110,\n",
      "         -6.7437, 17.1134]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.11335045046821\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2975,  18.0287,  -2.4037, -11.5176,  -2.4609,  -2.0981,  -3.0248,\n",
      "          -1.2575, -17.6021,  23.9697]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 23.969687402625333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1552,  5.0143, -1.1420, -6.1351, -0.9942, -1.2444, -1.4710, -0.6987,\n",
      "         -7.3057, 14.7624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.762407000637399\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4173,   9.1202,  -3.0110,   3.2203,  -3.3023,  -2.2713,  -2.9602,\n",
      "         -19.4682,  -3.5482,  25.1927]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.192696348318538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8077, 10.6983, -2.1420,  0.8830, -2.5457, -1.8719, -2.7844, -8.0812,\n",
      "         -5.6861, 13.7846]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 13.78463366235795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5697,  11.7675,  -2.1803,  -2.4823,  -2.2734,  -1.7826,  -2.0509,\n",
      "         -14.3361,  -4.8767,  20.0120]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.012027601699206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8564,   8.1723,  -2.0981, -15.5747,  -2.4245,  -2.1506,  -2.3561,\n",
      "           0.8806,  -6.0531,  23.8815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.88154183807759\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4459,  10.3166,  -1.8556,  -5.6449,  -1.7268,  -1.5307,  -2.1529,\n",
      "         -15.4418,  -3.4022,  24.3595]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 24.35950444688179\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0000,   3.3092,  -1.3865,   2.1892,  -1.2511,  -1.2636,  -1.3691,\n",
      "         -14.3268,   6.9046,   9.8989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.898885600410779\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8955,  15.6579,  -2.5735,  -4.7332,  -2.6691,  -2.1017,  -2.8975,\n",
      "         -13.5031,  -7.9913,  22.9357]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.93567957366538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9396, 11.1480, -2.0989, -8.5248, -2.1852, -1.9694, -2.4987, -7.6165,\n",
      "         -5.0495, 20.3648]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.364804178271395\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1299,  26.4315,  -2.5195,  -7.1394,  -2.6155,  -1.8037,  -2.8687,\n",
      "           1.0130, -27.7474,  18.4548]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 26.43147716974368\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1419,   4.2873,  -1.4254,   2.6059,  -1.6434,  -1.1372,  -1.4221,\n",
      "         -13.8947,   4.0203,  10.6718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 10.67180628392608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8511,  15.3933,  -2.3023,   0.7615,  -2.3600,  -1.9351,  -2.4936,\n",
      "         -14.7868,  -6.7401,  17.6953]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.695344966123706\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.6492, 11.5384, -2.8907, -6.0397, -3.4195, -2.6108, -3.0249, -7.4938,\n",
      "         -6.3835, 23.2064]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.20643638169193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7406,  9.8044, -2.1750, -4.3294, -2.2389, -1.7360, -2.4397, -3.7586,\n",
      "         -7.5601, 16.8341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.834057112106176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5977,  3.6766, -1.9352,  0.9907, -1.8867, -1.5087, -2.1268, -5.8124,\n",
      "         -2.7032, 12.6913]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.691337993685762\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6041,   7.3125,  -2.0355,  -8.5900,  -1.9888,  -1.5555,  -2.0528,\n",
      "         -18.6420,   5.8623,  24.4576]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.45756876792457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2973,   8.1578,  -1.5327,  -4.0186,  -1.5704,  -1.1837,  -1.4564,\n",
      "           0.0680, -11.5674,  14.2821]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.282145232842693\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9048,  10.0061,  -2.2997,   1.8722,  -2.5797,  -1.9696,  -2.3643,\n",
      "         -16.8011,   0.1138,  16.0591]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.059067443077833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3944,  10.3145,  -1.6352,  -0.8556,  -1.8415,  -1.4516,  -1.7955,\n",
      "         -16.4620,  -0.8583,  17.9811]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.98105178916523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3807,  17.7815,  -3.1166,  -7.3192,  -3.0174,  -2.1006,  -3.3674,\n",
      "         -16.2634, -10.6615,  32.2923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 32.29226726832947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2678,   5.2450,  -1.7138,   4.4614,  -1.9591,  -1.3653,  -1.8164,\n",
      "         -18.8961,   6.0048,  12.3809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 12.380861407342291\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7751,  4.3592, -2.0433, -7.3370, -2.4580, -2.1703, -2.4846, -9.0918,\n",
      "          5.7127, 17.6716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.671563619278885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8545,  14.8274,  -3.0384,  -2.0677,  -3.7772,  -2.9071,  -3.8614,\n",
      "         -10.5001,  -8.5315,  22.5749]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.574861252046745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6070,   4.5910,  -1.8932, -11.9464,  -2.0066,  -1.6869,  -2.0528,\n",
      "          -5.0669,   5.2476,  17.0150]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.015035234998802\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7367,   6.6414,  -2.0886,   7.0029,  -2.1498,  -1.5638,  -2.1348,\n",
      "         -17.2072,  -1.9084,  15.2944]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.29443055171512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8629, 13.1184, -2.2656, -4.3910, -2.4897, -1.9355, -2.4528, -5.1964,\n",
      "         -7.6277, 16.1219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.121858685255457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3277,   8.0410,  -1.3496,  -5.5665,  -1.3729,  -1.2060,  -1.8276,\n",
      "           2.2015, -10.0790,  12.0684]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.068355259532893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4552,  10.4088,  -2.7448,   4.1181,  -2.9199,  -2.2245,  -3.0505,\n",
      "         -14.0292,  -1.8242,  15.6472]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.647209395286117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3276,  8.8530, -1.4684, -3.7771, -1.4817, -1.1115, -1.6708, -1.8481,\n",
      "         -9.0758, 13.0084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.008443458879317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4423,  15.1333,  -3.2387,  -7.1451,  -3.1834,  -2.2522,  -2.9885,\n",
      "         -16.2824,  -6.4691,  30.5953]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 30.595314165076644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4262,   6.9612,  -1.4006,  -1.5672,  -1.6533,  -1.3410,  -1.6490,\n",
      "         -10.4758,   0.8190,  12.0880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 12.087981620788005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3584,  16.8385,  -3.1493,  -2.3697,  -3.1879,  -2.4497,  -3.1448,\n",
      "         -20.5104,  -4.5366,  25.5446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 25.544600018637038\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9246,  9.1752, -2.1556, -2.7031, -2.0648, -1.6897, -2.3568, -1.8710,\n",
      "         -9.9024, 15.4150]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.415035568972398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5674,  16.6943,  -3.3449,   2.6681,  -3.3541,  -2.5863,  -3.4856,\n",
      "         -18.0748,  -8.5072,  23.0929]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 23.092897932662005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8259,  11.1994,  -1.8521,  -5.8837,  -1.8939,  -1.6617,  -2.3648,\n",
      "           1.9687, -12.5802,  14.6962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.696249763050298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8896,  17.6120,  -2.3033,  -2.4267,  -2.3102,  -1.5218,  -2.3933,\n",
      "         -16.3651,  -9.8839,  22.2442]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.244163701892823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5146, 12.4897, -1.3997, -6.7605, -1.5738, -1.1836, -1.8644, -1.3020,\n",
      "         -8.5658, 11.9858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 12.489689145161174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5784,  4.5624, -1.9510, -6.5692, -2.0783, -1.7370, -2.1558, -9.7465,\n",
      "          9.6459, 12.5290]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 12.529038731886844\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0623,   6.8169,  -1.4415,   0.9008,  -2.0054,  -1.3935,  -1.4786,\n",
      "         -18.6140,   1.6486,  17.3930]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.39298090672377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5169,  10.0858,  -3.2689,   5.3431,  -3.6665,  -2.7410,  -3.5428,\n",
      "         -12.5655,  -6.1421,  19.7282]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.72820073289391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2881,  4.4293, -1.6215,  2.6289, -1.6523, -1.3614, -1.6693, -9.1374,\n",
      "          0.1317,  9.9510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.950977541750596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4628,   5.9966,  -1.7369,   1.2871,  -1.9384,  -1.2526,  -1.8938,\n",
      "         -18.4290,   3.5119,  16.0921]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.092106494127087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8849,  15.2555,  -3.7621,   8.2343,  -4.0111,  -2.9980,  -3.9167,\n",
      "         -13.5837, -10.8365,  19.0909]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.090874814226513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6901,  12.3492,  -2.3344,  -1.4093,  -2.0652,  -1.6726,  -2.1796,\n",
      "         -10.7258,  -6.4817,  16.7279]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 16.72788725608761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4417,  9.6441, -1.7052, -2.9680, -1.5749, -1.1815, -1.6880, -6.7706,\n",
      "         -5.3020, 13.4824]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.482355489665807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9685,  13.5245,  -1.9495,  -9.0901,  -2.0034,  -1.7153,  -2.3799,\n",
      "          -0.2701, -13.2234,  18.5862]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 18.58615574289285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0199,   6.5589,  -1.6840,   0.9144,  -1.8796,  -1.2651,  -1.7413,\n",
      "         -18.5446,   3.7528,  15.9601]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.960050493427307\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8457,  10.6846,  -1.6555,  -6.0542,  -2.3199,  -1.8172,  -2.1830,\n",
      "         -15.8269,   3.2821,  18.9167]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.916703701382218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1648,   8.5505,  -1.6239,  -1.7252,  -1.6012,  -1.1404,  -1.5252,\n",
      "         -10.7199,  -2.0949,  13.8869]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 13.886852531228739\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5878,   5.8959,  -1.7923,  -7.3330,  -1.8962,  -1.5279,  -2.0003,\n",
      "         -13.6976,   0.9582,  23.9672]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.967170642343582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4584,   8.4125,  -1.5481,  -4.8342,  -1.4778,  -1.3279,  -1.9401,\n",
      "           0.3529, -10.1608,  13.8488]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.848787205375807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1094,   8.8620,  -2.4027,   1.5176,  -2.9020,  -2.2565,  -2.9390,\n",
      "         -15.8786,  -1.0653,  19.0303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.030274620552632\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2358,  6.4841, -1.3241, -1.5686, -1.7896, -1.2916, -1.5717, -8.6648,\n",
      "          0.4609, 10.5158]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 10.51583678160538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1503,  8.6569, -1.4854, -8.5817, -1.5909, -1.1276, -1.1885, -8.2838,\n",
      "         -5.0792, 20.7286]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.72857834427962\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2705,   6.5745,  -1.6397,   2.1973,  -1.7934,  -1.2829,  -1.8312,\n",
      "         -10.5908,  -2.9463,  13.4294]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.42943475909103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9846,  8.5927, -1.3288, -9.2212, -1.3208, -0.9609, -1.0959, -3.5260,\n",
      "         -6.4686, 17.2194]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.219373892469036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2210,   4.4208,  -1.5511,   1.7672,  -1.7669,  -1.5083,  -1.3661,\n",
      "         -13.9957,   4.3249,  11.3504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.350412089395554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5181,  16.2484,  -2.8732,  -7.8853,  -2.9095,  -2.1826,  -2.8562,\n",
      "          -3.8193, -14.6882,  24.4261]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.426120460523606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9718,  4.6273, -0.9623, -1.0902, -1.1312, -0.9702, -1.0509, -3.9246,\n",
      "         -1.7723,  7.1983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 7.198253867658259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6643,  2.9309, -1.7779, -4.8651, -2.0605, -1.8836, -2.1875, -5.8127,\n",
      "         -0.3520, 17.7145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.71454415621416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1207,  12.2839,  -2.7035,  -0.8201,  -3.2636,  -2.0749,  -3.0966,\n",
      "         -18.3115,   0.0474,  21.0446]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.04460871963287\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5051,  16.9266,  -2.8342,  -6.6261,  -3.3400,  -2.5626,  -3.2293,\n",
      "         -15.3116,  -7.7637,  27.0272]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 27.027240790513986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0669,  5.1459, -1.0387, -2.6132, -0.9590, -0.8885, -1.1790,  0.5612,\n",
      "         -6.7133,  8.7264]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.72643883511608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6652,  14.4706,  -1.7099, -10.5155,  -1.8093,  -1.6824,  -2.3460,\n",
      "           2.2001, -15.3507,  17.6117]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.611716575296576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6539, 12.2969, -1.9049, -5.1137, -2.1470, -1.7650, -2.2897, -8.7589,\n",
      "         -4.7520, 16.1039]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 16.103874507613416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9619,   2.6835,  -2.3161,  -4.7848,  -2.4978,  -2.2309,  -2.5870,\n",
      "         -12.1697,   6.4813,  19.5077]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.507712225508193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3561,   8.9304,  -1.7717,   1.6657,  -1.8315,  -1.1004,  -2.0350,\n",
      "         -13.1131,  -3.7088,  15.7040]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.704002641934919\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8505,   8.7379,  -2.1710,  -3.4038,  -2.3347,  -1.8638,  -2.1748,\n",
      "         -19.0200,   1.4473,  23.2238]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.223804413787896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7437,   3.6231,  -2.2582,   8.5181,  -2.2940,  -1.8397,  -2.3597,\n",
      "         -24.4571,   7.4763,  16.1962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.19624497402904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8643,  13.7305,  -2.4434,  -9.1082,  -2.2201,  -1.6494,  -2.6345,\n",
      "         -10.2320,  -9.2656,  26.9804]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 26.98036678914245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7843,  10.8122,  -2.5321,  -5.4888,  -2.5808,  -1.6549,  -2.6295,\n",
      "         -18.0164,  -0.1336,  25.3943]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 25.394308021145115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9961,  11.4443,  -3.7915,   7.2349,  -4.2474,  -2.9338,  -4.3033,\n",
      "         -13.0993,  -9.4750,  23.2410]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 23.240992847828966\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5144,  11.4081,  -3.1806,   3.2612,  -3.7134,  -2.7451,  -3.1818,\n",
      "         -28.1303,   4.2202,  25.4398]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 25.439757813707306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2658,   9.8596,  -1.4311,  -4.8044,  -1.7401,  -1.5243,  -1.8631,\n",
      "         -12.8788,   0.5956,  15.6854]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.685433595661358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2805,  3.3610, -1.5602,  1.9637, -1.5799, -1.1829, -1.5801, -4.5843,\n",
      "         -1.7865,  7.8990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 7.899022644219851\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8244e+00,  1.2526e+01, -3.6506e+00, -3.4803e-03, -3.6325e+00,\n",
      "         -2.6367e+00, -3.7148e+00, -1.6011e+01, -7.7730e+00,  2.9404e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 29.4040045912195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2190,  6.9635, -1.4362, -1.4857, -1.3041, -1.1490, -1.7111, -2.8003,\n",
      "         -6.1651, 10.2048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.204771132737138\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8387,   7.8361,  -2.4245,   2.0790,  -2.5769,  -1.7303,  -2.6524,\n",
      "         -15.8394,  -5.0485,  23.6761]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 23.67608485969904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7209,  4.6955, -0.9262, -5.8858, -1.0405, -0.8285, -1.0094, -9.1329,\n",
      "          5.3869,  9.7412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 9.741150757652212\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5078,  13.8620,  -2.3226,  -3.0528,  -2.2097,  -1.5024,  -2.5975,\n",
      "         -12.5396,  -6.7834,  21.2342]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 21.234159053908975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8871,  10.7269,  -1.9775, -20.1922,  -2.3398,  -1.8151,  -2.3625,\n",
      "          -7.7498,  -8.6310,  36.3481]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 36.34807200207671\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8743,  15.9441,  -2.3826,  -2.4161,  -2.3285,  -1.6972,  -2.6860,\n",
      "         -11.3414, -11.6898,  21.9963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 21.99628580366936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8701,   8.4633,  -2.1595,   2.6898,  -2.3552,  -1.8788,  -2.1465,\n",
      "         -13.8773,   1.4018,  10.7158]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.71581377659446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3269,  11.9152,  -2.6123,   2.0948,  -2.6835,  -2.2714,  -2.5133,\n",
      "         -15.6094, -12.5221,  26.4000]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.400021981513554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7035,   5.2723,  -1.0160,   1.2136,  -1.2161,  -0.8495,  -1.2464,\n",
      "         -11.8484,  -1.6233,  13.4228]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.42275341181129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3861,   4.3689,  -1.6693, -15.7594,  -1.9414,  -1.6666,  -1.7739,\n",
      "          -2.7974,  -2.8260,  25.5243]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 25.52431338024697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2068,  4.2847, -1.5229, -2.2344, -1.6986, -1.0896, -1.4959, -6.6023,\n",
      "         -1.1763, 13.7556]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.755553291556124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8387,   9.3751,  -2.5252,  -0.3231,  -2.8502,  -1.9654,  -2.5653,\n",
      "         -17.0742,   1.1199,  19.5529]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.552904573097212\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2934,  12.0345,  -1.2617,  -8.7167,  -1.2875,  -1.2588,  -1.9667,\n",
      "           2.8169, -11.7003,  12.1460]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.14596490084786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9290,   2.0084,  -2.2503,   8.0644,  -2.4002,  -1.9880,  -2.5840,\n",
      "         -17.2987,   7.9334,  11.2394]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.239408220429176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8479,   5.8855,  -1.3597,  -3.6111,  -1.5008,  -0.8985,  -1.1896,\n",
      "         -12.2516,   1.1948,  15.7477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.747653875307677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9024,   6.0689,  -2.4724,   2.6793,  -2.4769,  -1.9047,  -2.5393,\n",
      "         -14.9548,  -3.2354,  22.2984]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.29842015233247\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1302,  19.4303,  -2.1270,   2.1699,  -2.4447,  -1.8992,  -2.6180,\n",
      "          -4.2273, -17.7434,  12.1336]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 19.43029709941149\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7155,   9.7028,  -1.7210,  -5.4388,  -1.7870,  -1.6332,  -2.2743,\n",
      "           2.3503, -12.0494,  13.9841]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.984059146762366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8685,  5.6255, -0.8018, -4.6380, -0.6238, -0.6480, -0.9704,  1.2372,\n",
      "         -6.2167,  7.7344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 7.7344184475686415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1073,  11.9944,  -2.7612,   1.0718,  -2.9313,  -2.3681,  -3.3753,\n",
      "          -6.8695, -10.1998,  17.5437]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.543698642559463\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4007,  22.3046,  -3.1406,  -3.1558,  -3.3918,  -2.3277,  -3.4061,\n",
      "         -20.1122,  -7.9624,  23.2980]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.297967807167925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9811,  10.7769,  -3.5594,  10.8524,  -3.8964,  -2.9657,  -4.0611,\n",
      "         -14.2000,  -4.3455,  14.4718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 14.47176488283269\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7060,   9.0131,  -2.4301,   0.8645,  -2.5924,  -1.8016,  -2.4324,\n",
      "         -19.4865,  -0.9726,  21.5614]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.561415623127726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9808, 11.2914, -2.0560, -6.4117, -2.2220, -1.8372, -2.1494, -7.1122,\n",
      "         -7.0913, 20.1147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.114678453312425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1770,   9.8092,  -2.8232,   6.0241,  -3.0614,  -2.0951,  -2.9830,\n",
      "         -16.2890,  -7.6407,  23.2289]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.2288922503975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7219,  10.4914,  -2.1267,  -1.6909,  -2.0961,  -1.5904,  -2.2534,\n",
      "          -5.3794, -14.5123,  21.1284]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 21.128363820358274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0632,   5.2464,  -1.3615,   1.9497,  -1.7811,  -1.0183,  -1.6037,\n",
      "         -18.3566,   2.9883,  14.7717]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.771705828873374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4401, 11.0409, -1.6689, -6.1969, -1.8288, -1.4468, -1.9011, -7.0559,\n",
      "         -8.5018, 19.7836]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.78360741187536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5472,   4.8598,  -1.8348,   4.9311,  -1.8795,  -1.4504,  -1.9708,\n",
      "         -17.7646,   2.1301,  15.3138]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.313849778837405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4184,   6.7421,  -1.7637, -12.2890,  -2.0828,  -1.8572,  -2.0303,\n",
      "           1.6772,  -9.7565,  22.4709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.470920591521654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4286,  1.4743, -0.5926, -1.0620, -0.5804, -0.6702, -0.8784, -5.2143,\n",
      "          4.5257,  3.7227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 4.525733037434605\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1391,  10.3839,  -2.7980,  -3.2577,  -3.1594,  -2.5173,  -2.9400,\n",
      "         -20.6611,   1.0334,  26.3737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.373735937117814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9331,   6.5986,  -1.2041,  -4.4207,  -1.4188,  -0.9569,  -0.9132,\n",
      "         -10.4609,   1.2405,  13.4704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 13.470370788512119\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3262,   6.5257,  -1.4280, -13.1945,  -1.5779,  -1.4355,  -1.4521,\n",
      "          -6.6962,  -4.1273,  24.9301]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.930069797517216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6115,  7.3648, -1.7562,  2.7100, -2.0165, -1.3661, -1.9968, -5.5360,\n",
      "         -6.4448, 11.4215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.421531995192403\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5266,   8.1000,  -2.1235,   1.2668,  -2.1767,  -1.5403,  -2.0267,\n",
      "         -14.1626,  -3.0152,  18.4630]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.463039697440696\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5376,  7.6758, -2.9927, -3.2816, -3.2169, -2.5124, -3.2609, -9.0996,\n",
      "         -0.0931, 19.9272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.927160115540687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2544,  8.5277, -1.1687, -6.4549, -1.2796, -1.1090, -1.7735,  0.4638,\n",
      "         -9.2329, 12.7833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.783343185603224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9434,  12.7929,  -2.5992,  -1.4724,  -2.5857,  -1.6805,  -2.7945,\n",
      "         -14.3642,  -5.6510,  20.6012]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.601244088434015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1494,   7.1602,  -2.9902,   1.6099,  -3.0494,  -2.3131,  -3.0540,\n",
      "         -11.7833,  -3.8172,  20.8033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.803279689693465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3164,  12.9989,  -2.5434,   3.7305,  -2.8507,  -2.1377,  -3.1303,\n",
      "         -17.7544,  -1.6957,  15.4791]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.47913793277137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6554,  12.7429,  -3.1981,  12.4409,  -3.2784,  -2.7298,  -3.2933,\n",
      "         -15.3320,  -7.2870,  12.4825]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.74290863040751\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4510,  14.7809,  -1.6095,  -8.6690,  -1.6718,  -1.3273,  -1.9220,\n",
      "         -13.2403,  -1.0990,  17.4191]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 17.41911140347811\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5898,   9.7530,  -1.7530, -11.1377,  -1.6556,  -1.2942,  -2.0619,\n",
      "          -3.4634,  -8.8504,  22.5653]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.565323236836193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2620,   7.4777,  -2.7227,   6.6119,  -2.9458,  -2.0828,  -2.9561,\n",
      "         -15.7748,   0.2944,  14.9522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 14.95215277634697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3724,  10.7625,  -1.7001,  -3.4605,  -1.6364,  -1.1927,  -1.5095,\n",
      "          -1.4639, -13.5747,  15.6087]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.608676040070925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8132,   5.3221,  -2.6552,   0.4293,  -2.5482,  -1.9844,  -2.9311,\n",
      "         -18.7456,   5.5079,  20.4676]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.46764926869221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0911,   3.8058,  -1.5571,  -1.0828,  -1.5071,  -1.1188,  -1.7490,\n",
      "         -11.8048,   0.3323,  17.3673]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.367281394443175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4725,   5.5515,  -3.1675,  11.0841,  -3.2209,  -2.1574,  -3.3414,\n",
      "         -20.2666,   0.1845,  18.9264]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 18.926435723365742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4504,   5.4701,  -1.7262, -14.8411,  -2.0380,  -1.8050,  -1.9303,\n",
      "           2.2628,  -7.2488,  23.2465]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.246483888336094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9481,  5.8073, -1.1395, -3.2313, -0.9025, -0.8448, -1.3503,  0.4676,\n",
      "         -6.8931,  9.0145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.014535993370824\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2210,  10.7944,  -2.8433,  -2.2575,  -3.1527,  -2.2019,  -3.1071,\n",
      "         -12.8576,  -2.5522,  20.7347]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.734663629502393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3948,   5.7445,  -1.7188,   0.5577,  -1.6678,  -1.3689,  -1.9298,\n",
      "         -12.9493,   2.2181,  13.4109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.41090366658748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4185,  7.0729, -1.5730, -9.4754, -1.6515, -1.4181, -1.7407, -3.4760,\n",
      "         -7.3119, 21.1697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 21.16973218275807\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6835,   6.9761,  -1.4319,  -3.4867,  -1.6111,  -1.0595,  -1.3055,\n",
      "         -21.6896,   7.3235,  17.7033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.703261432067276\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6168,   5.2423,  -2.2177,   6.1400,  -2.1770,  -1.5206,  -2.4194,\n",
      "         -10.7422,  -3.5813,  14.7345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 14.734532280455166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5972,  17.2524,  -1.6008,  -3.0195,  -1.5798,  -1.4683,  -2.0424,\n",
      "          -6.6722, -10.6467,  11.0339]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 17.252361764023426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3891,  15.3700,  -1.6484,  -6.1094,  -1.7302,  -1.2217,  -2.0467,\n",
      "           0.5534, -15.8786,  13.4924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.36997051081063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0969,  6.6432, -1.4811,  0.0236, -1.5069, -0.9715, -1.6978, -9.9030,\n",
      "         -1.8708, 13.5494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.549377355487852\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7892,  15.7408,  -2.1724,  -1.9331,  -2.3338,  -1.7689,  -2.5721,\n",
      "          -8.5472, -11.5948,  17.2820]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.282024394211724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5928,  12.5179,  -1.6282, -10.2654,  -1.6648,  -1.5065,  -2.1385,\n",
      "          -0.0378, -13.8669,  19.4363]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.43627261245569\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6086,  12.0999,  -3.1397,   8.4871,  -3.2326,  -2.5071,  -3.1818,\n",
      "         -13.7744, -10.0504,  17.6309]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.630888952628506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1979,  8.1161, -2.2194, -7.2537, -2.6089, -2.1927, -2.6109, -6.2531,\n",
      "         -2.1317, 18.9165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.916458593563405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9251,   7.2551,  -2.0303,  -7.0102,  -2.1039,  -1.7636,  -2.1907,\n",
      "         -10.7685,  -2.1959,  23.0041]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.004119423048625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6639,  2.5397, -0.5787, -6.2891, -1.0292, -0.7013, -1.0713, -4.3096,\n",
      "          5.8726,  6.7093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 6.709262920721749\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3521,   5.5081,  -1.6143, -14.4875,  -1.7811,  -1.6358,  -1.8130,\n",
      "           2.0806,  -7.5516,  22.4888]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.48877775318838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7635e+00,  1.7677e+01, -2.0066e+00, -2.6101e+01, -2.3889e+00,\n",
      "         -1.9405e+00, -2.4070e+00,  2.8657e-02, -1.5850e+01,  3.5051e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 35.0509245537741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5179, 14.0732, -2.9978,  1.7562, -3.2510, -2.3156, -3.2704, -9.3949,\n",
      "         -7.3923, 15.4898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 15.48979316200714\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0456,  7.6774, -1.0502, -5.1236, -1.0053, -0.8986, -1.4017,  0.5623,\n",
      "         -7.3825,  9.6195]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.619495094774095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5610,  5.3718, -1.6531, -4.2808, -1.8009, -1.3591, -1.9017, -6.1544,\n",
      "         -5.8805, 19.0105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.010546723876423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4734,   9.6502,  -1.9703,  -3.5119,  -2.0834,  -1.5421,  -2.2177,\n",
      "         -11.4484,  -2.7246,  17.5074]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 17.507378633248607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4374,  12.5643,  -2.7394,  -4.6284,  -2.9612,  -2.1324,  -2.9525,\n",
      "          -4.1701, -10.4468,  19.6180]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 19.61801005310997\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5552,  11.9140,  -1.9335,  -2.0570,  -1.9587,  -1.5827,  -2.2670,\n",
      "         -12.2807,  -7.3878,  20.6072]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.60724502936325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8280,   7.2990,  -2.2915,   2.8012,  -2.1809,  -1.6782,  -2.4173,\n",
      "         -20.2159,  -1.1210,  22.3792]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 22.379205469771794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9165,  8.2651, -0.9785, -6.1912, -0.9631, -1.0403, -1.4369,  1.7653,\n",
      "         -8.8445,  9.8837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.883732352803545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3246,  4.0378, -1.5344, -7.2377, -1.7158, -1.4388, -1.5121, -3.3465,\n",
      "         -2.2513, 16.4952]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.495154318559464\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3597,   8.2310,  -2.1574,  -1.2756,  -2.3770,  -1.5735,  -2.1271,\n",
      "         -17.5058,  -0.7613,  22.3268]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.32681411742874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5048,   9.8540,  -1.6990,  -8.3013,  -1.8123,  -1.5075,  -1.9889,\n",
      "          -4.9557, -13.8179,  25.5399]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.539945215779973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0694,  4.7431, -1.2339, -0.1135, -1.1690, -1.0882, -1.4581, -3.8483,\n",
      "         -3.9023,  8.7800]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.779955676077188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8522,  10.9557,  -2.3162,   0.9015,  -2.3508,  -1.7721,  -2.4291,\n",
      "          -7.1883, -16.0420,  22.3445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 22.34449910644123\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8533,   7.3799,  -1.3391,  -7.0152,  -1.3104,  -0.7389,  -1.2533,\n",
      "         -15.2834,   0.3474,  20.6966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.696619785909235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8621, 10.4502, -2.4062, -2.2017, -2.8246, -1.7648, -2.5382, -7.5068,\n",
      "         -8.2336, 19.7518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.751821210096672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4790,   6.9177,  -1.7508,  -2.5182,  -2.0369,  -1.4979,  -1.9005,\n",
      "         -13.7031,   0.9775,  17.0242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.024192800046897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4265,  16.3507,  -2.9172,  -3.1341,  -3.0025,  -2.1018,  -2.9055,\n",
      "         -10.9407, -15.4888,  26.0038]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.003773524276085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8080,  7.9491, -2.0474, -1.6985, -1.8281, -1.6524, -2.1986, -0.0619,\n",
      "         -9.4647, 12.4649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.464882336181441\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0140,  12.5182,  -3.4822,  11.2240,  -3.8650,  -2.9459,  -3.7023,\n",
      "         -12.3177, -13.4143,  18.9937]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 18.993717169207937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5916,   9.1156,  -1.9143,   4.9964,  -2.2110,  -1.8042,  -2.2108,\n",
      "         -15.2930,  -0.3866,  12.5200]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.519971730495882\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1515,   9.4498,  -1.4591,  -3.2471,  -1.4406,  -1.0116,  -1.2199,\n",
      "          -1.9720, -10.7801,  13.2290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.228952423194187\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8657,   9.1119,  -2.0238, -15.4925,  -2.1361,  -2.0442,  -2.5287,\n",
      "           3.4081,  -9.0947,  22.2882]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.28815794762365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3038,  9.0036, -1.6999, -9.2081, -1.5284, -1.1747, -1.9998, -2.2998,\n",
      "         -9.0570, 19.7557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.755712560694306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5197,  9.4081, -1.7288, -6.3625, -1.7823, -1.3051, -1.8832, -9.5224,\n",
      "         -2.4652, 17.2789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.278935737246606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1850,  17.0662,  -3.5774,   6.9315,  -3.7020,  -2.6537,  -3.7017,\n",
      "         -10.2611, -12.4316,  14.6656]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 17.06618738225066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4682,   5.8179,  -1.8199,   8.0613,  -2.2734,  -1.7504,  -2.0084,\n",
      "         -14.7759,   2.9084,   8.9797]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 8.979676785242571\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5471,  11.6456,  -3.1772,   4.4769,  -3.3103,  -2.4733,  -3.3597,\n",
      "         -14.3114,  -7.7873,  20.9795]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 20.97954703767221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7344,  10.1412,  -1.7670, -13.2787,  -2.5086,  -1.8000,  -1.9457,\n",
      "         -15.1100,  -0.2027,  28.4851]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 28.48511524836909\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8457,   7.3428,  -2.5775,   3.2399,  -2.2860,  -1.8091,  -2.6935,\n",
      "          -4.2947, -11.9903,  18.6090]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.60899454405414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6659,   9.1703,  -1.8475,   2.2849,  -2.6559,  -1.7793,  -2.1195,\n",
      "         -14.8310,   0.1324,  15.0245]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.02452336674077\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8598,   9.9872,  -2.5092,  -0.1606,  -2.9401,  -2.2560,  -3.0840,\n",
      "         -10.7550,  -4.5890,  18.8641]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.86405691599574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1163,   9.6446,  -1.4922,  -6.4589,  -1.7888,  -1.4085,  -1.8471,\n",
      "         -11.4553,  -0.3065,  16.5225]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.522524305185296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5996,  20.5411,  -1.8123,  -5.3114,  -1.7067,  -1.3103,  -2.0850,\n",
      "           3.7598, -23.3535,  12.4125]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 20.541133642236872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7014,  7.9488, -1.9391, -2.3229, -2.0758, -1.5935, -2.0083, -7.3429,\n",
      "         -2.9747, 14.1475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.147542728236333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1373,  7.2674, -1.4940, -3.0956, -1.4872, -1.1572, -1.2541, -5.9019,\n",
      "         -5.4143, 14.7510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 14.751029942500463\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7363,   8.4748,  -1.8190,  -0.0892,  -2.1571,  -1.6903,  -2.0812,\n",
      "         -18.1048,   2.4247,  16.9638]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.963803815295186\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5081,  9.9760, -2.0869, -4.9050, -2.2244, -1.6574, -2.3193, -8.8179,\n",
      "         -8.1723, 21.9885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.988508529066166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4960,   8.3500,  -2.2077,  -0.5090,  -2.2259,  -1.6425,  -2.1430,\n",
      "         -19.9188,   2.6693,  20.4640]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.463986909740015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8433,  7.8597, -2.1791, -0.4645, -2.2153, -1.8116, -2.0174, -5.2909,\n",
      "         -9.4220, 18.1087]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 18.108727409521688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5145, 10.2299, -1.6743, -3.3954, -1.8364, -1.6830, -2.0925, -9.5873,\n",
      "         -4.8962, 16.2982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 16.29818259226336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9934,  13.0547,  -3.0626,  -4.3574,  -2.9541,  -2.1659,  -3.0796,\n",
      "         -11.3606,  -4.5387,  21.2582]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.25815080348172\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9372,  12.8762,  -2.2445,  -0.2264,  -2.4728,  -1.6573,  -2.6019,\n",
      "          -9.2943, -10.6651,  17.7166]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.71660464718114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4935,  14.8302,  -3.3040,   2.1133,  -3.5967,  -2.4623,  -3.1103,\n",
      "         -23.4027,  -1.7170,  22.9776]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.977598306505982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6878,  11.0880,  -1.0954,  -6.6185,  -0.8763,  -0.8419,  -1.1995,\n",
      "         -12.2472,  -3.5761,  16.6757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.675657623358866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1856,  11.6902,  -2.8943,   4.2180,  -2.8841,  -2.1272,  -2.9322,\n",
      "         -18.2200,  -8.5431,  24.4573]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 24.45730169909746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8669,  11.8814,  -2.2802,   0.1407,  -2.4136,  -1.5556,  -2.7542,\n",
      "         -16.6215,   1.4780,  14.3607]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 14.360699634040689\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6729,  15.2275,  -3.4096,   6.1628,  -3.4454,  -2.6615,  -3.5099,\n",
      "         -16.8963,  -8.7994,  20.1389]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 20.138851294906065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9019,   4.8329,  -1.3398,  -1.2166,  -1.6962,  -1.1671,  -1.7150,\n",
      "         -12.7227,   5.6132,  10.9452]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.945245817519515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2237,   5.9477,  -2.9342,   9.7405,  -2.7198,  -2.0869,  -3.0546,\n",
      "         -16.1578,  -5.7780,  21.0362]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.036153303170874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8357,   7.2702,  -1.2883,   0.4227,  -1.2235,  -0.8616,  -1.3532,\n",
      "         -13.1388,  -1.4147,  13.6063]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.60629518039856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1958,   5.3695,  -1.3872, -10.7443,  -1.2616,  -1.1274,  -1.6403,\n",
      "          -8.1243,  -0.3430,  21.1724]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.172422975040593\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7707,  8.4319, -1.9746,  1.5387, -2.1688, -1.6687, -2.1081, -8.9393,\n",
      "         -5.2281, 13.9586]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.958551469230231\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6423,  10.6027,  -1.9496,  -9.5421,  -1.9369,  -1.5462,  -2.1975,\n",
      "          -6.8830, -10.4054,  25.6288]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.628773318625093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9990,   3.3633,  -2.5664,   3.3610,  -2.6734,  -2.2352,  -2.6526,\n",
      "         -27.9656,  11.0089,  22.4322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.43223545309839\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3539,  12.2371,  -1.6028,  -6.1741,  -1.7534,  -1.3306,  -1.9239,\n",
      "           1.7012, -14.2471,  13.9737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.973672192315501\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6967,  13.8393,  -2.1802,  -1.1980,  -2.1927,  -1.7927,  -2.4324,\n",
      "          -6.9100, -11.9148,  16.6136]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 16.613587268682885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9867,  4.4635, -1.3888, -5.4111, -1.3482, -1.1033, -1.4184, -9.9013,\n",
      "         -2.3138, 20.6364]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.63636019044063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5045,  8.9855, -1.6956, -1.9419, -1.7922, -1.3480, -1.8588, -9.6555,\n",
      "         -3.4416, 14.7232]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.723225825563487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0541,   8.7607,  -1.1406,  -7.0336,  -1.1793,  -1.1715,  -1.6025,\n",
      "           1.4925, -10.0928,  12.3373]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.337278695905296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6625,  9.4379, -1.8115,  3.9842, -2.0495, -1.4451, -1.8825, -8.1656,\n",
      "         -5.4913,  9.5614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.561376681494533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1807,  11.7897,  -2.7905,   6.4475,  -2.8719,  -2.3508,  -2.8729,\n",
      "         -16.2962,  -5.7654,  16.7777]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 16.777740018558795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0544,   7.3583,  -2.3431,   6.5108,  -2.5013,  -2.0188,  -2.5691,\n",
      "         -10.8405,  -2.0724,  10.1495]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.149470342395842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5953, 10.9768, -2.0020,  1.1626, -2.2459, -1.4014, -2.2365, -8.2141,\n",
      "         -8.2558, 14.8870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 14.886951088504286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9627,  3.7699, -1.2493, -2.1219, -1.1547, -1.1051, -1.1585, -7.2850,\n",
      "          0.1914, 12.3415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.341467888069582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7460,  15.4875,  -1.8534,  -1.7143,  -2.5164,  -1.7381,  -2.1823,\n",
      "         -13.5787,  -7.0860,  16.3966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 16.39664282867707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9486,  6.9477, -1.1893, -3.0628, -1.2304, -1.0086, -1.2269, -5.2455,\n",
      "         -1.1194,  8.1898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 8.189823199645227\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1556,   3.8593,  -1.6536,  -0.1324,  -1.5629,  -1.1113,  -1.7476,\n",
      "         -10.9669,  -0.2576,  16.5545]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.554472938794117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3955,  18.4896,  -2.5809,   6.7486,  -3.0336,  -2.3582,  -3.2055,\n",
      "          -9.5362, -12.7682,  11.0666]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.48958828340532\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4839,   6.5951,  -1.6364, -10.9139,  -1.7502,  -1.4654,  -1.8461,\n",
      "          -7.4460,  -3.8790,  23.8502]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.850239149757357\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3325,  8.3135, -1.4062, -2.9251, -1.0838, -1.1964, -1.5647, -6.0083,\n",
      "         -5.1040, 12.6917]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 12.691727078514546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5289,   8.9803,  -2.8237,   7.4250,  -3.0196,  -2.3305,  -3.1724,\n",
      "         -13.1277,  -4.8979,  15.7525]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.75252386181404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5319,  11.9196,  -1.9495,  -4.6202,  -1.9454,  -1.7323,  -2.0529,\n",
      "         -19.5859,   0.5702,  22.6747]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 22.67470374897225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4125,  2.4911, -1.6854, -5.9133, -1.9556, -1.5744, -1.7184, -6.9400,\n",
      "          3.0470, 15.9363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 15.936260707148929\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7903,  5.6699, -1.8672, -2.9165, -1.9348, -1.8108, -2.1310, -3.2861,\n",
      "         -5.7536, 15.3677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 15.367737481177056\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6655,   5.7654,  -1.8292,  -8.8125,  -1.9223,  -1.8157,  -1.9272,\n",
      "         -10.8232,  -2.6327,  25.6647]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.664664375368808\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1633,   7.4725,  -1.4979,   1.9882,  -1.7616,  -1.3496,  -1.7290,\n",
      "         -21.7354,   6.6363,  13.9005]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.900467137621327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5730,   8.2900,  -1.6291, -15.2352,  -1.8429,  -1.6351,  -1.6643,\n",
      "          -2.9240,  -5.8320,  24.1904]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.19035444487093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6022,  12.0426,  -2.0035,  -4.3722,  -2.2701,  -1.8974,  -2.0644,\n",
      "         -17.9089,  -0.3968,  21.1480]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.147979522464667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0809,  10.9675,  -1.3362, -12.9915,  -1.2357,  -1.0098,  -1.5644,\n",
      "           4.3279, -12.6158,  16.7040]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.704020075923687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1149,   6.4372,  -2.1469,  -4.0940,  -2.8957,  -2.2247,  -2.2559,\n",
      "         -28.4027,  12.1530,  25.6668]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.666838340239998\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8316,  5.5678, -2.3520,  3.7614, -2.2253, -1.7701, -2.4542, -6.4478,\n",
      "         -9.6648, 19.1227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.12272713447638\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2686,  7.5474, -1.4262, -6.3226, -1.3551, -1.0999, -1.7216,  0.1569,\n",
      "         -8.2066, 13.7903]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.790254857394105\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8608,   5.6120,  -2.0979,  -7.2074,  -2.3086,  -1.8398,  -2.0159,\n",
      "          -9.5698, -10.2750,  31.5530]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.55302240844691\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2640,   4.8001,  -1.4669,   0.2801,  -1.4597,  -1.2192,  -1.2603,\n",
      "         -11.9557,   2.0120,  11.9605]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 11.960535404948676\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8334,  10.8245,  -2.1901,  -7.6076,  -2.1572,  -1.6516,  -2.2791,\n",
      "          -1.9211, -15.3830,  24.2215]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.221529931736256\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [12]: loss = 16.377, accuracy = 8.20\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4124, -0.0329, -0.4580,  0.4758, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433, -0.0307], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.4124, -0.0329, -0.4580,  0.4758, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433, -0.0307], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.4350,  8.9038, -1.6386, -1.0408, 12.2801, -1.2860, -1.9636, -8.8498,\n",
      "         -2.9472, -1.9628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 12.280082564412183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4499,  11.8302,  -2.9917,  -6.9387,  21.2333,  -2.5488,  -3.0012,\n",
      "         -13.6294,  -8.7503,   7.0050]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 21.233294680911797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4532,  7.9636, -1.5398, -2.0312, 14.1146, -1.2824, -1.7903, -9.1335,\n",
      "         -1.9056, -2.8198]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 14.114603722678758\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2014,  13.2438,  -3.6787,  11.4053,  17.7037,  -2.8473,  -3.9354,\n",
      "         -14.3275, -12.1233,  -1.9646]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 17.703712644487595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4137,   6.0479,  -1.4265,  -2.2150,  17.2597,  -1.4951,  -1.4386,\n",
      "         -15.6867,   0.4735,   0.8482]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 17.25968219774942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3895,   6.9487,  -3.1225,   2.0708,  13.3697,  -2.5693,  -3.2284,\n",
      "         -10.6361,  -7.7725,   7.2144]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 13.369682649293932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3118,   8.9645,  -2.8747,   6.9101,   9.7237,  -2.2134,  -3.0197,\n",
      "         -13.1005,  -2.8866,   1.1861]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 9.723670386891143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3768,  5.0264, -1.7734, -9.1367, 15.8022, -1.7001, -1.8464, -2.5249,\n",
      "         -8.9904,  5.9653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 15.802158197300464\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1541,  11.4575,  -2.3150,  -5.7285,  16.3016,  -2.0140,  -2.6150,\n",
      "          -0.9259, -10.9915,  -1.4408]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 16.301620466484568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4195,   4.4522,  -1.7797, -10.7256,  19.1378,  -1.7948,  -1.9333,\n",
      "          -1.2542,  -6.1746,   1.1948]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 19.137808561730154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5153,  22.4568,  -3.9603,   7.9283,  19.0518,  -3.1301,  -4.3548,\n",
      "          -8.0061, -25.0418,  -1.2818]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 22.456845711162362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6675,   5.8851,  -1.8444,  -3.2513,  18.0852,  -1.7156,  -1.9624,\n",
      "         -12.7192,  -2.3080,   2.2533]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 18.085152670391977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3873,   6.9152,  -1.6522,  -5.1572,  17.3688,  -1.4650,  -1.9405,\n",
      "         -12.5690,   1.2003,  -1.0858]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 17.368817486890887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4009,  9.9455, -1.7613, -3.5155, 13.8380, -1.1919, -1.5743, -2.5724,\n",
      "         -9.3396, -1.8085]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 13.83801676734306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7514,  17.7762,  -3.4986,  -2.0694,  24.3506,  -2.5146,  -3.6391,\n",
      "         -19.0068, -11.3944,   3.8161]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 24.350599121562976\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1687,   5.6688,  -1.6316, -14.8569,  18.4359,  -1.6188,  -1.8638,\n",
      "           2.6939, -10.5892,   4.5191]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 18.435880192203985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3094,  9.8870, -1.4427, -3.0557, 14.2501, -1.3604, -1.6118, -3.5230,\n",
      "         -9.2238, -2.8792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 14.250128604972257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2740,  9.5390, -1.6516, -2.3889, 11.2280, -1.1250, -1.8018, -7.1899,\n",
      "         -6.4314,  1.6585]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 11.227958936431694\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0252,  13.7131,  -2.0383,  -7.6083,  22.8328,  -1.8546,  -2.5153,\n",
      "         -19.7194,   1.1432,  -0.7649]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 22.832775879557214\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7279,  11.2496,  -2.1326, -12.3705,  32.9232,  -1.5316,  -2.3749,\n",
      "           0.3073, -11.6506, -11.9392]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 32.92319540589007\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3234,  9.4424, -1.0353, -3.6130, 11.4353, -1.0796, -1.3716, -6.2813,\n",
      "         -3.7849, -1.6270]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 11.435325866403733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3511,  12.0762,  -2.9604,   3.3018,  14.5511,  -2.6569,  -3.0666,\n",
      "         -12.5648, -10.4464,   4.5907]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 14.551108809184935\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7311,   7.2346,  -1.5919,   0.1038,  13.3357,  -1.5169,  -2.0080,\n",
      "         -11.4599,  -2.3659,   0.6715]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 13.335701603580546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3894,   6.2077,  -1.8223,  -8.9772,  19.1444,  -1.5285,  -1.8390,\n",
      "          -4.2996, -16.0938,   9.8616]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 19.144369253676555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2697,  8.4826, -1.5332, -5.0871, 16.8564, -1.4047, -1.7089, -4.7747,\n",
      "         -5.3858, -3.3035]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 16.856369334593168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2230,  6.2490, -1.6433, -5.0763, 20.2797, -1.3665, -1.9586, -7.4667,\n",
      "         -4.8467, -1.4013]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 20.279660419171353\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8712,  4.8239, -0.9578,  0.0949,  9.1481, -0.6013, -0.9226, -8.4831,\n",
      "         -0.6767, -0.5157]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 9.148104340920796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4552,   7.3874,  -1.5099,  -7.2576,  23.1941,  -1.3600,  -1.8105,\n",
      "          -4.0625, -10.5924,  -2.5083]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 23.194119607889228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5724,  11.2222,  -1.8660,  -6.1716,  21.7619,  -1.5057,  -2.0464,\n",
      "         -12.7502,  -3.2160,  -3.7514]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 21.761912937712495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5726,   8.9946,  -1.7341,  -8.1683,  28.8128,  -1.2110,  -1.8809,\n",
      "          -1.4579,  -9.3982, -11.8962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 28.812790819525944\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6146,  9.3789, -1.9381, -4.3475, 17.6725, -1.5918, -2.3259, -8.4656,\n",
      "         -5.4925, -0.7270]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 17.672472507144207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4297,  14.6542,  -1.7297,  -4.9313,   7.2290,  -1.2691,  -2.0038,\n",
      "           0.2179, -15.2375,   3.8380]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.654162074239037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8921,   2.4315,  -0.9978,   0.8488,   5.5891,  -1.0440,  -0.9433,\n",
      "         -12.4646,   7.1274,   0.2469]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  9\n",
      "activation[8] = 7.127368035859909\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1037,  11.7059,  -2.7258,  -1.4970,  16.5487,  -2.2657,  -3.1155,\n",
      "          -8.2166, -14.2740,   5.7806]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 16.548746628938446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8274,  19.3505,  -3.3969,   8.3990,  18.6233,  -2.6583,  -3.7470,\n",
      "         -24.2787,  -6.0226,  -1.8459]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 19.350473529470076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7271,  9.8715, -2.3081,  1.7202, 14.2998, -1.6927, -2.4285, -9.1906,\n",
      "         -8.1694,  0.6369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 14.299786357900942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4123,   6.7301,  -1.9377,   2.2197,   8.2955,  -1.6122,  -2.1508,\n",
      "         -16.6975,   6.6765,  -0.1692]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 8.295498049766287\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1029,  7.1975, -1.6450, -9.7666, 21.0290, -1.1942, -1.5860, -7.7716,\n",
      "         -5.1081,  0.9545]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 21.029024930228804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6010,  13.4157,  -2.4709,  -2.1406,  20.8148,  -2.4502,  -2.8567,\n",
      "         -15.9519,   0.2108,  -5.4107]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 20.814791902787363\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4907,  16.1308,  -1.7103,  -8.0025,   8.7494,  -1.2578,  -1.8881,\n",
      "           2.3116, -17.3103,   3.7108]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 16.130810017381467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9963,  16.2587,  -2.4069,  -2.4419,  14.8058,  -2.2211,  -2.8846,\n",
      "         -11.8843,  -8.9181,   1.2910]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.258741501787114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4854,  15.4295,  -1.7161,  -6.3784,   6.5135,  -1.3066,  -2.2419,\n",
      "           0.2925, -15.6499,   5.9192]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.429504036444031\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8046,   7.4316,  -2.1861,   2.0132,   7.2662,  -1.8410,  -2.3912,\n",
      "         -10.0324,  -0.2379,   2.1189]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 7.43163980822766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2406,   4.1296,  -1.6648,  -4.4479,  20.2055,  -1.2486,  -1.6302,\n",
      "         -11.4233,  -1.6474,   0.0358]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 20.20547465127233\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1542,  2.0137, -1.4642, -0.8771,  7.2043, -1.4142, -1.7089, -7.7162,\n",
      "          4.7474,  0.3374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 7.204312618264923\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4598,   4.7079,  -1.5094,  -6.9934,  22.8240,  -1.3346,  -1.6201,\n",
      "         -11.8410,   3.1099,  -4.7404]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 22.823979617154382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9628,   4.7391,  -2.6028,   7.1294,  14.9965,  -1.8635,  -2.6011,\n",
      "         -21.4479,   5.8942,  -0.9402]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 14.996541614294134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7359,  16.2818,  -2.9748,   8.7212,  10.7946,  -2.3924,  -3.4731,\n",
      "          -9.0010, -12.8789,  -2.7388]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 16.281797657537446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8479,  4.0596, -1.0885, -1.7220,  6.8385, -0.7561, -1.1390,  0.8062,\n",
      "         -5.1680, -1.1354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 6.838506680249025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5936,  5.5630, -1.7762, -4.8707, 21.7138, -1.4820, -1.9293, -5.7986,\n",
      "         -9.9544,  0.0651]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 21.713787338832315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3261,  5.3466, -1.5961,  0.3422,  8.9662, -1.1889, -1.6842, -3.3328,\n",
      "         -4.3486, -1.3218]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 8.966226985158901\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3369,  6.0508, -1.7143,  0.0802, 14.7043, -1.1360, -2.0817, -7.8606,\n",
      "         -2.1782, -2.9875]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 14.704332920978345\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2396,  10.3708,  -2.5995,   7.2063,  11.0295,  -2.1066,  -2.9007,\n",
      "         -16.5529,  -1.2987,  -1.3327]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 11.029494605739192\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8795,   6.5224,  -0.9247, -14.4783,  22.0172,  -0.8778,  -1.0497,\n",
      "          -4.6631,  -4.9812,  -0.1002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 22.0172011958402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5013,   5.4407,  -2.2885,   9.5809,   6.2908,  -1.6291,  -2.5985,\n",
      "         -16.7605,   3.9106,   0.9340]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 9.58092869635652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7534,  4.3049, -1.2901, -5.6758, 19.1110, -0.9076, -1.3711, -7.5823,\n",
      "         -1.5998, -2.9057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 19.111028094388356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0070,   8.4534,  -1.5518,  -3.3127,  11.3668,  -1.3442,  -1.7172,\n",
      "         -15.2690,   5.4014,  -0.0295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 11.366767474455514\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0770,  10.8739,  -1.6269,  -3.8054,  19.3261,  -1.0107,  -1.6510,\n",
      "          -8.1551, -13.8685,   1.6452]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 19.326122201785566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6637,  4.4208, -0.8138, -2.9665,  8.0448, -0.6720, -0.8487, -0.5759,\n",
      "         -5.2844, -0.5322]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 8.044849441977336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0858,   6.4568,  -2.5459,   3.3591,  16.6681,  -2.0694,  -2.5440,\n",
      "         -11.2034,  -8.9083,   4.2183]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 16.668074144192992\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0855,  5.8269, -1.1540, -4.4310, 10.6865, -0.9534, -1.4062,  1.8479,\n",
      "         -7.5581, -1.9241]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 10.686492749316244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9008,   9.1428,  -2.7943,  -2.5232,  14.3747,  -2.2564,  -2.8964,\n",
      "         -12.2741,  -8.0685,   9.8007]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 14.374673487692469\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6299,  12.2554,  -2.0315,   0.5147,   8.4608,  -1.6981,  -2.3031,\n",
      "         -13.2062,  -2.6438,   1.7520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.255365184028797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0613,   5.1869,  -2.5982,   7.9882,  15.2164,  -2.0099,  -2.8892,\n",
      "         -14.9208,  -5.3044,   2.6473]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 15.216372168237037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8866,  4.7000, -1.2792,  2.2178,  4.7825, -0.9411, -1.3010, -3.8259,\n",
      "         -2.6770,  0.1951]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 4.782549839250723\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6275,   8.1193,  -2.0494,  -1.3567,  16.2946,  -1.7954,  -1.9752,\n",
      "         -10.1865,  -3.2122,  -1.7301]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 16.294613196550728\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3712, 10.8555, -1.2768, -3.5874, 14.5825, -1.3434, -1.8667, -9.8203,\n",
      "         -0.4854, -4.9797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 14.582479809052519\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1827,   4.1053,  -1.4814,  -3.7899,  19.6071,  -1.1514,  -1.6088,\n",
      "         -10.8471,  -1.2305,  -1.7203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 19.607118305173096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9443, 11.7766, -2.0540, -4.5935, 19.0245, -1.9816, -2.3430, -6.6561,\n",
      "         -8.9083, -2.8738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 19.024462050720743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6480,   9.0002,  -2.1930,  -3.6017,  17.7257,  -1.6699,  -2.4019,\n",
      "          -5.5603, -10.7136,   1.8700]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 17.725714783384635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4774,  16.1375,  -2.6476,  -3.2544,  13.7894,  -2.3376,  -3.2458,\n",
      "          -6.9536, -12.3173,   3.2113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.137452718615823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8169,   6.2861,  -2.4708,   4.5201,  13.8640,  -1.9715,  -2.3522,\n",
      "         -21.0113,   0.6069,   5.4748]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 13.863978742373408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7467,  17.4613,  -3.1386,  -1.3044,  14.0568,  -2.6080,  -3.5802,\n",
      "         -18.4457,  -3.4097,   3.5125]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 17.46126887910201\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3776,  11.9095,  -1.3617,  -8.3392,  12.5718,  -1.3267,  -1.9896,\n",
      "           2.0597, -11.8707,  -0.8144]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 12.57183943576062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2404,  16.5659,  -2.6530, -20.9428,  26.8252,  -2.1434,  -2.9208,\n",
      "           6.0122, -25.2576,   6.4654]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 26.825234162591304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3937,  11.7591,  -2.0503,  -7.9614,  16.2345,  -1.4870,  -2.1033,\n",
      "          -6.4560, -12.0346,   5.9739]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 16.234463684065027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7537,  15.8378,  -2.3014,  -2.4727,  17.0593,  -1.7819,  -2.7376,\n",
      "         -16.2001,  -3.8104,  -0.7669]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 17.059251288530866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4519,  12.9547,  -1.5155,  -6.8695,   9.6781,  -1.2489,  -2.0774,\n",
      "          -0.1084, -11.7716,   2.0947]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.95467761621427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6699,  7.1868, -1.6984,  3.9507,  8.6568, -1.5471, -1.8564, -7.3119,\n",
      "         -4.5065, -1.2296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 8.656799160334359\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3625,   3.0492,  -1.5030, -11.3069,  15.8701,  -1.5955,  -1.6362,\n",
      "          -2.4755,  -2.0513,   3.2814]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 15.870132195980162\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5002,  15.2481,  -3.2207,   4.3747,  17.6929,  -2.3319,  -3.5151,\n",
      "         -17.4886,  -5.1775,  -2.6636]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 17.69293913234486\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2153,  10.2724,  -2.9151,  -3.8594,  17.8642,  -2.1588,  -2.9407,\n",
      "         -18.8332,  -1.2000,   5.7704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 17.864199331331687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2005,   9.1772,  -2.5117,   1.7555,  15.0141,  -2.1244,  -2.5444,\n",
      "         -18.7109,   1.5373,   0.2535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 15.014138870776389\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3895,  12.0345,  -1.4843,  -7.3880,   9.9170,  -1.3357,  -2.0878,\n",
      "           1.8635, -12.9991,   2.2481]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.03445464836482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7278,  7.4908, -2.0087,  4.4873, 12.0640, -1.7181, -2.3038, -8.0958,\n",
      "         -4.2391, -3.0341]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 12.06398765639376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3531,   9.5548,  -1.6369, -11.0304,  29.4974,  -1.2529,  -1.9646,\n",
      "          -3.4852,  -9.2779,  -8.8827]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 29.49742804626153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4109,   7.8549,  -2.9533,  -2.8405,  19.5743,  -2.6596,  -3.0291,\n",
      "         -32.8901,  11.8193,   7.3278]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 19.574345345883046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8398,  11.7750,  -3.4148,  10.5655,  16.5329,  -2.8566,  -3.9280,\n",
      "         -14.2796, -10.1527,  -0.9009]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 16.532871835370905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7181,   7.8168,  -2.4207,   5.4344,  14.4385,  -1.7671,  -2.5634,\n",
      "         -21.9615,   1.2904,   2.9330]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 14.43849079773645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5933,   9.4492,  -2.0898,  -2.6144,  12.2273,  -1.6596,  -2.2446,\n",
      "          -7.8925, -10.7007,   7.2099]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 12.22725173471014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5376,  5.1333, -1.7430, -4.6657, 13.9817, -1.6609, -1.9082, -7.0067,\n",
      "         -1.2051,  0.3485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 13.981681752051678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7627,  9.2593, -1.9071, -3.0837, 15.1002, -1.6856, -2.0457, -6.2284,\n",
      "         -7.7336, -0.1721]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 15.10021615317175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0856,  6.6030, -1.0397, -2.5491,  8.2323, -0.9585, -1.5428, -8.8823,\n",
      "          2.5898, -1.1161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 8.232267323161398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1074,   7.8899,  -2.8262,   2.2871,  13.3009,  -2.1648,  -2.8356,\n",
      "         -12.1901,  -7.0619,   5.8740]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 13.300912193986115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0817,  9.3365, -0.9803, -3.8430,  9.9215, -1.0538, -1.3472, -4.1392,\n",
      "         -7.0068, -0.4103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 9.921451547381494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5803,   8.0988,  -1.9996, -16.3460,  19.8855,  -1.9373,  -2.2562,\n",
      "          -0.1561, -13.5736,   9.3769]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 19.88546649630195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5567,   6.8524,  -1.8552, -10.0075,  22.3743,  -1.8645,  -2.0543,\n",
      "         -12.7028,   1.5579,  -0.6176]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 22.37433143979264\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6419,   7.5315,  -1.8462,  -8.7070,  23.1355,  -1.5566,  -2.0447,\n",
      "          -3.6227, -17.5751,   5.8536]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 23.13545762106226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1517,   3.9361,  -2.5782,   9.6595,  14.1550,  -2.0755,  -2.4019,\n",
      "         -22.9277,   2.7946,   1.6916]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 14.154991378671877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4935,  11.9759,  -2.8593,   3.7716,  11.8523,  -2.1638,  -3.2343,\n",
      "          -2.8313, -15.1496,   1.3222]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 11.97586114779846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3767,  11.6553,  -1.6165,  -6.1079,  17.7888,  -1.2986,  -2.0145,\n",
      "         -10.0336,  -3.2981,  -2.4095]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 17.788837849276735\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6810,   5.9260,  -1.8268,  -7.8431,  22.4930,  -1.6313,  -1.7754,\n",
      "          -5.3378, -11.9198,   3.2426]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 22.49304621362744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2655,  10.0351,  -2.3557,   5.0922,  10.8945,  -2.1930,  -2.6669,\n",
      "         -14.8458,   0.7475,  -3.0757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 10.894502027534134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5413,  9.2556, -2.3147, -2.0178, 16.4344, -1.4263, -2.3013, -8.7635,\n",
      "         -4.7049, -1.0978]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 16.43438203118913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7107,  18.8651,  -2.9576,  -6.1211,  16.7470,  -2.6255,  -3.6468,\n",
      "          -8.8567, -12.7255,   3.9741]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.865059077519508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2781,   8.5255,  -1.3299,  -6.5997,  11.3264,  -1.1640,  -1.8367,\n",
      "           0.7117, -10.0384,   1.4463]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 11.326402238273825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7241,  15.0609,  -3.1133,   4.2908,  15.9543,  -2.4985,  -3.5405,\n",
      "          -7.6594, -14.4689,  -1.6042]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 15.954325283336747\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8425, 13.9726, -2.0719, -4.3092, 13.4425, -1.9737, -2.8405, -8.3795,\n",
      "         -8.3524,  1.7369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.972581870458898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3250,   5.1522,  -1.7889,   5.7954,  13.3999,  -1.3104,  -1.9268,\n",
      "         -20.7714,   3.8202,  -0.7736]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 13.399895815148167\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4203,   8.2068,  -2.8861,   6.3062,  10.8318,  -2.3620,  -3.4699,\n",
      "         -10.9152,  -1.7641,  -0.8646]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 10.831759658744339\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3764,  8.7273, -1.4552, -6.9896, 19.8681, -1.4173, -1.6936, -5.2895,\n",
      "         -5.8073, -4.5344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 19.86811747704891\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3942,  8.3066, -1.6141, -1.9987, 16.6893, -1.4379, -1.6662, -4.9372,\n",
      "         -5.7866, -5.7094]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 16.689256117191743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7039,   7.8940,  -1.6947, -12.0954,  26.2809,  -1.2142,  -1.6709,\n",
      "          -9.3946,  -0.9628,  -4.2264]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 26.280909944998257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5483,  8.6152, -2.0825,  2.3306, 11.2767, -1.5687, -2.1829, -5.1471,\n",
      "         -9.9785,  0.1661]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 11.276686017038124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6337,  6.2620, -0.8453, -8.8952, 13.0127, -0.7948, -0.9740, -5.3382,\n",
      "         -1.4785,  0.2408]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 13.01266111338101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0002,  5.0640, -1.2668, -0.3042, 12.5991, -0.9592, -1.3523, -8.3415,\n",
      "         -1.4673, -2.0146]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 12.59909591897338\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7831,   3.4424,  -2.1566,   4.6276,  12.6035,  -1.6778,  -2.0406,\n",
      "         -17.2220,   0.4567,   3.7037]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 12.603546167315887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6519,   7.6398,  -1.7986, -10.8062,  21.4787,  -1.8544,  -2.1598,\n",
      "           0.3962,  -8.4892,  -3.0309]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 21.478710131187114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4308,   6.8958,  -1.3600,   0.3246,  10.2415,  -1.2713,  -1.5879,\n",
      "         -11.1744,  -1.7997,   1.1122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 10.241453950614563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7676, 11.7948, -2.0687, -8.0224, 18.2048, -1.6457, -2.4362, -7.0731,\n",
      "         -9.6413,  2.2067]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 18.20481600105403\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0609,   9.6343,  -2.4270,   6.3103,  13.2884,  -2.1760,  -2.4125,\n",
      "         -13.2827,  -3.8264,  -3.2679]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 13.288422566958129\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8017,   8.6151,  -1.9011,  -5.8385,  23.2541,  -1.6084,  -2.1712,\n",
      "          -2.9997, -11.8046,  -4.1539]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 23.25412613217641\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5960,  6.2105, -0.7219, -4.2375,  7.7639, -0.7834, -1.0044, -8.8933,\n",
      "          3.8982, -1.2356]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 7.763853795859342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9917,   7.5974,  -2.6278,   0.8516,  19.9339,  -2.0509,  -2.7150,\n",
      "         -11.2981,  -7.1392,   1.4025]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.933878928168085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0245,  12.6218,  -2.7846,   0.3215,  14.1985,  -2.1068,  -2.8913,\n",
      "         -18.5186,  -1.0671,   2.3282]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 14.19846557395525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2564,  12.0269,  -1.3852,  -9.1934,  10.0150,  -1.1724,  -1.8051,\n",
      "           0.8674, -11.6522,   3.0908]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.02693021595446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1534,   4.8255,  -2.9686,   7.3407,  17.5899,  -2.0505,  -2.9177,\n",
      "         -11.8007,  -6.6003,   0.7200]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 17.589913137128374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1827,  17.1367,  -2.6740,  -2.5462,  20.5004,  -2.0730,  -3.0785,\n",
      "          -8.6961, -16.8061,   0.6444]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 20.50035474272709\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4520,  11.5617,  -1.6292,   2.6666,   4.4806,  -1.5126,  -2.1149,\n",
      "         -12.0479,  -2.0075,   1.9461]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 11.561668803923316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3555, 11.8792, -2.7290,  5.7161,  9.1030, -2.3138, -3.4746, -3.5792,\n",
      "         -9.7762, -1.6512]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 11.87923975922564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6132,  8.7291, -1.5142,  1.1971, 10.8355, -1.3407, -2.0561, -7.9654,\n",
      "         -2.9105, -2.9978]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 10.835504645141132\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8215,  10.3131,  -2.2721,  -7.1117,  25.8438,  -1.9624,  -2.3119,\n",
      "         -10.6969,  -2.1072,  -7.2273]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 25.843821565320983\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5104,   5.8132,  -2.3686,   4.1264,   7.0287,  -1.6529,  -2.6882,\n",
      "         -10.2951,   1.4801,   0.4752]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 7.028722019410482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0709,  15.0761,  -2.6357,  -1.9035,  13.0204,  -2.0174,  -2.8008,\n",
      "           2.9392, -17.3157,  -2.9068]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 15.076058930073666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0299,  3.7069, -1.1389, -4.6889,  9.5186, -1.0821, -1.0733, -0.4455,\n",
      "         -4.0221, -0.0170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 9.51860856370886\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5402,   8.4927,  -1.9934,   0.2883,  17.2660,  -1.4635,  -2.2709,\n",
      "         -13.5698,  -1.7903,  -1.3905]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 17.26595499265443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4969,  9.5326, -1.7184, -2.0694,  9.8035, -1.6157, -2.0974, -6.3809,\n",
      "         -4.2952,  0.1969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 9.803507034728508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6530,   8.9246,  -1.7946, -14.7326,  23.4901,  -1.9389,  -2.2670,\n",
      "           4.5165,  -9.3742,  -5.3105]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 23.49009682181148\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1932,  3.8407, -1.3333, -3.7941, 12.2363, -1.2366, -1.2329, -0.8466,\n",
      "         -5.4475, -1.0230]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 12.236306899307905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2732,  11.4433,  -2.6965,  -0.2247,  16.0921,  -1.9546,  -3.1183,\n",
      "          -5.1015, -11.2384,  -1.1669]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 16.092059070252798\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8178,  3.9860, -0.9327, -1.9414,  8.7445, -0.7724, -1.1431,  0.1265,\n",
      "         -5.0097, -2.2065]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 8.744464638926889\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4928,   9.8618,  -3.4017,   1.7576,  23.0253,  -2.3200,  -3.4091,\n",
      "         -13.2930,  -8.1221,  -0.0838]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 23.025305585501634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5683,  5.9923, -1.6860, -9.4790, 23.2630, -1.6766, -2.0418, -2.4297,\n",
      "         -3.0386, -7.1479]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 23.26297638349154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5134, 11.7518, -2.9840,  9.3832,  9.5443, -2.4643, -3.7028, -8.5002,\n",
      "         -7.4063, -2.6167]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 11.751791261050313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1564,   6.7492,  -1.7312,   1.9406,   6.4345,  -1.3724,  -1.8461,\n",
      "         -10.1367,   1.9427,  -0.4664]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 6.749169018216226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9958,  8.7384, -2.2874, -9.3446, 29.4572, -1.9277, -2.4925, -5.6067,\n",
      "         -7.0918, -6.7691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 29.4572356148299\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2935,  11.6329,  -2.0032,  -9.5227,  18.5913,  -1.4927,  -2.0825,\n",
      "         -12.9892,  -0.7752,   1.0678]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 18.591329076232615\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9535,  12.1913,  -2.2907,  -3.6594,  15.0840,  -1.7283,  -2.6084,\n",
      "           2.4767, -16.7950,  -0.9531]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 15.08404604054985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1334,   3.9792,  -2.6006,   5.9347,   8.4891,  -2.1296,  -3.0556,\n",
      "         -10.5689,   0.4162,   2.1337]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 8.48912766210163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4411, 10.9596, -1.6701, -7.0173, 14.9596, -1.3396, -1.9476, -6.4077,\n",
      "         -6.9682,  1.3416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 14.959624944041309\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4397,   8.7257,  -1.5537,  -2.4632,  16.3109,  -1.3445,  -1.5948,\n",
      "         -12.4441,   0.7703,  -4.4851]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 16.310935535438993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5632,   6.6295,  -1.6169, -10.9306,  20.1468,  -1.7990,  -1.9862,\n",
      "           1.2226,  -6.5738,  -3.7932]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 20.14681910503909\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6413, 12.8813, -1.7870,  1.3605,  4.4175, -1.5139, -1.9848, -7.5385,\n",
      "         -7.5750,  3.9253]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.881275564885653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1361,  10.1323,  -2.4031,  -4.2407,  19.7161,  -1.9401,  -2.5217,\n",
      "         -16.7361,  -4.6397,   4.7546]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 19.716061244592794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9801,  5.4445, -1.1158, -2.7829, 10.3670, -0.8456, -1.3787, -0.0802,\n",
      "         -6.1803, -2.4833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 10.367044090301423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6250,   8.8183,  -1.8057,  -7.4695,  24.5816,  -1.6701,  -2.0865,\n",
      "          -5.9647, -13.7063,   0.7061]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 24.581620080597567\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1206,  3.3468, -1.4261, -8.8829, 12.5541, -1.2275, -1.4791, -1.5592,\n",
      "          1.5109, -1.3041]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 12.5540813554566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3360,   6.2455,  -1.6359,   1.7064,   8.3601,  -1.1564,  -1.7441,\n",
      "         -10.4068,  -0.0311,   0.4989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 8.360090531440981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8291,  4.0625, -0.9790, -0.7596,  8.0750, -0.8481, -1.1428, -0.4799,\n",
      "         -4.8798, -2.1951]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 8.075022875268058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4035,  14.7089,  -3.1339,  -0.3140,  20.1004,  -2.1374,  -3.5572,\n",
      "         -15.9452,  -6.2659,   0.3961]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 20.1003731814104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3617,   6.0806,  -1.5030,  -4.1587,  13.6509,  -1.3663,  -1.5721,\n",
      "         -12.4258,   1.3271,   1.2222]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 13.650886329039231\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8168,   7.7979,  -3.3010,  12.0925,   8.8459,  -3.0309,  -4.0758,\n",
      "         -12.5253,  -2.5001,  -0.3222]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.092519595275157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0122,  4.0586, -1.2860,  1.1841,  6.7783, -0.9711, -1.4047, -3.7078,\n",
      "         -2.8367, -1.0973]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 6.778294590948159\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7540,  9.7302, -1.9655, -5.7401, 22.8070, -1.7316, -2.2117, -5.6367,\n",
      "         -6.7792, -6.3378]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 22.80695736959142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7826,  5.8379, -1.9482, -8.0680, 17.9975, -1.9052, -2.2846, -1.2494,\n",
      "         -4.2430, -2.7501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 17.997482531125527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4031,   9.2720,  -1.4389,  -7.7568,  13.0979,  -1.3338,  -1.8917,\n",
      "           0.2773, -10.1506,   0.7036]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 13.097904973475202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2935,   8.6934,  -1.4245,  -2.0807,   8.4105,  -1.2836,  -1.8285,\n",
      "         -16.9072,   2.3481,   5.4071]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  9\n",
      "activation[1] = 8.693355227417333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0185,  11.6168,  -2.1510,  -5.0466,  25.5731,  -1.8210,  -2.2802,\n",
      "          -5.0121, -10.6994,  -7.9249]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 25.573081847625385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3512,   7.9864,  -1.5767,  -2.0288,  14.1197,  -1.3355,  -1.6558,\n",
      "         -10.2563,   0.1316,  -3.4266]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 14.119660628794957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4292,  18.5755,  -3.3011,  -1.7904,  19.7385,  -2.2126,  -3.7949,\n",
      "         -14.7451,  -7.9078,  -0.4208]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.738534831473622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7951,   8.0101,  -2.1397,  -3.2914,  13.3534,  -2.1630,  -2.7060,\n",
      "         -12.9844,   1.3185,   2.4709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 13.353403584887928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6312,  10.8534,  -2.1926,  -6.4646,  17.4286,  -1.5343,  -2.3455,\n",
      "          -7.6288, -11.5481,   5.0105]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 17.428591887650512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1161,   7.8984,  -2.5359,  10.5258,  11.6423,  -2.2040,  -2.7897,\n",
      "         -13.6742,  -2.6786,  -2.6437]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 11.642295206297526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0224,   5.2325,  -1.3998,  -2.6411,  18.2774,  -0.9196,  -1.4513,\n",
      "         -11.0282,  -0.7675,  -3.1504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 18.27739196955601\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7253,  3.4202, -0.7027, -7.9319,  7.7553, -0.6404, -1.1450, -3.1765,\n",
      "          3.9180, -0.4019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 7.755288695663581\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2856,  18.2303,  -2.9770,  -0.5569,  16.4269,  -2.0046,  -3.1244,\n",
      "          -8.9395, -14.9077,   1.7026]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 18.23034054625489\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3130,   8.0488,  -2.9237,   8.6604,  19.6345,  -2.1015,  -3.1010,\n",
      "         -20.6779,  -3.4710,   0.2774]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.63445657447706\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3800,   5.0743,  -1.7039, -12.1009,  21.0597,  -1.5817,  -1.8222,\n",
      "           1.2523,  -6.5154,  -2.4845]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 21.05974940619922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2461,  3.9520, -1.6553, -7.0959, 11.6710, -1.3750, -1.6563, -9.7858,\n",
      "          9.1629, -1.0245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 11.670960042831002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7040,  14.7688,  -2.8610,   0.9730,  16.7244,  -2.3458,  -3.1949,\n",
      "          -6.0030, -14.1648,  -1.3615]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 16.72441426040873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4133,  7.2724, -1.5424, -2.4289, 10.4502, -1.3412, -1.6722, -5.1289,\n",
      "         -4.3194, -0.1612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 10.450239518764956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9166,   5.6752,  -2.2868, -11.1443,  24.4586,  -2.1652,  -2.4398,\n",
      "          -5.7261,  -1.7331,  -2.8195]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 24.45862658216964\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3445,  15.7820,  -3.1804,   0.2784,  20.3769,  -2.3575,  -3.4344,\n",
      "         -17.6873,  -4.3626,  -2.2033]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 20.376886655903146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9185,   8.3332,  -2.2966, -11.6502,  20.4428,  -2.2090,  -2.5077,\n",
      "          -2.4242, -11.0354,   4.5662]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 20.442788648834274\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3979,   8.8589,  -1.5619,  -9.1048,  15.8937,  -1.2077,  -1.7293,\n",
      "         -15.9278,   1.4222,   4.9966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 15.893724191811543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0652,   9.2705,  -2.3145,  -9.1583,  27.6787,  -1.9849,  -2.4911,\n",
      "          -8.3331, -10.6084,  -0.0526]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 27.678694695346998\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5877,   5.6441,  -2.2503,  -1.8873,  16.5515,  -1.6687,  -2.5995,\n",
      "         -11.4835,   3.0125,  -2.9769]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 16.551459468024234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4118,  17.0571,  -3.5456,   0.1189,  22.3050,  -2.3635,  -3.7321,\n",
      "         -11.9847, -11.2821,  -2.3606]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 22.305030711010613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4926,   6.2025,  -1.4275,  -0.7600,  13.3830,  -1.3945,  -1.7394,\n",
      "         -10.9794,   0.8881,  -2.5988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 13.383042147408347\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1297,  12.5305,  -2.4377,  -6.3766,  30.7059,  -2.1135,  -2.5774,\n",
      "          -6.6377, -10.7316,  -9.7386]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 30.70588602030076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7771,  11.1079,  -2.5223,  -3.8925,  19.5034,  -2.1938,  -2.8302,\n",
      "         -21.9032,   6.3824,  -0.0425]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.503448007851254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5998,  7.8119, -1.6959, -6.0570, 20.2864, -1.5738, -1.8759, -9.4259,\n",
      "         -4.1577, -1.7096]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 20.286350567289176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7646,  11.7171,  -3.4181,  11.9447,  10.5075,  -2.7143,  -3.9861,\n",
      "         -12.7502,  -6.3127,  -2.0161]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.944725412581505\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6061,  6.7686, -1.7484, -0.9632, 15.9621, -1.5528, -1.9567, -9.4710,\n",
      "         -4.8527, -0.8579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 15.962066208831423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3612,   6.1456,  -1.5531,   5.4054,  10.9076,  -1.5217,  -1.6512,\n",
      "         -17.7352,   0.3059,   1.1691]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 10.907622351707342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3175,   6.3338,  -1.4435, -10.9805,  22.1639,  -1.2801,  -1.6260,\n",
      "           2.8514,  -8.0319,  -6.5378]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 22.163925440968306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4672,  24.4178,  -2.7070,  -8.8917,  19.9128,  -2.0482,  -3.0958,\n",
      "           0.0475, -24.0984,  -1.5818]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 24.417842934060157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0039,  12.6637,  -2.6672,  -2.3647,  19.6135,  -1.8470,  -3.1068,\n",
      "         -12.3533,  -4.5082,  -2.0859]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.613536604951825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1026,  4.6083, -1.1273, -7.5026, 10.2342, -1.1036, -1.4938, -6.2957,\n",
      "          1.4145,  2.2854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 10.234170391007911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5638,   8.8504,  -1.8472,  -4.3615,  15.3636,  -1.4785,  -2.1217,\n",
      "           1.0358, -14.2552,   0.1617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 15.363586682813242\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1611,  4.2041, -1.4408,  1.0527,  7.5933, -1.1491, -1.4753, -2.8250,\n",
      "         -3.7585, -1.5894]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 7.593269748000281\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4750,  14.0521,  -2.9852,  -5.6556,  19.0826,  -2.2505,  -3.3079,\n",
      "          -3.4278, -16.6357,   3.0926]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 19.082554374537203\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3457,  14.2127,  -1.6490,  -4.2906,  14.8201,  -1.3484,  -1.8887,\n",
      "          -6.2450, -12.0922,  -0.2271]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 14.820075163167818\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7296,  12.3173,  -2.0328,  -5.2776,  16.9525,  -1.5241,  -2.4409,\n",
      "           0.2327, -13.8334,  -2.5277]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 16.952521553605255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3138,  6.5810, -1.4504, -9.7125, 19.5809, -1.4910, -1.6571,  1.1758,\n",
      "         -8.7618, -3.3407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 19.580940519949777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0968,   7.0878,  -2.4291,  -6.4220,  24.6580,  -2.1048,  -2.5789,\n",
      "         -12.6454,  -0.9168,  -2.4952]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 24.658032481655837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5597, 13.8777, -1.1888, -3.4809, 11.2597, -1.2147, -1.9065, -7.2463,\n",
      "         -4.8176, -3.5817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 13.87767244810525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6652,  13.7509,  -3.1275,  -4.8313,  20.4823,  -2.6490,  -3.4461,\n",
      "         -12.3986,  -9.3489,   3.5293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 20.48234489069645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2171,  11.0752,  -2.0221,  -0.1809,  18.1713,  -2.0171,  -2.3711,\n",
      "         -10.9154,  -5.3928,  -4.3981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 18.171259570583775\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0064,   9.3620,  -2.4424,  -0.7969,  16.9728,  -2.0799,  -2.6350,\n",
      "         -12.0207,  -6.6590,   1.7047]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 16.972787257532374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4002,  5.7008, -1.3108, -6.2832, 12.0164, -1.4540, -1.5825, -0.9834,\n",
      "         -3.8297, -1.0818]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 12.016379774019516\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3383,  2.7714, -1.7376, -8.4103, 16.4285, -1.6429, -1.7290, -7.9711,\n",
      "          5.5945, -1.2998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 16.42852014982032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6675,  4.2587, -0.8209, -2.0828,  7.5026, -0.7170, -1.0052, -8.8799,\n",
      "          4.0319, -1.0459]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 7.502623663076045\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0644,   8.0443,  -1.2694,  -3.3965,  12.9875,  -1.0324,  -1.6419,\n",
      "          -0.1252, -11.5920,  -0.6670]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 12.98752742105594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2899,   7.5886,  -2.9373,   2.3347,  19.2663,  -2.2124,  -3.1609,\n",
      "         -16.7343,  -0.4960,   0.8345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 19.26633329064002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5308,  7.8952, -1.6749, -2.0943, 12.3973, -1.4881, -1.8979, -8.4215,\n",
      "         -3.2207,  0.8673]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 12.397345993778114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3190,  10.8168,  -1.9586,   3.3170,  19.9140,  -1.3038,  -2.0767,\n",
      "         -16.0302,  -7.3219,  -2.3782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 19.913976600401867\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9965,   7.9373,  -2.4023,   1.0603,  13.4288,  -1.7661,  -2.5504,\n",
      "          -2.2577, -11.8706,   0.2726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 13.428843346379665\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3418,  7.1672, -1.3989, -2.6371, 10.6987, -1.2916, -1.5923, -8.2736,\n",
      "         -2.2877,  1.5100]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 10.698705217739871\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9690,   9.7345,  -3.2107,  12.6813,  10.2314,  -2.7980,  -3.8772,\n",
      "         -10.4690,  -8.3067,  -1.0658]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.681307097157234\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8138,   8.9811,  -3.2745,  -0.3818,  24.9513,  -2.8437,  -3.4797,\n",
      "         -14.3412,  -1.5310,  -4.9013]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 24.951339031197776\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0457,   9.6129,  -2.5966,  -3.0393,  16.2101,  -2.1041,  -2.5980,\n",
      "         -14.7940,  -4.3438,   5.4866]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 16.210117022960745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5628,  10.4221,  -2.0533,  -0.9662,  21.5686,  -1.6707,  -2.4188,\n",
      "         -17.9759,  -0.6533,  -2.9660]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 21.5686416679968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2916,  8.4440, -1.1725, -6.6256,  9.7448, -1.1023, -1.7184,  1.1228,\n",
      "         -9.3301,  1.4375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 9.74482608253155\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5715,  18.4014,  -2.7776, -10.2846,  24.3579,  -2.3627,  -3.1350,\n",
      "         -17.0557,  -5.3826,   0.9940]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 24.357946151921507\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6418, 12.6381, -1.9045, -5.7259, 11.6892, -1.4958, -2.1334, -4.6700,\n",
      "         -9.8357,  2.9391]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 12.638111786356218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1945,  2.0867, -1.3961, -4.9733, 12.4739, -1.3961, -1.5619, -5.0902,\n",
      "          2.2439, -0.8708]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 12.473866066506957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6204,  11.7637,  -1.9759,  -8.4019,  17.8240,  -1.5965,  -2.1201,\n",
      "          -6.5481, -12.2587,   4.6094]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  8\n",
      "activation[4] = 17.824042661825967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8281,  18.3505,  -2.3897, -10.8980,  18.4546,  -1.6635,  -2.1476,\n",
      "         -12.0617, -11.3144,   5.7531]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 18.454560806828518\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0570,   9.5584,  -2.5058,   1.2343,  15.7026,  -1.8310,  -2.6045,\n",
      "           0.0505, -15.7201,  -1.9974]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 15.702636259789678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5712, 10.6381, -1.4596, -3.6062, 11.6409, -1.4152, -1.9140, -9.8442,\n",
      "         -0.3981, -1.7500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 11.640853656474604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3611,   8.9759,  -1.5577, -11.9434,  25.4734,  -1.3868,  -1.6363,\n",
      "          -3.6564,  -9.6038,  -3.3440]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 25.473403668929457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5677,   1.9983,  -2.1383,  -0.7578,  14.2991,  -2.0240,  -2.3518,\n",
      "         -17.0234,   6.3233,   3.3779]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 14.299074706460477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5110,  14.7015,  -3.3408,  -1.0848,  16.7958,  -2.6143,  -3.7925,\n",
      "         -12.3608, -13.5725,   7.5248]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 16.79579319843332\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8783,  2.9981, -1.1724,  0.4307,  7.1597, -0.9012, -1.2251, -2.9122,\n",
      "         -2.7275, -1.4000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 7.159671242752259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1129,  13.2702,  -2.6467,  -0.9891,  13.6703,  -2.2621,  -3.1045,\n",
      "         -10.8861,  -6.7361,   1.8914]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 13.670319068645611\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8992,  8.2555, -0.8842, -2.6746,  7.0569, -0.9489, -1.2863, -3.6390,\n",
      "         -5.9494,  0.4822]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 8.25552879801335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6060,  10.4824,  -3.5890,   4.6638,  22.3862,  -2.5567,  -3.6556,\n",
      "         -16.6386,  -7.1401,   0.6742]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  0\n",
      "activation[4] = 22.386225312076768\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3875,  7.2675, -1.4263, -0.2047, 12.1294, -1.1160, -1.4499, -3.3075,\n",
      "         -8.6971, -2.2565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 12.12940070073926\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2666,  11.9158,  -1.5075, -15.4078,  23.3483,  -1.3877,  -1.8045,\n",
      "          -2.5088, -11.8944,   0.2896]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 23.34830431155722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8147,  5.9021, -1.0946, -3.0966,  8.3156, -0.9645, -1.1439, -8.6931,\n",
      "          1.7958,  0.0751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 8.315606288830455\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9725,  12.4916,  -2.6312,  -6.7639,  18.3829,  -1.7878,  -3.0416,\n",
      "          -8.4974, -10.6036,   4.3500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  2\n",
      "activation[4] = 18.38286256140245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7740,  20.0115,  -3.3463,  -4.6612,  25.5107,  -2.9451,  -3.9728,\n",
      "         -20.6326,  -5.5999,  -0.9081]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  3\n",
      "activation[4] = 25.510662984983682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9498,  12.5202,  -2.0909,  -8.8931,  26.7217,  -1.8355,  -2.5164,\n",
      "          -2.6681, -12.5912,  -6.8612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 26.721654741009363\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7668,  7.4155, -1.8184, -0.2334, 15.3147, -1.5231, -1.8972, -9.0613,\n",
      "         -5.8272, -0.7851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 15.314713541796603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9920,  6.2758, -2.1867, -8.8826, 20.3404, -2.2388, -2.5472, -0.8638,\n",
      "         -4.2820, -4.0686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 20.34043476311856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2843,  4.9548, -1.4901,  2.7088,  4.9174, -1.2133, -1.5503, -6.0849,\n",
      "         -1.0539, -0.5328]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 4.954753636726308\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.8674,  9.9150, -3.1701,  7.9089,  9.2926, -2.7819, -3.7890, -9.1624,\n",
      "         -5.5183,  0.1582]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 9.91495419476613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3675,   8.2901,  -1.7172,   3.8185,   6.7787,  -1.1680,  -1.8683,\n",
      "         -13.2380,   1.1809,  -0.8927]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 8.290065341719362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2322,  10.4828,  -2.2666,  -4.7946,  17.5077,  -2.0021,  -2.8217,\n",
      "           0.2342, -12.4898,  -2.1691]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  1\n",
      "activation[4] = 17.507735762698847\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0410,   6.4885,  -1.4194,  -9.5616,  16.7069,  -1.1079,  -1.4553,\n",
      "         -15.3059,   4.6518,   2.3983]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 16.706850133613827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1985,  12.1820,  -3.7155,  13.4584,  10.2926,  -3.1246,  -4.2921,\n",
      "         -15.3601,  -6.2920,  -0.0459]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 13.458406830423032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4149,  2.8109, -1.6120, -6.0875, 14.0733, -1.6430, -1.9023, -6.2164,\n",
      "          4.7070, -2.3048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  7\n",
      "activation[4] = 14.073338264901356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2150,   4.1724,  -1.6835,   0.7689,  16.6599,  -1.1023,  -1.8824,\n",
      "         -11.1109,   0.4028,  -3.2467]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 16.659943806360246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3100,  10.2166,  -1.5388,  -9.0129,  12.5121,  -1.2426,  -1.9371,\n",
      "           5.2868, -12.6622,  -0.0592]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  5\n",
      "activation[4] = 12.512114328125506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2830, 12.4787, -2.5862, -1.7849, 13.7850, -2.0043, -2.8993, -8.3170,\n",
      "         -7.8982,  1.9577]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  6\n",
      "activation[4] = 13.784997304786938\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [13]: loss = 14.129, accuracy = 15.23\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3058, -0.0329, -0.4580,  0.0823, -0.0291,  0.4340,  0.3818,\n",
      "        -0.5433, -0.0307], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3058, -0.0329, -0.4580,  0.0823, -0.0291,  0.4340,  0.3818,\n",
      "        -0.5433, -0.0307], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -1.5579,   6.0216,  -2.1039,  -0.7518,   0.0347,  -1.6176,   9.8321,\n",
      "         -17.1048,   1.6857,   6.4719]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 9.832087939765131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2573,  15.6742,  -2.6885,  -4.8336,  -4.0520,  -2.2810,  21.0903,\n",
      "          -7.1936, -17.4234,   4.3287]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 21.09025587443891\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9391,   3.8244,  -0.9236,  -5.6755,   1.9577,  -1.1310,  16.5460,\n",
      "         -12.3616,   3.0437,  -3.1795]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 16.545965106462898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4568,  13.9057,  -2.7800, -10.2466,  -0.2715,  -2.1261,  24.0123,\n",
      "           2.4095, -22.6836,  -0.7210]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 24.01232493831075\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9748,  4.1741, -2.0720, -0.7630,  0.6000, -2.1554, 11.0439, -9.8177,\n",
      "         -5.1590,  5.2237]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 11.043894733912405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9347,  12.3678,  -2.5731,  -2.1856,  -2.8224,  -2.0485,  21.0994,\n",
      "         -11.6433, -11.5368,   1.8929]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 21.099372675399145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2514,   5.5885,  -1.0040,  -1.7602,   2.2450,  -1.1326,  11.0618,\n",
      "         -10.6694,  -0.1634,  -2.0444]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 11.061753932935169\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3432,   3.8750,  -1.7706,   0.7667, -14.6117,  -1.2388,  30.4865,\n",
      "          -6.6645,  -7.9058,  -0.1702]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 30.486472659168296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1704,  10.8209,  -2.3265,  -0.4339,   2.2371,  -2.1704,  14.3420,\n",
      "         -12.5234,  -4.2635,  -3.4295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 14.341994585717833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9538,   9.3492,  -2.7293,  -1.2728,   1.6247,  -1.7864,  20.9498,\n",
      "         -14.6492,  -7.4990,  -0.0877]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 20.949848226526797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4535,  11.2801,  -3.3905,  -6.8010,   0.5112,  -2.5804,  24.8258,\n",
      "         -25.6960,  -4.5625,   8.9773]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 24.825830936284564\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6141,   9.7796,  -1.9315,  -5.8085,   0.6037,  -1.6375,  16.3341,\n",
      "          -5.6218, -12.5728,   2.9894]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 16.33411785087937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5474,   8.0438,  -1.9779, -11.2127,   4.0550,  -1.3404,  21.8860,\n",
      "           1.4896, -12.2501,  -6.8010]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 21.88603949638662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9366,  15.9090,  -2.3077,  -2.0544,  -8.1756,  -1.8132,  22.3965,\n",
      "          -7.6508, -15.3323,   1.6375]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 22.396478832803272\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8375,   6.7013,  -2.1978,  -3.9101, -11.4538,  -1.8977,  27.9894,\n",
      "         -13.6884,  -1.1681,   2.3252]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 27.989432854252346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6853,   1.2550,  -1.8999, -13.0766,   6.5486,  -1.8979,  18.1208,\n",
      "          -1.0193,  -4.4231,  -1.9469]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 18.12078878463885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6294,  2.1702, -1.7576, -2.5167, -5.7802, -1.4314, 18.8634,  0.4810,\n",
      "         -7.4867, -1.2803]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 18.863370887380555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4261,   4.2312,  -1.3739,  -7.2666,  -6.2986,  -1.2979,  20.8354,\n",
      "           1.5949, -10.3852,   1.0464]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 20.835367073789556\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0017,   7.2772,  -1.3282, -20.3698,   1.2469,  -0.7717,  18.9805,\n",
      "          -4.6531,  -3.9511,   5.1250]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 18.980451442658126\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.6342,   7.4860,  -4.1777,  15.3946,  -5.3216,  -3.4584,  20.5752,\n",
      "         -12.6542, -12.5036,  -1.7247]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 20.57521449496522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5670,  4.7913, -1.6704,  0.7581,  1.9890, -1.4587, 11.3903, -7.9518,\n",
      "         -2.1880, -3.8386]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 11.390311868980163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2183,  -0.5491,  -1.6606, -12.3100,   3.9723,  -1.5404,  15.0749,\n",
      "          -1.0038,  -3.9277,   2.7771]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.074907775308324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1703,  4.2365, -0.9987, -6.4514,  1.9251, -0.9141, 15.1630, -2.3174,\n",
      "         -6.6745, -2.8654]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 15.162993677194905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7253,  4.9534, -1.9497, -8.0066,  9.2479, -1.5469, 18.2544, -2.5818,\n",
      "         -9.3149, -7.1465]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 18.254429763033773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6592,   5.0450,  -2.0624,  -0.4414,   6.8038,  -1.5117,  11.6130,\n",
      "         -16.0293,   1.9865,  -3.0284]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 11.612972420341244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5721,  5.5062, -2.0209, -5.9325, -1.9586, -1.7578, 22.1598, -9.8102,\n",
      "         -6.4461,  1.7928]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 22.1597628449754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0714,  8.5649, -2.8091,  0.0931,  5.0444, -1.9512, 11.0154, -8.8481,\n",
      "         -6.8516, -2.0670]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 11.015411274332493\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5900,   4.1910,  -1.6343,  -7.0519,   4.0495,  -1.5555,  18.3321,\n",
      "           0.8264, -11.6971,  -4.0661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 18.33213682076622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1754,  11.4114,  -1.6495, -13.4302,  -1.2704,  -1.0635,  19.1867,\n",
      "           3.6972, -16.4598,   1.1951]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 19.186726808937717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9792,  9.0694, -2.4771, -4.0429, -6.9716, -2.0241, 24.4196, -7.9658,\n",
      "         -9.8606,  1.7455]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 24.419600217046376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5202,   4.8457,  -1.9061,   5.5562,  -6.0008,  -1.5419,  16.0261,\n",
      "         -10.1494,  -2.6219,  -3.1204]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.026130456246808\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6648,  2.9545, -1.6949, -2.9742,  8.0269, -1.4262, 14.7560, -5.9060,\n",
      "         -9.2302, -3.0476]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 14.756014940518742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8606,   5.1327,  -1.8512,  -2.3169,  -2.4676,  -1.8160,  21.0915,\n",
      "         -10.8307,  -2.9768,  -1.8733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 21.091502879533653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4262,   6.8308,  -1.6615,  -6.0846,   2.5329,  -1.3864,  16.5265,\n",
      "          -0.1304, -12.2167,  -2.8142]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 16.526484509546755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7955,  10.0162,  -3.4285,  -3.4774,  -2.2809,  -2.6940,  29.7521,\n",
      "         -11.0655, -13.7074,   1.2789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 29.75209208274828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0778,   5.8294,  -2.5734,  -1.7057, -19.5828,  -1.9679,  37.9981,\n",
      "          -5.6716, -12.6971,   2.4627]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 37.9980605790438\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8901,   2.7149,  -1.9500,  -0.6081, -13.5057,  -1.5729,  29.0923,\n",
      "          -5.5654,  -6.5308,   0.4084]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 29.09234571023424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3062,   7.4461,  -2.7206,  -8.9753,  -6.2943,  -2.0437,  30.2151,\n",
      "          -8.5431, -13.0960,   6.0039]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 30.215082965132282\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0102,   3.1977,  -2.2786,   2.6585, -15.7062,  -1.6887,  32.2408,\n",
      "          -5.9441,  -9.4272,  -0.1718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 32.240791871645655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4397,  11.2454,  -2.8859,   1.3318,  -8.9228,  -2.1723,  25.3780,\n",
      "          -8.3616, -11.2333,  -1.9873]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 25.378027444136695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4126,  0.5273, -1.4553, -3.4660, -3.2624, -1.5411, 13.9647, -4.9032,\n",
      "         -0.2552,  1.4774]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 13.964738355761332\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9511,  8.2656, -2.8241, -1.5229, -4.3929, -1.9044, 24.4319, -8.8165,\n",
      "         -8.6310, -1.1965]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 24.431930603066853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4169,  10.1034,  -1.5083,  -8.6307,  -0.1582,  -1.4388,  22.1115,\n",
      "         -13.6161,  -2.8484,  -1.0085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 22.11147168607478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7206,   3.0893,  -1.8974, -12.7783,  10.6436,  -1.6303,  21.0068,\n",
      "         -10.9089,  -5.3113,  -0.0879]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 21.006750340642892\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9937, -0.5043, -1.3035, -5.3927,  4.0627, -1.1062,  9.8435, -1.8468,\n",
      "         -0.8937, -1.9900]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 9.843497271822152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6129,   5.9464,  -1.6700,  -8.0055,  -7.7039,  -1.4888,  22.1378,\n",
      "           1.6195, -14.0403,   4.1234]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 22.137844137639654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3200,   3.1421,  -2.8718,   2.3776,  -5.9292,  -2.2782,  21.3154,\n",
      "         -19.5854,   3.8802,   2.4786]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 21.315407508537472\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2115,   6.5248,  -1.3316,  -7.9361, -10.1631,  -1.1185,  20.2439,\n",
      "           0.7536, -11.7410,   5.4886]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 20.243924929569843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7455,   5.2950,  -2.2975,   8.5035,  -0.9029,  -1.9502,   6.9172,\n",
      "         -24.9787,   5.2644,   6.0504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 8.503474924138755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2542,   0.9423,  -2.7095,   8.1527,  -2.5138,  -2.3009,  14.3157,\n",
      "         -18.9806,   1.0616,   5.5053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 14.315683758826122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1712,   0.9078,  -3.0016,  11.0016,   0.9498,  -2.1962,  15.4352,\n",
      "         -20.9222,  -1.7782,   2.7874]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 15.435212551026527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5748,  12.8210,  -1.7552,  -6.7349,  -5.3639,  -1.4138,  16.8506,\n",
      "           0.8730, -16.0754,   1.5118]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 16.85064774479876\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9027,  1.7404, -0.8827, -2.2845, -3.8486, -0.7066, 12.0709,  0.6689,\n",
      "         -5.3538, -0.5447]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.070861114871777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2316,  8.7276, -1.4522, -6.6882,  2.7032, -0.9522, 16.5221, -8.7750,\n",
      "         -6.0405, -2.3609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 16.52214273078676\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0461,  12.2824,  -1.1810, -15.5238,   1.2976,  -0.9220,  16.9723,\n",
      "          -1.1867, -10.4007,   0.8863]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 16.972286860330616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7426,   3.4488,  -3.3736,   8.8049,  -2.0789,  -3.1635,  15.1093,\n",
      "         -16.0308,  -1.1182,   0.9399]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 15.109336407633569\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9801,   3.7297,  -2.4724,   3.5036,  -0.8120,  -2.2875,  18.9870,\n",
      "         -18.1972,  -2.8482,   3.1951]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 18.98701291163921\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3936,  5.2484, -1.8049, -5.3525,  1.4970, -1.5531, 14.8327, -9.1051,\n",
      "         -1.9945, -0.3250]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 14.832667149169698\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5438,  5.5998, -2.3030,  1.9973, -6.1790, -1.5390, 16.4147, -5.7179,\n",
      "         -6.7116,  1.1036]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.414664622407475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2621,   1.8003,  -1.5689,  -0.6033,  -8.2170,  -1.0546,  25.1757,\n",
      "         -10.2954,  -2.3462,  -0.2956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 25.175702092039614\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5281,  6.8460, -1.7578, -1.4961, -1.5296, -1.6574, 15.3741, -5.3447,\n",
      "         -5.4737, -3.4633]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 15.374127092671605\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3752,  3.2317, -1.6038, -2.3351,  2.1957, -1.4777, 15.3706, -9.8973,\n",
      "         -2.9991, -0.8163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 15.370608088418289\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3732,   9.9998,  -2.6910,  -7.3935,  -3.5295,  -2.3856,  26.0134,\n",
      "         -12.9124,  -7.1786,   1.7150]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 26.013377349016032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1911,  4.7931, -1.5821, -5.4335, -2.9336, -1.0766, 12.1688, -4.3920,\n",
      "         -5.2806,  6.0679]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 12.168820106682029\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8159,   8.1954,  -2.4190,   3.1934,   3.3975,  -1.6935,  14.8378,\n",
      "         -16.0832,  -7.0918,   0.3680]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 14.837827583827654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6034,  17.8787,  -1.7231,  -5.3404,  -0.8488,  -1.2501,  10.2161,\n",
      "           3.1337, -22.5086,   1.4854]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.878686585079546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6200,  2.2353, -1.7598, -1.6844, -7.0600, -1.4199, 20.5313, -1.3891,\n",
      "         -7.7126, -0.4832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 20.531279595776347\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9389,   4.0799,  -2.8438,   8.4556,  -7.8657,  -2.0065,  17.2773,\n",
      "         -15.0213,  -0.7993,   1.3399]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 17.277259337339537\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9172,   8.5544,  -2.6874,   1.7937,   4.3038,  -1.9041,  19.4887,\n",
      "         -24.9143,  -3.9499,   2.8218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 19.488656943470207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2111,   4.8109,  -3.8856,  13.9678,  -2.5256,  -3.2310,  14.4712,\n",
      "         -15.6559,  -4.5646,  -0.2263]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 14.47117037933563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3373,   8.4490,  -2.4502,  -5.6779,   3.3846,  -2.0806,  21.1974,\n",
      "         -12.4550,  -6.0715,  -2.3143]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 21.19744669350964\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8905,   2.9103,  -1.1097, -12.9638,  10.7008,  -1.0085,  13.5024,\n",
      "          -0.0305,  -7.5666,  -3.3895]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 13.50243479399605\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2778,   8.3672,  -2.7582,   6.0796,  -6.4560,  -2.0896,  18.5187,\n",
      "         -11.5730,  -7.4891,   0.1651]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 18.518740401429675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3125,  4.7725, -1.8850, -7.8155,  0.4022, -1.5711, 19.3783, -4.6132,\n",
      "         -6.1496, -1.0115]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 19.378345043295738\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5067,   5.3288,  -3.2269,   4.7019,  -2.8368,  -2.7450,  16.6862,\n",
      "         -14.6682,  -2.3494,   2.0281]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.68616401060513\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4789,   1.5505,  -1.9660,  -2.2878, -15.7042,  -1.4292,  34.4944,\n",
      "          -8.1680,  -6.4042,   2.1752]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 34.494415491758794\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6583,   3.5363,  -1.9231,   2.4629,  -3.8612,  -1.5678,  16.7048,\n",
      "         -14.1671,   2.2291,  -1.7719]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.704781226824288\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1769,   6.3197,  -1.5501, -15.3974,   3.1529,  -1.3633,  13.6600,\n",
      "           2.7494, -12.9438,   6.2271]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 13.660049136697609\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5073e+00,  4.1275e+00, -1.6584e+00, -4.6476e+00, -6.4340e+00,\n",
      "         -1.3931e+00,  2.0465e+01, -2.2749e-01, -9.2553e+00,  8.5601e-03]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 20.464999030973797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7184,   8.6292,  -1.6896,  -9.0294,  -4.1272,  -1.2991,  21.9158,\n",
      "          -2.8501, -13.0966,   2.8047]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 21.91582530352319\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6449,  2.1467, -1.7332, -2.1918,  0.4931, -1.7249, 15.4415, -3.5245,\n",
      "         -5.3230, -2.4589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.441470053063096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1456,  5.1556, -1.4074, -5.3044, -0.5715, -1.0799, 12.4933, -3.1887,\n",
      "         -7.6637,  3.7243]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 12.493291308363009\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3921,   6.4180,  -2.1997,   2.6330,   3.3928,  -1.5662,   5.6465,\n",
      "         -20.6307,   6.1800,   2.3125]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 6.4180384035934805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5594,  14.7893,  -1.7237,  -8.6843,  -3.8311,  -1.2603,  14.1212,\n",
      "           1.7232, -18.4573,   4.1484]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.789318413551696\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4461,  1.6963, -1.6160, -1.9277, -3.3057, -1.2760, 15.6339,  1.3914,\n",
      "         -7.6181, -2.0431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 15.633948540237675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1847,   7.4511,  -2.7531,   6.3305,  -7.8470,  -2.3950,  20.6111,\n",
      "         -18.8638,  -0.9042,   1.8085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 20.61110747931863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4409,   4.2507,  -1.4239,   0.3554,  -1.4014,  -1.3747,  13.1488,\n",
      "         -13.7739,   3.5367,  -1.5538]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 13.148785530866633\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6999,   1.2835,  -1.9190,  -7.3331,   2.6305,  -1.9955,  12.5857,\n",
      "         -13.1568,   0.4780,   8.6595]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 12.585715872201241\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9603,   3.9653,  -1.2078,   0.9632,   5.8011,  -1.0729,  10.5575,\n",
      "         -17.2475,   0.3123,  -0.6256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 10.557537048812712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6992,   1.4330,  -0.8276, -12.1538,   9.1738,  -0.8722,  10.9168,\n",
      "          -2.7380,  -4.7651,   0.5882]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 10.916771317685772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2779,  2.4872, -1.3267, -4.3902, -4.4045, -1.0832, 17.5243,  1.7057,\n",
      "         -8.5800, -0.9179]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 17.524264651051542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8098,   5.0690,  -1.0450, -10.3539,   4.4747,  -0.9544,  14.9284,\n",
      "           0.5761,  -7.3094,  -3.9619]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 14.928443312015858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7711,   5.8968,  -2.2420,  -3.8025,  -0.0821,  -1.5910,  20.8267,\n",
      "         -13.8350,  -5.5057,   1.8755]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 20.826673927071877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2284,   1.3575,  -1.7285,  -4.5517, -13.0821,  -1.2649,  32.6648,\n",
      "          -5.6292,  -6.7417,   1.3086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 32.66484978538697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2004,   5.1096,  -3.4773,   7.0687, -12.3640,  -3.0821,  29.0639,\n",
      "         -14.0676,  -6.5324,   2.0192]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 29.063863781041096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2604,  -0.4483,  -1.4556, -15.4351,   3.1286,  -1.4934,  15.3674,\n",
      "           2.5689,  -3.3268,   2.3659]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.367356906786402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3316,   8.1231,  -2.8988,   4.9072,  -6.0559,  -2.1453,  16.2186,\n",
      "          -3.3102, -10.5120,  -1.1923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.218630902877287\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5644,  13.4649,  -2.7267,  -2.0067,  -4.8413,  -2.1204,  23.6012,\n",
      "          -4.0662, -18.9743,  -0.4970]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 23.60124860877656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0351,  4.7008, -1.0907, -9.2052,  1.2883, -1.0984, 13.0037, -8.2429,\n",
      "          3.7989, -1.2933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 13.003688236604201\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3543,   8.0128,  -1.5135,  -7.3504,  -5.6073,  -1.4257,  16.6057,\n",
      "           1.5308, -13.7248,   4.0898]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 16.6057457546442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1159,  4.1784, -1.1924, -7.7884,  7.0377, -1.2446,  9.4333,  1.7868,\n",
      "         -6.0933, -4.9643]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 9.433319654563208\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5082,   5.5851,  -2.2845,   1.9067,   0.4176,  -1.6271,  12.4363,\n",
      "         -22.1805,   5.1624,   3.6330]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 12.436270416527968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5099,  3.3724, -1.7457, -5.6273, -9.1079, -1.4795, 27.2609, -2.1213,\n",
      "         -9.9614,  0.7106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 27.260923234974378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8950,  4.7234, -0.9202, -6.9360, -6.2159, -0.8719, 14.9722,  1.2029,\n",
      "         -8.5291,  3.0956]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 14.97215294579528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9694,   1.3434,  -3.4476,  -0.5353,  -7.7858,  -2.8230,  33.6777,\n",
      "         -11.2221,  -4.3030,  -1.6906]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 33.677720115756124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3275,   3.1980,  -1.6300,   1.6264,  -1.5888,  -1.5754,  14.9580,\n",
      "         -18.6577,   3.9109,   1.0666]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 14.958032088292146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6581,   3.8692,  -2.2899,   3.7170,   3.9073,  -1.5951,  11.7381,\n",
      "         -16.4239,   0.2022,  -0.6486]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 11.738063190430427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0043,   3.1881,  -2.3756,   6.9119,  -4.8285,  -2.2327,  13.5665,\n",
      "         -15.2438,   1.9343,   0.6392]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 13.566451192579283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5616,  6.6750, -0.2241, -5.3289,  7.4277, -0.4992,  5.2000, -6.6296,\n",
      "         -0.9431, -4.0387]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 7.427700496269481\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1333,   6.6500,  -1.4714, -14.2509,   9.0632,  -1.1886,  14.8405,\n",
      "          -0.0923, -13.6154,   1.4685]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 14.840490686764927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9894,  11.1010,  -2.1357,  -0.3724,   1.1544,  -1.6324,  14.6822,\n",
      "          -1.6143, -15.6243,  -4.3723]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 14.682248860319255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8866,   3.4376,  -1.0129, -11.0178,   8.5998,  -0.8224,  10.0444,\n",
      "          -1.7083,  -5.9805,  -0.2815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 10.044442018072482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2343,  5.0104, -1.4107, -7.3449, -9.3938, -1.1357, 24.9942, -1.5154,\n",
      "         -9.3152,  1.2268]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 24.994177020208774\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5761,   4.9017,  -1.9403,  -0.0258,  -3.9654,  -1.4139,  19.2145,\n",
      "         -11.5121,  -1.1746,  -1.8520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 19.21454340650131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3588,  2.4085, -0.5353, -8.3537,  2.8044, -0.2144,  4.2763, -0.9482,\n",
      "          2.6126, -0.6929]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 4.276329208585545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6750,   6.6411,  -2.3647,  -0.8465,   6.1806,  -1.5911,  10.6752,\n",
      "         -15.4846,  -3.8938,   3.6605]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 10.675150553759\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2556,  11.7300,  -1.5819,  -9.4315,  -0.3164,  -1.4106,  20.5860,\n",
      "          -6.0828, -13.0732,   1.2143]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 20.585962719688975\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9495,   6.6260,  -2.5039,  -0.5029, -15.2609,  -1.8551,  35.6715,\n",
      "         -10.2362, -11.0234,   2.1221]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 35.671514408928054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9922,   8.7539,  -2.6658,  -4.9309,  -6.1925,  -2.0042,  25.4993,\n",
      "         -16.1252,  -1.8139,   1.2617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 25.49926936261583\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5950, -0.1415, -1.6580, -0.8795,  4.0942, -1.4036, 16.2359, -7.5567,\n",
      "         -6.2170, -0.6678]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 16.235941366456654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7199,  0.2804, -0.7893, -4.9874,  2.3944, -0.8214,  7.3737,  0.6712,\n",
      "          0.3402, -3.5510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 7.373661592924477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2616,  4.4549, -1.6247, -3.7140, -8.8194, -1.1564, 28.9927, -9.3735,\n",
      "         -6.1517,  0.3791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 28.9927244504054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2432,   4.1846,  -1.6017,  -2.5419,   1.6987,  -1.3864,  12.3053,\n",
      "         -12.4508,   2.5731,  -1.0658]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 12.305338211024374\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5326,   4.4906,  -1.9263,  -0.8180, -16.4808,  -1.3801,  31.8602,\n",
      "          -9.8034,  -5.5656,   2.1700]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 31.860235944966128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2592,   9.3919,  -2.8448,   4.8682,   5.4056,  -2.2448,  12.3624,\n",
      "         -10.2497,  -9.9176,  -4.2359]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 12.362385703541968\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6796,  3.9044, -0.8043, -7.9750,  4.3436, -0.7395, 12.0139, -0.3945,\n",
      "         -4.2700, -4.5790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 12.013881703970322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6158,  3.5485, -1.9082,  1.2490, -3.9699, -1.3908, 19.8817, -8.2305,\n",
      "         -2.9269, -3.2403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 19.881724516334227\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2823,   8.2220,  -1.4481,  -7.8885,  11.2888,  -1.2717,  10.9627,\n",
      "          -0.7070, -12.8661,  -5.2137]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 11.288793735395316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0762,  0.7403, -2.4509,  2.9683, -6.3327, -2.0179, 19.4930, -5.7586,\n",
      "         -3.9363, -1.3038]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 19.492989833293446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0947,   8.2582,  -1.2913,  -9.3497,   8.1830,  -1.2066,  13.0597,\n",
      "           0.5496, -12.8809,  -4.4218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 13.059708511316606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2960,  3.8831, -1.3162, -3.1502, -2.7301, -1.4053, 15.9632, -9.3720,\n",
      "         -0.9028,  0.5492]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 15.96319870847136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5014,  4.5871, -1.8043, -5.9067,  8.6620, -1.3901, 14.0832, -5.9935,\n",
      "         -5.9729, -4.5763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 14.083223478555308\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5948,  9.3542, -3.1973,  0.0972, -3.2138, -2.6207, 17.9957, -7.4848,\n",
      "         -8.8990,  0.8809]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 17.99568773683439\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7026,   3.6910,  -1.9746,  -1.3833,  -1.8832,  -1.6224,  21.8053,\n",
      "         -11.8758,  -1.4926,  -2.3874]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 21.805303989107014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5807,  2.6389, -1.8145,  5.6937, -5.7679, -1.5741, 14.2703, -7.7984,\n",
      "         -3.8979, -0.3275]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 14.270275119582589\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2650,   0.2406,  -1.5330, -12.7111,   6.1500,  -1.3926,  14.8982,\n",
      "           0.8225,  -4.8706,  -0.5548]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 14.898178653787362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1048,  1.2841, -1.4098,  1.0079, -3.0598, -1.0847, 11.6392, -2.3620,\n",
      "         -3.7321, -1.4775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.639164706492643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8306,  4.9524, -1.7585, -5.4630,  6.8731, -1.7673, 16.0365, -7.4563,\n",
      "         -5.2995, -4.1397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 16.036549073117605\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5434,   7.1149,  -1.7300,   0.3739,   2.9866,  -1.6638,   9.9525,\n",
      "         -10.2618,  -4.0036,  -1.1760]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 9.952494925444606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5650,   3.5951,  -3.3958,   3.9584,  -2.5378,  -2.6887,  20.8962,\n",
      "         -14.9346,  -4.4772,   2.2071]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 20.896175289936306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3376,   5.2514,  -1.3587,  -8.2461,  -6.2149,  -1.2997,  21.0171,\n",
      "           1.6782, -10.3460,   0.1860]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 21.01708359494565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7253,   3.0344,  -1.9226, -12.8277,   5.7268,  -1.8748,  17.5487,\n",
      "           3.4252,  -9.9093,  -2.1093]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 17.548694327568832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3317,   4.3271,  -3.2212,   0.8441,  -1.5774,  -2.4150,  24.1825,\n",
      "         -15.7782,  -5.1120,   2.0929]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 24.182513363345578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6842,   4.9171,  -3.1376,  12.4310,  -5.0767,  -2.7911,  14.3324,\n",
      "         -13.9688,  -2.0817,  -1.5993]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 14.332444780312695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7382,   9.7139,  -3.3596,   3.2139,   2.6490,  -2.5130,  15.3085,\n",
      "         -13.6244,  -8.3053,  -0.1325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 15.308548404081584\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9281,   8.6307,  -1.1165,  -6.3532,  -6.4349,  -0.8637,  12.0571,\n",
      "           1.6649, -11.8734,   4.7892]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.057116047580477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4045,   5.5342,  -1.8374,  -1.4868, -11.1904,  -1.2326,  27.2830,\n",
      "          -5.7486,  -9.3434,  -0.3662]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 27.283010979172346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4040,   5.5789,  -1.6806,  -9.8217,  16.3169,  -1.3636,  14.1255,\n",
      "          -1.2636, -11.1813,  -9.2437]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 16.316904408685126\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6579,  11.4509,  -3.1105,   4.1490,  -3.7819,  -2.4988,  20.3432,\n",
      "         -23.0755,  -2.5806,   1.3665]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 20.34318973892442\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4589,  5.0138, -1.5848, -9.1018, 12.1261, -1.2889, 13.8789, -3.5007,\n",
      "         -7.5512, -6.2949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 13.878937008999298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8078,  3.0786, -1.8378, -2.0583, -7.9088, -1.5766, 23.0436, -1.1462,\n",
      "         -9.2906, -1.1271]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 23.043643161176846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3111,  3.9421, -1.8398, -1.3235, -1.4747, -1.3045, 21.1130, -9.6762,\n",
      "         -4.1011, -2.5464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 21.11299090279756\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3117,  10.7352,  -2.6627,  -2.5212,  -2.5354,  -2.1375,  19.9609,\n",
      "         -20.0116,  -2.0722,   3.5141]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 19.960860470670884\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6402,   7.0727,  -1.6777, -10.1753,  10.9402,  -1.4910,  18.2935,\n",
      "          -0.9605, -14.9544,  -5.2435]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 18.29351521751636\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7903,  12.6263,  -3.2656,  -0.4879,  -1.4452,  -2.5636,  24.0642,\n",
      "         -26.1314,  -1.6881,   1.2241]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 24.064238157463336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0652,   8.5798,  -2.0831,  -5.8084,   3.3889,  -1.9215,  20.5301,\n",
      "          -8.7884, -11.1945,  -0.9897]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 20.530100901134176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9163,  5.2702, -1.9751, -4.1194, -1.4064, -1.6956, 18.0822, -7.4940,\n",
      "         -4.0567, -0.7796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 18.082198935418155\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5254,  2.9197, -1.7386, -1.6969, -7.9161, -1.3463, 26.5481, -8.7151,\n",
      "         -5.6713,  0.4067]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 26.548100975278384\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0925,  7.9702, -1.1637, -4.8749, -4.3992, -1.1356, 16.8818, -4.3849,\n",
      "         -8.7234,  0.5381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 16.881759049483502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3207,   7.5971,  -1.4212,  -8.4505,  -1.1608,  -1.4055,  15.2593,\n",
      "           2.5237, -13.4668,   1.2509]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 15.259334015647298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6406,  2.2456, -0.6554, -4.5927, -3.4865, -0.5418, 11.9286,  0.9693,\n",
      "         -4.9030, -0.2454]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.928635562125471\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8566,  3.8261, -2.1821, -3.2543, -7.0643, -1.6210, 22.2432, -8.1284,\n",
      "         -4.6850,  2.8594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 22.243218429644095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6494,   7.0407,  -3.6221,  -2.0355,  -0.8918,  -2.4816,  27.7842,\n",
      "          -8.8741, -15.1642,   2.4644]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 27.78421766374618\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1242,   4.1396,  -2.4498,   6.0482,   0.2978,  -2.2838,  10.8931,\n",
      "         -15.1828,   0.3546,  -0.3776]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 10.89305308712392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1132,  5.9330, -1.2915, -8.7872, -1.5259, -1.2605, 15.1726, -5.7315,\n",
      "         -0.8604,  1.3753]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 15.17264043857302\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4378,  10.4396,  -2.8056,   0.6731,  -4.4740,  -2.0853,  22.3977,\n",
      "          -7.0393, -13.9661,  -1.1786]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 22.39769066374748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9969,  10.7438,  -2.2685,  -5.8967,   2.6430,  -2.0632,  20.5622,\n",
      "          -1.6574, -14.2597,  -6.5344]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 20.562183858948412\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2304,  11.4149,  -2.5615,   0.8025,  -1.3282,  -2.0301,  18.5506,\n",
      "         -14.0743,  -8.6803,  -0.3876]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 18.550578956515732\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3299,   3.7929,  -1.4050,  -1.4456,   3.8711,  -1.1545,  10.9158,\n",
      "         -19.4582,   7.1262,   0.1504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 10.91580666622362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2250,  10.1754,  -2.4868,  -2.9104,  -3.7661,  -1.8964,  21.2190,\n",
      "          -8.1136, -12.4166,   1.6511]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 21.21903046187173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5550,  5.2530, -1.3140, -9.4124, -5.2081, -1.4171, 22.3340, -8.5794,\n",
      "         -0.4673,  0.0868]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 22.33403794563063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1381,   9.5862,  -2.4839,   2.3844,  -2.7011,  -1.8844,  19.2443,\n",
      "          -8.2253, -12.7192,  -1.4701]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 19.24430378299849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9111,   1.1691,  -2.2859,   5.9521,  -1.2084,  -1.8223,  13.7194,\n",
      "         -19.0000,   2.1449,   2.7049]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 13.71944045382969\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0295,  11.3269,  -2.4276,  -0.5523,  -3.9425,  -1.9427,  20.2643,\n",
      "          -8.4031, -11.0567,  -1.4387]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 20.264331085584654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2758,  12.0383,  -2.9859,  -3.1080,  -2.8310,  -2.2606,  25.0826,\n",
      "         -14.1590,  -6.9019,  -1.9430]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 25.08259483304231\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0881,   3.9240,  -1.4076, -10.6934,  11.3845,  -1.1233,  13.3089,\n",
      "           0.0663,  -9.7114,  -4.3712]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 13.308902327876385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2696,  3.0503, -1.3916, -1.1978, -3.6973, -1.2397, 13.2987, -7.1156,\n",
      "         -1.9296,  1.1219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 13.298697442045107\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3727,  -0.3744,  -1.6207, -12.3565,   4.1153,  -1.6447,  15.5065,\n",
      "          -0.5442,  -4.5033,   2.8550]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.506501235626498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8690,  7.8989, -1.0009, -9.4474,  9.7057, -0.9348,  8.2000,  0.8041,\n",
      "         -8.7054, -4.8115]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  9\n",
      "activation[4] = 9.705667376093631\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9844,   1.0800,  -1.2846, -17.3732,   4.7600,  -1.2779,  15.0070,\n",
      "           2.6511,  -7.7989,   5.0695]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.00699383767528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5377,  0.9260, -1.7663, -1.1721, -3.0078, -1.3613, 15.5963, -9.4566,\n",
      "          3.0480, -0.7457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 15.59631369871281\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5373,  15.4037,  -1.7307,  -8.1669,   0.2252,  -1.2359,  10.5196,\n",
      "           3.6119, -20.7804,   3.2477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.403738433120859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3244,  11.3524,  -2.6242, -14.3677,  -4.4747,  -2.2305,  26.2168,\n",
      "           6.0407, -25.9318,   7.8389]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 26.216798114957065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5161,   4.3738,  -1.6463,  -6.1062,   7.5668,  -1.4230,  14.5981,\n",
      "          -6.0266, -11.1836,   0.9366]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 14.598073313388646\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5127,  10.9138,  -1.8771,  -1.0132,  -4.6106,  -1.4512,  15.3675,\n",
      "          -7.6662, -10.0324,   1.2546]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 15.367507984152962\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8756,  13.0352,  -2.0447,  -4.4855,  -2.0995,  -1.5680,  18.9034,\n",
      "          -2.8294, -17.8582,   0.4777]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 18.903438226461663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9282,   4.2601,  -2.7012,   1.3538,  -2.1132,  -2.0462,  16.6248,\n",
      "         -22.0416,   3.9154,   6.2865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 16.624830698941413\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3261,  -0.8296,  -1.5419, -13.1723,   3.6255,  -1.5152,  15.2455,\n",
      "          -1.3520,  -4.6438,   5.1423]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 15.24549394788924\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4304,   5.4468,  -2.3266,   0.2557,   2.8643,  -1.7600,  13.9027,\n",
      "         -24.6896,   6.3688,   2.8606]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 13.902692258205931\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8776,  10.2569,  -2.0609, -12.5380,  -3.4405,  -1.5142,  21.6033,\n",
      "           1.1292, -17.4145,   5.5517]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 21.603288823405435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8255,  2.0513, -1.8135, -4.5499, -5.2818, -1.9440, 19.6043, -6.7311,\n",
      "         -0.1122,  0.2905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 19.604278745819396\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1851,   3.8612,  -2.4775,   1.9671,   0.7590,  -2.0826,  15.6856,\n",
      "         -11.2275,  -3.9388,  -0.5952]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 15.685618695723496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7408,   1.8050,  -1.9268,   4.8448,  -4.1669,  -1.4044,  19.2148,\n",
      "         -15.4584,   1.4967,  -1.9207]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 19.214844976278176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8924,   2.5540,  -3.5230,  14.3075,  -1.4497,  -2.9139,  12.5673,\n",
      "         -11.9944,  -3.9660,  -2.9483]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.307501863389888\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0179,   7.6259,  -1.7426,  -6.6428,  -6.0479,  -1.6987,  27.1885,\n",
      "         -10.1883,  -2.1900,  -3.6601]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 27.188521688523732\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3809,  2.4562, -2.6730,  9.7946, -7.9474, -2.5143, 15.6236, -9.0298,\n",
      "         -3.0614, -0.6803]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 15.623606311544151\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4478,   4.4636,  -3.4790,   5.5680,  -2.2773,  -2.5736,  27.2698,\n",
      "         -25.5520,  -1.9496,   3.0090]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 27.269772664553386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1829,   4.5137,  -1.3569,  -7.7062,   1.9616,  -1.1512,  15.8784,\n",
      "           1.6246, -10.0673,  -2.3409]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 15.878415344410392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9912,   2.5508,  -2.3444,  -1.2227,   1.2700,  -2.1735,  20.1359,\n",
      "         -21.1847,   4.9711,   0.1236]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 20.13589656898866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7441,  3.5356, -2.1431, -1.7502, -0.7817, -1.6310, 16.5549, -1.4360,\n",
      "         -8.8841, -1.4078]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 16.554853461474035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6750,   5.2704,  -1.6135, -10.1813,   2.1243,  -1.4990,  17.5125,\n",
      "          -6.5153,  -2.1150,  -1.0310]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 17.51246193486585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7322,   4.4916,  -2.2060,  -1.1822,  -2.4411,  -1.6902,  17.3063,\n",
      "         -11.6987,  -5.0490,   5.7443]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 17.306320753111443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6699,  4.5431, -0.8507, -1.3621,  2.3717, -0.6173,  9.0949, -8.3051,\n",
      "         -1.4547, -1.6827]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 9.09486930214928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9241,  0.7908, -1.8782, -5.2956,  0.6407, -1.7097, 17.9300, -8.5685,\n",
      "          8.0266, -6.3495]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 17.929984073220677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1702,  2.0480, -1.3530, -1.7065, -2.3851, -1.0958, 12.1847, -0.9269,\n",
      "         -5.3071, -0.8165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.184733049226434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3211,   2.8541,  -1.5500, -12.4102,   6.9514,  -1.2961,  19.8841,\n",
      "          -2.3853,  -4.7516,  -5.5240]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 19.88408256107063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3954,   4.5502,  -2.9449,   4.3167,   0.9813,  -2.5346,  12.9686,\n",
      "         -12.6161,  -3.6038,   2.4837]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 12.968562371765483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8134,  4.5320, -1.0006, -8.6117,  1.3122, -0.7118, 12.2343,  3.4385,\n",
      "         -7.4964, -2.3612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 12.234332357082216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9472,   4.4334,  -1.3212,   0.4051,  -5.5316,  -1.0972,  15.6327,\n",
      "         -11.8695,   1.9602,  -0.2634]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 15.632702094045433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1942,  2.7160, -1.6368, -3.4420, -6.9190, -1.1777, 24.6200, -2.3508,\n",
      "         -9.7394, -0.3017]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 24.62002407069018\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6938,   9.0385,  -2.0428, -10.8688,   4.2333,  -1.8028,  18.1646,\n",
      "          -0.3341, -11.6159,  -3.4204]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 18.16460220801296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7258,  3.9495, -2.0781, -1.2126, -0.5672, -1.7488, 16.8619, -4.1427,\n",
      "         -7.8876, -0.3382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 16.861900354981206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3156,  1.9835, -1.5598,  0.9537, -2.0470, -1.2121, 12.5207, -2.7183,\n",
      "         -5.1638, -2.0323]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.52067624913948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3518,  6.9506, -1.8372, -7.9951, -1.3510, -1.1094, 17.5523, -7.2628,\n",
      "         -4.8989,  2.7729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 17.55229266340047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5061,  4.5076, -2.6556,  1.9648, -0.6935, -2.4791, 20.8014, -7.7287,\n",
      "         -8.5366, -1.9246]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 20.801370025139697\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2605,   1.7239,  -1.9347,  -2.2278,  -4.4508,  -1.4102,  22.3465,\n",
      "         -13.4324,  -5.0558,   7.0753]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 22.346498347334133\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2606,   7.0557,  -1.3347, -13.3737,   5.0208,  -1.3136,  19.9780,\n",
      "          -7.2670,  -1.7569,  -4.1012]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 19.977975740386608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5949,  16.3723,  -1.7907,  -8.7869,   2.6834,  -1.2451,   9.0528,\n",
      "           4.1090, -21.6618,   2.4156]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 16.372255439271942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3790,  2.6758, -1.4264, -3.1573, -4.1350, -1.2216, 17.4090,  1.6727,\n",
      "         -9.0564, -1.6749]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 17.408965474925925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0113,   3.2973,  -1.3516, -15.5364,   9.8584,  -1.1654,  16.7245,\n",
      "           0.5156, -10.6343,  -0.2587]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 16.72445296420245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2943,   7.5843,  -2.6168,  -1.8844,  11.6208,  -1.9669,  14.5785,\n",
      "         -16.1412,  -2.4832,  -5.9436]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 14.578487823112473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2479,  11.2148,  -1.3998,  -8.5862,  -3.6367,  -1.1398,  12.9112,\n",
      "           2.5640, -15.7955,   4.6629]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.911201448461544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5864,  3.3188, -3.0511,  8.0003, -6.8961, -2.5280, 21.0977, -9.8997,\n",
      "         -4.4739, -2.2571]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 21.09768235638084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2794,   5.8704,  -1.2932,  -7.2963,   0.2275,  -1.3226,  14.2327,\n",
      "           2.9344, -11.3855,  -1.5044]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 14.232725455061928\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3174,   0.9257,  -1.8325,   2.2653,   0.8143,  -1.3661,  13.2712,\n",
      "         -13.1126,   3.3551,  -2.4617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 13.271242194778152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1448,  10.8129,  -1.3726,  -8.3856,  -1.0230,  -1.1377,  17.8338,\n",
      "          -3.7947, -11.4470,   0.0847]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 17.833765097806506\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7585,   6.6560,  -2.2484,  -1.1844,  -6.0767,  -1.7517,  21.3548,\n",
      "         -14.9318,  -1.1572,   2.0104]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 21.354777921221473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2280,  13.3570,  -2.4316,  -3.8948,  -2.5653,  -1.8087,  20.7339,\n",
      "          -0.2482, -21.2289,  -0.1979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 20.733887780529223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0899,  0.9767, -1.0481, -2.7811, -1.8093, -1.2680,  9.8687, -1.7134,\n",
      "         -2.5918,  1.3880]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 9.868739005894842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0621,   7.7779,  -2.7597,  -0.3065,  -4.9762,  -2.2434,  19.5583,\n",
      "          -7.0354, -11.5874,   4.0112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 19.55826989622204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1100,   2.7680,  -3.0696,   8.3356,  -0.7977,  -2.2188,  15.5701,\n",
      "         -17.0113,   0.0505,  -0.1305]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 15.570116723726402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1540,  -1.0674,  -2.0963,  -2.3313,  -0.2989,  -1.4319,  26.4828,\n",
      "         -17.0881,   0.9340,  -0.1857]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 26.48284821107531\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0217,  2.4485, -1.3413, -2.7698, -3.5214, -1.0578, 17.5181, -2.3401,\n",
      "         -5.5030, -2.2908]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 17.518073218044048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5076,  14.2344,  -1.7143,  -8.6407,  -5.6049,  -1.3067,  15.4449,\n",
      "           3.4863, -20.0326,   5.0011]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 15.44485661861062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0101,   4.9342,  -1.8490,  -2.5644,   6.6248,  -1.3892,   8.4780,\n",
      "         -20.6057,   6.5776,   2.0809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 8.478043740131845\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0953,  3.9236, -1.1536, -7.4741,  2.9371, -0.8868, 11.4926,  2.1672,\n",
      "         -7.8699, -1.5277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 11.49260091324476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2614, 10.4998, -1.8478, -5.8116, -9.1836, -1.2649, 24.1655, -6.9614,\n",
      "         -9.9041,  1.9649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 24.165514563823688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8608,   6.1594,  -3.3558,   3.9233,  -2.4203,  -2.9001,  18.4230,\n",
      "         -17.2821,  -3.5193,   5.1834]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 18.423019551704325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7163,   3.8200,  -0.9120,  -6.7924,   1.9847,  -0.6748,   9.5335,\n",
      "         -10.8646,   4.9914,   0.4829]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 9.53348771667453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9856,   6.8028,  -2.1397,  -6.5947, -11.0782,  -1.6700,  29.5618,\n",
      "          -1.1129, -15.4695,   3.2915]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 29.561791297310112\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7348,   4.5824,  -2.3943,  -3.3797,  -0.4707,  -1.6936,  25.1422,\n",
      "         -17.7593,  -1.2025,   1.2646]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 25.142241188902293\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9120,  10.7219,  -2.7629,   2.1106,  -1.6510,  -2.1057,  20.5511,\n",
      "         -17.0708,  -9.3246,   2.5060]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 20.551117696456878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8732,  2.1140, -1.2175, -3.4912,  1.0769, -0.9063, 12.3539, -8.7697,\n",
      "          0.0130, -0.0604]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 12.353901418527446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5502,  10.7732,  -3.3371,   7.9072,   0.1146,  -2.5870,  16.3774,\n",
      "         -12.9670,  -9.6989,  -3.5772]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 16.377373872800277\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2606,  5.6854, -1.1102, -3.5083, -6.0192, -1.0508, 18.0499, -4.3143,\n",
      "         -3.5624, -2.5952]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 18.04994088240628\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0669,   5.3839,  -1.4033,  -3.4610,   4.2230,  -1.1081,  11.7937,\n",
      "         -18.8378,   6.4942,  -0.2541]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  4\n",
      "activation[6] = 11.793716699593709\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3699,  4.2249, -1.5014, -4.7169, -7.7192, -1.4854, 19.5776, -2.4209,\n",
      "         -6.5475,  1.4080]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 19.577592104430753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0560,   7.7407,  -2.5031,  -3.6131,  -1.0458,  -1.8950,  22.2844,\n",
      "          -6.3812, -11.8096,   0.4522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 22.284402598246754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4432,  0.2835, -1.9403,  1.5491, -3.6879, -1.3587, 14.1973, -7.6509,\n",
      "          1.7291, -0.8829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 14.197314156461411\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4723,   8.6891,  -1.6867,  -3.3509,  -1.7141,  -1.4799,  15.5671,\n",
      "         -13.9919,  -0.8590,   0.8502]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 15.567076269811908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1870,  9.6299, -1.2814, -8.0523, -7.0068, -1.2272, 21.6146, -7.4504,\n",
      "         -7.5017,  2.7878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 21.614622601971263\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7835,   5.5264,  -1.8677,  -3.0509,   1.8572,  -1.3000,  12.3348,\n",
      "         -12.6340,   4.4925,  -2.4673]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  7\n",
      "activation[6] = 12.33482443259686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6865,  6.8109, -0.9780, -7.4814, -1.1908, -0.9036, 12.2020, -5.2532,\n",
      "         -1.8732,  0.3968]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  5\n",
      "activation[6] = 12.20201662397391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8838,  12.7392,  -3.5484,   5.8426,  -3.0247,  -2.8006,  21.2496,\n",
      "         -22.4411,  -5.0207,  -0.2704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 21.2495997063734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7178,   8.2168,  -2.3560,  -4.8443,  -7.9932,  -1.8924,  22.7861,\n",
      "          -5.7184, -11.3213,   5.8029]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 22.78607511184035\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4069,   5.1768,  -1.3570,  -5.4972,   1.1055,  -1.3592,  14.5323,\n",
      "         -10.0793,  -0.1176,  -1.1522]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 14.532344245711402\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [14]: loss = 15.350, accuracy = 12.11\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3058, -0.0329, -0.4580,  0.0823, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4693], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3058, -0.0329, -0.4580,  0.0823, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4693], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -1.4471,  10.9868,  -1.9215,  -1.7488,   5.0048,  -1.5639,  -7.6689,\n",
      "         -17.3102,  -4.8843,  20.5612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.561192871088142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6497,   3.4689,  -3.2201,   8.0925,  -6.0629,  -2.8618,   1.5135,\n",
      "         -20.6014,   1.5501,  21.9807]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.98067276024516\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3304,   4.6682,  -2.4467,  -5.1191, -12.4893,  -1.8665,  20.1032,\n",
      "          -7.6121, -10.5825,  18.2827]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 20.103222711014254\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1670,  2.4795, -1.1951, -3.8158, -3.8034, -0.9419, 11.4681, -0.0919,\n",
      "         -6.2068,  3.1771]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.468113108411318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0751,  4.2264, -0.9698, -2.3672, -2.7429, -0.9630, -8.1019, -9.6928,\n",
      "          2.1069, 19.7975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.797467522637874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0213,   9.9063,  -2.6108,   4.5017,  -9.2809,  -2.1646,  10.8671,\n",
      "         -18.9842,  -7.6521,  18.5245]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.524542031527996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8260,  4.0968, -1.2120, -2.5443,  4.1231, -1.0764, -4.7527, -8.9144,\n",
      "         -5.6019, 17.2661]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.266129368591862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3600,   4.0244,  -2.6811,   2.5171,  -1.6473,  -2.1724,   8.4244,\n",
      "         -13.1091,  -2.2436,  10.0656]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.06558514914705\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7251,  4.9642, -0.7832, -6.7876, -9.0500, -0.6596, 10.2092,  0.7175,\n",
      "         -7.7477,  9.6642]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.209161085437655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9658,  1.4822, -0.9633, -4.1390, -1.8502, -0.7688,  8.4102,  2.0189,\n",
      "         -6.5506,  3.3124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 8.410242031909446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6771,  3.8764, -0.5649, -9.9211,  5.2400, -0.8463, -5.9138, -2.4668,\n",
      "          0.9412, 12.1573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 12.157294559008648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9602,   7.9427,  -2.5351,  -1.1164,  -0.8276,  -1.8589,   3.7384,\n",
      "          -6.2004, -10.8474,  14.1280]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.128007234729477\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8082,   1.0024,  -2.5463,   4.1792,  -1.7288,  -1.9511,   6.6983,\n",
      "         -10.4083,  -3.4720,  11.0400]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 11.039964155259389\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4339,   7.4734,  -1.6479,  -3.3735,  -0.8310,  -1.5900,   0.8969,\n",
      "         -13.5628,  -0.9210,  16.0139]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.013898062101322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4651,   6.5677,  -2.6427, -12.8014,   3.2184,  -2.1887,  10.5990,\n",
      "           3.4152, -18.9327,  14.9517]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.951715297956103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5243,  3.9789, -1.7323, -5.2944, -0.4510, -1.4710, -1.0727, -9.9259,\n",
      "          6.1330, 12.7646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 12.764601518091457\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3010,  6.2832, -1.5213,  0.0677, -1.3906, -1.2256,  2.7246, -8.1803,\n",
      "         -3.6681,  8.3101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 8.310096297215408\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8025,  12.5510,  -3.4820,  10.0168,  -0.5806,  -2.5630,   0.5297,\n",
      "         -19.0329,  -8.0319,  14.2599]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 14.259913412900485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2438,  4.3429, -1.2582, -5.0361, -6.4273, -1.1700, 12.2589,  2.2343,\n",
      "         -9.9145,  5.8710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.258850414406215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7818,  11.7368,  -3.2948,  -7.7102,  -1.4145,  -2.4209,   4.7031,\n",
      "          -3.0270, -16.8502,  22.2058]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.205806668660554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0422,  2.0755, -1.1858, -3.6898, -4.8538, -0.9311,  9.0028,  0.1080,\n",
      "         -6.1276,  6.4260]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 9.002818454259554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2345,  11.1692,  -2.3986,  -8.7115,  -9.2916,  -1.9916,  17.1532,\n",
      "           1.7243, -19.6888,  13.4736]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 17.153228633884655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5815,   2.4661,  -2.7900,   7.2678, -11.1517,  -2.5324,   7.9704,\n",
      "         -16.7466,   2.5559,  15.2432]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.243233344393825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3074,  10.4743,  -3.1213,   7.6629,  -8.6573,  -2.3234,  11.0620,\n",
      "         -24.3184,  -4.9259,  17.5263]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.52632057620335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0539,   4.3859,  -1.3864,  -5.3053,   4.6019,  -1.0462,  -7.3009,\n",
      "         -11.7768,   2.3197,  16.8600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.859963383932698\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5900,   7.8635,  -3.2420,   0.4267,  -0.5579,  -2.7447,  -1.1844,\n",
      "         -13.7912,  -3.8991,  19.2874]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.287400812820152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6953,   2.6869,  -2.6308,   3.8975,   3.7600,  -1.9539,  -6.1397,\n",
      "         -21.7220,   7.8885,  17.5878]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.587807241502386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1496,   4.3639,  -1.2652,  -1.6644,   2.4303,  -1.1709,  -9.8579,\n",
      "         -20.7249,   9.3244,  21.3488]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.348780861175687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5618,   4.7939,  -2.1246,   2.2647,   4.4181,  -1.8136,  -1.0710,\n",
      "         -20.4575,   3.0697,  15.1969]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.196945772446739\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8838,   9.5577,  -2.3045,  -6.1055,  -1.2310,  -1.7112,   5.1599,\n",
      "          -0.6250, -11.4384,  12.1176]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 12.117553047793454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4538,   8.3730,  -3.9349,   1.9141,  -5.5924,  -3.3733,   1.6667,\n",
      "         -19.3361,  -1.0409,  24.6255]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.625501051287184\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4217,  7.3148, -1.4540, -3.4447, -3.3695, -1.2927,  3.8471, -9.5036,\n",
      "         -1.9852, 11.3990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.399016075323193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4640,  10.4244,  -2.8161,  -1.2653,  -2.9824,  -2.2407,   2.7739,\n",
      "         -22.1034,  -1.1849,  21.8111]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.811108855900006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6822,  2.4200, -2.0425, -6.8176,  1.9833, -1.7026,  0.3828, -5.9953,\n",
      "          1.3206, 13.0403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.040283034858096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3918,  0.8044, -0.9704, -6.3027, -0.8174, -1.2631, -7.3346, -7.0169,\n",
      "          5.5494, 19.3684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.368430824900983\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1745,  10.4164,  -3.8347,  10.0223,  -2.7127,  -3.0120,   2.4140,\n",
      "         -23.3995,  -7.7252,  22.0086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.00861793912757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7807,   2.8744,  -0.8492, -10.0093,   1.7238,  -0.5457,  -4.7097,\n",
      "          -5.2217,   5.6947,  12.4284]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 12.428376297471996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3352,   6.5354,  -1.3926,  -9.7796,   9.6030,  -1.2592,  -0.9643,\n",
      "           0.6640, -12.1406,   9.7788]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 9.778834305210296\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1900,  5.7558, -1.3768, -2.6925, -4.8050, -1.2820,  1.0186, -9.8945,\n",
      "         -1.2296, 16.7020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 16.701961265396655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5206,   2.4577,  -2.0905,  -2.8845,  -1.9020,  -1.7486,   1.1319,\n",
      "         -17.9949,   4.9360,  20.7793]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.779282313421792\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4226,   2.7068,  -1.5966,  -4.4188,   4.6824,  -1.4230, -12.0166,\n",
      "         -13.1252,   2.1295,  24.9729]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.972899116325486\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7208,   8.1495,  -1.9009,  -0.1205,   5.9054,  -1.5381, -13.6358,\n",
      "         -13.7075,  -1.8518,  21.0343]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.034332730216978\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1311,  4.7235, -1.0639, -0.3596, -1.7665, -1.0692, -0.4157, -4.9528,\n",
      "         -3.8178,  9.0319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.031939250581438\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5775,   4.6265,  -3.4842,   9.0054,  -6.8261,  -3.0003,   6.6049,\n",
      "         -21.7475,  -2.3119,  20.6987]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.698718917185236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2953,   3.5795,  -1.4363,  -3.7196, -11.6509,  -1.2071,  15.3845,\n",
      "          -1.8305,  -8.4155,  10.1716]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 15.384481990950238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2207e+00,  5.3674e+00, -1.5631e+00, -6.1575e+00,  8.8222e-01,\n",
      "         -1.5091e+00,  1.7603e+00, -1.2522e+01, -7.3542e-04,  1.5805e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.80477337670693\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6129,  18.4811,  -3.1003, -17.7796,   5.7285,  -2.3726,   7.9389,\n",
      "          -0.5347, -29.1498,  23.3635]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.363539862185835\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8048,   4.7774,  -1.0429,  -7.8306,   3.1022,  -0.6216,  -2.9898,\n",
      "         -10.0667,   0.7962,  15.0995]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.099472722659957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0273,   4.0137,  -1.3959,   2.6657,  -3.2153,  -1.2579,   0.1597,\n",
      "         -16.7086,   5.6806,  12.5091]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 12.509075307881151\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3075,   1.8589,  -1.4144,  -0.8439,  -1.3512,  -1.1146,   1.2980,\n",
      "         -10.0637,   7.2368,   6.8920]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 7.236811447332782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8784,   5.2989,  -1.2302, -10.3175,  -2.2944,  -1.1174,   9.0955,\n",
      "           0.7494, -12.3107,  13.1432]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.143209743190782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5102,   1.0915,  -3.1542,   6.3174,  -4.7880,  -2.3715,   9.2657,\n",
      "         -13.5578,  -5.3867,  15.9256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.925614505806324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3861,  4.7131, -1.6844,  0.0266, -3.5744, -1.2246, -2.1082, -7.2883,\n",
      "         -2.9424, 15.9366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.936645900179773\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0459,   4.5928,  -2.5878,   2.4191,  -4.5511,  -1.8608,  10.4991,\n",
      "          -8.9319, -13.0657,  16.7165]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.71653193999143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8336,   2.1626,  -2.3331,   8.5328,   1.1118,  -1.8566,   2.2530,\n",
      "         -18.9980,   3.6257,   8.5744]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 8.574418566958688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5278,   6.9189,  -1.6046,  -2.5838,   7.4042,  -1.4105, -10.0540,\n",
      "          -6.4143,  -6.0941,  15.8586]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.858567410200001\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9714, -0.8953, -1.2709, -5.9362, -0.3807, -1.2730,  2.1067, -6.6209,\n",
      "          0.5622, 14.4498]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.449797397067828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6360,  3.3642, -2.0593, -8.2221, -1.1012, -1.6381, -1.4937, -9.4302,\n",
      "          4.1637, 19.0373]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.037284516731138\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9035,   7.5132,  -1.8013,   0.2937,  -5.3929,  -1.6635,   7.8926,\n",
      "          -5.4980, -10.4516,  11.7093]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 11.709280731037666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9838,  11.5313,  -3.4474,   2.4603,  -5.6297,  -2.7666,   3.1927,\n",
      "         -22.8405,  -5.4562,  25.9516]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.95160386554556\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0829,  10.9613,  -2.0394,  -0.9667, -12.1048,  -1.7672,   6.6648,\n",
      "          -6.5581, -11.5917,  18.5630]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 18.56302642577409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6164,   7.7342,  -1.6649, -12.3922,  -1.5896,  -1.5357, -10.5884,\n",
      "         -16.2066,   3.1531,  35.1973]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 35.19732129026471\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4929,   4.0655,  -1.7299,  -1.7957,   0.1327,  -1.6117,   0.9462,\n",
      "         -14.2315,   0.4161,  16.1761]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.176065021432873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4081,   7.0291,  -3.2532,   6.4300, -10.7265,  -2.5540,  12.4844,\n",
      "         -22.5935,  -2.9852,  19.1224]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 19.1224015719859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8334,  -1.2188,  -2.3281,  10.4935,  -6.7401,  -1.7942,   8.0069,\n",
      "         -15.4739,   2.1966,   9.3370]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 10.493474078222215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1416,  4.2018, -1.0968, -5.3212,  2.7143, -1.0276, -6.1236, -3.2928,\n",
      "         -5.7798, 16.8395]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.83948779784996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4944,   3.4517,  -1.9138,  -3.8020,   4.3837,  -1.6776,   2.8570,\n",
      "         -16.0685,  -0.1277,  15.5148]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.51479252475325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4537,  10.5549,  -4.0913,  10.9226,  -1.0411,  -3.4129,   4.0812,\n",
      "         -12.2453, -13.3754,  12.6927]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.692675845566342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4620,   4.6119,  -1.3851,  -1.5972,   1.7189,  -1.2478,  -8.4489,\n",
      "         -10.5803,  -0.1222,  18.7154]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.71543270169688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1957,   6.1080,  -1.4965, -13.0222,  -2.5404,  -1.1568,  -3.0439,\n",
      "         -19.0236,   1.1724,  34.7348]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 34.73483126481162\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4616,   6.4289,  -1.9531,  -1.9782,  -1.3686,  -1.3426,   7.0027,\n",
      "         -16.0061,  -7.4449,  19.6670]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.666989998464825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4936,   8.3975,  -4.1203,   8.1007,  -0.8129,  -3.3478,   1.9528,\n",
      "         -18.1215,  -7.7974,  19.2313]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.23129049679604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9516,   4.2394,  -2.4922,   4.8577, -10.2149,  -2.2942,   8.7377,\n",
      "         -19.9685,   5.6504,  13.6177]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.617713843852716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3129,  13.7295,  -3.9724,  -2.0945,  -1.4602,  -3.2261,  -0.8493,\n",
      "         -25.8330,  -8.0230,  35.1618]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 35.16180770548157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9712,  11.4179,  -3.3635,  -0.4873,  -4.3842,  -2.5873,  -1.0779,\n",
      "         -15.6643,  -6.7667,  25.5749]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.574885409012698\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3557,   9.4499,  -3.1836,   5.3118,  -9.9180,  -2.2770,   9.8098,\n",
      "         -21.8836,  -6.7689,  22.2054]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.20539865144914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2967,  5.3318, -2.8724,  1.8872,  0.0421, -2.3506,  6.3862, -7.9867,\n",
      "         -9.9373, 12.5910]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.590982225811533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3377,   1.8065,  -2.9024,   8.4038,  -5.1479,  -2.4917,   1.2794,\n",
      "         -18.7905,  -2.7351,  24.2254]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 24.225354323178465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9156,  1.6013, -1.1167, -3.7659, -1.7838, -0.8593,  5.6978,  2.7780,\n",
      "         -6.6384,  4.6104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  9\n",
      "activation[6] = 5.697818173653911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1885,   6.9704,  -2.3708,   0.2072,  -0.5861,  -2.1195, -11.6126,\n",
      "         -13.6401,  -3.9926,  29.2914]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 29.291448769204006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9411,   9.5099,  -1.9381,  -2.0384,  -0.7438,  -1.4192,  -0.2183,\n",
      "         -11.9326, -10.1747,  20.3445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.344454830463604\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3349,  11.9271,  -3.9621,  10.3209,  -6.9925,  -3.1408,   6.0884,\n",
      "         -22.7036,  -6.6090,  19.0784]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 19.078362032546085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6066,  6.2381, -1.7653, -2.2329,  2.8941, -1.4729, -7.7988, -9.0320,\n",
      "         -4.3612, 19.3084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.308371907798094\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2781,   4.5706,  -1.8995,  -6.7214,   5.4134,  -1.5048,  -2.8459,\n",
      "         -12.3461,   0.3822,  17.5740]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.574040985962515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8230,   2.5696,  -2.0101, -10.0393,   9.4322,  -1.6386,  -0.4239,\n",
      "         -17.3940,  -1.2813,  23.2438]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.24378098539448\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8668,   6.5831,  -2.3828,  -1.9602,   0.1186,  -1.6399,   8.4946,\n",
      "          -2.5864, -13.1123,   9.4843]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.48427759598199\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7680,   7.5342,  -2.0335,   2.1958,  -3.3319,  -1.7210,   2.9383,\n",
      "         -14.9967,  -0.5713,  11.7183]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 11.718294683639586\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4907,   6.6056,  -1.8218,  -7.1536,   5.2315,  -1.4994,  -0.6506,\n",
      "         -14.3384,  -3.4944,  19.8671]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.8670654301181\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2142,   2.4976,  -2.6917,  -2.4376,   2.6494,  -2.5897,   0.1908,\n",
      "         -16.4879,   1.3985,  19.3865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 19.386500712133593\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7140,  9.0083, -2.3538, -8.4263,  6.9384, -1.6743, -0.1442, -4.9953,\n",
      "         -8.3130, 12.7998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 12.799793763771568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1347,   3.6491,  -2.2590,   5.2060,  -7.4390,  -1.9251,   3.1420,\n",
      "         -14.4709,   2.4846,  12.8554]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.855358156363401\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1662,  3.8641, -1.2287, -6.3373, -6.0265, -0.9922, 12.0132,  0.3693,\n",
      "         -8.8124,  8.2344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.013178623344777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0430,  5.3286, -1.3654, -6.5195,  1.5796, -1.1681,  1.1361, -9.9420,\n",
      "         -2.8340, 16.1193]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 16.11933193179362\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6732,   9.0151,  -2.1970,  -5.9404,   4.7823,  -1.7449, -10.5883,\n",
      "         -10.0669,  -7.4378,  26.6426]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 26.642583051997672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5948,  4.4798, -1.6094, -5.8006, -0.8874, -1.4490, -5.3296, -9.9465,\n",
      "         -3.5610, 25.8752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.87517848287806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3850,   4.4182,  -3.2188,   5.6746,  -8.3949,  -2.5749,   9.7800,\n",
      "         -19.7056,  -5.5976,  22.3975]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.3975081764092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4769,   8.8676,  -2.7110,  -0.1225,  -6.2398,  -2.6034,   5.5925,\n",
      "         -13.1704,  -5.1047,  17.9718]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.97180858511527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2392,   5.3679,  -1.5100,  -7.5082,   3.7312,  -1.1641,   4.8203,\n",
      "           2.4907, -12.3541,   8.1512]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 8.151188913351218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6180,  7.2961, -0.7973, -8.7917,  5.7080, -0.7143, -3.3087,  0.5457,\n",
      "         -6.9583,  8.9128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 8.912769538335882\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3400,   6.8458,  -2.6721,   7.3803,   3.2833,  -2.4722,  -0.5983,\n",
      "         -15.4237,  -2.1920,   8.3968]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 8.396788467733167\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8602,  0.6930, -0.9647,  0.5279, -1.4235, -0.8479,  2.3560, -7.1724,\n",
      "          3.1852,  4.7734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 4.773382003061289\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9126,   0.3239,  -2.4698,   4.5396,   0.2750,  -1.7063,   2.7967,\n",
      "         -10.3525,  -8.3565,  17.5525]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 17.552478533779997\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1100,   4.5274,  -1.1154,  -6.7319,  -1.7267,  -1.1429,  -5.6640,\n",
      "         -14.9074,   5.0053,  23.5527]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.55270239644782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7269,   7.2885,  -3.4417,   8.5489,  -0.9254,  -2.8163,   7.0845,\n",
      "          -9.1269, -10.4705,   7.7573]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 8.548851656748713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6358,   7.3951,  -1.7800,  -7.8106,   2.1012,  -1.3393,  -1.4816,\n",
      "         -11.9652,  -2.4529,  18.8113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 18.811348228807763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7101,  14.9715,  -3.5166,   2.6612,   5.5656,  -2.6616,  -6.3795,\n",
      "         -24.5361,  -6.6536,  23.0392]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.039228793102026\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0160,   3.7207,  -2.2893, -11.8713,   0.4814,  -2.1932,  -0.4211,\n",
      "         -24.9451,   3.5825,  36.0113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 36.011263332895446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1642,  5.3801, -1.4856, -9.0295,  4.9531, -1.2198, -8.1867, -4.0615,\n",
      "         -2.2858, 17.1996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.19959521014128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3558,  2.2904, -2.7372, -0.2742, -8.0155, -2.3676,  8.9885, -8.3416,\n",
      "         -4.8151, 17.0882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.08815330018154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8342,  5.2171, -2.2217, -4.2716,  2.2945, -1.6950, -5.7488, -7.0514,\n",
      "         -3.6873, 18.9782]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.97821898616236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0340,   7.2316,  -1.5253,  -8.7847,   0.5165,  -1.3606,  -2.8903,\n",
      "         -14.9674,   4.3141,  19.4147]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.414733329496368\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7339,   1.9246,  -2.3185,   5.2555,   1.1007,  -1.5511,   3.6830,\n",
      "         -10.2474,  -8.4634,  13.4440]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.443951286555539\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1513,  0.3298, -1.3680, -2.9068, -0.9157, -1.1782, -0.3844, -0.4198,\n",
      "         -4.2543, 11.9471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 11.947142000874486\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8931,  5.3094, -2.1883, -0.0177,  9.7122, -1.6836, -6.6603, -7.5647,\n",
      "         -8.2063, 13.1136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.11361846250324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7080,   7.8183,  -2.1669,  -2.2446,   3.9099,  -1.9026,  -9.3521,\n",
      "         -20.6711,   3.2909,  23.9171]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.91708009346831\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8999,  13.1959,  -3.6952,  10.4858,  -1.3069,  -2.9131,   3.3581,\n",
      "         -13.4224, -13.3484,  11.3458]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 13.195908146178121\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9478,   8.9182,  -2.2868,  -8.7584,   4.4092,  -1.8649,  -1.4746,\n",
      "         -17.3447,  -2.7112,  24.5402]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 24.540236526508856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1541,   8.8834,  -1.6268,  -7.1299,   4.4224,  -1.2644,  -7.4158,\n",
      "         -16.1489,   2.3696,  20.4707]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.47065387446656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5436,   2.8960,  -2.2385,   1.5554,   2.7779,  -1.7504,  -2.7611,\n",
      "         -19.7104,   2.1701,  20.4057]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.405658332542743\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5951,  2.9671, -1.5439, -6.7550, -2.1148, -1.4900, 10.2652,  1.4788,\n",
      "         -8.8531,  7.1222]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.265218385670275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9702,  4.1165, -1.1460, -7.8925,  1.5673, -0.9694, -5.2633, -8.1805,\n",
      "          3.8358, 15.7624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.762448451452595\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0742,   3.6518,  -2.7567,   5.7154,  -2.7560,  -2.0959,   3.1344,\n",
      "         -14.1930,  -6.8568,  18.6803]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 18.68030016484236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8188,   0.6976,  -1.2588,  -4.2851,   3.1584,  -1.2065,   1.3836,\n",
      "         -13.6172,   3.9466,  12.8852]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.885204073619635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5445,   8.7574,  -3.8433,   8.0165,  -1.0742,  -3.2889,   3.1638,\n",
      "         -13.5880, -11.7671,  17.8790]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.879020923404223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0539,   4.3896,  -1.0273,  -1.6337,   3.2933,  -1.2025, -12.3512,\n",
      "          -9.1717,   2.3039,  16.7203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.720308935043217\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2857,   2.9374,  -3.1056,   4.4301,  -2.3043,  -2.3212,   2.1192,\n",
      "         -13.5205,  -5.4294,  20.6256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 20.62564292059152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7434,  5.1196, -2.2260, -6.1495, -3.2234, -1.8396,  4.8056, -6.2341,\n",
      "         -5.8646, 16.6149]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 16.614880868964512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6498,  12.3186,  -3.2727,   4.0686,  -4.1846,  -2.5151,   0.8203,\n",
      "         -25.1159,  -3.6672,  24.8395]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.839505679291182\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5078,  5.9205, -1.6212, -5.3125, -6.4192, -1.7466,  4.6839, -8.3809,\n",
      "         -4.5183, 18.4169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.41689307954658\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9707,   9.5291,  -3.5159,   9.5618,  -0.8468,  -2.5567,   3.9143,\n",
      "         -14.6879, -11.4156,  13.5797]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.579748113634956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1237,  2.5977, -1.1814, -4.1674, -4.8025, -0.9595, 10.4403,  1.2266,\n",
      "         -7.6953,  5.4366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.440329809417554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6688,   4.1216,  -3.2637,   0.8361,  -2.3589,  -2.6677,   3.2974,\n",
      "         -10.1166,  -8.3023,  21.9331]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 21.933097919637223\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3500e+00,  6.4037e+00, -1.5986e+00, -6.1410e+00,  7.2998e-01,\n",
      "         -1.1795e+00, -5.4585e-01, -1.0807e+01, -5.2574e-03,  1.5725e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.724590716921089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7570,  5.3056, -1.0482, -6.7764,  0.2198, -0.6816, -2.7883, -8.2828,\n",
      "         -1.6991, 16.6664]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.66640294947089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1481,  1.5308, -1.2494, -0.7468, -1.2879, -1.3432, -4.5455, -5.3426,\n",
      "          0.8010, 13.5048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.504790296824197\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7644,   1.1111,  -2.2191,  -0.0262,  -6.7167,  -2.1656,   2.5908,\n",
      "         -13.9691,  -1.1406,  25.4194]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 25.419354902129612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3075,  13.2284,  -3.0282,  -7.2135,   3.7175,  -2.1135,  -3.0655,\n",
      "         -20.5447,  -3.0874,  25.1598]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 25.159844160010376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3814,   1.3681,  -1.3782,  -2.1334,  -0.5968,  -1.2703,   1.0523,\n",
      "         -11.1171,   9.3161,   7.2123]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  7\n",
      "activation[8] = 9.316082469870302\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5364,  7.3871, -1.9522, -4.6616, -4.6661, -1.8924,  3.3104, -8.0922,\n",
      "         -7.0460, 19.4507]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 19.450657199855584\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2918,   9.7760,  -1.4840,  -7.5534,  -9.5480,  -1.1159,   8.9783,\n",
      "           1.1156, -14.3331,  14.9021]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.902092098285491\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7623,   1.4289,  -0.7078,  -2.2684,  -1.2418,  -0.5349,  -4.5330,\n",
      "         -18.8202,   9.9940,  18.5824]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.58241072561313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2982,   5.9257,  -1.4833,  -5.9970,  -9.2984,  -1.2378,  12.4224,\n",
      "           0.1480, -11.6969,  12.0113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.422382325529368\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9596,   4.2005,  -1.3240,  -1.5064,  -0.5294,  -0.8832,   5.9069,\n",
      "         -10.5195,  -2.5783,   9.8218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.82176017671677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3442,  12.2573,  -2.9606,   1.6864,   6.1628,  -2.3735,  -4.6689,\n",
      "         -15.4023, -12.7623,  20.3703]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.370332054750097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1290,  1.5297, -1.3228, -2.6675,  0.6832, -1.2005, -0.0255,  0.4590,\n",
      "         -5.3124,  8.5145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.514518912546922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6344,  11.7407,  -1.9615,  -6.6543,  -6.8260,  -1.5494,   9.7959,\n",
      "           1.0183, -17.4337,  12.6259]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.625949415292819\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5347,   6.9273,  -1.5994,   0.1993,  -3.5994,  -1.6124,  -1.1514,\n",
      "         -10.7268,  -2.2421,  15.7492]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 15.74915242633375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2183,   1.8501,  -1.3028,  -5.7994,   0.5051,  -1.3631,  -1.6847,\n",
      "         -11.4173,   7.7123,  13.4447]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.444709774946034\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5289,  5.0289, -1.8015, -2.2551,  4.4481, -1.6207, -1.3773, -5.9829,\n",
      "         -5.8674, 11.2946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 11.294590950919716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3514,   8.5279,  -1.4740, -10.2095,  -8.0124,  -1.2707,   9.4202,\n",
      "           1.2950, -13.9526,  16.3844]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.384367293224674\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4856,   2.5199,  -1.7814,  11.1364,  -2.3816,  -1.5842,   2.5103,\n",
      "         -11.6967,   0.9785,   2.6676]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 11.136376235824779\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7328,   7.2682,  -3.3900,   9.5251,   1.7462,  -2.6853,   2.1410,\n",
      "         -10.6829, -11.8292,  10.5201]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.520144569327691\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2097,   2.0780,  -1.4713,  -0.6061,  -2.4428,  -1.1476,   6.2654,\n",
      "         -10.9588,   0.1501,  10.5636]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 10.563586200907206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2902,  10.0092,  -2.6735,   2.7920,   2.7497,  -2.2436,  -4.4741,\n",
      "         -18.1701,  -9.4884,  23.6848]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.684767961206465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.4652,   3.1008,  -0.2708,  -2.5372,   6.4339,  -0.5160,  -5.4621,\n",
      "         -12.5043,   6.4408,   6.9517]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 6.951689110440672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1060,   6.0528,  -1.7177,  -3.1653,  -0.6333,  -1.2820,  -3.3980,\n",
      "         -19.2683,   6.4202,  19.1500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.149963327319245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3029,   3.2170,  -1.7744,  -1.9099,   1.4047,  -1.4651,   3.5819,\n",
      "         -10.9593,   2.4021,   7.2844]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 7.284446465009568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2642,   6.4656,  -2.9580,   3.5523, -10.6205,  -2.4759,  10.6266,\n",
      "         -20.3135,  -1.3987,  19.7752]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 19.775229871346315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1012,  10.2240,  -2.6305,  -0.4209,   9.5025,  -2.2474, -10.2047,\n",
      "         -27.9006,   4.2410,  21.8040]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 21.80402841527166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8907,   4.5104,  -2.5512,  -0.2358,   2.4387,  -1.9228,  -3.1297,\n",
      "         -12.6614,   0.1504,  16.6632]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 16.663223784867284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3325,  11.0586,  -3.0497,   5.0554,   0.6267,  -2.2874,   0.2972,\n",
      "         -16.3600,  -5.3070,  13.0006]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.00064451694378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0813,  5.1172, -1.1168, -7.6446,  4.7431, -0.9526, -6.4632, -1.5631,\n",
      "         -6.7086, 15.7393]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.739291881507484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9088,  3.5504, -0.9258, -7.4353,  1.2288, -0.8184, -6.9845, -4.6444,\n",
      "         -0.9382, 18.0682]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.068209111176426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6381,  2.2145, -0.6904, -6.1656,  0.5154, -0.5932, -3.4681, -9.0187,\n",
      "          8.5034, 10.5617]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.561735124954431\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4663,  -1.0250,  -1.9576,  -0.3396,  -0.2312,  -1.6813,   0.3540,\n",
      "         -12.6060,   4.2720,  14.1368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.13682454743058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2749,   6.8344,  -1.5628,  -5.9174,  -1.1566,  -1.4243,  -0.3752,\n",
      "         -11.5034,  -0.3436,  17.0950]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.095013059240667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7295,  3.4826, -1.8196, -7.4457,  0.5537, -1.8394, -2.3474,  1.1156,\n",
      "         -7.5541, 17.1154]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.115397579601648\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1667,  3.2085, -1.1746, -4.8603,  0.9560, -0.9192, -4.6697, -8.5928,\n",
      "          6.3896, 12.0822]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 12.082184562591054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3438,   5.8216,  -3.1477,   1.1336,   2.4836,  -2.4794,  -4.7304,\n",
      "         -24.4359,  -1.1004,  30.0430]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 30.04300665482733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8251,   4.4309,  -0.9598,  -0.5575,   0.6650,  -0.8659,  -6.4291,\n",
      "         -17.5919,   7.5628,  16.3573]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.357262755351428\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7792,   8.4466,  -1.9303,   2.6373,  -0.3541,  -1.7624,  -4.1558,\n",
      "         -13.0304,  -0.7597,  12.5835]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.583462232442235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3278,  3.6809, -1.2186, -6.4556, -4.6047, -1.1351, 10.8443,  2.2964,\n",
      "         -9.5504,  7.0117]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.844321656775525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1414,   8.1448,  -2.8488,   3.6552,  -1.6755,  -2.2733,   1.5595,\n",
      "         -11.6703,  -8.4140,  16.1889]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 16.188868031874495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1377,  5.7450, -1.1962, -8.8703,  0.3907, -0.9419, -2.6291, -5.6249,\n",
      "         -2.7646, 17.0410]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.04095816754158\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7684,  2.9800, -2.0410,  1.6342, -3.6619, -1.5409,  8.4863, -5.3932,\n",
      "         -6.9005,  8.1759]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 8.486265915409911\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4830,   8.7851,  -3.2204,   3.1695,  -3.5602,  -2.3260,   4.3440,\n",
      "         -18.9449,  -4.3330,  19.3788]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 19.3787687294591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4347,   6.3479,  -1.5310, -12.2199,  -0.8005,  -1.1274,  -6.6801,\n",
      "         -15.8338,   6.6234,  27.5279]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.527871499695255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2475,   4.8614,  -1.5865,  -4.1957,   7.3231,  -1.0853,  -8.3410,\n",
      "         -11.2656,  -0.6726,  16.7965]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.7964710656328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2149,   3.9959,  -1.5190,  -6.9744,   2.4696,  -1.3895,   1.6020,\n",
      "         -16.8928,   1.3477,  18.6002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 18.60018520186479\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3358,   4.9694,  -1.2438,  -6.4559,  -7.0069,  -1.1649,  13.2561,\n",
      "           1.8481, -10.5144,   7.3353]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 13.256097102554596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7952, -0.8054, -1.1043, -0.0533, -2.6386, -1.0104,  5.2593, -7.8017,\n",
      "          1.4847,  8.1243]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 8.124317222049344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4324,  10.1673,  -1.9045,  -6.9208,  -8.1219,  -1.2381,   9.1104,\n",
      "         -10.6002,  -9.3719,  20.1511]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.15107783737104\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7900,   3.0067,  -2.5871,  -8.4602,  -0.3118,  -2.0423,   1.0724,\n",
      "         -21.8378,   6.1825,  26.4782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.478181311059057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5476,   8.3902,  -1.6548,  -3.7999,  -4.2504,  -1.4167,   3.3860,\n",
      "         -11.3571,  -1.9923,  14.6903]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.690287402774478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2876,   5.5895,  -1.1821,   3.4131,   4.2232,  -1.4106,  -1.0331,\n",
      "         -15.5184,  -1.0263,   9.3507]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.350697226933082\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5169,  2.7114, -1.7968, -6.8224,  0.9736, -1.5439, -4.1038, -3.7910,\n",
      "          1.3073, 15.2816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 15.28162054108016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2664,   4.7936,  -2.5426,  -3.9616,  -2.7698,  -1.9178,  -2.1330,\n",
      "         -11.6672,  -5.0853,  27.5682]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.568228475985286\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1101,  3.7278, -1.1027, -5.4568, -4.0359, -1.0517,  9.7274,  1.4175,\n",
      "         -8.2741,  5.6458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 9.727352068705533\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4965,   4.4149,  -2.1754,   0.1319,   0.9463,  -1.5516,   0.5043,\n",
      "         -15.7920,   4.6407,  12.6880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.687989025054787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5685,   5.0670,  -1.6690,  -3.9407,   1.5239,  -1.5814, -10.8679,\n",
      "         -11.5538,  -2.8734,  27.0878]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.087823709684255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6651,  1.9086, -0.9578, -3.7964,  1.8867, -0.8060,  4.9968, -7.5288,\n",
      "         -2.6050,  8.7481]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 8.748053857464393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3328,  12.7286,  -3.8917,  11.7477,  -5.2719,  -3.1704,   2.2118,\n",
      "         -22.0188,  -9.6491,  20.8776]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.87759916488696\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6104,   8.0546,  -2.2394,   0.7082,   0.9712,  -1.7784,  -7.5338,\n",
      "         -23.4671,   4.1622,  23.8302]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.83015376183904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1951,   1.5844,  -2.8191,   7.6135,  -2.9188,  -2.2147,  -0.7825,\n",
      "         -18.5154,  -1.1714,  22.7757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 22.775671706376844\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3976,   5.0453,  -2.1514,  -5.9304,   4.1477,  -1.6069,  -2.7688,\n",
      "         -13.1280,   0.4012,  19.0248]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.024826813600882\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5881,   9.0941,  -1.9835,  -0.4956,  -2.9064,  -1.7624,   2.0013,\n",
      "         -18.8888,  -1.2437,  19.2579]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.257869898832826\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1143,  0.0258, -1.2001, -2.4978, -2.7575, -1.1729, -8.1782, -6.2363,\n",
      "          4.0321, 19.0722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.07217432489738\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2793,   4.1318,  -1.6757,  -8.2764,  -1.9238,  -1.4635, -10.2045,\n",
      "         -13.7194,   1.9297,  32.3119]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 32.31194248284502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0376,  4.1018, -1.2769, -8.6014, -5.1236, -1.2668, -3.8788, -8.0922,\n",
      "          1.7814, 23.3979]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.39786500957948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4192,   5.5993,  -1.7454,  -1.4559,   4.6417,  -1.3096,  -9.2144,\n",
      "         -11.8996,  -0.5749,  18.4070]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.407041206701667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7615,   6.2456,  -0.9266, -11.6870,   6.9798,  -0.6529,  -9.8972,\n",
      "          -5.7743,  -2.3780,  19.6002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.60023668843203\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0362,  4.3474, -1.1413, -8.1518, -1.5340, -1.0841, -9.5234, -6.6016,\n",
      "         -0.9537, 25.5933]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.593263288909817\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4952,   2.3711,  -1.9502,  -4.8921,   0.1257,  -1.6919, -13.1948,\n",
      "         -20.2249,   9.1661,  32.1955]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 32.19551185514351\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5710,  7.1690, -1.5988, -7.7840,  6.1771, -1.3646, -6.0569, -3.8467,\n",
      "         -9.9669, 18.7666]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.7665883078943\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6527,   2.8766,  -1.9410, -17.4393,   4.0602,  -1.7177,   0.8028,\n",
      "           1.1558,  -4.8421,  18.7940]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.7940001811171\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7692,   8.1445,  -2.0678,  -4.9815,   1.2628,  -1.7839,  -0.1616,\n",
      "         -14.0724,  -4.3147,  21.1269]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 21.12691383979774\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7197,  1.2708, -0.5082, -6.8576,  1.0621, -0.5938, -9.3529, -3.9876,\n",
      "          2.4303, 17.6875]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.68750152239437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2696,   2.6165,  -2.8141,  -1.0381,  -8.1814,  -2.6175,   6.6990,\n",
      "         -14.9913,  -3.2206,  26.8088]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 26.808822760798524\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0553,   1.4891,  -1.3126,  -2.1648,  -1.0815,  -1.3033,   2.1703,\n",
      "         -12.7277,   3.3774,  12.7782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 12.778227339127488\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9907,   6.8703,  -2.2411,   4.3015,   2.8890,  -1.9568,   0.5708,\n",
      "         -11.3210,  -9.5886,  12.4546]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.454595366517022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1037,  -0.6139,  -1.6315,  -0.7549,  -0.0328,  -1.2807,  -2.4081,\n",
      "         -17.9221,   9.6505,  17.4717]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.47165810529314\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2124,  3.2814, -1.3176, -1.0614,  1.7571, -0.9090, -1.6388, -9.3775,\n",
      "          3.3804,  8.2923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.292269150807062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4654,   6.1417,  -1.6170,  -5.6846,   5.5296,  -1.2360, -10.0287,\n",
      "          -8.5921,  -2.4423,  19.8056]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.80555173949615\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4094,   6.1002,  -1.4948,  -7.8110,  -2.8099,  -1.4666,   6.6518,\n",
      "           1.8241, -12.4317,  12.0829]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.082940156526487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3266,  12.9252,  -1.4231, -11.5375,  -0.7098,  -1.0360,  -1.1874,\n",
      "           2.5369, -18.7293,  20.0509]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.050875930360764\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0728,   8.1017,  -2.9409,   5.5762, -10.3122,  -2.1401,   9.7485,\n",
      "         -19.7973,  -6.9709,  21.0124]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.01240320417312\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3995,  1.5105, -1.7915,  0.2489, -2.3369, -1.4050,  6.3943, -2.7823,\n",
      "         -5.2452,  6.3598]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 6.394338415070105\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4138,  8.1516, -1.8102, -8.9874,  6.2324, -1.7429, -6.6960, -7.9834,\n",
      "         -3.4501, 18.0143]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 18.014288579158787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3280,  1.5482, -1.6264,  0.7295, -4.7385, -1.2111,  5.8665, -4.7134,\n",
      "         -3.5368,  8.6697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.669732599757209\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6118,  7.8293, -1.9302, -5.2578,  4.2738, -1.8486, -8.6747, -8.9036,\n",
      "         -4.0461, 19.9759]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.975912309528557\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8631, -0.4096, -1.0935,  1.0266, -1.6550, -1.1138, -2.8574, -7.9310,\n",
      "          6.6118,  8.3987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.398696044226519\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4722,   2.0784,  -1.6097, -13.4133,   6.6860,  -1.5826,   1.2916,\n",
      "           0.5084,  -2.0214,  10.0989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.09891830216483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7077,   3.6681,  -1.0877,  -0.3627,   1.8504,  -0.9492,  -7.3108,\n",
      "         -17.6361,   9.2933,  13.3150]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 13.314997770874044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2226,  12.7949,  -3.8143,   3.5710,  -2.1055,  -2.6661,   4.7771,\n",
      "          -9.8684, -14.7636,  14.9846]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 14.984622479282343\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9950,  4.7293, -1.2724, -2.5509, -1.2618, -0.9300,  2.9708, -7.3875,\n",
      "         -3.0512,  9.9790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.97895544459509\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9144,   2.7980,  -2.7570,   9.8198,   1.3557,  -2.3306,  -7.7347,\n",
      "         -23.3514,   5.2745,  19.4393]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.439307841523664\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0842,  5.2901, -1.2968, -0.7723, -2.2965, -1.2485, -1.9289, -7.4163,\n",
      "         -2.4870, 13.0786]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.078611323126498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5034,   7.3639,  -1.6932, -10.4895,  -3.9053,  -1.5059,   9.8980,\n",
      "          -0.8199, -12.3032,  14.4245]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.42453895028299\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8899,  5.6501, -2.3221,  3.9059, -2.2676, -1.7303,  2.8740, -8.1568,\n",
      "         -3.3870,  7.8093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 7.809294923178146\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6125,  15.1334,  -3.2379,   2.3207,  -7.4373,  -2.5623,   5.3660,\n",
      "         -11.6180, -17.7666,  21.9822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.982182759639514\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6930,   1.8934,  -2.0956,   1.0427,   1.2471,  -1.6879,  -4.6872,\n",
      "         -15.4322,   6.2007,  17.2737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.27365853692403\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4637,   8.7048,  -3.4563,   8.7301,   0.3651,  -2.6530,   1.9280,\n",
      "         -13.7100,  -7.7274,  10.6548]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 10.65479767341483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7161,   6.4533,  -2.2223,   0.7251,  -6.0677,  -1.8568,   2.9329,\n",
      "         -16.8385,   1.5021,  16.9556]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 16.955603798057485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0591,   8.1981,  -2.1878, -12.4792,  17.3749,  -2.0210,  -4.0217,\n",
      "          -6.6469,  -9.5983,  14.1900]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 17.37486201042012\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3875,   7.7700,  -1.4462, -11.0095,   3.4901,  -0.9081, -10.9529,\n",
      "          -7.5094,  -2.3181,  24.9884]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.988428845978778\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7141,   4.9867,  -2.5043,   6.5468,   3.6356,  -1.6949,  -2.4626,\n",
      "         -17.4272,   0.4314,  11.0567]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.05666133457153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1702e+00,  6.9382e-03, -1.4234e+00,  6.7336e-01, -5.2749e+00,\n",
      "         -1.0953e+00,  1.1172e+01, -8.6987e+00, -8.2752e-01,  7.4763e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 11.171616715051188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1371,   1.6540,  -1.6180,  -2.5368,   5.1663,  -1.3674,  -1.9635,\n",
      "         -13.6348,   1.4750,  15.3569]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.356857834494402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0316,  1.4929, -1.2761, -0.1695, -2.0026, -0.9900,  4.1954, -1.6477,\n",
      "         -4.5328,  5.7119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 5.711888700811495\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3307, -0.7865, -1.3247, -8.9433,  2.2315, -1.5673,  1.7279, -8.1461,\n",
      "          4.1472, 14.6553]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.655286665681272\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3363,   3.9209,  -1.6784,   0.6668,   0.5335,  -1.3496,  -2.0061,\n",
      "         -13.1356,   1.7445,  12.5290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.528950383297616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6833,   5.2356,  -2.9824,  -0.8040, -11.4863,  -2.4636,   9.5083,\n",
      "         -10.7587,  -4.5211,  20.5679]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.56787821955842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4223, 12.3355, -1.5105, -3.2554, -6.1066, -1.1729,  4.6319, -7.3067,\n",
      "         -8.7927, 12.9095]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.909478823662154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9048,  2.3714, -2.0388, -2.8112,  4.4265, -1.9183, -0.7352, -5.8528,\n",
      "         -4.6564, 13.2174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 13.217406933569018\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5271,  2.7305, -1.9572, -0.2626,  3.4412, -1.2646, -3.5169, -9.0848,\n",
      "         -2.5814, 14.1544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 14.154385328932433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9004,   1.7589,  -2.6776,   8.3241,   4.6893,  -2.2077,  -5.9769,\n",
      "         -21.9800,   1.8928,  19.2974]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.297423744165382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9763,  7.4486, -2.1932, -5.6628, -6.5036, -1.9673,  6.8744, -6.9611,\n",
      "         -7.1068, 17.9327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.93271579742937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3930,   8.6853,  -1.4994, -10.0407,  -7.7488,  -1.3563,  11.3304,\n",
      "          -0.4791, -12.2997,  14.0158]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.015849670722591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5065,   1.5545,  -2.0330,  -0.4689,  -0.5886,  -1.4982,   1.8794,\n",
      "         -15.3428,  -1.7322,  21.2123]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 21.21226036378599\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5610,  17.0602,  -3.2774,   0.4543,  -6.3960,  -2.6403,   5.5339,\n",
      "         -10.3269, -20.9717,  22.8111]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.81106936694266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6914,   7.4498,  -1.7303,  -3.9083,   4.4071,  -1.4872, -10.6055,\n",
      "          -3.0025,  -8.9760,  19.2865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.286465296408757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5618,   8.4734,  -3.2916,   5.6106,   5.8571,  -2.6461,  -7.4680,\n",
      "         -15.2934,  -7.6109,  18.6164]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 18.616416764224596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2923,   6.1268,  -3.0478,   6.7032,  -5.3798,  -2.3859,   5.7960,\n",
      "         -15.5801,  -1.5861,  12.0740]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.074014545111002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6538,   8.0301,  -1.7074, -10.2533,  14.1679,  -1.4480,  -4.9868,\n",
      "          -4.2441,  -9.3566,  12.1560]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  4 Label:  4\n",
      "activation[4] = 14.167937766193148\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4101,   1.3288,  -1.5769,   2.3125,   1.9361,  -1.2060,  -3.6907,\n",
      "         -11.7227,   1.1693,  13.1289]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 13.128925500849135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7946,   6.3604,  -2.6754,   4.2102,   1.9919,  -1.6121,   3.0003,\n",
      "         -14.5698,  -8.4862,  14.4923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.492291184625582\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [15]: loss = 14.500, accuracy = 12.50\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3056, -0.0329, -0.4580,  0.0823,  0.4709, -0.0660,  0.3818,\n",
      "        -0.5433, -0.0305], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3056, -0.0329, -0.4580,  0.0823,  0.4709, -0.0660,  0.3818,\n",
      "        -0.5433, -0.0305], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.1548,  0.9876, -1.3625, -1.4747, -1.1642,  7.5232,  1.2007, -2.7917,\n",
      "         -4.5334,  2.2004]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 7.523177694043394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4420,   4.3388,  -1.7275,  -5.2469,   5.0358,  22.0365,   1.3106,\n",
      "         -15.7179,  -2.0750,  -5.1355]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 22.036513540083536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6918,   8.7275,  -3.2272,  10.7654,  -3.2162,  23.7862,   3.9778,\n",
      "         -24.1059,  -4.1983,  -9.4170]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 23.786209461584786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4621,  -0.1934,  -1.6822, -13.2461,   6.0234,  13.6066,  -0.5173,\n",
      "          -2.5027,  -2.8777,   2.8265]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 13.606611411160888\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5509,   0.6672,  -1.9327,   3.8556,  -7.6732,   9.2525,   2.4023,\n",
      "         -11.6603,   3.9805,   2.1998]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 9.252526221058375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3368,   9.4189,  -2.7958,  -1.6783,  -8.6626,  23.8789,   7.0596,\n",
      "         -11.4985,  -9.6147,  -4.3754]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 23.878864325825134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7232,  4.2853, -1.7290, -6.2180, -3.0321, 14.8527, -2.3761, -6.7680,\n",
      "          1.2480,  1.6779]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 14.852662531619437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9476,  2.9001, -2.1915, -4.4642,  5.5656, 16.9541, -2.4765, -8.2994,\n",
      "         -5.8463, -0.2847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 16.954109698920284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1427,   7.7391,  -2.6461,  -3.7268,   2.6303,  19.9879,   6.7648,\n",
      "          -9.3960, -10.9388,  -7.4100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 19.987879765481726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2678,   4.8226,  -1.9480,  -3.4521,   8.2614,  28.2620,  -6.5932,\n",
      "         -12.6770,  -0.3632, -13.9109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 28.261990796553786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5138,  2.2029, -1.7594, -0.8848, -5.2384,  9.0963, 10.1962, -0.9204,\n",
      "         -7.3112, -4.0376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.196200654764265\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5784,  12.2906,  -1.7037,  -7.9442,  -8.7706,   9.7964,   7.8448,\n",
      "           0.9800, -16.6757,   4.9376]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.29063644515459\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6080,   3.9618,  -1.7241,  -0.3214,  -0.5851,  10.9719,  -7.6051,\n",
      "         -11.5413,  -1.7391,  10.1605]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 10.971886973775591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2629,  13.9995,  -2.9529,  -2.1758,   0.4698,  18.8056,   1.4947,\n",
      "          -8.6637, -16.7479,  -2.1648]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 18.80559429716977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6857,   8.0487,  -2.0013, -11.7297,   1.0796,  15.3959,  -6.1231,\n",
      "          -5.9975,  -3.3172,   6.5780]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 15.395891279612364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2646,   2.9602,  -1.9725,   0.5711,  -4.7829,  20.6537,   1.5566,\n",
      "         -11.7047,   3.6302,  -9.0741]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 20.653732950533865\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6010,   3.9745,  -1.8950,  -4.1146,   4.3792,  15.6726,  -0.5459,\n",
      "         -18.1881,   1.7632,   1.1909]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 15.672635912474428\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6452,   5.2798,  -1.9649,  -2.6907,   6.2212,  17.3647,  -7.2843,\n",
      "         -10.2998,  -2.2595,  -1.8076]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 17.364690044125425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2327,   7.6933,  -2.5428,  -8.1688,  -6.8173,  19.9866,  17.7140,\n",
      "          -8.1133, -14.6197,  -2.4897]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 19.986635260197666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0051,   1.0534,  -2.6153,   7.8181,  -1.4058,  31.9442,   2.8688,\n",
      "         -13.3230,  -1.9625, -21.8887]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 31.944248844098603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7279,   4.3134,  -2.5449,   1.9214,   7.8065,  34.1282,  -5.8993,\n",
      "         -21.7602,   0.8983, -16.9629]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 34.12824718297346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2738,   3.0523,  -1.6275,  -3.9619,   3.8158,  21.1543,   5.6212,\n",
      "         -11.8020,  -4.0735,  -9.3274]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 21.154291125663967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1238,   6.1452,  -1.8495,  -9.5813,   5.2963,  20.2651,   3.0692,\n",
      "          -5.2371,  -3.0769, -12.7703]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 20.26514754204839\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2837,   4.9066,  -1.3655,  -8.9107,   4.1538,   9.8183,   0.0716,\n",
      "           0.7208, -10.5934,   2.1050]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 9.818294328262814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4728,   9.9910,  -1.5956, -13.7405,   1.1166,   9.5457,   8.7410,\n",
      "           3.2257, -13.4880,  -1.8318]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.990963529216863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9873,   4.9193,  -2.2967,  -1.0618,  -6.7977,  16.3686,   9.8807,\n",
      "         -11.0080,  -5.6324,  -2.9477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 16.368597047753536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3607,   5.6472,  -1.5476,  -0.2678,  -1.6295,   9.8260,   0.7575,\n",
      "         -15.6962,   2.9713,   1.0650]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 9.826025717767864\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6218,  3.1174, -1.7937, -4.5261,  6.0325, 13.1966, -4.0567, -4.9865,\n",
      "         -6.0331,  0.4308]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 13.196550131348125\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5665,   4.5876,  -1.8641,  -2.7116,  -8.3663,  12.8422,   0.6989,\n",
      "         -10.9716,  -1.3465,   8.8244]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 12.842196792827304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1921,   3.0745,  -1.6012,  -3.0537,  -0.9755,  17.3214,   8.1027,\n",
      "         -12.8268,  -2.3903,  -4.8645]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 17.321397794412185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1712,   1.1534,  -2.5941,   5.7570,   0.6447,  32.0256,  -5.1831,\n",
      "         -27.4501,   7.0813,  -8.0635]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 32.02555874026116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0208,  7.1749, -2.2446, -2.3403, -6.0372, 13.2736,  7.6576, -7.8999,\n",
      "         -7.4755, -0.0382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 13.273566800016289\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7090,  11.8907,  -3.2756,   7.3784,  -0.5182,  23.4686,  -0.6779,\n",
      "         -17.7541,  -5.3431, -11.4109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 23.46856491519404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2956,   4.1957,  -1.4592,  -3.7881,   1.8838,  18.7639,   6.4322,\n",
      "         -11.7362,  -4.0229,  -7.6043]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 18.76393520486039\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7469,   6.7330,  -1.6946,  -5.6391,   2.6701,  18.8290, -11.8959,\n",
      "         -10.3582,  -0.3747,   4.1739]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 18.82896477305767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2779,   7.2797,  -1.6479,  -0.3935,  -1.2747,  23.3588,   9.0237,\n",
      "          -3.2386, -14.1421, -16.3117]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 23.358831605107493\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.5886,   4.6669,  -1.2266,  -1.2056,   2.6312,  13.3029,  -5.6132,\n",
      "         -18.2262,   6.4884,   0.7686]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 13.30290309839739\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4670,   4.7028,  -1.6612, -10.0431,  11.5871,  16.0643,  -0.6362,\n",
      "          -2.2056,  -7.0148,  -8.7796]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 16.064345653172097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1153,  2.8741, -0.9980, -5.1759, -4.4639,  6.7552, 10.3429,  0.9598,\n",
      "         -6.9333, -2.6455]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.342907925138205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0155,  11.1799,  -2.5248,   0.3598,   1.2820,  20.1827,  -1.6568,\n",
      "          -8.0153, -16.7100,  -1.6670]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 20.182678434314766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9879,   7.7320,  -1.2601, -10.3421,  -3.6772,   8.5805,   1.2918,\n",
      "          -3.3137,  -7.2399,   9.5295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 9.529475261515046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1067,   4.8759,  -2.7918,   5.5955,   4.9140,  32.4710,  -1.2874,\n",
      "         -17.5649,  -6.7897, -15.3931]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 32.470959155540385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2708,  -0.1328,  -2.6548,  12.0796,  -3.7971,  21.2725,   1.6684,\n",
      "         -18.1985,   0.8168,  -7.6808]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 21.272541943230873\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1947,   8.4525,  -2.5283,   0.6781,  -8.6156,  14.3979,   6.3835,\n",
      "          -6.8218, -11.5263,   2.0097]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 14.39789183203261\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.4668,   3.4696,  -0.9780,  -2.7307,   4.3075,  16.5065,  -2.1503,\n",
      "         -11.6029,   3.1998,  -9.1194]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 16.506487053142045\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2338,   7.2515,  -1.3776,  -7.0588,  -5.5344,   7.7316,   6.9957,\n",
      "           0.4244, -12.2077,   4.4513]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 7.7315955136624375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8576,   7.7037,  -2.4248,   1.3354,  -2.3693,  13.0206,   3.1774,\n",
      "          -4.5062, -10.4076,  -3.4569]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 13.020636353103257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3312,  -0.3458,  -1.7232, -13.7709,   3.7619,  11.3749,   0.0407,\n",
      "          -3.5519,  -3.5013,   9.0283]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.374926875357087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3737,   0.8263,  -1.9858,   8.4061,   0.3150,  21.2921,  -0.7786,\n",
      "         -10.8345,  -3.9555, -11.0100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 21.29211062574813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6550,   8.1570,  -1.6949,  -8.3975,  -1.8872,   8.5500,   9.4981,\n",
      "           2.3304, -14.4193,  -1.3598]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 9.49809461435945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8581,  1.4855, -2.4203, -6.4380, -4.8795, 14.0188,  5.5405, -5.9901,\n",
      "         -2.2117,  2.7986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 14.018772824008273\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2554,   7.6316,  -2.7341,  -1.7075,  -7.2664,  19.1444,   9.4788,\n",
      "          -7.2091, -13.6858,  -1.5386]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 19.144398926697885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0850,   7.8707,  -2.9176,   0.7850,   0.1991,  21.3503,   2.2361,\n",
      "         -15.7851,  -3.9181,  -8.1440]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 21.350268481859317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6268,   8.3666,  -3.1472,   8.5019,  -0.7258,  20.7963,  -1.9532,\n",
      "         -12.7240,  -7.3369,  -8.0132]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 20.79627465934876\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1327,  0.8607, -1.3452, -8.6064, -2.4753, 17.0849, -7.9608, -8.3877,\n",
      "          9.7952,  2.6515]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 17.084909365898074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2820,   8.2307,  -1.7813, -15.4607,   4.3544,  10.4089,  -1.3710,\n",
      "           3.9450, -16.4761,   9.2006]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 10.408919719422304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1622,   5.4677,  -1.9797,  -2.1193,   6.2559,  26.5474, -10.5421,\n",
      "         -23.7640,   6.8656,  -4.9208]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 26.5474268258176\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6838,  13.8956,  -1.8602,  -7.3393,  -7.1843,  10.3559,   8.6346,\n",
      "           0.3382, -19.3879,   3.6074]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.895636115409868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9110,  3.0434, -1.0135, -4.5149, -2.7574,  8.0262,  7.0086, -1.1464,\n",
      "         -5.4824, -2.6319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 8.026160049358122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5369,   2.2665,  -1.7837, -14.3668,   9.3365,  14.2303,  -1.6870,\n",
      "          -0.3051,  -6.2719,   0.1153]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 14.230252916421849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1637,  1.5322, -1.4848, -1.1967, -3.2917,  7.4113,  7.2199, -0.8192,\n",
      "         -5.9036, -2.6685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 7.411251383749981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5683,  13.4316,  -1.8997,  -7.3596,  -7.2264,  10.4511,   9.4018,\n",
      "           1.3946, -18.8442,   1.3414]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.431587180078164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2107,   7.9696,  -2.5836,  -1.1540, -13.4957,  17.3866,  10.1382,\n",
      "         -11.7219,  -6.0780,   2.3236]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 17.386597635266444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3381,  3.8918, -1.7266, -9.6443,  7.9219, 16.2144,  0.1661, -4.4551,\n",
      "         -7.0669, -3.3502]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 16.214359767215594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6954,  3.6055, -0.7039, -5.6762, -3.2844,  9.1283,  0.0542, -5.2548,\n",
      "         -1.3481,  4.7365]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 9.128309764656187\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3061,   5.3941,  -1.5451, -10.6943,  13.1062,  15.0330,  -4.3380,\n",
      "          -4.2383,  -7.3992,  -3.4245]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 15.033023426704744\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2205,   3.8681,  -1.7807,   2.1790,  -3.5079,  15.2614,  -1.1071,\n",
      "         -14.1419,   2.7896,  -1.6073]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 15.261351271946573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8144,   4.8395,  -2.4713,   5.9291,  -0.1183,  34.4010,   4.7925,\n",
      "         -11.6267, -10.4817, -21.8376]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 34.40095401602127\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8658,  6.6043, -1.0998, -9.1730,  3.6798, 14.1046, -0.7067, -6.5254,\n",
      "         -3.5250, -0.9611]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 14.104606075350716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4951,   2.7364,  -1.8286, -15.2108,   6.0947,  11.8949,  -2.2560,\n",
      "           0.4085,  -8.0838,   7.2293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.894942107596815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9881,   3.0420,  -2.1700,   1.9662, -16.4919,  15.0787,  18.7157,\n",
      "          -8.1984,  -7.4180,  -1.3974]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 18.715701795841582\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7177,  6.6629, -2.0551, -7.5749, 12.9141, 16.3639, -2.4196, -5.4371,\n",
      "         -8.3067, -8.2269]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 16.363869667526053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8150,  3.3717, -1.9206, -1.1834,  2.4055, 14.9261,  3.1261, -4.1151,\n",
      "         -9.5137, -5.4828]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 14.92608484240999\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7221,  2.6505, -1.9851, -3.1943,  4.7744, 18.9219,  1.5801, -8.2523,\n",
      "         -7.5730, -5.3238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 18.92189670768829\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1285,  0.7948, -1.2331, -0.5720, -1.6144,  8.1551, -7.0760, -4.4009,\n",
      "         -2.2478,  8.8600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.859959111133861\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1856,   1.5576,  -1.5358, -16.9469,   5.1135,  10.5688,   1.2001,\n",
      "           3.6338,  -9.0436,   6.2636]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 10.568789444898657\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2968,   1.0777,  -1.7554, -11.9887,  -0.1951,   7.7019,   1.3365,\n",
      "          -4.6210,  -4.0397,  13.2028]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 13.202784001965897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9176,  10.1937,  -2.6833,  -2.4705,  -3.7650,  15.6909,   3.3741,\n",
      "          -9.0728, -11.2630,   2.0508]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 15.690886169077167\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1746,   3.9423,  -1.6258,  -1.8782,  -3.7566,  11.5322,   3.2968,\n",
      "         -10.1050,   0.3606,   0.2196]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 11.532158378972586\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4885,   3.6915,  -1.6604,  -3.0001,  -0.6584,  15.4956,   7.4871,\n",
      "         -12.1954,  -4.7198,  -1.8653]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 15.495630939987029\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7547,  10.5355,  -3.2537,   2.9337,  -4.2338,  32.2091,  -0.3589,\n",
      "         -20.9620,  -3.4158, -10.4579]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 32.20910689814097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9557,   3.5912,  -2.5392,   8.4354,  -0.3657,  32.0722,   5.4444,\n",
      "         -15.1296,  -7.0945, -21.3452]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 32.07224626376483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4261,   3.7108,  -1.9356,   0.6496,   7.5999,  30.9113,  -4.0327,\n",
      "         -16.9173,  -0.9167, -17.0160]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 30.911256932359933\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5250,   7.8458,  -3.3336,   3.8512,   4.8153,  32.1983,  -3.1143,\n",
      "          -8.9502, -13.4755, -17.2095]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 32.19830531319636\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2591,  5.7676, -1.5319, -6.2091, -4.7289, 11.6823,  4.3380, -9.9535,\n",
      "         -3.6246,  5.4814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 11.682339976675381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7921,  3.2446, -2.0342, -6.5945,  9.8375, 14.4391, -4.5643, -4.1222,\n",
      "         -7.9480, -0.4040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 14.439134475285746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0604,  1.5896, -1.0674, -2.3160, -4.0494,  6.0127,  8.9804,  0.4337,\n",
      "         -6.0969, -2.5719]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 8.980446742171205\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3132,   4.1208,  -2.4833,  -0.6303,   3.7803,  19.7838,  -6.7227,\n",
      "         -12.5501,  -4.6451,   1.6538]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 19.783793543639916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.3650,   7.5521,  -3.9258,  -7.2014,  -0.9705,  32.1408,   0.9654,\n",
      "         -28.6778,   3.4865,   0.7263]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 32.140817286379416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9427,   4.7799,  -2.1501,   4.6341,  -3.9121,  21.2776,   0.7048,\n",
      "         -17.2281,  -0.4508,  -4.3123]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 21.277620249514367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7671,   6.8707,  -2.3015,   0.7253,  -7.5942,  13.5432,   8.4127,\n",
      "         -14.5553,  -3.1277,   0.1811]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 13.54324263431767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1311,   0.6436,  -2.2778,   1.4805,  -1.9394,  16.0218,   4.0800,\n",
      "         -13.8356,   0.2860,  -2.7327]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 16.02184707811006\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0692,   3.6203,  -1.4749,   3.0172,  -0.1850,  16.2096,   2.2996,\n",
      "         -12.5293,  -2.4529,  -5.9439]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 16.20964029357955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7309,  4.0056, -1.8950, -3.4283,  2.6493,  8.9742,  2.0411, -3.8886,\n",
      "         -9.2786,  2.0817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 8.974191169383987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6721,  5.3640, -1.7663, -4.4519, -6.9090,  6.1699,  7.5782, -9.3647,\n",
      "         -4.6591,  9.7264]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 9.726365238809365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9034,   2.5218,  -2.3037,  -2.7544,   2.9639,  14.9479,  -1.6479,\n",
      "         -12.3994,   3.2022,  -2.2711]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 14.947896826415032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6894,  8.2931, -1.5477, -4.6511, -1.1708, 12.1101,  3.1851, -8.8543,\n",
      "         -4.6394, -0.2861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 12.110148294880164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7087,   5.4528,  -2.5927,  -0.4851,   7.2507,  37.5933,  -2.9724,\n",
      "         -20.7546,   1.4227, -21.3769]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 37.59332778359993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7452,   5.4700,  -2.3617,  -1.9816,  -1.1155,  26.5210,   2.6104,\n",
      "          -7.6224,  -4.1676, -15.1006]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 26.521029067233272\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3100,   4.2095,  -1.7487,  -2.2882,   1.5796,  16.4249,   0.1689,\n",
      "         -17.6422,   3.6144,  -1.6334]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 16.424924985065232\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8033,  4.0172, -1.7434, -8.7113, -0.2641, 14.6404, -1.3694, -0.8170,\n",
      "         -6.9899,  2.5815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 14.640447593709563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7036,   7.4183,  -2.0493,  -1.2701,   1.6738,  21.9124,   0.4036,\n",
      "          -7.5203, -13.1848,  -4.6532]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 21.912386133389862\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7036,   1.9361,  -1.9403,  -2.3562,  -4.8771,  11.2823,  -3.8459,\n",
      "         -10.8347,   0.8758,  10.7988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.28233256518103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1848,   3.8309,  -1.6101,   0.4640,   0.5589,  25.0616,   1.9784,\n",
      "          -7.8601,  -7.3096, -12.4251]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 25.061557590569084\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1218,   6.2047,  -1.4331,  -6.3712,   2.8545,   6.7885,   5.2138,\n",
      "           4.3168, -11.1624,  -4.6605]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 6.788523848228559\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5293,  10.1691,  -1.7723, -10.4861,  12.4630,  14.7981,  -0.5896,\n",
      "          -1.6052, -13.4190,  -7.6463]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 14.798114422371379\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0497,   4.7494,  -2.3097,  -1.8435,   4.2115,  20.8420,  -5.4947,\n",
      "         -14.7951,  -2.4584,  -0.1262]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 20.841979921613476\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4313,   6.8249,  -2.0869,   1.4550,   5.9762,  25.8475,  -0.6629,\n",
      "         -18.6201,  -4.1029, -11.4064]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 25.847499527317037\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2238,  14.8285,  -2.6307, -14.8599,  -1.6643,  17.2607,  -1.7503,\n",
      "          -3.9053, -21.5651,  16.2696]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 17.260698257836097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.4306,   4.6857,  -3.9827,  12.9003,  -2.1785,  21.6453,   4.1105,\n",
      "          -9.4598, -12.7262, -11.6019]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 21.645281864978717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1019,   8.1905,  -2.5932,  -3.8305,   4.5142,  24.5689,  -0.1814,\n",
      "         -13.4072,  -7.3560,  -6.3122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 24.568939265168233\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4694,   0.1451,  -1.5939, -10.3221,   0.5409,  11.2806,   3.9655,\n",
      "          -4.0665,  -1.6545,   3.4570]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.280593962706874\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2153,   6.9264,  -2.3456,  -0.1507, -15.9910,  13.2467,  17.2210,\n",
      "          -5.1428, -12.2401,   1.0754]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 17.221033815085757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7545,   4.5302,  -1.4627,  -3.7540,   5.4673,  22.4495,  -2.8413,\n",
      "         -11.1607,  -1.1145,  -9.3187]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 22.44945300478131\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9340,  1.5442, -1.1272, -0.8154, -1.6174,  6.4566,  7.0544, -0.8341,\n",
      "         -5.0440, -4.6804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 7.054396669087307\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3716,   6.5845,  -1.4846,  -9.7919,  -6.2543,   8.9453,  10.8545,\n",
      "           0.4520, -12.0352,   3.3945]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.854516961570729\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1937,  14.3334,  -2.4037, -10.8880,  -9.8145,  14.7583,  14.7042,\n",
      "           0.2600, -21.6629,   1.9997]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 14.758295061964482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4479,   8.4555,  -2.1000,  -7.0435,   5.6245,  19.3981,   3.7977,\n",
      "          -2.5306, -12.5590, -10.5606]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 19.3981407629527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6685,   9.8913,  -3.3977,   0.1173,  -3.7272,  26.8349,   0.0980,\n",
      "         -23.1662,   0.8438,  -3.7918]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 26.83489041538416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1140,   7.0872,  -2.6825,   0.1951,  -5.5739,  19.7367,   4.2688,\n",
      "         -14.8977,  -4.8892,  -0.6052]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 19.7367425344991\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7658,   5.2886,  -2.1528,   0.8964,  -3.9643,  26.3608,   8.7685,\n",
      "          -4.6714, -12.1147, -15.2972]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 26.360826617697963\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5891,  4.1408, -2.1968, -3.5677, -1.5231, 16.7144,  2.8437, -9.1312,\n",
      "         -6.0958,  0.5635]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 16.714364321029237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7317,  1.9377, -1.9046, -1.0997, -4.8706,  9.0951,  8.6430,  0.0371,\n",
      "         -7.9998, -2.5390]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 9.095120186169687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5240,   4.2368,  -1.4197,  -6.9538,  -5.7421,   9.3476,  11.6059,\n",
      "           1.6178, -10.7196,  -1.0809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.605935435248982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5428,   4.5631,  -1.9567,   0.1973,   2.8907,  27.8664,  -4.4622,\n",
      "         -14.2959,  -0.3776, -12.3300]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 27.866397209038688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1248,   7.9456,  -3.0886,  -2.6308,  -2.4754,  16.5946,   2.5565,\n",
      "         -10.5020, -10.7754,   4.6226]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 16.594590916620994\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1201,  2.3068, -0.9623, -3.6489, -4.0181,  6.0651,  9.3386,  1.8300,\n",
      "         -7.2849, -2.8190]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 9.338575867204353\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6917,  1.7575, -1.8085, -4.6889,  8.9581, 18.0457, -2.4616, -8.3883,\n",
      "         -5.4559, -3.9642]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 18.04570721935695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6600,  -0.0466,  -2.3009,  -5.2798,   2.9749,  20.6413,   1.5563,\n",
      "         -19.5198,   5.4141,  -1.5773]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 20.641295979006088\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5255,  11.0687,  -3.2963,   5.2469,   0.1263,  31.4278,   6.0698,\n",
      "          -5.6083, -15.5293, -25.6759]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 31.42781867522635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5913,   5.0916,  -2.8262, -10.5939,   8.3294,  24.2406,   1.3239,\n",
      "         -13.1686,  -2.7715,  -5.9914]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 24.240612200569437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3193,   6.3797,  -1.3566,  -6.8032,  -9.0587,   8.9086,  11.5303,\n",
      "           0.0959, -11.7235,   2.8297]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.530270217459572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0272,  -0.8372,  -2.5259,   6.2992,  -3.4270,  27.2821,   0.2613,\n",
      "         -25.9032,   7.2914,  -4.5704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 27.282139089164087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5793,   7.6502,  -2.0618,  -9.5959,  12.7719,  19.8992,   0.3553,\n",
      "          -1.8401, -12.1397, -12.8801]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 19.899153132511348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2533,   7.4303,  -2.8580,  -1.6992,   2.6949,  21.6025,   1.6394,\n",
      "          -7.7961, -14.2151,  -4.9647]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 21.602520833949786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0003,   7.3432,  -2.7416,  -6.0108,   1.5375,  19.4279,   1.6715,\n",
      "          -7.1932, -13.6766,   1.9109]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 19.42787901078904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8339,   3.1804,  -2.2304,  -4.5989,  -5.3745,  15.0943,   3.6266,\n",
      "         -19.2374,   4.5586,   6.6520]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 15.094335286636927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0503,  3.4022, -2.1510, -2.6639,  4.8699, 18.2629,  1.4128, -6.4318,\n",
      "         -9.3739, -5.3706]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 18.262872878832734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1676,   3.6016,  -1.8070,  -6.3106,   3.1784,  13.4837,  -4.7042,\n",
      "         -14.6593,   5.0571,   3.8604]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 13.48371648973578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4162,   8.9106,  -2.8931,   0.9907,  -1.3627,  19.9579,  -0.3542,\n",
      "         -10.5066, -10.5102,  -2.3695]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 19.957862218245918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7359,  14.7669,  -3.7778,  -5.0372,   1.8009,  30.2858,   5.9866,\n",
      "          -6.7182, -22.6257, -11.2578]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 30.285827491102925\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4247,  11.5732,  -2.9019,   3.3899,  -4.1102,  16.3787,   4.1548,\n",
      "          -7.8983, -13.0050,  -4.8997]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 16.37867761642185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4657,  5.8946, -1.5207, -5.7759, -0.7846, 10.7165, -0.6059,  0.1759,\n",
      "         -8.4037,  1.7105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 10.716491775488414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3764,  1.7899, -1.6696, -3.1989, -0.6688, 14.9282,  5.1055, -8.3309,\n",
      "         -3.4587, -3.1426]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 14.928197444144093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1298e+00,  2.5147e+00, -1.2604e+00, -3.6852e+00, -8.7539e+00,\n",
      "          1.2194e+01,  8.9869e+00, -7.7858e+00, -6.0851e-01,  6.3249e-03]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 12.193913456748433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6440,   2.2874,  -1.1059,  -3.8764,   3.9863,  14.6862,  -0.2196,\n",
      "         -11.1133,   0.5281,  -3.0308]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 14.68618513093856\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1549,   9.2945,  -2.7556,   4.7333,  -2.4905,  23.8551,   0.1147,\n",
      "         -23.0290,  -3.2334,  -4.1952]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 23.85506212670716\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6980,   6.4908,  -1.9187, -14.9298,  12.2861,  14.8807,  -3.5137,\n",
      "          -0.8799, -15.3356,   4.4226]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 14.88066586518325\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4662,   2.1912,  -1.8561,   3.9270,  -1.3250,  19.4197,  -5.4142,\n",
      "         -21.7880,   7.6823,  -0.0345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 19.419669297830424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1472,  11.1312,  -2.5433,  -5.7550,  -0.7404,  16.1360,   4.8249,\n",
      "          -4.2179, -19.3590,   2.6928]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 16.136002658335844\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0028,  5.5850, -0.9345, -8.4486, -3.3179, 12.6273, -0.6583, -9.9612,\n",
      "          0.9432,  5.7226]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 12.627295492706725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3189,   5.6333,  -1.4628, -14.8588,  10.9149,  13.0930,  -2.7452,\n",
      "           0.4622,  -9.0428,  -0.5487]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 13.093009639436591\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8516,  2.1584, -1.1738, -8.4495,  1.3627, 19.9997, -6.0530, -9.0899,\n",
      "          9.1479, -5.5110]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 19.999656542205734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2495,   3.7804,  -1.4804,  -4.7559,   5.9755,  16.0592,  -1.4018,\n",
      "         -11.6898,  -1.7480,  -2.9964]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 16.059156751623902\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0180e+00,  7.3739e-01, -1.3018e+00, -1.8132e+00, -6.0828e-03,\n",
      "          1.1919e+01,  7.0703e+00, -9.8050e+00, -6.9457e-01, -4.1074e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 11.918726374502592\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7772,   3.7615,  -3.3405,  11.0385,  -7.8356,  24.4522,   5.8545,\n",
      "         -16.6965,   0.6090, -15.1967]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 24.452216595172455\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1866,  2.1932, -1.3050, -2.3677, -4.1523,  6.3783,  7.4145,  1.2194,\n",
      "         -7.2576, -1.2886]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 7.41450677110078\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0128,   8.3687,  -3.7472,  11.9960,   0.8742,  26.5846,  -0.8768,\n",
      "         -17.0060,  -5.2467, -17.6789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 26.584591758865496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2420,   4.9668,  -1.7220,  -6.1619,   3.8762,  16.7999,  -9.5628,\n",
      "         -16.1736,   4.6906,   5.4779]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 16.79988918567577\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8342,   1.2803,  -1.1400,  -1.0011,  -3.3533,  11.4469,  -0.7174,\n",
      "         -13.8276,   5.1871,   4.5046]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 11.446857784303754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7971,   3.3147,  -2.0470, -14.0103,   5.4415,  11.5383,  -0.8701,\n",
      "          -0.1083,  -9.8960,   8.0764]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.538305552782663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3220,   7.7031,  -3.0107,   6.3985,  -1.3913,  25.2940,   0.7605,\n",
      "         -12.4958,  -4.1746, -16.5465]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 25.29396702281121\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1310,   3.8635,  -3.0039,   1.9282,   2.2879,  36.4345,  -0.1713,\n",
      "         -20.3201,   2.6851, -19.1130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 36.4345192047914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2220,   4.7405,  -1.3132,  -6.4207,  -8.9460,   8.8345,  13.1165,\n",
      "           0.0503, -10.3620,   1.2225]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 13.11648912568379\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2031,   5.4018,  -1.7659,   1.4792,   6.3021,  16.2556,  -5.4879,\n",
      "         -17.3056,   5.5595,  -8.5598]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 16.25557131053563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2767,  14.6265,  -2.7714,   4.9870,  -6.8865,  22.2338,  10.3086,\n",
      "          -5.2187, -23.3250, -11.5546]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 22.233828224132733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1702,  1.6459, -1.3771, -1.0175, -0.0803,  8.5409, -0.2208, -8.7105,\n",
      "          0.2784,  1.5006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 8.540897467506753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7634,   3.5827,  -2.4088,   4.6485,   2.3001,  30.1320,   2.8189,\n",
      "          -9.4815,  -5.9680, -23.5528]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 30.131981841407015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2740,   5.1534,  -2.1814,   2.7065,   7.3694,  28.2188,  -5.2384,\n",
      "         -16.6812,   1.9851, -19.0598]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 28.21875636716828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2282,   4.7560,  -2.1635,   2.2746,   5.4176,  27.0338,   0.3610,\n",
      "         -14.2158,   0.9569, -21.3171]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 27.03383875574452\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7461,  1.6993, -0.8613, -2.5520, -3.3750,  6.5208,  8.8847, -1.4513,\n",
      "         -4.7403, -3.5202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 8.884711772596946\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0543,   8.8769,  -2.8391,   6.3738,   0.0416,  26.9659,   2.2075,\n",
      "         -14.3301,  -4.9467, -19.9120]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 26.965945688300707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4695,  1.7707, -1.7234,  1.3383, -4.0483,  8.2899,  4.3783, -4.2971,\n",
      "         -4.1939, -0.3084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 8.289864775129429\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1301,   8.0166,  -1.3234,  -6.5913,  -7.7435,   7.9088,  10.5984,\n",
      "           0.7146, -12.8430,   1.8378]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.598437636285214\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4872e+00,  7.2701e-01, -1.8675e+00,  1.3200e-02,  5.6992e-01,\n",
      "          1.4341e+01, -7.8939e-01, -8.0737e+00, -1.5614e-01, -3.8454e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 14.341321141726342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8105,   2.5207,  -2.5241,   5.1288,  -0.9323,  36.2091,   7.5131,\n",
      "         -13.9620,  -6.0164, -24.3202]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 36.2091354748001\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6734,  10.8196,  -3.2355,  -1.6881,  -8.6947,  18.0199,   6.3370,\n",
      "         -13.7612,  -9.7454,   4.5529]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 18.019924832531668\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5001,   0.7830,  -2.1299,   3.3839,   0.3045,  25.2817,   4.0217,\n",
      "          -6.5526,  -3.0903, -18.9238]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 25.28174403567383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4165,   5.6732,  -1.5122,  -1.6343,  -0.3430,  18.1644,   8.4245,\n",
      "         -11.6684,  -6.6360,  -7.8131]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 18.164350332002574\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7592,  1.4783, -2.0114, -3.8266,  5.0841, 18.9967, -1.2748, -8.9611,\n",
      "         -4.1324, -3.3998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 18.99671822594588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5693,  1.1220, -0.5568, -8.6029,  1.0349, 11.8929, -6.6538, -3.0362,\n",
      "          4.1319,  1.6233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 11.892939795573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8721,   6.7306,  -2.1656,   0.2108, -10.2352,  15.8186,   8.4576,\n",
      "          -7.9203,  -7.7271,  -0.9127]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 15.818592979886024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1833,   8.7543,  -3.8464,   7.0220,  -6.4337,  29.4068,   6.3926,\n",
      "         -14.8732,  -5.5057, -17.0130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 29.406787343292905\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6349,   7.8498,  -2.4044,   0.6584,   8.4020,  30.9870,  -9.1826,\n",
      "         -25.0119,   1.4522, -10.1672]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 30.986970581185624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4314,   4.9569,  -2.7180, -10.6427,   2.0856,  12.9685,   3.2864,\n",
      "          -5.1801,  -4.3303,   1.7543]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 12.96853469611909\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6905,  2.6784, -1.8753, -3.8421,  7.4282, 13.0669, -3.2950, -8.8605,\n",
      "         -4.2980,  0.4199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 13.066908825319347\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0160,   1.9550,  -1.1724,  -4.3426,  -0.5002,  10.8214,  -7.8745,\n",
      "         -13.3147,   4.9666,  11.0161]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 11.016072662392101\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2962,   6.3188,  -3.0316,  -0.3146,  -1.1953,  35.1542,   8.9702,\n",
      "         -14.7046,  -7.1619, -20.0112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 35.154205484888955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7929,   6.3520,  -3.1559,  -0.7833, -11.2991,  18.2334,  12.0240,\n",
      "         -14.9422,  -3.1418,   0.1354]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 18.233359923910953\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9595,  12.9326,  -2.1820,  -8.9365,  -0.5116,  11.5711,   6.7704,\n",
      "           1.5768, -18.7055,  -1.4004]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.932647309249603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8616,  4.7278, -0.7082,  1.5494, -3.5944,  6.1657,  3.6222, -9.2999,\n",
      "          0.5002, -1.0462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 6.165716884683707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9789,  17.0920,  -2.8159,   0.3030,  -1.7870,  17.7857,   0.1900,\n",
      "         -13.1088, -13.9877,  -1.3853]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 17.78571064988136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4151,   6.4416,  -1.8160, -11.1556,   1.7998,  26.0409,  -4.5912,\n",
      "         -15.0913,  -3.4590,   3.4757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 26.040949145870876\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8519,   2.3196,  -3.3852,   5.2927,  -8.4718,  34.0841,  12.8882,\n",
      "         -12.5065,  -4.2638, -21.8656]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 34.084144127484954\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2963,  -0.9424,  -1.2743, -14.2673,   3.8691,   9.2872,   3.2386,\n",
      "          -0.9136,  -0.6523,   2.9614]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 9.28724200231594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5120,   2.0846,  -1.5426,  -7.7255,   4.3181,  12.6192,  -3.8532,\n",
      "         -12.2532,   2.5546,   5.8496]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 12.619211938605043\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4316,   5.6994,  -2.8687,  -0.7699,   2.6997,  21.0165,   0.9048,\n",
      "         -15.0271,  -5.7499,  -3.8230]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 21.01645742411535\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2044,   3.3235,  -2.7773,   3.7723,  -4.0459,  22.3120,   3.2450,\n",
      "         -12.3361,  -7.1685,  -3.6496]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 22.312013695536663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2531,  6.4111, -1.4541, -8.5195,  2.6023, 13.6210,  0.0847, -9.7111,\n",
      "          0.4292, -1.5628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 13.62099850056117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3912,   5.2207,  -1.9047,  -1.8912,  -7.0117,  23.5364,  13.9971,\n",
      "         -15.3222,  -4.3650,  -9.1113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 23.53638584207242\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5095,   8.8220,  -3.0432,   7.6560,   0.2129,  21.8497,  -1.4122,\n",
      "         -13.9098,  -5.8231, -11.7535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 21.849671928093734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1045,   0.0727,  -1.3368,  -9.2511,  -0.1360,  22.2473,  -5.1618,\n",
      "         -13.0769,   8.7014,  -0.2156]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 22.247283867302663\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8178,   8.5771,  -2.5269, -22.2238,   1.2791,  14.9398,  -0.7101,\n",
      "          -2.1095, -13.5039,  17.6303]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.63031763887897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5791,   9.1564,  -3.0111,  -3.3330,   1.2771,  26.6694,   0.7996,\n",
      "         -24.2094,  -6.0598,   0.6136]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 26.66938627552218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7576,   5.5804,  -2.5096,   2.9534,   2.7629,  36.1129,  -1.6707,\n",
      "         -25.5971,   2.4882, -16.5350]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 36.11294882886185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0198,  3.9928, -2.2633, -7.7887,  8.4786, 20.0071, -1.3665, -5.9949,\n",
      "         -7.9271, -5.0600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 20.007082030177394\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0565,  0.7434, -0.9685, -7.4678, -0.5731, 16.3884, -3.1232, -1.9563,\n",
      "          2.9318, -3.3073]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 16.38841255607783\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7222,   5.5010,  -2.4219,   0.9576,  -2.1068,  31.6389,   6.8741,\n",
      "         -10.4568,  -4.9624, -21.9900]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 31.638863585501642\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9392,   4.0160,  -2.6894,   4.4977,   4.7784,  35.0780,  -1.8870,\n",
      "         -26.0673,   0.7996, -15.8894]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 35.07803955231546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7540,  17.6044,  -2.0745,  -6.2089,  -5.6752,  10.4903,   5.9793,\n",
      "           1.5390, -22.6848,   1.7792]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.6043912268942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0975,  2.4101, -1.1235, -4.9730,  0.2510,  8.4627, -0.5742, -4.4039,\n",
      "          1.7181, -0.2467]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 8.46273840772301\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3526,   8.8742,  -3.3609,   1.5803,  -8.7562,  21.5483,  10.2983,\n",
      "         -19.3212,  -5.3207,  -2.9789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 21.5482964182294\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3567,   8.6488,  -1.5581,  -0.5465,   1.2635,  12.8176,  -4.6194,\n",
      "         -15.7957,  -0.6515,   1.3817]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 12.817600804249887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5462,   3.1561,  -3.0059,   5.3727, -10.0643,  27.9633,  10.6534,\n",
      "          -8.8447,  -4.5859, -17.3066]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 27.96325051980261\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0436,  5.4334, -1.1837, -8.5886,  3.7971, 11.1541,  0.8949, -5.6197,\n",
      "         -4.7091,  0.6961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 11.154093907789626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1030,   2.3151,  -1.0920, -10.9413,   5.5697,  10.3923,  -1.4131,\n",
      "          -5.7234,  -1.7071,   4.6112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 10.392268819212982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9526,   2.7703,  -0.8604,  -5.6476,  -1.2862,  16.0332,  -5.3631,\n",
      "         -13.4829,   1.2771,   8.0435]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 16.03323506729647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7140,  7.6131, -2.2615, -4.1577, -1.3271, 16.6808,  3.5230, -4.6452,\n",
      "         -8.6636, -3.7629]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 16.6807979612178\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6405,   1.5465,  -2.1109,  -1.0495,   1.9668,  19.6678,   2.1994,\n",
      "         -18.5348,   4.8602,  -5.9045]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 19.66783475341226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5027,   1.7230,  -2.0574,  -2.7018, -12.5878,  23.0109,  20.3072,\n",
      "         -11.8984,  -4.7608,  -7.7764]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 23.010874810726943\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0316,   1.6914,  -1.2043,  -5.3194,  -0.7751,  11.6132,  -6.5291,\n",
      "         -13.0850,   2.6905,  12.1069]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 12.10691509883154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1773,   4.2420,  -1.3917,  -4.3910,   2.9159,  17.7179,  -0.9908,\n",
      "          -8.7417,   4.9801, -11.8822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 17.7179026304858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7453,  3.4938, -0.8620, -3.5780,  7.4925, 15.9963, -9.6050, -6.4566,\n",
      "         -5.4143,  0.3091]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 15.996259165373559\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1710,  10.2520,  -2.6162,  -5.1240,   4.3103,  17.2466,   8.0391,\n",
      "          -9.3051, -13.5428,  -7.0322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 17.246564325804915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5073,  0.9598, -0.7795, -1.4626, -1.6728,  3.4241,  3.8787,  0.2216,\n",
      "         -3.3130, -0.9015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 3.878690256244937\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8059,   3.0999,  -2.1268,  -4.9527,   9.1868,  21.2143,  -2.3144,\n",
      "         -12.6353,   0.1371,  -8.8261]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 21.21429547066144\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4073,  -0.0982,  -2.5249,  -0.4096,  -5.5087,  25.4351,   1.7997,\n",
      "         -12.3511,   0.2349,  -2.3335]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  1\n",
      "activation[5] = 25.435133040667065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0605,   4.1677,  -2.6628,   4.1736,   2.3896,  38.8610,   4.8227,\n",
      "         -18.6330,  -4.3920, -24.4483]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 38.861049185788666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6885,   3.7260,  -3.0091,   5.1016, -11.7085,  17.8666,   9.4238,\n",
      "          -9.9708,  -5.0695,  -3.5957]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 17.86663599659071\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7346,  14.1823,  -2.0660,  -7.4998,  -4.2580,  10.6861,   5.7824,\n",
      "           0.8216, -19.4009,   2.4267]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.182267513229096\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2580,  3.4372, -1.2439, -4.8816, -4.9351,  7.7360, 10.6230,  2.3653,\n",
      "         -9.1662, -2.8406]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.623028561586445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1982,  10.7151,  -3.0432,  -0.7611,  -3.4893,  21.3081,   9.5139,\n",
      "         -14.5470, -10.3078,  -6.0865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 21.308077617642596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5158,   2.1087,  -1.7952,   1.7743,  -3.9860,  16.0129,   6.1384,\n",
      "         -16.7741,   1.7644,  -2.2916]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 16.012893327350348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4789,   4.5457,  -3.0707,   2.3360, -11.3538,  22.8774,  12.1128,\n",
      "          -7.1298,  -6.4315, -10.8097]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 22.877447954719887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6673,  0.2482, -1.9270, -4.3559, -1.8361, 16.5131, -2.8602, -6.0076,\n",
      "          0.8384,  1.1791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 16.51307610123805\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0291,   0.3645,  -0.9186, -10.8478,   4.8193,  10.7339,   1.9055,\n",
      "          -9.1946,   2.5051,   2.3528]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 10.733897484231566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2540,   1.1185,  -3.1163,  12.0409,  -1.5843,  30.6867,  -0.8562,\n",
      "         -24.2544,   4.5622, -14.9350]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 30.68673541843757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2281,   9.9122,  -1.3258, -11.0496,  -0.7774,   8.7202,   8.8496,\n",
      "           1.7294, -11.6749,  -2.3545]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.912193193094065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7069, -0.3073, -1.1500, -1.3235,  2.0104, 10.8088,  3.5690, -9.0042,\n",
      "          1.9016, -4.8111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 10.808833742838342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3547,   1.1610,  -2.0204,  -2.4403,  -8.5268,  27.0131,  13.6501,\n",
      "         -15.6334,  -2.6263,  -6.9556]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 27.013124853041973\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5475,  2.5245, -1.7134, -0.4419, -9.0448, 11.7267, 11.8515, -5.3188,\n",
      "         -3.8603, -3.7798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 11.851515025556575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5742,   0.6032,  -1.8247,  -5.9281,   3.0438,  22.2665,  -1.7219,\n",
      "         -13.5016,   8.8298,  -8.6817]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  7\n",
      "activation[5] = 22.266494108028215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7438,   4.8133,  -2.1262,   3.0188,  -1.7924,  27.0700,  -3.9032,\n",
      "         -23.4602,   5.2146,  -5.3464]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 27.070036999330306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8684,   8.4148,  -3.5134,  -5.9125,  -3.3224,  26.2622,  16.1247,\n",
      "         -12.4127, -17.2566,  -5.3301]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 26.26219492063957\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5451,   0.6549,  -2.2113,  -0.6751,  -4.5622,  17.1472,   5.0213,\n",
      "         -24.2896,   9.6892,   1.3245]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  8\n",
      "activation[5] = 17.147181311068643\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1939,   3.6776,  -2.5864, -16.5410,   7.3580,  21.8744,   6.6064,\n",
      "          -4.0262, -12.5352,  -1.8523]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 21.874443103307577\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7738,   9.4936,  -2.1192,  -5.3900,  -5.9642,  14.7419,   6.1161,\n",
      "          -8.0972, -11.2888,   4.1617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  2\n",
      "activation[5] = 14.74187401369517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1686,   0.9911,  -1.5473,  -1.4629,  -4.0990,  13.7080,  11.8659,\n",
      "         -11.4052,  -1.3049,  -4.1743]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  6\n",
      "activation[5] = 13.708042236870499\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5553,   1.6143,  -1.8869,  -4.7549,   2.3129,  13.1504,  -8.9857,\n",
      "         -16.8013,   7.3049,  10.1430]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  4\n",
      "activation[5] = 13.150413403306366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3829,   8.2200,  -1.4920,  -8.0522,  -7.1176,   8.4534,  11.1486,\n",
      "           1.7192, -13.5106,   1.2239]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.148590009050958\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4622,   2.0877,  -1.6917,   2.9611, -10.7984,   9.8717,  13.9254,\n",
      "          -6.5722,  -5.7075,  -1.3315]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 13.925393842361439\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9360,   4.1282,  -2.0363,  -5.3327,   8.7685,  19.7742,  -5.4493,\n",
      "         -10.7036,  -5.9258,  -1.0588]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 19.774210587851833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9160,  6.0528, -1.9916, -0.7325,  0.7321, 12.4492, -3.8096, -7.8296,\n",
      "         -7.4340,  4.2597]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 12.449217128603372\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9065,   5.5161,  -1.8934,  -3.6188,   2.4566,  22.7722, -11.3079,\n",
      "         -18.5026,   3.8058,   3.4778]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 22.772217566539414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1132,   8.7415,  -3.3885,   8.5640,  -5.5780,  18.1978,   8.7827,\n",
      "          -8.8329, -12.5670, -10.9257]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 18.197770458045074\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7738,  3.7536, -2.0212, -5.3749,  4.8241, 17.3494, -6.8962, -9.1395,\n",
      "         -2.1451,  1.6857]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  9\n",
      "activation[5] = 17.34940633005342\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [16]: loss = 15.001, accuracy = 12.11\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3056, -0.0329, -0.4580,  0.0823, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4695], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3056, -0.0329, -0.4580,  0.0823, -0.0291, -0.0660,  0.3818,\n",
      "        -0.5433,  0.4695], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[-1.7168,  3.6606, -1.7717, -2.3833, -6.7070, -3.3648,  6.8213, -7.8640,\n",
      "         -3.7258, 17.3266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 17.326565252904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2850,   0.5244,  -1.4006,  -2.9097,   1.0901, -12.5252,  -4.4037,\n",
      "         -16.4252,   8.0870,  30.3089]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.308879111837644\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8337,  2.9309, -0.8489, -3.2951,  0.4740, -4.7021, -6.5338, -9.0019,\n",
      "          4.9145, 18.1570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.15704831399722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4475,   5.2989,  -1.5507, -13.4741,   8.7174, -11.3380,  -3.3798,\n",
      "          -2.4396,  -7.5868,  27.4169]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.4169203038221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0138,   6.6468,  -2.4762,  -3.8720,   2.4021,  -4.7561,  -0.9256,\n",
      "         -21.1425,   3.3556,  22.4531]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.453111619133473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8578,   2.7331,  -3.5788,   8.5079,  -9.9614,   9.4228,   7.9882,\n",
      "         -10.3827,  -4.8651,   3.4214]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 9.422770454617927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0332,   3.9010,  -1.5124,  -3.5855,   5.0773,  -3.5413,  -6.8943,\n",
      "         -14.1613,   3.6360,  18.9991]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.9991387886103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.0399,   9.4996,  -4.6322,   5.0858,   0.0468,  -0.9945,   7.5316,\n",
      "          -8.5833, -21.3569,  17.8235]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.82347137619698\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0745,   2.1399,  -1.3342,  -1.1587,   2.4903,  -2.9418,  -6.8574,\n",
      "         -15.6338,   3.1588,  20.7912]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.79119301000838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5723,  13.4572,  -1.8255,  -8.1280,  -3.0471,  -0.1437,   5.5977,\n",
      "           1.2852, -18.0181,  11.6174]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.45719714470843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8417,   4.9228,  -1.5833,  -1.6131,   4.4416,   1.1752,  -5.9214,\n",
      "         -21.2856,   7.2579,  13.8216]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 13.821594289555295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3923,   0.9084,  -1.6336,  -1.0822,   3.1435,  -7.3231,   1.3366,\n",
      "         -15.4397,   5.4880,  16.4698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.469822909630842\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0038,   4.0762,  -1.4573,  -3.1518,   6.0232,   9.2025,  -6.8464,\n",
      "         -15.2698,   1.9729,   7.1028]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 9.20250034274522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7289,  12.9818,  -2.0301,  -9.4867,  -1.7143,  -0.9816,   4.2630,\n",
      "           1.5123, -19.5125,  15.8705]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.87050952936623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7817,   0.3456,  -2.1990,   3.6325,  -7.4538,  -3.6791,  11.8573,\n",
      "         -16.1810,   1.1797,  14.7791]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.779092584568327\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6630,  10.6993,  -0.9812, -11.2112,   2.1783,  -2.4328,   1.8329,\n",
      "          -0.9339, -10.1007,  12.2963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.296261967897339\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5074,   3.0130,  -2.1448,  -1.6339,  -9.7464,   0.5971,  16.6843,\n",
      "         -12.0815,  -5.1287,  13.5852]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 16.684339380174627\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1783,   3.1398,  -1.4438,  -2.3141,  -3.0734,  -6.8966,  -2.2466,\n",
      "         -10.2612,  -1.7287,  27.4294]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 27.42941852823322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9808,  9.9687, -0.5766, -7.6555,  9.2974, -5.9136, -5.5495, -8.2086,\n",
      "         -6.0180, 16.9668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.966837757285397\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6389,   6.7346,  -3.3341,  -2.0305,  -0.8890,   5.4304,  10.6788,\n",
      "          -7.9124, -12.0894,   7.7880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 10.678832188473137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4096,   4.2744,  -1.7285, -11.3092,   7.2315,  -6.2327,  -1.1725,\n",
      "          -3.0233,  -6.8411,  20.4113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.411298768333467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4455,   4.6378,  -2.7095,  -7.5644,  10.2740,  -4.5318,   4.0288,\n",
      "          -3.4242, -16.6841,  18.0789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.0788544883761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3488,   4.5934,  -1.4210,  -3.9595,  -0.3981,  -8.3899, -11.2970,\n",
      "          -8.2417,  -0.7475,  31.4881]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.488095122748323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5082,   5.0194,  -3.0210,   4.4032,  -2.6325,  -3.5207,   4.6972,\n",
      "         -11.0294, -10.9294,  20.4122]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.41220461568364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9698,  4.4041, -0.9842, -6.2912, -8.0847, -1.0333, 12.1349,  0.3064,\n",
      "         -7.3994,  7.6504]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.134857336217827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2917,   7.9745,  -3.9296,  12.3803, -11.5545,   7.4035,   6.5461,\n",
      "         -20.1188,  -4.2868,   9.3129]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.38026375777791\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2541,   5.1557,  -2.5290, -12.0066,   6.0790, -10.5904,   1.6211,\n",
      "           1.2709, -11.4663,  24.9726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.972611018512822\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0508,   8.0485,  -2.8296,  -3.3014,   3.7152,   6.5293,  -2.5379,\n",
      "         -20.7749,   0.6456,  15.0622]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.062163186646552\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9907,  5.1455, -1.1514, -1.5667, -1.0088, -6.1940, -6.0381, -8.2884,\n",
      "          0.1306, 20.3561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.35613854774692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2870,   2.3626,  -1.6758,  -7.0348,   3.6537,  -9.7860,  -1.6362,\n",
      "         -12.7672,   2.1289,  26.4923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 26.492346043645753\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4083,   2.1658,  -1.8428,   1.8808,   5.3782,   3.8573,  -7.9673,\n",
      "         -18.1410,   0.7996,  15.5890]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.58899217508713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9779,   6.1166,  -2.2922, -10.1040,   6.9029, -18.9021,  -6.2379,\n",
      "         -11.6966,   0.3672,  38.7698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 38.7698256970136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9417,  1.7079, -2.3551,  1.3617, -3.3816, -6.9992,  6.3342, -3.0876,\n",
      "         -5.8055, 13.6557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.655659892335505\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3395,  13.6034,  -2.7775,  -7.3580,  -0.6248,   0.1540,   8.7981,\n",
      "          -0.1708, -19.9332,   9.7123]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.603395196791535\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1473, -0.9867, -1.2947, -4.4098,  0.6849, -8.5070, -0.4101, -4.8312,\n",
      "          0.8316, 20.3839]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.3838923703553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5461,   1.9651,  -1.7150, -15.4180,   7.0399, -10.1097,  -1.4675,\n",
      "           1.3707,  -5.2237,  24.9654]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 24.965440818214375\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2612,   5.0980,  -1.7553,  -1.2600,   4.6865,  -3.3426,  -6.0061,\n",
      "         -13.5862,   3.2041,  15.0975]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.097473206224352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2242,   1.9952,  -1.9009,  -3.5905,   2.0278,  -5.4799,  -0.1801,\n",
      "         -17.0347,   5.9215,  20.0983]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.098286507809803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6691,  3.5061, -1.2040, -1.9040,  3.3964,  6.1403, -1.0144, -7.0161,\n",
      "          2.5171, -2.8321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 6.140272085490555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7103,   1.5307,  -1.9088,  -5.4568,   4.3050, -17.4179,  -6.8924,\n",
      "         -18.6358,   8.0477,  38.6396]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 38.63962145440179\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2518,  10.8215,  -2.7844,   6.2482,   4.7302,   4.1584,  -3.6477,\n",
      "         -17.6146,  -5.0919,   5.9823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 10.821547817413645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6066,   8.1383,  -1.6845, -10.9671,   1.1023,  -3.5967,   5.6894,\n",
      "           4.8828, -15.3743,  12.6230]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.62302992902377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8670,   7.7547,  -1.9689,  -2.1457,   4.8032, -12.7658,  -8.1042,\n",
      "         -11.9732,  -2.1044,  27.7062]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 27.706225268296947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4183,  11.8628,  -2.9169,  -5.2631,   0.5784,   5.6322,   9.8572,\n",
      "          -2.9628, -19.7868,   4.9592]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 11.862770970763407\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7139,  3.4920, -1.7184, -3.2287, -6.9605, -6.4359, 11.3711, -1.0971,\n",
      "         -8.1021, 13.6996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.699640032769393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4568e+00,  2.6551e+00, -1.5117e+00, -1.3063e+01,  6.0274e+00,\n",
      "         -1.1634e+01,  1.6091e-02,  1.7584e+00, -3.0597e+00,  2.0866e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.8664092493861\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0319,   4.4888,  -2.2995,  -1.9032,  -7.3913,  -8.1801,  10.7914,\n",
      "         -12.6939,  -3.3376,  23.9039]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.903881281883333\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7656,   5.6650,  -1.9699,  -3.9642, -14.9476,  -2.1418,  18.2811,\n",
      "          -6.6984,  -8.9158,  17.1106]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 18.2811068450392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3576,  3.0361, -1.3597, -1.3964, -9.9506, -0.2616, 10.1472, -3.8733,\n",
      "         -5.6366, 11.0851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 11.08514451571889\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6738,   7.3708,  -3.5383,  -3.0105,   1.8010,   0.5016,   7.4393,\n",
      "         -11.1420, -10.0216,  14.3300]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 14.330043655679761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1190,  2.0530, -1.1703, -0.5850, -2.3904, -6.7860, -1.5330, -9.0962,\n",
      "          0.8354, 19.4972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.49720696962682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1412,  12.1131,  -3.7283,  -5.8548,  -3.6683,  -0.6331,   6.7410,\n",
      "          -9.7834, -16.8722,  23.8563]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.85631336931217\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0337,  3.3785, -1.3476, -9.0750,  0.7934, -7.1811,  0.0253, -9.7033,\n",
      "         -0.0787, 25.1420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.141979653228336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7674,  11.5091,  -1.8906, -10.1673,  -2.0979,  -0.5439,   7.6120,\n",
      "           1.3762, -17.5981,  12.6144]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.614406188752668\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0672,   2.4092,  -1.7644,   1.9820,  -5.5311,  -0.7019,   0.6810,\n",
      "         -16.6277,   4.7827,  17.2367]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.23670541708912\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8514,  12.1454,  -3.1461,  -4.1352,  -0.2945,   3.6000,   9.0913,\n",
      "         -11.4505, -16.5766,  13.9297]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.92967706244606\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7670,  4.3854, -0.8431, -5.1559, -7.5700,  0.2815, 10.5470,  0.2385,\n",
      "         -6.4544,  5.1472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.546989668688823\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6199,  9.9902, -0.7603, -4.6748,  2.9433, -2.1078,  1.1527, -5.9312,\n",
      "         -7.7202,  8.1873]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 9.99020380067267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9749e+00,  3.0413e+00, -2.3289e+00,  7.1044e+00, -5.6875e+00,\n",
      "         -5.1962e+00,  1.7445e+00, -1.2322e+01,  1.1501e-02,  1.5107e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.10705536494144\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2287,   6.9063,  -1.5084,  -4.6634,  -0.2590,  -1.3856,   7.5913,\n",
      "         -11.8544,  -7.1159,  15.4112]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.41120049759631\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1149,   1.4802,  -1.8185,  -0.2257,   6.2835,   7.1689,  -2.9739,\n",
      "         -14.8273,   2.8051,   3.7322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 7.168924999589381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8084,  13.0701,  -3.3915,  -2.0557,   0.8740,  -7.8847,   3.4283,\n",
      "         -14.6361, -13.5927,  27.4311]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 27.431109484708596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4699,   6.4667,  -1.7683,  -0.9192,   0.8470,  -4.0131,  -6.5499,\n",
      "         -14.6926,  -0.8074,  23.2091]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.209142916142437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9822,   3.3538,  -2.5665,   6.2777,   3.7367,  16.0042,   1.1634,\n",
      "         -19.2991,  -2.3786,  -2.4353]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 16.004178765349135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1690,  2.6900, -2.3503, -1.8245, -6.0111, -9.4404,  7.8954, -2.5807,\n",
      "         -7.8057, 20.8159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 20.81586009872626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0869,  3.9622, -2.5489, -5.3785,  6.6930, -8.2607, -1.8283, -9.5176,\n",
      "         -4.1059, 23.5634]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.563393131306437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2521,  2.8164, -1.4778, -4.1122, -3.5611, -2.3958, 12.3383,  0.1997,\n",
      "         -8.3317,  5.6737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.338308243230177\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8978,  17.8249,  -2.2563,  -8.4473,  -0.1923,  -0.4163,   3.2395,\n",
      "           2.9508, -23.6954,  12.0283]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.824928682730324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6687,   5.6372,  -1.7659,  -7.2457,   6.0497, -16.9544, -15.3223,\n",
      "          -5.9314,  -4.2442,  41.4130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 41.41302604372706\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8697,  12.0032,  -0.9609, -12.8426,  -0.0769,  -0.1482,   4.6005,\n",
      "          -0.2957, -11.6224,  10.3623]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 12.003171202359685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3799,  3.2584, -1.4643, -6.1889, -3.6139, -0.7265, 11.6718,  0.9392,\n",
      "         -9.2793,  6.3850]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.671773215445906\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1329,  10.7520,  -2.5222,   0.4533,  -3.1204,  -8.6328,   6.6264,\n",
      "          -2.0818, -14.7578,  16.4003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.40032826921955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0160,   2.1616,  -2.7526,  10.0380,   3.8066,   6.7315,  -4.3822,\n",
      "         -26.8716,   3.9419,  10.3490]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 10.349020774452239\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7399,   7.4225,  -1.8154,  -9.0072,  14.1218, -10.4411,  -4.5281,\n",
      "          -1.9799, -10.5063,  18.6360]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.635985937964474\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5559,  1.0769, -0.6589, -2.6333, -0.9550, -3.2026,  0.5790, -3.1268,\n",
      "          0.1028,  9.6366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.636583050699562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7850,   4.0901,  -2.5071,   3.4951,  -2.3546,   3.3844,   5.5010,\n",
      "         -17.0264,  -5.3806,  13.3221]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.32208998261204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1677,   3.3506,  -1.5590,  -4.0328,   4.4421,  -7.3834,  -6.0833,\n",
      "         -10.0549,   1.2855,  21.7342]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.734154251505576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3105,   1.5555,  -1.4634,  -4.7101,  -1.1918,  -9.5901,  -1.1452,\n",
      "         -10.9185,   8.7424,  20.5993]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.599288629995126\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5470,  4.2329, -0.5998, -6.4127,  3.0833, -5.1876, -5.0022, -9.2243,\n",
      "          4.8067, 16.2383]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.238349661386376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4318,   0.2822,  -1.8192,  -8.7213,   2.8346, -13.5888,  -5.3435,\n",
      "          -8.2029,   3.6281,  33.0467]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 33.04669849245888\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8528,   7.6827,  -2.2539,   3.8440,   0.8173,   1.7691,  -1.8912,\n",
      "         -17.6015,  -2.2594,  11.9285]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 11.928469560775772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0905,   7.3465,  -2.7684,  -0.3089,  -2.6178,  -0.8836,   5.7070,\n",
      "         -11.5286,  -8.1581,  16.4141]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.414133760794613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5291,   8.1095,  -1.5083,  -5.5437,   4.1428,  -3.8142,   5.7231,\n",
      "           1.2325, -12.6350,   6.1292]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 8.109543579123818\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6583,   4.4372,  -3.0819,   6.5693, -12.4843,   5.8874,  13.0467,\n",
      "          -7.6768,  -6.5179,   3.2657]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 13.046684321211224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5135,   4.6009,  -1.7612,   0.0665,   3.4472, -10.5289,  -7.6379,\n",
      "          -8.9133,  -4.0113,  26.0963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 26.096293830229612\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1914,   4.0420,  -2.9796,   3.3224,   3.4652,  11.1282,   4.7077,\n",
      "         -15.2771,  -7.5587,   3.6021]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 11.128189359648893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9938,   3.1169,  -1.3594,   2.1139,  -8.8225,  -0.2876,   6.8438,\n",
      "         -10.2754,   2.1861,   7.6716]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 7.671649655155585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3309,   9.7341,  -1.7827,  -9.3749,   4.4870,  -6.1211,  -0.8852,\n",
      "          -3.9734, -13.0306,  22.2116]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.21163745483326\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.1902,   2.5730,  -0.4335,  -3.7750,   1.9854,   0.8593,  -5.5114,\n",
      "         -11.5370,   5.1606,  12.0699]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 12.069930855235757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6487,  7.8015, -0.6253, -9.3374,  3.0242, -5.8388,  0.2970, -0.1882,\n",
      "         -6.8662, 12.6524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.652352974837497\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8771,  2.8306, -0.8540, -5.1584, -5.1494, -1.5919,  9.7765,  1.3918,\n",
      "         -6.6182,  6.1681]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 9.776537883101458\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7699,  12.8008,  -2.6261,  -5.1896,   2.6939,  -1.5947,   3.5710,\n",
      "         -10.1769, -15.5576,  18.8086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.80858873863058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1581,   5.1740,  -1.2191,  -2.7533,  -2.6496,   0.3822,   4.7834,\n",
      "         -12.4074,   0.4476,  11.0570]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.05702377261501\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2746,   1.4848,  -1.5536,  -9.0802,   3.8736, -14.9534,  -4.3814,\n",
      "          -0.7958,  -2.0943,  28.8964]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.896422947799945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1309,   6.3956,  -1.1920,  -7.1335,  -6.4057,   1.2864,  10.0197,\n",
      "           1.6521, -10.4385,   6.3645]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 10.019685320735832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.0614,   9.3279,  -4.7060,  14.1483,  -8.1753,   2.7282,   7.4387,\n",
      "         -15.2024, -11.4627,   9.8286]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.148298185162128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8555,   4.9630,  -2.0787,  -8.1290,  -2.1451,  -3.4969,  11.4217,\n",
      "           1.7107, -15.8246,  15.1618]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 15.161820262060674\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7692,   9.2096,  -1.7768,  -9.8923,   0.4557,  -2.6582,   6.2360,\n",
      "           2.1595, -14.7053,  11.8785]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 11.878492839272328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0157,   3.2031,  -2.5595,   1.6937,   3.1739,  -5.9293,   0.8745,\n",
      "          -6.8149, -10.2746,  18.9709]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 18.97089475136227\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5824,   4.0411,  -1.5093,  -8.4872,   7.9909, -15.2914,  -5.2287,\n",
      "          -8.0926,  -1.2802,  30.2585]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.25849468545883\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1897,   5.1364,  -1.5487,   1.7475,  -0.6218,   4.7288,   1.0069,\n",
      "         -12.1084,   0.8735,   2.0939]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 5.136402890712047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4252,   4.6722,  -1.4581, -12.3833,   6.5749, -12.3798,  -2.0438,\n",
      "          -6.9838,  -3.0006,  29.0812]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.081242974806546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5654,   4.8670,  -2.0748,   2.2334,  -3.6995,   0.9164,  11.1176,\n",
      "         -15.3538,  -5.0781,  10.2512]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 11.11763192016859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.5228,   5.0882,  -4.1456,  16.3415,  -7.4611,   3.3597,   4.4858,\n",
      "         -13.7427,  -8.0890,   7.2153]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 16.341474227090405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1485,  4.0794, -1.3210, -5.2839,  0.1495, -8.7992, -1.3239,  0.8374,\n",
      "         -6.0091, 18.6332]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.63316075676785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1938,  12.6223,  -4.4743,  -5.9298,  -2.2752,   2.8660,   6.0717,\n",
      "         -21.0780,  -8.3345,  25.7743]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 25.774294166500415\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9108,  1.8106, -1.1706, -3.2321, -1.9978, -2.2345,  8.0424, -0.2459,\n",
      "         -5.6988,  5.4358]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 8.04242864612992\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1950,   8.6323,  -2.8006,  -4.5577,   3.3071,  11.4748,  -0.8602,\n",
      "         -12.5583,  -6.9182,   8.4887]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 11.474848956569174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6450,   3.2676,  -3.0443,   1.2698, -12.1870,   0.2808,  14.5121,\n",
      "         -10.4031,  -4.6595,  13.6476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  2\n",
      "activation[6] = 14.512098789117214\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4956,  13.4683,  -1.8126,  -8.5307,   6.9214,  -0.8285,   2.2946,\n",
      "           1.7724, -19.9855,   8.4344]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 13.468341903974068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3049,  5.1958, -1.1901, -0.1894, -2.1118, -8.3135, -8.7178, -7.3900,\n",
      "         -0.2192, 24.3744]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.374357645382897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2439,   1.2902,  -1.3143, -10.8517,   6.2519,  -7.3972,  -3.3294,\n",
      "           0.4310,  -3.3857,  19.5154]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.51536606135336\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4313,   9.5001,  -2.8468,  -3.1871, -11.5626,   2.1601,  11.2056,\n",
      "         -10.6676, -11.9296,  20.0478]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.04776606334226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6407,  2.1811, -1.8968, -3.7609,  2.1960, -5.8503,  0.8664, -2.5079,\n",
      "         -8.4862, 18.7441]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 18.744050746785057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5002,   6.8460,  -2.0679,  -1.4618,   2.2397,   2.6430,   1.9951,\n",
      "         -13.1155,  -2.9126,   9.3891]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 9.389104242475124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4044,   0.9596,  -1.7947,  -7.9187,   3.0167, -14.9988,  -7.1112,\n",
      "          -8.3767,   3.2623,  34.9950]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 34.99502786322827\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5737,  3.5726, -1.5626, -5.7518, -3.6449, -4.3267,  5.6199, -0.6792,\n",
      "         -7.0694, 15.5375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.537522513186014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6211,  11.6584,  -2.7956,  -5.3812,  -2.2374,   2.5663,  10.4788,\n",
      "          -0.9396, -19.9085,   8.7215]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 11.658379187079687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5523,  2.3749, -0.5518, -2.1405, -2.9167, -5.0847,  2.0552, -9.3204,\n",
      "          3.2534, 14.1947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.194678044594538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8256,   4.6303,  -2.2558,  -5.5829,   2.6456,   5.0802,   8.5808,\n",
      "          -7.3296, -10.8195,   7.0745]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 8.580770849264088\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5475,   4.2783,  -1.8661,   6.1318,  -3.6045,  11.4378,   3.6438,\n",
      "         -15.8094,   2.0426,  -3.4333]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 11.437813361802371\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2320,   0.0694,  -1.6088,  -8.0319,   2.2565, -14.7764,  -5.2033,\n",
      "          -5.5728,   1.4975,  32.9121]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 32.91211411643635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5455,   4.3848,  -1.6689,   8.5456,  -4.7296,  11.6847,   4.7107,\n",
      "         -17.8225,   1.2121,  -3.1307]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 11.684728494338952\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8995,   3.8230,  -2.3212,   2.0765,   2.7814,  -5.1781,  -7.1581,\n",
      "         -19.1575,   0.1014,  27.3431]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.34312387165235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8426,   4.6297,  -2.5380,   5.5186,   2.7311,  15.2677,   4.2040,\n",
      "         -17.0339,  -4.5825,  -4.8009]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 15.267733237406565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3129,   0.5211,  -1.8349,  -2.1610, -12.1884,   2.7952,  19.7255,\n",
      "          -9.9723,  -3.9477,   9.4125]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 19.7255120627929\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5989,   5.2157,  -1.4945,  -3.7116,   1.5906, -10.0009, -12.2453,\n",
      "          -6.6713,  -2.8711,  31.9401]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.9401107730637\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.9578,   6.4303,  -4.7006,  14.3250,  -3.0349,   2.3381,   1.2913,\n",
      "         -17.3171,  -7.9720,  12.3162]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 14.324970517313366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2614,  3.7370, -1.5533, -1.7985,  3.9648, -5.6726,  3.0423, -2.1854,\n",
      "         -8.4489, 10.3914]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 10.39142028379763\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7171,  11.8010,  -2.0827, -10.1158,  -2.8786,  -1.2874,   5.0169,\n",
      "           1.7379, -18.1832,  16.9056]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.90563908969304\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4141,   6.9968,  -1.7177, -13.2027,   8.0802,  -0.9117,  -2.7397,\n",
      "          -3.0078,  -1.9605,  10.8088]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 10.808803837671208\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8335,   0.1207,  -1.1817,  -6.3916,  -1.5740,  -4.0273,  -5.4177,\n",
      "         -12.7561,   9.1225,  23.5295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.529506574347675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7560,   7.6584,  -1.6347,  -5.9197,   4.0682,  -6.2102,  -5.1840,\n",
      "         -10.3547,  -2.4302,  22.9898]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.98975832287555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1775,   4.4503,  -2.2219,  -4.4909,   8.0600, -14.8569,  -5.3445,\n",
      "         -11.9100,  -7.1640,  36.1535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 36.153507720001826\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8765,  1.7364, -2.1940, -4.8718, -2.4724, -4.3172,  3.1505, -8.4557,\n",
      "         -4.5991, 23.5228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 23.52278437212571\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0939,   0.8409,  -1.6164,   1.9428,  -4.5973,   1.5710,  11.7534,\n",
      "         -10.8478,  -2.8245,   6.5959]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  6\n",
      "activation[6] = 11.75340053015088\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0827,   6.4819,  -0.8227,  -5.5898,  -1.5308,  -5.4289,   3.2278,\n",
      "         -10.8795,  -0.0979,  16.9952]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.99515633832366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0305,   5.3464,  -3.7829,  10.0234, -12.5524,   4.8459,  13.7073,\n",
      "         -19.2700,  -2.6502,   8.6462]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 13.707301520441526\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8404,  4.2135, -2.5991,  2.5328, -3.8035,  9.2191,  7.6113, -8.2650,\n",
      "         -1.0113, -4.7790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 9.21912619677141\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.1612,  11.1024,  -3.9739,  10.6955,  -3.6036,   7.9996,   2.3644,\n",
      "         -12.3294,  -9.8773,   1.1249]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 11.102368479902916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7620,   5.4217,  -1.9823,   2.9116,  -0.5029,   1.3303,   0.6087,\n",
      "         -13.6491,  -1.5848,   9.3880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.387988141801772\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5260,  11.2093,  -1.7278, -10.1051,  -6.4021,  -0.6275,   5.7267,\n",
      "           0.9885, -16.1118,  17.8086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.80860282094472\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0004,   7.4317,  -2.6158,   3.9557,  -5.6026,   1.5703,   5.8446,\n",
      "         -13.0524,  -3.3878,   8.3406]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 8.340557743144316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0869,   9.6764,  -2.7659,  -0.9649,  -7.5458,   3.4660,  12.1386,\n",
      "         -14.9327,  -2.5724,   7.1839]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 12.138593860976238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8684,   6.0488,  -1.7753,   1.7142,  -0.2917,  -9.2606,  -3.8862,\n",
      "         -13.4125,  -2.3531,  25.3979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.397873541050647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5244,  11.4119,  -2.1746,  -5.5896,   4.3243,  -0.6003,   2.2223,\n",
      "          -6.9364, -15.3663,  14.7808]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.780827238194686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0162,   1.2841,  -0.9904,  -5.5046,  -1.1662,  -7.8786, -11.8445,\n",
      "          -5.4682,   2.0212,  30.4085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 30.40848783644757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3957,  11.3866,  -2.8437,   1.1398,   1.0913,   8.1671,   1.3722,\n",
      "         -21.1890,  -9.2200,  14.3685]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.36854998282188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2397,   5.3985,  -1.5008,  -2.7025,   4.6085,  -6.5493,  -9.2151,\n",
      "         -12.6135,  -0.5894,  24.5594]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.559418580392514\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8284,   7.2076,  -2.4118,  -2.9356,  -0.6396,   9.7676,   0.3690,\n",
      "         -14.8238,  -3.8832,  10.7956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 10.795557242458548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3362,  2.8789, -2.0866,  1.7569, -5.0338, -2.4410,  5.9408, -8.1545,\n",
      "         -2.2494, 11.6966]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 11.696562683508688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1216,   6.0537,  -2.8777,   2.3230,  -1.1744,  -0.9775,   6.2102,\n",
      "          -8.2822, -12.7343,  14.0428]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.042789114798866\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8337,  1.1989, -2.2172,  0.3117, -3.3417, -6.9346,  6.6807, -3.0815,\n",
      "         -5.2575, 13.9641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.964121370598054\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5599,   0.6617,  -2.0018,   1.5661,  -6.9089,  -2.8375,  11.7215,\n",
      "         -15.7109,   0.9494,  15.7535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.753511653328788\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8716,   8.2914,  -2.2224,   4.0816,   1.9113,   1.6927,   0.3063,\n",
      "         -14.1381,  -3.4093,   5.4554]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 8.29135224264523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5713,   4.6446,  -1.8364,  -0.6486,  -4.1771,  -4.8256,   9.1739,\n",
      "         -13.4655,  -4.6356,  18.8791]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.879134987704386\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5561,   4.1197,  -1.2304,  -3.1391,  -5.3346, -10.6994,  -4.8397,\n",
      "         -13.5483,   3.9240,  32.4188]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 32.4187740856369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5768,   6.5592,  -1.8969,  -2.8077,   0.1025,   1.4009,   7.4913,\n",
      "         -17.8177,  -1.0867,   9.8190]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 9.819012426998283\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5338,   0.9960,  -1.8179,  -9.0002,   0.3327, -11.4082,   1.1144,\n",
      "          -6.2147,   5.3138,  22.7782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.77815876536587\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3733, -0.3196, -1.4854, -8.4642,  2.7455, -9.5942, -1.9307, -4.9129,\n",
      "          1.1771, 24.7321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 24.732076933732195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2569,  4.2055, -1.8564, -2.7758,  6.7818,  7.2190, -2.9476, -9.2803,\n",
      "         -0.8545,  1.4905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 7.219038892112843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7998,  10.7663,  -3.2829,   7.6968, -10.1103,   2.3172,  10.4350,\n",
      "         -10.0641, -11.7667,   6.5649]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 10.766271761119036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0564,   3.0446,  -2.1998,  -2.3488,  -3.7361,  -8.4212,  10.3102,\n",
      "          -5.2783, -10.6491,  21.6665]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.666481465132843\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3319,   8.5004,  -1.7420,  -7.9869,  -0.6491,  -5.9733,   4.6933,\n",
      "          -5.4711, -13.5623,  24.2217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 24.22172016967044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7855,   3.3006,  -1.0761,  -7.5469,   0.3446,  -0.8906,  -1.7940,\n",
      "         -10.6752,   3.9342,  15.5082]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.508166760348722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9309,   8.9834,  -2.4105,  -8.4939,   4.1235,   3.0958,   6.3385,\n",
      "         -14.2120, -11.1284,  15.4859]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 15.4859275062108\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7454,   6.7226,  -3.1324,   6.4200,  -3.5800,  -0.5820,   5.4080,\n",
      "          -8.0951, -14.0116,  13.1399]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.13989163233825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2705,   4.1668,  -2.7115,   3.3593, -12.1130,   8.9931,  10.9824,\n",
      "          -5.8524,  -5.4532,   2.0054]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  3\n",
      "activation[6] = 10.982414006556088\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9102,  -0.3976,  -1.0823,   0.8327,   0.2026,  -4.5414,  -1.7034,\n",
      "         -12.7174,   5.3832,  15.3966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.3965979323635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7287,  13.8024,  -3.5116,  -0.6703,   0.3278,  11.2018,   6.6648,\n",
      "         -11.7972, -15.1628,   2.8725]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 13.802397153401042\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5232,  2.8139, -1.4263, -4.4251, -1.6501, -9.7070, -5.7768, -2.1557,\n",
      "         -4.8277, 28.2445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.244494391977828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5389,   6.6775,  -1.6412,  -8.2981,  -9.2893,   1.9566,  14.5925,\n",
      "           2.2297, -13.5906,   8.3254]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 14.592502238815275\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6531,   1.3633,  -1.9915,   3.0673,  -5.8336,  -0.7867,   9.5212,\n",
      "         -13.3524,  -0.6198,  11.4729]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.472894785918704\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7824,   7.8382,  -3.1986,  -0.6058,  -5.8907,  -1.0132,   2.5643,\n",
      "         -14.8641,  -9.4973,  27.3701]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 27.370144048224443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3694,   9.9736,  -3.0249,  -2.6193,   1.8954,  12.9037,   1.7917,\n",
      "         -19.7165,  -4.0721,   6.9345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 12.903707278339338\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2364,  10.1088,  -3.6125,  11.8975,  -3.9223,  -2.2631,   1.4333,\n",
      "         -11.3572, -14.8897,  15.9169]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.916936608224855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9446,  5.9494, -1.3941, -1.0356,  2.0789,  2.8315,  2.8527, -8.4630,\n",
      "         -7.1082,  6.5659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 6.5659403294367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1248,   1.5870,  -1.4029, -14.5268,  12.4202, -10.8761,   0.9661,\n",
      "           3.5951,  -6.6015,  16.7306]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.73063346133271\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5943,   4.8294,  -1.4518,  -2.0740,   0.0653, -11.3726,  -6.1183,\n",
      "         -10.7938,   0.6528,  28.1527]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 28.152737329992373\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4872,  13.6160,  -3.0550,  -5.8249,   4.8207,   3.3580,   4.4437,\n",
      "          -5.3009, -23.9045,  13.6665]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.666530888564932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2579,   8.0813,  -1.6093,  -9.3867,  -2.2007,   1.0572,  -3.8676,\n",
      "         -13.9899,  -0.6620,  24.0801]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.08008548152238\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8079,   6.3398,  -1.9272, -10.9596,   8.0077,  -6.9275,  -1.9884,\n",
      "          -4.6563,  -9.5033,  23.4467]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.446663678999553\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2216,   4.5776,  -2.9276,  -5.6574,   0.6452,   4.4484,   0.8714,\n",
      "         -12.1479,  -7.7192,  20.1482]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.148206924446175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2608,  10.4295,  -3.0036,   2.4157,  -2.8247,   9.2827,   5.4989,\n",
      "          -9.5584, -14.6223,   5.3038]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 10.42948680907213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1978,  1.5944, -1.2722, -2.7810, -0.5538, -6.8364, -4.9939, -3.2907,\n",
      "         -4.2679, 23.1102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.11023001898391\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9499,  10.2014,  -3.3556,   9.6697,  -0.4825,  10.8489,  -1.1079,\n",
      "         -14.6804,  -9.6136,   1.6585]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 10.848885832464887\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5026,  12.0740,  -3.1211,   7.6522,  -2.5089,   1.3724,   4.8736,\n",
      "         -13.3312, -11.2954,   6.2342]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 12.073966332734212\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5667,   0.8362,  -1.9561,  -0.0627,   1.3979, -12.2519,  -4.7109,\n",
      "         -18.2738,   8.0686,  29.3007]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.300683168746563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7081,   2.1290,  -2.0859,   5.2745,   0.6055,   8.7260,  -6.0305,\n",
      "         -17.3900,   0.4633,   9.8847]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 9.88474794206016\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5067,   2.7499,  -1.7292, -11.8945,  12.0088, -10.7548,  -2.9491,\n",
      "           3.0293,  -8.2536,  19.5613]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.561342703936877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4511,  4.3406, -1.4378, -5.6966, -7.5950,  1.9127, 13.9488,  0.2153,\n",
      "         -9.7574,  5.0363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 13.94877003683069\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5122,  12.0106,  -2.8610,  -0.7516,  -1.5194,   1.1616,   5.8851,\n",
      "          -4.4535, -19.9568,  12.4966]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 12.496590601637871\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4913,   6.2322,  -2.1296,  -2.2396,   4.1423,  10.7890,  -7.7983,\n",
      "         -20.2007,   2.2665,  11.4496]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 11.449568249295682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1016,   6.9984,  -2.4798,   0.1147,  -2.5511,   7.7072,   2.1494,\n",
      "         -14.7172,  -5.4647,  10.8478]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 10.847818930961768\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9865,   5.7623,  -3.2955,  -1.5099,   1.3263, -12.0314,   1.6562,\n",
      "         -14.7413,  -6.3660,  33.0262]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 33.026204786605916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3393,   7.9145,  -1.5250,  -7.1250,  -9.2241,   1.9436,  13.2016,\n",
      "           1.5242, -13.4415,   7.5160]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 13.201625032965575\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9696,   8.1670,  -1.8194,  -4.7174,   4.2878, -12.1195, -12.9249,\n",
      "         -13.3780,  -1.0175,  36.1474]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 36.147448392159134\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9265,   9.5724,  -2.7888,  -9.7261,  -8.2726,   5.0432,   9.7899,\n",
      "         -12.0489, -13.8643,  24.0088]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 24.008764716673987\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5271,  2.4344, -1.7780, -1.2198, -5.6508, -5.5153,  7.6203, -2.4723,\n",
      "         -6.5677, 14.2956]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.295605520240693\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9421,  10.8188,  -3.5102,   4.4917,   2.1168,   3.0766,  -3.4459,\n",
      "         -16.6977, -11.8748,  17.5864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.58642978993841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5008,  1.7648, -1.5069, -6.3499, -4.8546, -9.7001, -8.8278, -9.5420,\n",
      "          2.6942, 37.5544]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 37.55441394221994\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3457,  -0.3288,  -1.4444,  -4.3180,   0.8189,  -9.2041,  -1.1991,\n",
      "         -15.0752,   8.0080,  24.6854]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.68535883021246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3193,  -0.5196,  -1.5938,  -4.3761,  -2.7763, -12.0821,  -6.7752,\n",
      "          -8.7230,   6.7473,  31.6870]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 31.686973869035914\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7962,   6.2775,  -2.2382,  -2.2718,  -0.8351,  -1.7271,   5.2108,\n",
      "          -1.3696, -14.3621,  13.9297]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 13.929722339489667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1090,  2.6313, -1.2981, -4.8416, -5.1399, -0.1416, 12.7349,  0.1316,\n",
      "         -7.5067,  4.7416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 12.734854952640346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4234,   3.8920,  -1.7983,  -7.8454,   0.4972,  -0.3519,   4.8584,\n",
      "         -11.9980,  -4.8807,  20.4967]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.496687977076437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5446,   5.0986,  -1.9414,   4.3819,   4.4383,  10.9082,   1.0466,\n",
      "         -18.5954,   0.3247,  -3.9293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 10.908177485618166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3995,   1.2655,  -1.5141,  -5.6835,   2.2941, -10.5012,  -0.9916,\n",
      "          -5.2420,   3.6522,  18.9720]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.972033561725592\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6807,  4.8494, -2.0592,  3.0889, -2.3701,  0.7204,  3.1520, -6.2139,\n",
      "         -8.1217,  9.3036]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.303634837096263\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2132,   8.9053,  -2.5168,  -2.3633,  -3.3904,   4.7990,   9.3907,\n",
      "          -6.2244, -15.4724,   8.6794]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  8\n",
      "activation[6] = 9.390651860659542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6535,   3.8366,  -1.6237,  -2.1857,   2.2236, -14.9429, -18.1350,\n",
      "         -12.6796,   1.6651,  43.5434]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 43.54337637380406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9686,  5.0922, -1.9234, -5.2614,  5.4881, -5.9477, -1.0844, -9.1072,\n",
      "         -5.2074, 20.3526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.352595887619348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0503,   9.0876,  -2.5950, -10.4482,   3.4493,  -3.2158,  -4.5657,\n",
      "         -19.5869,  -1.5495,  32.5137]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 32.51373028595404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1043,   9.1368,  -2.5917,  -0.1566,  -0.1429,  -3.2194,   7.9778,\n",
      "           2.9440, -16.2600,   4.9403]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.136845511803203\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2786,   2.7998,  -1.7575,   3.3902,  -1.0934,   7.2410,  -4.4265,\n",
      "         -23.1969,   9.4907,  10.3804]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 10.380378509070404\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4583,  11.6017,  -1.8277,  -7.3093, -10.1323,   1.6204,  11.9305,\n",
      "           1.3139, -17.2020,  10.6788]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 11.930461503197922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4009,   1.4605,  -1.8182,   6.3141,  -0.1955,  10.0614,   4.1238,\n",
      "         -15.4414,   2.7560,  -4.9065]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 10.061426495846908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6739,   5.6562,  -1.8337,  -9.9496,   5.2422, -12.6510,  -2.8335,\n",
      "          -8.6808,  -4.6050,  31.6086]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.608617541454603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6830,   0.0294,  -2.1249,   0.0706,  -1.0473,  -4.5763,   6.4723,\n",
      "         -14.4573,   0.7243,  18.0035]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.00347512234138\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5762,   1.1015,  -1.9914,  -0.7112,  -2.1437,  -2.7779,   2.1756,\n",
      "         -18.2651,   2.6388,  21.7533]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 21.753330341894966\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5297,  4.3683, -1.9924, -5.3016, -5.1938,  2.9815,  1.5991, -9.0386,\n",
      "         -1.7297, 17.2363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.23627798920454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2631,   2.6615,  -1.5844, -14.8677,  12.8015,  -7.8100,   1.9213,\n",
      "           4.0539,  -9.7822,  14.3431]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 14.343070756163746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8039,   0.5840,  -1.2136,  -2.9208,  -0.9948,  -4.5149,  -3.0045,\n",
      "         -19.6369,  11.3037,  21.8924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.892376738636948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5986,  13.4981,  -1.8332,  -7.6561,  -4.4281,   1.4502,   8.8479,\n",
      "           1.9566, -19.3877,   8.4967]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.498088859619813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5584,   4.5856,  -1.4753,   2.2684,   0.0664, -10.0615,  -7.9441,\n",
      "          -8.3496,  -2.8632,  25.5236]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.523556175640334\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7468,  4.1363, -2.4816,  1.4141, -2.1780,  8.3945,  8.2078, -5.3156,\n",
      "         -8.2581, -0.4124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 8.394533837359662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4677,   1.5233,  -1.9926,  -5.9409,   4.4063,  -4.9674,  -4.0583,\n",
      "         -13.3159,   1.7467,  23.5687]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 23.568659008484527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8007,  6.2581, -1.9991, -8.1799,  4.7631, -9.6883, -0.5490, -8.0881,\n",
      "         -6.2642, 25.8982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.89824489491787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7680,   2.2934,  -2.5712,  -6.1362,   0.2619,  -3.5688,   3.4922,\n",
      "         -21.2061,   3.3381,  25.8768]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 25.876821983579152\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6230,  3.7268, -2.4706, -3.8855, -0.8730,  0.2399,  8.4202, -4.7078,\n",
      "         -9.4394, 12.1077]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 12.10768890867107\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0587,   0.9214,  -1.1311,  -1.9263,  -1.6828,  -8.4528, -11.9965,\n",
      "          -7.5371,   3.1805,  29.4090]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.409040730039294\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6900,   6.1275,  -2.1209,  -4.0503,   4.2762,  -3.6122,   7.1207,\n",
      "          -0.0793, -15.0807,   9.5999]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.599854553854072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7942,   7.5322,  -1.7962,  -1.2391,  -1.8972,  -7.6751,  -6.3438,\n",
      "         -15.0036,   1.4585,  26.0726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 26.07256609115522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6984,   5.5893,  -2.0101, -15.3687,   8.4428,  -3.1535,   1.7491,\n",
      "          -3.7425, -13.9848,  23.9369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.936858134806645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0545,  1.1871, -1.2555, -6.8951, -2.3093, -9.9146, -5.0773, -5.9355,\n",
      "          5.8588, 25.7429]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 25.74294807233719\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4205,   1.9292,  -1.5970, -12.4092,   6.9982,  -7.5235,   1.8231,\n",
      "           0.0521,  -4.3673,  16.5987]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 16.59867648554241\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9814,   9.5870,  -2.3878, -15.8366,   5.4089,  -3.2536,   2.3239,\n",
      "           1.9382, -19.5840,  23.4346]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.434553985231556\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5426,  13.2765,  -1.8028,  -5.4851,  -6.7158,   2.6134,   9.2734,\n",
      "           0.7834, -18.5664,   7.5493]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 13.276508334216057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6850,  3.3212, -1.0703, -4.6741,  2.4736, -3.4426, -9.0759, -6.7578,\n",
      "          0.9144, 19.5725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.5725446989688\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-3.0560e+00,  2.9324e+00, -3.4948e+00,  7.7285e+00,  1.1166e-02,\n",
      "         -2.8041e+00,  3.2199e+00, -6.2122e+00, -1.6193e+01,  1.7311e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.31095599760053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1775,  3.4238, -0.9213, -4.5450, -4.9920, -6.7954, -0.0547, -8.6591,\n",
      "          1.3184, 22.2997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.299658010900565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0770,   0.5591,  -1.4038,  -3.0127,   0.9879,  -0.4733,   2.4960,\n",
      "         -11.9778,   1.7592,  13.0214]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.021388490637777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0208,  -0.0991,  -1.2789, -11.8533,   4.4723,  -6.2555,   0.3006,\n",
      "           0.1938,  -3.5960,  19.0724]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 19.072421381754804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.5541e+00,  5.5369e+00, -2.7154e+00,  6.9780e+00, -3.2129e+00,\n",
      "         -1.8872e+00,  9.6153e-03, -1.0888e+01, -8.6902e+00,  1.7345e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.34530901616383\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0458,   9.8494,  -2.6178,  -5.0428,  -7.1356,   0.8193,  13.7377,\n",
      "         -12.1472,  -6.6526,  12.1290]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  0\n",
      "activation[6] = 13.737676773120219\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2957,   9.3327,  -2.7135,   0.3573,  -1.9372,  -5.5856,   2.7423,\n",
      "         -11.3999,  -9.4576,  21.1372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.137159999957664\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6567,   9.0952,  -3.4678,   6.9200,  -5.3819,  17.5513,  10.0177,\n",
      "         -15.5650,  -7.7989,  -8.2546]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 17.551342949548346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5325,  2.2483, -2.2162, -0.1669,  0.9384,  7.2405,  4.0031, -9.7578,\n",
      "         -1.6466,  2.5965]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 7.240500757717031\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3074,   4.1108,  -1.5406,   3.7181,  -4.5426,   8.9275,   0.4697,\n",
      "         -17.2595,   2.2782,   6.7600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 8.927481322602366\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6066,  5.4108, -1.6046, -8.8579,  7.9815, -9.4808, -2.2433, -3.9972,\n",
      "         -9.7966, 24.0884]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.088383969754982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6316,   5.4640,  -1.9100,  -5.0315,   3.0382, -10.7473,  -2.2102,\n",
      "         -10.7929,  -3.3935,  27.6647]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.66471390678795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8969,   5.8572,  -2.6349,   2.4190,   1.0204,  10.3144,   5.0666,\n",
      "          -6.9525, -12.4940,   0.7831]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 10.314385143144877\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6875,   5.1591,  -2.0844,   4.4026,  -9.8468,   0.6299,   8.9003,\n",
      "         -14.8436,  -0.6742,   9.9177]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 9.917731928319435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1744,   0.8471,  -1.7659,  -4.5288,   6.5175,  -2.5666,   1.4659,\n",
      "         -15.0642,   1.9038,  15.9187]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.918712380208929\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0060,   4.1474,  -1.2153,  -3.4124,  -0.9452,  -7.0040,  -9.6084,\n",
      "         -11.8838,   2.8561,  28.5493]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.54928091460423\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4821,  10.1245,  -1.6390,  -6.8196, -12.0050,   2.2427,  13.8763,\n",
      "          -0.0707, -14.9106,  10.2148]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  6 Label:  1\n",
      "activation[6] = 13.876286854875179\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [17]: loss = 14.562, accuracy = 16.41\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.7944, -0.0329, -0.4580,  0.0823, -0.0291, -0.5426,  0.3818,\n",
      "        -0.5433,  0.4573], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.7944, -0.0329, -0.4580,  0.0823, -0.0291, -0.5426,  0.3818,\n",
      "        -0.5433,  0.4573], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -1.5204,  17.5464,  -1.5893,   1.7614,  -3.7574,  -0.6049, -11.7739,\n",
      "         -13.6588,   1.9204,  11.0957]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 17.546390599577062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6225,  10.0810,  -1.8364,  -9.5264,   9.9812, -11.7947, -11.1892,\n",
      "           1.4723,  -7.6299,  22.1865]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.186547183797813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6310,  6.5991, -0.6843, -7.0011,  1.1759,  3.5603, -8.5659, -5.6591,\n",
      "          5.7375,  6.3703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  7\n",
      "activation[1] = 6.599109308919544\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8619,  21.5198,  -2.3815,  -5.8414,  -7.4253,  -3.3794,  -7.3996,\n",
      "         -10.0581,  -5.3882,  23.5399]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 23.539916649323853\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0402,  15.1815,  -2.8679,  -2.6881,   2.6014,   0.7166, -15.9913,\n",
      "         -21.6710,   5.2615,  23.8558]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 23.855753427368462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0861,  23.8078,  -2.3847,  -3.7126,  -1.7927,  -0.3003,  -6.4513,\n",
      "          -8.1579, -17.0313,  18.1633]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 23.80780616206708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3662,   7.2424,  -1.5257,  -7.3863,   1.2463, -12.9536, -11.4775,\n",
      "          -0.2105,  -3.7982,  29.7104]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.71040083415588\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9698,  18.4951,  -3.5080,   9.5456,  -3.9371,   6.7761,  -8.7587,\n",
      "          -5.5906, -14.1542,   4.0320]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 18.495059636698585\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1584,  20.8632,  -1.9974,  -5.5317,  -3.1481,  -3.8306,  -3.9231,\n",
      "          -1.1406, -11.1405,  12.6870]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 20.86324854636603\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4162,   6.4351,  -1.5386,  -3.5537,   4.4595, -11.9906,  -7.2573,\n",
      "         -12.2912,   3.9562,  24.6019]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.60185012932771\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4583,  7.5435, -0.6381, -4.9521, -2.4037,  0.5498, -7.7707, -4.7490,\n",
      "         -1.0256, 14.4978]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.497767978583024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5116,   9.4405,  -1.7874, -14.8345,  12.2393, -10.6574,  -5.6450,\n",
      "           3.3290,  -7.6848,  17.2935]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.29352222286281\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0952,   3.7758,  -1.6076,  -1.0369,   4.6671,  -5.3181,  -2.9074,\n",
      "         -12.9192,   2.2849,  15.1674]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.167376201328818\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7321, 10.3002, -1.1370, -9.3163, -0.1527, -2.0492,  2.0950, -5.9564,\n",
      "         -3.6901, 11.7045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.704454567056462\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9867,  3.7435, -1.1991, -1.9253, -2.8048, -9.1601, -4.3439, -1.0984,\n",
      "          0.5621, 17.3228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.32275969093014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9304, 13.1181, -1.5533, -5.4644,  2.6416,  2.7222, -1.8703, -9.3167,\n",
      "         -6.1703,  8.2000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 13.118090211730806\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3707,  12.2839,  -1.3829,  -5.1798,  -2.8194,  -6.5102, -14.3689,\n",
      "          -7.4468,  -0.9828,  28.0504]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.050446516918058\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.0999,  19.1783,  -3.5999,   7.1092,   0.8357,   0.0916, -11.3762,\n",
      "          -8.3496, -15.7150,  14.8163]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 19.178310186781196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4620,  18.1393,  -2.0161,   2.5253,  -5.8737,  -3.3064,  -7.8574,\n",
      "         -15.0661,   1.0966,  13.6734]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 18.139253376752986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1884,  24.6892,  -2.8232,  -1.4671,  -6.6910,  -1.1999,  -9.7840,\n",
      "         -13.2617,  -8.0536,  20.2815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 24.689201782345005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2362,  13.0887,  -2.3821,  -5.6719,  -1.9876, -14.1591, -17.7888,\n",
      "          -7.2517,  -1.4572,  39.5389]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 39.53890046116816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1072,  16.7872,  -2.3083,   1.1253,  -1.1523,  -2.7285,  -8.1149,\n",
      "          -3.4244, -12.3237,  14.0150]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.787218011615742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7559,  11.2182,  -2.3085,   2.6397,   4.5023,   6.1282, -10.2236,\n",
      "         -19.9102,   0.2201,  10.1239]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 11.218167502341364\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1039,  27.0749,  -2.3803,  -6.8819,  -0.2364,   4.2184,  -6.3840,\n",
      "          -1.5773, -22.5020,  10.2928]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 27.07494769325337\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1791,   9.9972,  -1.4600,   4.8694,   3.5944,   5.8330,  -9.3523,\n",
      "         -13.4600,   3.6596,  -1.9423]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 9.997242168728892\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0959,  13.4062,  -2.1573,  -6.0788,   5.2187,  -3.1923, -10.7127,\n",
      "          -9.9297,  -6.0830,  21.8538]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 21.85382321507053\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7265, 13.4036, -1.8705, -2.2492,  3.1695, -5.5997, -7.6642, -3.8632,\n",
      "         -8.4656, 14.6756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 14.675594335812137\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2988,  5.1907, -1.4628, -8.5656,  9.3339, -6.6253, -2.4312, -7.3871,\n",
      "         -1.7164, 15.6046]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.60464918295586\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5079,   9.9568,  -1.8403,  -2.0484,  -8.1048,  -3.2375,   0.5311,\n",
      "         -11.7522,   4.2540,  14.4053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.405272583548976\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1160,  25.9923,  -2.2733,  -4.9172,  -1.6306,   2.9085,  -5.7192,\n",
      "           1.0015, -23.0683,   9.3443]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 25.99225165903871\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3096,  7.6010, -1.9452, -5.6159,  4.6557, -6.6515, -4.9387, -7.5027,\n",
      "         -5.9064, 22.1040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.104022638010875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7959,  24.2475,  -2.1473,  -9.4871,   1.4863,   2.0347,  -7.9945,\n",
      "          -4.8811, -17.7778,  15.7300]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 24.24754727959725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1110,  20.0402,  -2.5654,  -4.3195,  -0.1266,  -4.0934, -14.2523,\n",
      "         -12.3156,  -2.7535,  22.1213]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.121286754766512\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6247,   6.6841,  -1.6038,  -9.0438,   6.5500, -10.1900,  -4.4600,\n",
      "          -3.8848,   0.3855,  17.6127]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.612677796055213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2178, 10.0751, -1.2781, -0.1040,  1.7921, -8.5772, -9.1783, -5.2138,\n",
      "         -2.4884, 15.7268]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 15.726780064964434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2996,  32.0236,  -1.5819,  -7.4032,  -7.4946,   1.2337, -12.4869,\n",
      "           1.3970, -15.6924,  10.6053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 32.023553011981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4001,  18.8428,  -1.9037,  -2.4282,  -7.9125,  -3.6194,  -9.1747,\n",
      "         -14.9081,   1.6523,  21.6140]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.614029375489103\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8675,   7.5155,  -2.4215,   8.1739,   1.7423,  10.7310,  -2.8054,\n",
      "         -11.5906,  -6.1682,  -1.7869]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 10.730972352178837\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7898, 11.9506, -0.7563, -5.0419, -2.2220,  0.8360, -1.3167,  1.1812,\n",
      "         -5.6840,  1.8648]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.950594310134916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1257,  20.0211,  -2.4275,   1.0898,  -3.3571,   3.2046,  -4.4379,\n",
      "          -7.5870, -13.6242,   8.9496]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 20.02112531653475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4140,  32.5796,  -2.7982,  -6.5510, -11.7133,  -3.0522,  -3.6189,\n",
      "          -7.7522, -16.8949,  22.3905]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 32.57955536354378\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5000,   6.1177,  -1.7742, -14.1144,  12.2527, -10.9233,  -5.6983,\n",
      "           0.0564,  -4.1146,  20.1988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.19880100501703\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1729,   2.7899,  -1.3693,  -1.4012,  -1.9356, -10.2370,  -5.5600,\n",
      "          -4.0402,   2.9368,  20.1038]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.10377159943898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4425,   8.1172,  -1.6144, -13.2006,  12.2233,  -8.3223,  -5.1840,\n",
      "           0.8417,  -6.4768,  15.3919]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 15.391862440789915\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9689,   6.6570,  -0.9963,  -6.2313,  -0.0257, -10.8397, -10.6134,\n",
      "           0.7660,  -1.3634,  23.5457]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.545719943350292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4329,  15.9226,  -1.8308,  -1.4851,  -0.0400,  -0.7476,  -1.3463,\n",
      "           2.4427, -13.0922,   2.1153]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 15.922619764779396\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7245,  16.4910,  -2.4039,  -0.5421,  -3.0400,   0.3888,  -3.9458,\n",
      "          -3.7393, -11.4029,   9.6385]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.4910146773288\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0234,  18.8092,  -1.9486, -11.2342,   8.5812,  -7.2056, -16.7501,\n",
      "          -6.7831,  -9.6850,  28.1198]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.11978618575218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6376,  23.7694,  -3.1240,   4.6554, -12.7865,  -1.0447,  -8.5429,\n",
      "         -15.2753,  -1.8313,  17.1821]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 23.769364460006024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8785,  29.4517,  -2.4922,   3.6146,  -3.4337,  -2.4628, -15.3755,\n",
      "          -9.2717, -12.0921,  14.3930]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 29.451706920048494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8380,  23.5980,  -2.2580,   2.2155, -15.4946,  -0.9301,  -3.6912,\n",
      "          -5.9503,  -7.2886,  11.3766]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 23.598019145338682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3695,  23.3813,  -3.2675,   8.7198,  -0.3673,  11.5098, -12.7839,\n",
      "         -15.4055,  -6.8927,  -1.9574]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 23.381322404543692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1388e+00,  1.4798e+01, -1.5547e+00,  1.9866e+00, -2.2837e+00,\n",
      "          7.1168e+00, -1.0326e-02, -9.4978e+00, -7.1494e+00, -8.4526e-01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 14.79803190684359\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3309,  30.5059,  -1.6044,  -7.5886,  -7.6125,   1.2454, -12.7645,\n",
      "           2.0001, -14.5865,  10.9699]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 30.50591249779868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3775,  12.0350,  -2.0162,  -2.2662,   0.3750,  -4.4408, -12.7778,\n",
      "         -15.2101,   2.3743,  24.0057]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.005716745487106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3213,  25.2231,  -1.4442,  -6.7704,  -4.1972,   0.3916, -11.1923,\n",
      "           1.7133, -11.8103,   8.7949]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.22311194609437\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9179,  13.7743,  -2.1339,   3.2342, -10.9635,  -6.7227,   0.8051,\n",
      "          -9.4132,  -3.8910,  17.7836]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.783583166791352\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8230,   5.7990,  -1.9992,  -0.1671,   3.0920, -12.7742,  -8.6267,\n",
      "         -18.7428,   7.5567,  28.3814]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 28.381391878853453\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0785, 10.3122, -1.3357, -1.8925,  6.6639, -1.2987, -6.3011, -8.1066,\n",
      "         -2.5566,  6.5576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 10.31220605241985\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7247,  18.0807,  -2.2849,  -5.2549,   3.6404,  -1.0489,  -3.4116,\n",
      "           1.6770, -16.0023,   6.5069]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 18.080693608132563\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3971,  31.3675,  -1.3939,  -7.4076,  -9.1314,   1.0408,  -7.9595,\n",
      "          -1.2952, -10.9632,   6.7203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 31.36750741507667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0018,  14.6366,  -1.4410,  -6.2817,   2.5393,  -2.0974,  -1.8014,\n",
      "           2.4872, -10.1035,   3.8053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 14.636588773790367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3856,  24.7427,  -1.8956, -10.2463,  -5.6023,  -0.5682,  -6.6979,\n",
      "          -2.5506, -12.2336,  16.1468]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 24.74270360941639\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.8516, 10.8791, -2.5065,  3.2035,  2.2596,  8.0941, -4.3762, -6.0422,\n",
      "         -7.5151, -0.5855]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 10.879147118999981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9766,   8.0239,  -1.3293,   2.9835,  -2.9735,  -1.6149,  -8.7436,\n",
      "         -20.6094,   6.0782,  19.2204]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 19.220387401682746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5530,   6.0218,  -1.6553,  -4.8496,   3.9502, -12.2374,  -8.2212,\n",
      "          -8.3188,  -0.7692,  28.3692]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 28.369181009169672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3669,  11.9265,  -2.1640,  -0.0163,  -1.4174,   8.0086,  -4.2944,\n",
      "         -12.5562,  -0.5408,   3.2103]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 11.92651738514656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7385,  23.1575,  -1.8615,  -6.8215,  -3.5665,   4.8754,  -2.9228,\n",
      "          -6.8836, -12.6157,   8.4895]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 23.157494012882786\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3533,  30.8697,  -1.5204,  -4.0750,  -6.4516,   1.9592, -12.2121,\n",
      "          -0.1683, -15.1873,   7.4500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 30.869745829563627\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3745,  14.6062,  -1.7818, -19.1111,  13.0172,  -9.8762, -13.8732,\n",
      "           3.7746, -13.7451,  28.6248]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.624791619983625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9384,  5.2987, -0.8934, -5.2482, -1.9657, -4.8705, -8.4931, -2.4250,\n",
      "          1.9284, 17.9602]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.9602253428682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2290,  5.7953, -1.3143, -9.7902,  8.0947, -7.1928, -4.4168, -8.1746,\n",
      "         -0.1207, 18.8960]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.89602136661466\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4778,  17.0556,  -2.9107,   3.8501,  -2.7584,  -0.1658,  -2.2748,\n",
      "          -2.6652, -14.5041,   7.4077]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 17.055561751383475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3550,  14.0736,  -1.4642, -13.3767,   9.3325,  -7.0501, -10.1685,\n",
      "           0.1803, -13.3582,  23.2782]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 23.278214468612642\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9748, 13.9096, -1.2346, -1.9006,  0.1583,  0.0339, -6.0031, -5.3818,\n",
      "         -4.0530,  6.7593]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 13.909609409834895\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1380,  18.9429,  -2.7204,  -0.4044,  -4.8890,   1.1344,  -4.4196,\n",
      "         -11.9343, -11.8544,  18.4747]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.942872095770355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4335, 11.9974, -1.5941,  0.3009, -3.5719, -3.6844, -5.0138, -5.8120,\n",
      "         -3.2211, 12.5610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.56097266863092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5779,  18.1922,  -2.7618,   5.4766,  -1.2124,  -7.6322, -16.5466,\n",
      "         -12.1817,  -7.8698,  27.0430]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 27.04304350706668\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6164,   4.0885,  -1.0762,  -3.8790,   3.0604,  -4.2472,  -3.3333,\n",
      "         -11.4369,   3.5967,  14.8824]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.882413474271974\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3805, 14.1720, -1.5314, -8.3022,  4.2253, -1.1456, -6.2536, -6.2589,\n",
      "         -6.9585, 14.5985]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.598499769327503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8658,   5.5902,  -1.8962,  -1.8013,   2.2280, -11.1848,  -6.5539,\n",
      "          -5.9779,  -0.2140,  21.0335]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.03346320595942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3435,   4.9950,  -1.4091,  -4.0877,   1.8666, -11.2457,  -7.8309,\n",
      "         -10.2425,   3.0976,  27.3390]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.338989961172686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9649,  11.7655,  -1.0922,  -1.2041,   0.6467,   2.4497,  -6.2055,\n",
      "         -10.9409,  -1.3092,   6.9492]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 11.765470893995893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3585,  26.2485,  -1.6275,  -7.1791,   0.1615,  -0.1405, -12.6138,\n",
      "           2.5867, -15.6284,   8.9143]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 26.24852782019489\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3133,  11.5587,  -1.6500,  -4.0506,   4.7857,  -7.3175, -10.8089,\n",
      "         -10.8255,  -3.0968,  22.9063]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.906315376944136\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7957,  18.7145,  -3.6489,   6.6330,  -1.7621,  -0.7305,  -5.1264,\n",
      "         -14.2974, -11.6915,  14.7991]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 18.714524182858717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9108,  25.5427,  -1.9530,  -7.1140,  -5.1202, -13.8737, -12.4731,\n",
      "          -4.6867, -10.3210,  31.8105]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 31.810456931572222\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6530,   4.7759,  -1.5453,  -3.3739,   2.3476, -13.1755,  -9.0572,\n",
      "         -13.5960,   5.4638,  30.6637]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.663687294567207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6293,  34.4054,  -3.0907,  -7.6233,  -5.5364,  -6.5075, -20.1201,\n",
      "         -17.2189,  -6.5711,  34.6965]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 34.69652105786617\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3928,  25.6882,  -1.6553,  -7.9790,   1.4940,  -1.2210, -12.9393,\n",
      "           2.6776, -16.3332,  11.1362]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.688165091784867\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8022,  32.2880,  -2.3849,  -0.2016, -11.9827,   0.3135,  -7.3992,\n",
      "         -10.6443, -11.9084,  14.3065]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 32.28796939398309\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1724,  13.7195,  -2.6572,   5.3959,  -1.5601,   5.2251,  -5.8915,\n",
      "         -13.2853,  -7.3893,   9.0313]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 13.719496462839478\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4322,  14.4056,  -1.7543,   3.3464,  -0.7932,   9.6085,  -9.9674,\n",
      "         -20.8777,   2.1098,   6.9662]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 14.405598589677409\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5582,  24.7198,  -1.6319,  -7.2691,  -0.7626,  -0.5545,  -9.7691,\n",
      "           3.2924, -14.1405,   6.7789]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 24.719811284350673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.2285, 17.4848, -2.6051, -3.2444, -4.8267, -5.2353, -7.8158, -7.5510,\n",
      "         -3.3884, 18.9326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 18.932616302526373\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6572,  17.7132,  -1.8405, -12.9979,   5.8493,  -8.9456,  -5.5726,\n",
      "           1.5480, -11.3273,  17.7348]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 17.73483790099712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0253,  21.4126,  -2.2270,   2.8579,  -1.5316,  -2.1655, -10.8163,\n",
      "         -12.3184,  -7.3383,  13.6969]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 21.412559179906083\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6944,  22.1318,  -2.9768,   3.7157,  -2.9234,  -3.6438,  -9.7063,\n",
      "          -1.3760, -19.2066,  16.3218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 22.13183049820484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5406,   4.4754,  -1.8676,   6.9392,  -0.0838,   2.2926,  -3.2881,\n",
      "         -14.8965,   2.2169,   6.1610]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  5\n",
      "activation[3] = 6.9392214417205675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5342,  25.6902,  -2.3209, -11.0303,  -8.7964,  -1.3148,  -6.6730,\n",
      "          -7.3050, -11.5111,  24.6224]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 25.690180545527454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5816,   9.2451,  -1.7872, -13.1023,   7.5510,  -8.3613,  -9.3258,\n",
      "           0.8187,  -6.3542,  22.6683]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.66827766465312\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0506,   6.4436,  -2.6153,  10.4771,  -0.2763,   7.7045,  -4.5223,\n",
      "         -16.2850,  -1.0385,   3.3146]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  0\n",
      "activation[3] = 10.477082233789227\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6267,  10.4938,  -2.0013,  -4.6674,   5.5525, -14.5738, -14.1304,\n",
      "          -8.9591,  -3.2228,  33.1944]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 33.194411499085305\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1844,  15.9819,  -2.9255,   7.2097,   0.0530,  12.2729,  -5.3307,\n",
      "         -10.5344, -10.7595,  -2.1116]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 15.981876448486004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8458,  12.1908,  -1.0498,  -9.2221,   3.3579,  -2.3593, -15.9519,\n",
      "         -16.8547,   3.3069,  28.2897]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.28970865017115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5330,  21.1390,  -2.4730, -13.3864,  -6.2230,   0.3228,  -4.6340,\n",
      "          -8.3494,  -9.7605,  24.7322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 24.732161245100315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9603,  9.1016, -1.1369, -6.7060, -6.3702, -2.0693, -8.5561, -8.0540,\n",
      "          2.0832, 23.0447]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.044741283695302\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9205,  10.3228,  -2.5740,  -0.9583,  -0.2874,  -0.5995,  -4.1389,\n",
      "         -18.8367,   0.0721,  19.3242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 19.324173702226467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9667, 11.9985, -2.2164, -4.0332,  7.7136, -6.5841, -5.8574, -2.6142,\n",
      "         -7.9150, 11.4592]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 11.99845511264687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2867,  18.4418,  -3.7901,   9.6234,  -1.7052,   0.9623, -12.0588,\n",
      "          -7.8197, -15.1347,  14.5939]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 18.441818355664868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.9271,  21.5935,  -3.6822,   9.9611,   6.1653,  10.6889, -19.7104,\n",
      "         -27.1262,  -2.0311,   8.3611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 21.593513698262168\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1072,  13.4025,  -1.4250,  -6.4790,  -2.3834,   0.7016,  -8.5450,\n",
      "         -11.5582,   0.4955,  18.0045]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.00446561348668\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1835,  11.8733,  -1.3398,  -1.6499,  -1.8103,  -9.9962, -16.6223,\n",
      "         -10.7215,   2.1912,  29.4813]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.481340938755565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9569,  19.9354,  -2.4094,  -5.5980,  -2.8683,   9.0255, -12.5887,\n",
      "         -13.9801,  -1.7293,  13.6621]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 19.935419086559715\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7717,   9.8422,  -1.0247,  -8.9914,   2.9269,  -0.9428, -11.6332,\n",
      "          -9.6405,   0.8820,  20.0543]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.054276415823193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9105, 11.2504, -2.2945,  2.2778, -5.3294, -6.9551, -3.8656, -6.7048,\n",
      "         -3.8211, 17.0613]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.061252378515007\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0839,  16.6854,  -2.3514,   2.5227,  -5.8314,  -2.7134,  -4.9751,\n",
      "         -14.1846,  -2.0181,  16.2930]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 16.68537489850675\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4785,  26.0045,  -1.9745,  -6.1599,  -5.1967,  -6.6192,  -9.8316,\n",
      "          -5.9393, -11.1786,  22.4525]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 26.004470272331666\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9689,  21.7766,  -2.1834,  -4.8044,  -8.2221,  -7.2347,  -3.6433,\n",
      "          -1.0756, -10.4249,  17.1494]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.776572086785965\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5571, 15.3647, -2.0272, -3.3454,  0.3688,  1.4492, -6.5265, -6.3752,\n",
      "         -4.9979,  9.2222]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 15.364723003502656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2330,   7.0336,  -1.3638,  -8.5569,  -1.1781,  -8.8468, -11.7025,\n",
      "          -4.6971,   4.9888,  26.1915]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 26.191494923732225\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.0774e+00,  1.6582e+01, -1.0363e+00, -5.3983e+00,  9.4084e-01,\n",
      "         -4.4928e+00, -1.1855e+01, -9.0108e+00, -1.6680e-03,  1.6244e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 16.581923946971813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7348,  13.0563,  -2.3563,   5.6866,  -6.7374,   0.9028,  -4.0477,\n",
      "         -14.9335,   2.3470,   7.7215]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 13.05631239394048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7598,  19.5346,  -2.2184,   2.1048,   4.7700,   1.4462, -17.2903,\n",
      "         -19.2554,   0.8971,  12.5343]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 19.534618911654015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7864, 16.8251, -1.9353, -4.6081, -6.5913,  0.9973, -0.4539, -0.7480,\n",
      "         -8.3796,  6.6333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 16.825054744857358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3670,  10.0438,  -1.6433,  -4.5268,   0.9013,  -6.9765,  -6.8702,\n",
      "         -16.7782,   4.9480,  23.8744]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 23.87440861642055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.3525,  3.9549, -0.4134, -5.1278, -0.5405,  0.2782, -5.6323, -2.8573,\n",
      "          4.3652,  6.9209]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 6.920886919687881\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6970,  10.2809,  -1.6604,  -5.3655,  -3.8719,  -8.4825, -14.4817,\n",
      "          -5.7243,  -1.1379,  32.0332]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 32.03320925118318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8457,  15.2664,  -1.3189, -11.1737,   3.9807, -10.1789,  -8.6679,\n",
      "          -2.4894,  -6.7441,  23.1840]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 23.18395762503133\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9136,  26.0130,  -2.4438,  -6.5923,  -1.8346,  -9.1396, -20.0494,\n",
      "         -23.8035,   5.6582,  34.5817]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 34.58171014551044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4644,  33.3390,  -2.8495, -11.2571,  -4.4970,  -4.5034, -17.8574,\n",
      "          -9.9546, -12.2717,  32.1377]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 33.338989103576964\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5468,  12.9349,  -1.7280,  -3.1096,   2.0995, -10.6839, -19.0884,\n",
      "         -14.6070,   2.6583,  33.6731]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.673087076205405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6842,  6.2183, -0.7132, -1.8074, -2.4793, -1.7528,  0.6352,  1.2979,\n",
      "         -4.3972,  3.5954]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 6.218333272430669\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5242,  15.2239,  -1.9270,  -4.0934,  -4.8035,   3.0401,  -8.5498,\n",
      "         -14.1055,  -1.6212,  19.8197]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 19.81970931880611\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.1964, 15.1821, -2.5969,  0.7641, -6.4393, -7.5222, -3.8898, -5.8627,\n",
      "         -6.3484, 18.4420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 18.441992509574284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9318,  25.3586,  -1.9397,  -7.0660,  -8.6830,  -2.7137,  -3.9489,\n",
      "           1.0183, -12.3559,  11.7997]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.358609803653977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5448,  31.7145,  -3.4520,  -9.4181,  -3.0660,  -1.9161, -16.8347,\n",
      "         -22.2618,  -0.5358,  30.1234]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 31.71448087931115\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9408,  23.6126,  -2.3466,  -8.0904,   1.0712,  -6.6545, -17.6824,\n",
      "         -10.8623,  -8.7865,  33.1980]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 33.19803982347999\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8486,  18.3649,  -2.1516,   3.9960,  -1.9071,   1.8686, -13.3839,\n",
      "         -15.0942,   1.7027,   7.9321]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 18.364895134616255\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0291,  21.0730,  -2.5439,  -1.8654,   2.9322,   7.8199, -14.7572,\n",
      "         -16.4941,   2.2889,   3.6294]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 21.073033816113565\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.6851, 13.1110, -1.9104, -1.0705, -5.2315, -6.4674, -3.0085, -0.0553,\n",
      "         -8.2056, 14.0466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 14.046597997498349\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9688,  19.5239,  -1.8226,  -2.6960,   5.5574, -15.8322, -14.4183,\n",
      "          -7.9432,  -6.7464,  26.6220]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 26.62201283532102\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7553,  18.9695,  -1.6665,  -2.2847,   3.2202, -11.7348, -23.3941,\n",
      "         -13.0915,  -1.6999,  33.8474]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 33.84739499410473\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6681,  23.2827,  -3.4759,   2.3284,   2.1339,  14.4104, -14.5978,\n",
      "         -13.4256,  -9.5461,   3.2613]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 23.282728608279097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-7.7634e-01,  1.0607e+01, -1.2735e+00, -5.6261e+00,  7.9157e+00,\n",
      "          1.2542e-03, -1.3231e+01, -1.2290e+01,  1.1951e+00,  1.3219e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 13.218867562368654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5265,   6.4723,  -1.9935,   0.1974,  -0.3811,  -5.4133,  -4.9012,\n",
      "         -20.0768,   8.8230,  20.5417]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.541655384695446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2620,  9.9890, -1.3686, -0.3815, -1.6972, -5.9913, -8.6410, -6.3411,\n",
      "         -2.7041, 18.0885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.088469459589714\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9384,   7.8161,  -1.9813,  -9.6405,   0.2427, -16.0427, -13.0575,\n",
      "          -6.4246,   3.6603,  37.6137]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 37.613701252165015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8356,  14.1180,  -0.9369, -11.2553,  -1.7756,  -2.4281,  -6.2573,\n",
      "          -2.7017,  -1.7005,  15.5069]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 15.506943890222754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5719,  27.6399,  -3.1538,  -1.6536,  -0.2472,  -3.8822, -14.1174,\n",
      "         -16.5744,  -6.8857,  21.1133]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 27.63990445906189\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2887,  16.9332,  -2.7390,  -1.5111,  -1.8734,   2.4314,  -7.7362,\n",
      "          -4.9704, -13.6118,  15.4809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 16.933165456817314\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0903,  13.9355,  -2.6116,  -2.8418,   1.9497, -12.6495, -14.8914,\n",
      "          -9.1010,  -5.7844,  33.7765]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.776532307065004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9365,  7.1983, -1.2057,  1.4884, -3.5335, -3.1615, -1.5500, -2.3918,\n",
      "         -3.0516,  6.9832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.19827138556628\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7349,  15.1462,  -2.3665,   1.4773,   0.7856,  13.5763, -13.5752,\n",
      "         -18.2705,  -3.2378,   9.5155]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 15.146214933685734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6143,  16.8658,  -3.3174,   2.4884,  -9.4824,   3.2112, -12.2502,\n",
      "         -18.5846,   4.7480,  19.8203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.820299200287142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6949,  25.2168,  -1.8340,  -7.7154,  -9.2723,  -0.1212,  -2.1764,\n",
      "           0.1585, -12.0222,   9.3048]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.216811293108435\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6580,  16.0928,  -2.2025,  -0.3335,  -3.1553,  11.8151,  -6.1772,\n",
      "         -10.7941,   0.4806,  -3.4685]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.092777715977245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6772,  32.3025,  -2.3651,  -3.2782,  -7.8648,  -2.2563, -11.9071,\n",
      "          -7.9474, -14.2090,  19.8062]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 32.302457417192834\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3577,  28.3703,  -2.7940,  -0.9506, -11.6104,  -2.6177, -13.4393,\n",
      "         -17.3034,  -0.9893,  24.0963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 28.370336114726292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5868,  19.2548,  -2.4773,  -3.5346,   0.1274,  11.9332,  -7.7302,\n",
      "         -12.0773,  -3.3925,   0.4358]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 19.2548088996369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3961,  23.8435,  -2.6747,   8.0363,  -1.4142,   2.6646, -13.8425,\n",
      "         -17.7678,  -2.5723,   5.8733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 23.843465288988245\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2433,  22.1800,  -2.1130,  -1.1904,   2.7133, -16.2055, -17.9354,\n",
      "         -10.0143,  -6.4855,  31.3758]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 31.37580763880847\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6961,  20.4360,  -1.8097,   5.0057,  -5.0348,   1.9762,  -3.2313,\n",
      "          -3.1476, -11.6389,  -0.5393]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 20.43596563906215\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2746,  24.6585,  -3.2239,  -1.7350,   1.2821,   4.3133, -15.0344,\n",
      "         -15.9603,  -9.4421,  17.8500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 24.658508376725266\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7207,  15.4263,  -1.8727, -13.7688,   8.9383, -12.4567,  -9.5010,\n",
      "           2.8834,  -9.4901,  21.6831]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.683050106428293\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2832,  12.1803,  -1.9081,  -3.0365,  -1.3713,  -5.2606,  -8.1560,\n",
      "         -19.3127,   4.1889,  25.5615]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 25.561461874415635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4223, 11.9656, -1.9487, -1.4353,  1.3993, -0.6438, -8.3346, -8.4012,\n",
      "         -0.7391,  8.9126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 11.965632886097893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0755,   9.3919,  -2.1942, -10.9529,   1.4691, -14.3650,  -5.9959,\n",
      "          -6.2518,   3.4649,  28.3320]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.331959697489072\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1237,  18.0931,  -2.6248,  -7.9271,   2.5592, -11.5916,  -7.5826,\n",
      "         -13.5815,  -3.6034,  29.5729]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 29.572871920821093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6349,  22.6335,  -3.3001,  -3.7412,  -0.3059,  -4.4820, -14.1301,\n",
      "         -19.1816,  -3.0437,  27.5893]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 27.58925772713377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2692,  12.1629,  -1.2226,  -1.7328,   3.1135, -10.0519, -13.7849,\n",
      "          -5.1768,  -3.2174,  21.0285]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.028468740067677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8191,  12.7730,  -1.9492,  -6.2106,   4.7893,  -7.4536,  -8.1136,\n",
      "           0.2910, -10.5664,  17.9844]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 17.984387136631515\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.9048, 14.5888, -0.8856, -5.3707, -3.9601,  0.7524, -3.2616,  1.5722,\n",
      "         -6.6966,  3.8391]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.58878034695718\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2767,  21.9372,  -2.5816,  -3.4968,  -0.1974,  -7.5437, -19.0968,\n",
      "         -18.3975,  -2.8875,  34.4979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 34.49792243169051\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7071,  17.7823,  -2.1442,  -6.7752,   4.3787,  -1.0769,  -4.8929,\n",
      "         -12.5006,  -7.7905,  15.9882]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 17.782316829467803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7442,  16.0965,  -2.2754,   1.4209,  -0.7902,   8.3575, -15.9348,\n",
      "         -22.8819,   6.1757,  13.0841]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 16.096468544293757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1024,   7.0209,  -1.0969, -13.9313,   5.6162,  -6.6127,  -4.3290,\n",
      "          -2.7177,   2.4743,  15.1580]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 15.157972046424682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2284,  17.5697,  -3.2416,   7.3529,   3.9580,  17.0138, -14.3602,\n",
      "         -17.4845,  -2.4797,  -4.9037]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 17.56966362864089\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4820,  13.5221,  -1.5645,  -2.4631,  -6.9458,  -8.9515, -13.1392,\n",
      "         -10.9504,   0.7610,  31.1325]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 31.132492043114052\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2991,   9.8800,  -2.0015,  -3.2639,   1.1566,  -2.4166,  -7.1389,\n",
      "         -18.8790,   4.8090,  20.9171]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.917075354500202\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3716,  17.4484,  -1.7609,   0.4629,   1.1761,   6.2280, -16.1414,\n",
      "         -19.5783,   5.6833,   8.4427]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 17.4483623599685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2272,  12.6088,  -1.8900,  -5.6810,   1.8796,  -3.5854,  -7.8097,\n",
      "         -17.9543,   2.1807,  22.5293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 22.52931127241797\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1667,  8.3542, -1.4058,  0.3630, -1.2147, -3.8915, -2.2707, -3.8449,\n",
      "         -3.7105,  8.4445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.444489877787046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1506, 15.2781, -1.3740, -9.9429, -1.6990,  0.4930, -6.0007, -3.3433,\n",
      "         -5.2539, 14.5271]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 15.27812183154656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3391e+00,  1.0137e+01, -1.8872e+00,  1.8407e+00, -8.7165e+00,\n",
      "          5.4655e-01,  4.5741e+00, -1.3557e+01,  7.4121e-03,  9.6467e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 10.137218387660454\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.8534,  22.2093,  -3.2541,  -4.0598,   1.9041,  -9.6022, -17.4342,\n",
      "         -19.4313,  -2.5692,  34.7355]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 34.73545648282402\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1244,  13.8189,  -1.4202,  -6.0935,  -4.0338,  -5.3325,  -9.0548,\n",
      "         -12.5936,   2.7371,  23.1830]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.183003660401482\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4820,  13.6782,  -3.3531,  10.6180,  -0.7153,  18.5300,  -9.5577,\n",
      "         -28.0822,   2.9621,   0.2699]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 18.52999635210778\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2721,  17.7657,  -1.4675,  -4.1579,   3.3809,  -3.8180, -15.2213,\n",
      "          -9.3445,  -2.5258,  17.5299]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 17.76569332319467\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.8785, 23.6293, -1.4953, -6.1329, -4.1317, -4.3546, -8.6441, -4.8956,\n",
      "         -9.8292, 17.0771]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 23.629273462001446\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0330,  23.3991,  -2.5006,  -1.1796,  -5.5346,  -7.9746,  -9.6653,\n",
      "         -17.9032,  -1.4603,  26.2068]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 26.206845973499956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1788,  20.8020,  -2.7625,   4.2498,  -2.0945,   7.3084, -10.9596,\n",
      "         -17.5746,  -0.2204,   3.6217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 20.802029622704687\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8884,  23.1012,  -2.2707,  -3.3252,  -2.3730,  -8.2388, -19.0980,\n",
      "         -13.7284,  -3.5356,  31.5916]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.591574326903253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3739,   6.9936,  -1.7013,  -8.8453,  -1.9273, -11.4370,  -9.3825,\n",
      "         -10.0063,   8.4604,  29.9832]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.983155274740195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.5537,  5.7795, -0.7557, -1.3892, -1.4590, -1.5404, -3.6840, -8.5976,\n",
      "          1.9607, 11.3363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 11.336285779798267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4338,  16.6434,  -2.6137,  -5.1015,   4.3027, -19.4053, -20.0021,\n",
      "         -18.3159,  -2.1749,  49.5725]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 49.5724596073062\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5269,  14.1364,  -1.9540, -11.3983,   0.5784, -12.2599,  -9.9471,\n",
      "          -4.5037,  -3.2992,  29.9893]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.989340980154118\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9821,  21.4518,  -1.7367,  -3.2282,  -0.1540,  -9.7624, -10.8892,\n",
      "          -6.6890,  -5.9752,  19.2217]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 21.451829783430345\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.1753,  26.2766,  -2.3767,   2.2684,  -5.7372,   2.3553,  -9.6958,\n",
      "          -2.9592, -13.5082,   5.7733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 26.276551890865157\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4976,   6.4505,  -1.9094,  -6.4440,   3.6373, -13.8071, -12.1716,\n",
      "          -3.7393,  -1.1423,  30.5027]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 30.502691671169433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6843, 10.6232, -0.8717, -0.7274, -1.6191,  4.7469, -7.5229, -6.7466,\n",
      "          2.2966,  0.3570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 10.62322725477142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5329,  29.5740,  -1.6962,  -6.9307,  -8.5602,   3.1238,  -8.9959,\n",
      "           1.3883, -13.5364,   6.4151]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 29.574029079994993\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1265, 17.6563, -1.0273, -6.0555, -4.9934, -1.6498, -2.6268,  1.2531,\n",
      "         -7.6495,  5.7850]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 17.65626005372425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3686,  16.0198,  -2.7045,  -4.2892,   4.3259, -14.9609, -14.6690,\n",
      "          -6.8820,  -7.5500,  33.3880]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.38795209018116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3292,   7.6981,  -2.1638,   4.1502,  -0.7630,   4.5041,  -8.7619,\n",
      "         -22.2312,  10.4181,   9.5764]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  8 Label:  0\n",
      "activation[8] = 10.418100498860406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6387,  26.7310,  -1.6462,  -5.6700,  -8.5577,   0.7010,  -5.6889,\n",
      "           1.4632, -11.8203,   5.6374]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 26.73098127859548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.3865, 12.4419, -1.8823, -3.0916,  2.0607, -8.6562, -8.6230, -6.5278,\n",
      "         -4.1351, 20.3819]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.381869491773323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7673,  17.8183,  -1.9150, -16.0524,   7.5830,  -9.3370, -13.2444,\n",
      "           3.1511, -10.4200,  24.2847]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 24.284681098716838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7191,  15.3828,  -2.1175,   5.4997,  -6.2031,   1.3873,  -1.9447,\n",
      "         -14.9464,  -4.6891,  10.1539]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  6\n",
      "activation[1] = 15.382790356792388\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7104,  36.8612,  -1.8359,  -8.1737, -11.0048,   1.8018, -11.3572,\n",
      "          -1.0488, -16.1382,  11.8518]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 36.8612262785033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.7986,   5.7619,  -1.1833,   3.1091,  -3.0575,   0.0733,  -3.5027,\n",
      "         -10.3989,   3.5864,   7.4655]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 7.465502588641578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9941,  14.1357,  -2.9060,   2.9078,   1.7529,  13.7911,  -8.9592,\n",
      "         -23.3500,   1.7644,   4.9946]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 14.135711115162284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2684, 21.1074, -1.6183, -7.6567, -5.1717, -4.1408, -6.1509, -5.4225,\n",
      "         -4.0099, 15.4855]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 21.10736749646562\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7493,  16.3335,  -2.5451,  -0.6041,   2.8063,   6.6203, -13.7085,\n",
      "         -25.0060,   5.4965,  14.5366]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 16.333471475363204\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.7853, 15.3642, -0.8272, -4.9224, -4.8146,  1.3851, -4.3782, -1.0254,\n",
      "         -5.6390,  5.4302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 15.364239630281967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.6103,  17.3937,  -1.7702,  -5.9394,   5.8483, -12.4817, -15.6935,\n",
      "          -7.2580,  -6.8865,  28.4512]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 28.451245279947784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4578,  15.0618,  -1.6201,  -5.4768,   3.5518,  -9.7581, -23.4468,\n",
      "         -16.6264,   2.8347,  38.0994]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 38.09940259150359\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5500,  34.4096,  -1.7074,  -9.5362,  -9.9286,   2.3888,  -7.7436,\n",
      "           0.0594, -14.7308,   7.8283]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 34.40955322418324\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.2797, 16.5178, -1.8420, -2.7178, -3.9344,  8.1628, -5.3970, -8.5437,\n",
      "         -2.1388,  1.7252]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.51776111964406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7155,   6.0493,  -1.8403,  -9.1726,   1.3075, -11.0526,  -2.3582,\n",
      "          -7.4896,   6.9158,  20.1915]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.19147613001153\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0743,   5.1716,  -1.5533,   2.4043,  -2.8810,   0.1606,   4.1755,\n",
      "         -10.5518,  -0.9220,   6.5526]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 6.552571975795173\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9345,  18.2353,  -2.8766,   5.1948,   0.5996,  18.8644, -11.1162,\n",
      "         -19.6044,  -1.2078,  -4.2726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 18.86442494828369\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0460,  16.9282,  -2.6140,  -1.5455,  -1.6990,  -3.3039, -13.3619,\n",
      "         -17.6547,   1.1956,  24.8098]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 24.809762385344662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5850,  12.7561,  -1.7561, -12.9740,   8.6822,  -8.8192, -10.9671,\n",
      "           2.2387,  -8.8902,  21.1971]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.197056652977828\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5314,  21.9305,  -3.0600,   4.4771,   1.3965,  -3.1128,  -8.5161,\n",
      "         -14.1394,  -8.8937,  13.1724]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 21.930490474511398\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4416,  30.0568,  -1.5517,  -7.2585, -12.6662,   2.7089,  -3.6592,\n",
      "           0.0974, -11.9656,   5.5920]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 30.056801536384906\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.0677, 20.3748, -2.4105, -1.0855, -4.3756, -8.9678, -7.2894, -4.0161,\n",
      "         -8.3602, 17.5959]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 20.3747631142139\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7557,  17.4457,  -2.2561,  -1.1213,  -3.4745,  12.6341,  -5.2270,\n",
      "         -10.2168,  -1.2618,  -3.5361]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 17.4457498128686\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3650,  17.6035,  -1.5787,  -4.8635,  -0.4945,  -4.8899, -10.2358,\n",
      "         -12.3492,  -2.7755,  20.8337]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 20.83370830266732\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9805,  23.2760,  -2.9461,   1.4328,  -2.8407,   2.3295, -10.2288,\n",
      "         -13.6028,  -5.1314,  10.7461]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 23.276019006737226\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9924,  26.3789,  -2.3370,  -1.6612,  -2.1578,   4.8955, -16.2519,\n",
      "         -18.9824,  -1.6359,  13.7218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  8\n",
      "activation[1] = 26.37894869030427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7913,  26.1429,  -3.4142,   6.1047,  -2.9607,  12.9432, -11.1568,\n",
      "         -11.9478,  -6.6729,  -5.4724]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 26.14286659845883\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.5651, 16.5116, -2.0289, -0.1360, -2.4395, 11.5485, -5.6260, -6.5126,\n",
      "         -1.0946, -7.7092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 16.511577874814222\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3633,  25.6947,  -1.3157,  -7.4676,  -5.9823,   0.4916,  -8.1159,\n",
      "           1.9355, -11.4931,   6.9900]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 25.69466002973359\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9645,   4.6448,  -1.5133,   0.2676,  -2.7686,  -4.4565,  -3.6670,\n",
      "         -16.0597,   8.0801,  17.8478]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.84782269494859\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5944,  10.5107,  -1.7296,  -4.1353,   4.8869,  -2.1427,  -8.6932,\n",
      "         -13.8462,  -0.9401,  18.7781]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.778137037757382\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1696,  14.1089,  -2.0405,  -3.7688,   7.8764,   7.3557, -15.2049,\n",
      "         -17.0747,   2.4436,   8.7322]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 14.108917342238541\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5026,  16.7194,  -2.8352,  -2.7105,   2.8712, -13.1527, -19.4490,\n",
      "         -13.2959,  -3.3194,  37.8831]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 37.88311443691109\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.6795,  4.9862, -0.6488,  0.8916,  2.2072,  2.0323, -7.0035, -7.9474,\n",
      "         -0.7559,  7.7580]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 7.7580443515603825\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.8740,   8.6332,  -2.1803, -12.8444,   4.4699, -14.7280,  -8.1690,\n",
      "          -3.8529,  -0.3335,  30.8234]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 30.823369331293097\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.4041,  7.4847, -0.5937, -7.1611,  3.5242, -1.9385, -8.5542, -2.7800,\n",
      "          2.1909,  8.6715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 8.671488651110531\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.3778,  12.3709,  -1.7962,  -5.5574,   1.8534, -10.1518, -13.2236,\n",
      "         -11.8399,  -0.1761,  30.4595]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.45951846374808\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.2358,  11.3250,  -1.4006,  -4.4375,  -1.1426,  -9.1833, -16.0994,\n",
      "         -14.8846,   1.3431,  36.1424]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 36.14238592766543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9393,  12.0227,  -2.4894,   1.4509,   0.2360,  11.8079,  -7.3767,\n",
      "         -13.3627,   1.0033,   0.0622]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  3\n",
      "activation[1] = 12.0227327874878\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.8168,   7.2201,  -0.9211,  -0.3759,  -3.2646,  -0.2670, -10.5804,\n",
      "         -17.5386,   4.9577,  21.6752]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 21.67524128256579\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.2102,  12.3133,  -2.9464,  10.3150,  -1.9175,  16.6223,  -8.2081,\n",
      "         -28.4052,   5.7884,   0.5394]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 16.6222692194868\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0886,  19.7886,  -2.4255,  -4.5493,  -1.5433,  -5.4106, -11.6218,\n",
      "         -14.2463,  -2.4108,  24.3083]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.308349898753846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.3981,  22.3244,  -3.2428,  -0.3518,  -6.4878,   3.4979,  -6.7813,\n",
      "         -17.5525,  -8.3081,  20.3514]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  2\n",
      "activation[1] = 22.32441941887705\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.9671,  25.1381,  -2.7227,   2.5045,   0.6400,  11.7610, -13.6338,\n",
      "         -21.7871,  -4.6860,   5.1603]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 25.138091343558546\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.0253,  13.7779,  -2.9049,   4.8487,   1.0968,  14.8297, -12.5271,\n",
      "         -16.1552,   3.1894,  -2.5962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  5\n",
      "activation[5] = 14.829740260392708\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4683,  8.6226, -1.8516,  2.7044, -2.3920, -4.4553, -0.9147, -1.4433,\n",
      "         -6.2028,  7.0058]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.622612684124714\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.5683,  23.8368,  -3.5380,  -0.6280,  -3.5533,  -0.5968,  -9.7754,\n",
      "         -16.7855,  -9.9312,  24.4178]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 24.417802803409025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.4408, 10.5951, -1.5792, -4.0913,  1.1197, -9.1053, -9.6522, -0.6362,\n",
      "         -6.8707, 21.1409]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.14092640925902\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4743,  13.4852,  -1.5957,  -6.3719,   2.8051,  -5.1903,  -7.7303,\n",
      "         -10.3000,  -1.5241,  19.5184]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.518358262309615\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9345,  12.5059,  -1.1548, -10.4951,   1.6485,  -5.6772, -14.8608,\n",
      "         -14.7236,   6.3683,  28.4636]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.463622988609927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.7733,  14.9955,  -2.2940,   4.4727,  -5.7410,  11.4493,  -6.7712,\n",
      "         -20.3507,  -1.7728,   9.5113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  0\n",
      "activation[1] = 14.995514913670695\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [18]: loss = 17.876, accuracy = 18.36\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([ 0.4914,  0.3104, -0.0329, -0.4580,  0.0823, -0.0431, -0.5426,  0.3818,\n",
      "        -0.5433,  0.4552], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([ 0.4914,  0.3104, -0.0329, -0.4580,  0.0823, -0.0431, -0.5426,  0.3818,\n",
      "        -0.5433,  0.4552], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ 4.3352e+01, -3.0724e+01, -1.8331e+00, -1.9992e-01, -3.0557e-03,\n",
      "          2.7026e+00, -1.1368e+01, -1.5673e+01,  1.8577e+00,  1.3446e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 43.352184374244864\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.6070,  -2.9247,  -3.5990,  -0.7702,  -0.5900,  -4.9654, -16.3991,\n",
      "         -23.0240,  -3.4958,  26.6739]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 28.606990613046634\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.0995, -10.3514,  -2.4258,  -4.5865,  -7.5546,  -6.6754,  -6.2757,\n",
      "          -9.6568,  -2.0813,  22.5407]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 27.099516776974376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.7238, -17.6552,  -2.1837,  -8.8602,   1.3885, -18.0260, -21.4656,\n",
      "         -24.0688,   6.7543,  52.7723]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 52.772274307227235\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.9340,  -5.6090,  -1.5317,   1.3438,  -8.9494,  -1.7327,   1.7771,\n",
      "         -10.9623,  -1.8735,  12.6188]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 15.934029089694143\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 33.9480, -17.0344,  -1.8669,  -5.8358,   0.7448,  -1.0596, -10.4608,\n",
      "         -15.3169,  -0.1626,  18.2796]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 33.94804096074055\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.3079, -4.2314, -0.9209, -3.8015,  0.8577, -3.7214, -3.6911, -6.6031,\n",
      "         -4.4584, 14.1673]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.167275616361573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.0847,  -2.6800,  -4.0198,   9.4280,  -2.1945,   7.5544, -12.4872,\n",
      "         -13.0994,  -8.8169,  -1.5259]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 29.084713039587626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[13.9595, -5.8615, -0.5815, -5.1843,  2.9953, -3.8717, -7.4649, -5.4483,\n",
      "          1.0631, 11.5864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 13.959458871533576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.2198, -14.5017,  -2.8618,   5.5943,   7.7259,  10.9311, -13.0720,\n",
      "         -16.3064,  -0.7174,  -4.7762]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 29.219765393583792\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.4390,  -4.0489,  -1.3282, -10.7833,  -3.1366,  -6.4691,  -9.4359,\n",
      "          -8.5054,   5.5620,  23.7067]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.706656939568376\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.0908,   2.2486,  -1.7141,  -4.9603,  -1.7050,  -5.7321, -13.4406,\n",
      "          -5.2368,  -8.1859,  18.8944]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 20.09078652059977\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.6539, -0.0221, -1.2038, -5.0054, -6.9276, -4.5108,  5.7855, -2.8112,\n",
      "         -6.5497, 12.1518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.151766553527896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 34.0433,  -2.1625,  -3.7529,   0.6377,  -6.1139,  -5.6351, -20.2505,\n",
      "         -24.4406,  -5.5353,  33.2368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 34.043290996639655\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.7935, -17.1043,  -2.8113,   7.4509,  -7.2182,   6.8308,  -3.0218,\n",
      "         -16.7623,  -7.5183,   9.4771]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 31.7935081786431\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.3727,  18.1699,  -2.0816,  -8.5704,  -8.1435,  -1.2191,  -8.8604,\n",
      "           1.1720, -15.3101,  11.6701]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 18.169901137999936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.4794, -18.9359,  -2.0998,   0.9688,   2.1359,   8.3147,  -8.2346,\n",
      "         -21.5186,   4.1466,   6.4070]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 29.479416839008678\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.0308,  -8.2923,  -3.1194,   2.1933,   2.9514,  10.5895, -12.8190,\n",
      "         -15.1400, -11.6670,   4.9852]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 32.03078525286122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.2906,  -3.3221,  -0.4656,  -7.7835,  -1.3667,  -5.4756, -10.1411,\n",
      "          -4.3727,  -1.4614,  17.6951]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 17.695070885799385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.6797,  -4.0503,  -2.6754,  -5.0865,   6.8622, -21.2280, -18.2637,\n",
      "         -11.4386,  -4.7026,  42.9965]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 42.99646459114724\n",
      "----------------------------------------------------\n",
      "output:  tensor([[24.5480, -7.8832, -3.3643,  6.6132, -3.2610,  5.5007, -9.4317, -8.6039,\n",
      "         -7.6792,  4.2280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 24.548026501945934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 64.9512, -47.4705,  -2.7385,   0.6646,  -1.8653,   7.7600, -11.4312,\n",
      "         -22.7515,   1.9173,  13.0043]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 64.95120950825661\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.0729,   1.0248,  -1.4158,  -0.9220,  -1.6067,  -9.8982, -20.4791,\n",
      "         -10.5468,   0.1034,  28.4435]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.443493882479082\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 36.2851, -16.7816,  -1.9495,  -8.0654,   4.3626,  -3.5413, -12.8464,\n",
      "         -19.0135,  -3.2297,  25.4110]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 36.2850501925106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.0651, -0.3985, -2.2523,  6.7682, -2.6249, -0.3855, -2.2502, -7.0185,\n",
      "         -4.8446,  1.1022]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 12.065076175110855\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.6260, -13.2837,  -2.4059,   3.2032,   7.1508, -16.4579, -14.0605,\n",
      "         -15.4772,  -0.1698,  27.4692]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.46923461630213\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.7651,  6.7952, -1.4648, -0.4700, -7.6175, -3.4540, -4.1262, -5.9572,\n",
      "         -2.6239, 10.5272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 10.527231727178647\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.2893, -23.3250,  -1.8999,  -3.2716,   0.4636,  -5.7086, -10.1575,\n",
      "         -20.6103,   3.7596,  23.9434]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 38.289320722556816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.4688,  13.4463,  -2.2323, -12.7653,  10.9637,  -2.9913,  -8.6806,\n",
      "           2.7963, -19.0615,  10.0272]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  4\n",
      "activation[1] = 13.446330333887785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.9285, -13.4922,  -3.0618,  -2.5983,   3.2576,  -8.0003, -15.4985,\n",
      "         -19.6433,  -1.1246,  31.9600]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 31.960017950119095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[11.6651,  7.2331, -1.4349, -2.0310, -6.6308, -6.9123, -7.8514, -5.0638,\n",
      "         -5.4684, 15.7425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 15.742499633632358\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.2917,  14.6341,  -1.3574,  -7.8313,  -7.9861,   0.1058,  -3.3552,\n",
      "           1.0825, -11.7750,   7.0126]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 14.634105176749523\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.6664, -13.2944,  -1.8135,   0.5231,  -1.4235,   6.1158,  -9.1802,\n",
      "         -18.6843,   2.6648,  10.9566]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 24.666412526492984\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.1556, -13.2664,  -2.1963,  -2.8958,   3.3999, -12.8425, -17.6591,\n",
      "         -12.7567,  -3.8107,  30.3508]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 32.155621739189534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 34.6327, -29.4144,  -1.3934,   5.5631,  -1.3245,   5.6702,  -5.2621,\n",
      "          -9.4463,  -0.1057,   2.4535]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 34.63271509276071\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.6966,   4.8592,  -2.0691, -13.3987,   4.0198,  -4.3303, -16.6398,\n",
      "          -0.0528, -14.1093,  22.6102]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 22.610154802114685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.6159, -0.7580, -1.5485, -1.4800, -2.2890, -4.4132,  0.9458, -0.1342,\n",
      "         -6.4601,  6.3507]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 9.615871605833695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.0039, -15.8065,  -3.0036,   4.1415,  -2.0517,  14.1885,  -6.2953,\n",
      "         -11.5530,  -2.8112,  -6.2599]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 31.00388861297334\n",
      "----------------------------------------------------\n",
      "output:  tensor([[29.0098, -6.2696, -1.7109, -6.1980, -9.1465, -4.4850, -2.2308, -9.1218,\n",
      "         -5.7726, 17.2813]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 29.00977152057044\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.5121, -13.5070,  -1.8122, -11.1649,   2.2227, -16.9072,  -8.9681,\n",
      "          -3.6213,   1.3153,  33.2698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 33.26981487009303\n",
      "----------------------------------------------------\n",
      "output:  tensor([[18.2028, -4.1398, -1.6432, -3.2510, -5.7607, -4.7579, -3.8705, -7.0479,\n",
      "         -4.9318, 17.0709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 18.20283389409922\n",
      "----------------------------------------------------\n",
      "output:  tensor([[16.4688,  4.0286, -1.2054, -8.2850, -6.7567, -2.7079, -5.8403, -2.6845,\n",
      "         -7.6250, 15.1214]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 16.468804188497344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.5481,   1.2289,  -1.9093,  -3.7020,  -5.7167,  -3.3314, -11.3577,\n",
      "          -5.8947,  -8.1006,  16.4280]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 22.548072425380596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[18.7419,  1.7902, -1.5726, -9.0571, -4.7050, -3.2955, -7.3623, -1.4472,\n",
      "         -9.4475, 16.0781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 18.741945314019766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.9900,  -0.1815,  -3.4136,  -5.1395,  -4.0608, -12.8086, -12.0688,\n",
      "          -7.9426,  -5.8217,  28.0393]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 28.03925554551237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 75.4415, -56.0972,  -2.5440,   2.0587,  -5.7950,   8.5433, -11.2145,\n",
      "         -23.1910,   1.3526,  13.4617]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 75.44149680119298\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.4658,   0.8833,  -2.0572,  -0.1276,  -8.3215,  -0.5433,  -4.4958,\n",
      "          -3.8984, -10.3230,  12.0006]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 16.465789250082203\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 66.2295, -45.9284,  -2.6481,  -3.1663,  -0.6984,   6.0843, -14.7958,\n",
      "         -22.6143,   4.4287,  14.8459]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 66.22951648384188\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.5019, -17.2922,  -0.9110,   3.2124,  -0.7566,   7.8484,  -1.3700,\n",
      "          -6.2221,  -2.5491,  -5.0630]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 24.501901658239653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.4719,  8.8694, -1.2150, -6.2609, -4.5907, -0.5747, -1.5179,  0.8553,\n",
      "         -8.0427,  3.8023]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.869354978006095\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.3889,  -6.4869,  -2.5992,   4.1283,  -9.1261,   2.9757,  -3.4884,\n",
      "         -15.3492,   2.5414,   8.8133]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 19.388940388602897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.8677, -12.9992,  -2.6939, -12.8220,   3.3672, -12.6069, -10.4704,\n",
      "          -4.5915,  -1.9384,  30.2463]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 30.24627041708183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 33.0418, -16.2571,  -2.3288,   1.0615,   3.0042,  -1.2235,  -5.7819,\n",
      "         -18.7085,  -5.1288,  14.2343]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 33.04178100781768\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.1253, -10.5416,  -1.8857,  -6.9008,   2.6447, -12.9609, -10.0375,\n",
      "          -2.8923,  -0.8463,  27.3725]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 27.372487188130236\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.1785, -22.1622,  -3.1219,   2.2756,  -1.6107,  -5.7650,  -7.7144,\n",
      "         -21.4033,  -2.0191,  20.8981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 42.178502027061285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.0694,   0.7230,  -2.7914,  -9.2800,   5.4729, -22.4282, -18.5874,\n",
      "          -6.5240,  -6.4329,  42.3603]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 42.360256361289494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.1075,  -8.4024,  -3.1789,   0.9182,  -8.7743,   0.3507,  -9.1140,\n",
      "          -8.3846, -16.7319,  12.6492]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 42.10754545976194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 35.6779, -20.1499,  -2.7130,   0.3737,   2.6918,   9.7624, -12.8620,\n",
      "         -17.4512,   6.0229,   0.3044]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 35.6779365883741\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.9229, -19.8791,  -2.4294,   7.3497,  -5.7204,  -2.4047,  -7.8591,\n",
      "         -24.0125,   5.2440,  21.0490]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 30.922948530958777\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.9551,   0.6455,  -2.5517,  -8.3927,   8.1389,  -9.7497,  -9.2172,\n",
      "          -2.9016, -10.1667,  22.0961]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 22.096088658536416\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.4862, -13.0696,  -0.9797,  -5.8385,  -0.0555,  -3.0629, -12.1069,\n",
      "         -11.2633,   2.5151,  21.1827]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  9\n",
      "activation[0] = 23.486249080830838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.6605,  -3.6897,  -3.5257,  -3.0990,   0.1692,  -4.3061, -17.5378,\n",
      "         -23.9176,  -3.4034,  29.9021]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 29.902104755938545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.6421,  -6.1378,  -1.9372,  -3.3927,   9.3056,   3.4568, -21.2314,\n",
      "         -19.2943,  -4.9260,  17.1368]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 27.642098916405722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.1910,  -5.9549,  -2.6771,  -6.3072,   8.3091,  -8.0697,  -8.8734,\n",
      "         -11.4933,  -9.2591,  25.9297]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.92968877893417\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.1442,  -7.1600,  -1.6232, -14.3851,   7.3065, -11.5261,  -9.3373,\n",
      "           1.8762,  -6.2309,  25.7661]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 25.766111593643792\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 47.6063, -30.4602,  -2.8213,   1.1772,  -3.5503,  -1.2737,  -7.8546,\n",
      "         -25.3277,   3.1198,  21.4305]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 47.60631698167361\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.3080,  -1.9162,  -4.0471,   8.5737,  -8.7138,   0.4487, -13.4615,\n",
      "         -15.9691,  -4.8299,  15.7194]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 24.30796153566117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 36.5759,  -3.2753,  -4.1469,   0.0869,   4.7860,   0.4734, -19.0969,\n",
      "         -20.3857, -16.6522,  21.4487]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 36.57590509075484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.5818,  27.6889,  -2.3713, -12.9061,   0.6661,  -1.8315, -17.2364,\n",
      "           5.7580, -31.8235,  16.7454]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 27.688882835077237\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.0067e+01,  2.2076e-02, -3.4090e+00, -1.2529e+00, -1.3010e+01,\n",
      "         -5.2809e+00, -1.4484e+01, -2.1416e+01, -1.0464e-01,  2.9237e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 30.0665964551133\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.3240, -20.6444,  -1.0836,  -9.0059,   0.3863,  -2.7256,  -9.0022,\n",
      "          -9.0069,   5.1156,  19.1314]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  9\n",
      "activation[0] = 28.32398839650569\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.7467,   1.8622,  -1.7556, -10.6939,  -2.9130,  -7.8023,  -9.1562,\n",
      "          -4.1828, -12.0269,  23.5632]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 23.746705450809067\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.8697, -12.2071,  -1.5397,  -1.7400,  -1.4414, -11.2112, -14.8052,\n",
      "          -9.0531,   0.6588,  34.1256]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 34.125570054632284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.0347,  -5.6709,  -2.9472,  -1.3212,   0.3950,   8.5473, -12.9524,\n",
      "         -12.8525,  -5.0449,   1.5496]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 31.034707785369292\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 4.6506e+01, -3.6125e+01, -1.6131e+00,  2.4868e+00, -4.1889e+00,\n",
      "          2.3305e+00, -6.3329e+00, -1.4631e+01,  2.5478e-02,  1.2426e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 46.5056354050043\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 47.8971, -37.9628,  -1.7443,  -3.3454,  -0.8545,  -7.2597,  -5.2419,\n",
      "         -17.5177,   6.1638,  21.1159]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 47.89714813629065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 35.3215,  -2.5447,  -3.0957,   4.7009,  -2.8894,   3.5224, -17.0926,\n",
      "         -19.2510,  -7.6757,  10.5015]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 35.321540832697174\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.7328,  20.6780,  -2.4708,  -9.2673,  -3.7277,  -2.3037, -10.5286,\n",
      "           1.9545, -19.0335,  10.2067]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 20.67803237266397\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.5540, -29.2708,  -1.5550,  -1.6597,   3.1903,   1.3305, -14.7211,\n",
      "         -16.7745,   7.1489,  10.8939]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 42.55402440789597\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.0925,   7.0498,  -1.2710,  -7.0000,   2.0721,  -4.0132, -12.8958,\n",
      "          -0.6317, -12.6950,  15.0738]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 15.092473231291242\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.3829, -14.8953,  -0.9048,  -0.2830,  -0.0878,   3.5057,  -6.5416,\n",
      "          -9.2557,   2.7422,   1.7860]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 24.382889269721318\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.7502,  -5.5927,  -2.5470,  -5.3386,   1.7518, -11.6385, -21.4524,\n",
      "          -8.4681,  -3.8914,  36.5226]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 36.52264642772942\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.7152,  -5.0622,  -2.1299,  -1.0771,   1.4575, -10.3839,  -9.1164,\n",
      "          -7.9697,  -3.7203,  25.2327]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.23271073985559\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.5926,  -8.8563,  -3.4045,  -6.7545,  -2.5792,  -6.9540, -14.2222,\n",
      "         -25.7495,  -1.2604,  37.0511]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 37.051118969671045\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 48.8123, -17.8665,  -3.4348,  -1.9297,  -4.2646,  -0.2182, -14.7807,\n",
      "         -20.5158,  -8.6354,  24.4441]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 48.8123103342573\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 25.7107,  -8.9496,  -2.1253, -16.0075,   9.1907, -20.6756, -18.0342,\n",
      "         -11.9763,  -0.3043,  43.3612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 43.361247265913065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 40.5618, -26.0603,  -2.6158,  -4.8742,   5.9734,  -0.0725, -11.0399,\n",
      "         -16.0963,   2.6451,  13.0814]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 40.56179928061517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.1331,   1.6273,  -1.8378,  -6.1506,   2.9301, -10.8372,  -3.4338,\n",
      "          -0.4399, -12.1796,  15.2046]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 16.13306055374548\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.9239, -1.7643, -1.0957,  1.4605, -1.4250, -3.5780, -3.6479, -3.3438,\n",
      "         -2.1270,  9.1920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 9.192038270776052\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.7289,  -0.8156,  -2.6501,  -5.4486,  -2.5269,  -5.9456, -12.5530,\n",
      "         -12.6565, -11.2903,  24.4651]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 30.728860778893733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.0286,  -8.1380,  -3.5178,  -1.0306,  -6.2312,  -3.9694, -19.5661,\n",
      "         -24.0230,  -4.0688,  29.6471]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 42.028640634298576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 41.3338, -35.2926,  -1.8322,   1.1292,  -1.3322,  -3.5109,  -2.9738,\n",
      "         -19.1330,   7.8024,  15.5298]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 41.33383804249406\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.7237,   0.1564,  -2.8618,  -1.2756,  -7.7041,   4.3384,  -9.8593,\n",
      "         -17.4646,  -3.0054,  15.2567]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 22.723677183219536\n",
      "----------------------------------------------------\n",
      "output:  tensor([[18.9243,  2.8652, -1.8879, -0.7561, -8.0645, -0.1391, -5.3529, -7.4436,\n",
      "         -9.7168, 12.2021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 18.9243062183766\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.4502,   0.5824,  -1.7356,   0.5746, -14.4560,  -3.2165,   2.7076,\n",
      "          -8.8457,  -3.8506,  15.3153]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.315289118254357\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 34.0420, -20.3293,  -2.3956,  -6.3668,   8.3169, -11.3909, -14.5619,\n",
      "         -13.2346,  -4.2146,  30.9140]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 34.04203093838668\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.5086,  -5.5822,  -1.7721,   3.3555,  -2.1778,   2.8539,  -5.4887,\n",
      "         -11.9283,   0.0932,   9.0338]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 11.508647388627551\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.1347,  -1.4093,  -4.1807,   0.3184,   0.3232,  -1.3221, -12.3789,\n",
      "         -16.2849, -17.2686,  21.8203]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 30.134673597070424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.1336,  -3.0093,  -2.0535,  -3.9623,  -2.8270,  -2.0981, -12.5124,\n",
      "          -9.4816,  -2.2183,  15.1611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 23.133604983590757\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.8978, -15.5602,  -1.8509,  -1.2653,   4.2853, -15.2295, -14.8378,\n",
      "         -13.5755,   0.9672,  33.1960]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 33.19596439257328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.3811, 11.0291, -1.3312, -7.0762, -4.6453, -3.0031, -5.0149,  0.0598,\n",
      "         -8.6553,  9.7327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.029061492874762\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.8137, -21.5697,  -2.2495,  -3.8758,   4.2934,  -7.0461,  -9.8494,\n",
      "         -22.6113,   0.8225,  24.8834]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 38.81373443440251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.1886, -13.6593,  -2.3764,   0.4068,  -8.7790,  -2.3158,  -1.0477,\n",
      "          -8.4374,  -2.8087,  13.2380]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 26.188585058297498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.2971,   5.9320,  -1.4622, -10.8395,   0.4429,  -3.5353,  -1.9233,\n",
      "           1.7794, -15.6726,   9.5514]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 16.297113587327253\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.2651, -6.1043, -1.2950,  1.5300, -5.1591, -2.3804,  2.6982, -8.8652,\n",
      "          0.7697,  6.8703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 12.26505659658032\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 43.7857, -28.0545,  -1.7853,  -7.2683,   2.7011,   1.9123, -15.9675,\n",
      "          -6.0005,  -4.4345,  15.9096]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 43.78572019498554\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.4537e+01, -2.2188e-02, -2.7308e+00, -2.9568e+00, -6.1352e+00,\n",
      "         -6.5368e+00, -1.0482e+01, -1.2535e+01, -6.7299e+00,  2.3568e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 24.53737951333639\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.0685,  -4.3823,  -2.9804,   1.9547,  -7.2789,  -7.6193,  -3.9350,\n",
      "         -11.7282,  -1.5415,  19.0476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 19.04758328226955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.3054, -4.4747, -1.4511, -1.4570, -7.3404, -3.8981, -0.2710, -4.7540,\n",
      "         -0.9905, 12.5060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.505996628828893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 39.9239, -17.9282,  -2.2196,  -2.6513, -10.6489,  -7.0753,  -8.3243,\n",
      "         -16.8701,  -0.9755,  27.6060]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 39.92391483582737\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.1956, -16.7535,  -2.2068,  -0.4958,  -0.9068,   1.0654,  -5.2800,\n",
      "         -20.2405,   3.7028,  14.3031]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 28.195616345706767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.4928,  -2.9270,  -2.7888,  -0.5362,   2.4265,  -3.8887, -18.6730,\n",
      "         -15.2126,  -4.1320,  23.4510]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 23.4510137016185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.8457,  -8.5633,  -2.6174,   0.0880,   0.1360,  -8.3237, -13.0184,\n",
      "         -14.0975,   1.0124,  28.0604]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.060371729546596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.0420,  -3.5553,  -1.3222,  -7.6612,  -1.6497, -10.0380, -15.4876,\n",
      "         -10.7847,   0.0345,  29.3426]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.342577899523075\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.0136, -15.7756,  -2.5114,  -2.4198,  -9.7732,  -3.9094,  -2.3564,\n",
      "         -17.6184,   3.6168,  20.1746]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 31.0135515096502\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 44.2325, -24.7040,  -2.6219,   1.8839,  -1.6728,  10.4715,  -9.1694,\n",
      "         -15.1940,  -4.5470,   2.4621]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 44.23254947683791\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.1303,  -7.4907,  -1.6001,  -2.9722,   2.8171,  -5.0755,  -9.1130,\n",
      "         -13.4309,  -4.8179,  16.9797]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 26.130336333510122\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.2783, -16.4152,  -1.0231, -14.8018,   4.7901,  -4.3734, -13.5992,\n",
      "          -1.8938,   3.2103,  18.4346]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 27.278289832490252\n",
      "----------------------------------------------------\n",
      "output:  tensor([[10.8385, -1.5823, -1.3539, -3.6999,  0.4942, -1.1277, -8.6796, -5.8759,\n",
      "          1.6597, 10.1382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 10.83845035723028\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 40.8056, -14.6973,  -2.5571,  -2.7314,  -1.4660,  -2.2757, -17.5642,\n",
      "         -30.5124,   4.2755,  26.7345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 40.805598733170314\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.3688,  -5.2657,  -1.0531,  -5.7325,   2.7422, -11.3448, -10.1810,\n",
      "          -5.5798,  -2.4453,  24.6642]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 24.664224265957355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 37.9901, -22.3214,  -2.0424,  -5.7261,   4.8626,   1.0641, -14.9505,\n",
      "          -7.5630,  -7.2150,  17.2817]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 37.99011986652221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.9775,  -1.5932,  -0.7963,  -9.6943,   8.6019,  -6.5967, -18.9001,\n",
      "          -4.0937,  -2.8138,  19.6921]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.6921210409745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.0375, -0.4454, -2.1101,  0.0780, -3.4048, -5.4086, -1.4255, -4.5190,\n",
      "         -5.9840, 11.0043]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 12.037450843369568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[13.5506, -3.6908, -1.2266, -3.1075, -2.6512,  0.7368,  0.6178, -7.8016,\n",
      "         -1.6380,  6.4817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 13.550629355918009\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.0696, -12.0289,  -2.8601,   1.7457,  -9.3546,  -3.2516,  -6.5950,\n",
      "         -16.7763,   0.3275,  19.1438]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 30.069638160322306\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.2444,  -1.9017,  -1.3447,  -2.4324,  -5.4796,  -6.2302, -10.3704,\n",
      "          -6.7419,  -2.2829,  23.1385]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.138515416420475\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.1329,  -2.1649,  -2.9833,   4.6937,   4.9736,   0.5371, -16.6646,\n",
      "         -13.7119,  -6.5887,   9.9445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 22.132947585807607\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.2327, -0.0333, -1.7467,  4.2594,  5.4439,  0.2371, -8.8446, -9.4214,\n",
      "         -2.9859,  1.3217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 12.232747265087069\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.0436e+01, -3.2293e+00, -1.1461e+00, -7.2490e+00, -2.6964e-03,\n",
      "         -1.0522e+01, -1.7799e+01, -1.2226e+01,  2.1738e+00,  3.0267e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.267450776775707\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 48.9160, -20.8040,  -2.2174, -13.7454,  -2.2161,   0.2880, -10.5881,\n",
      "          -3.0924, -10.8086,  16.0105]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 48.91602689816931\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.4500, -16.7580,  -2.8640,   5.8917,   4.3914,  12.8442, -15.6613,\n",
      "         -18.9065,   1.1559,   0.2539]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 30.450019508017782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.2734,   1.6478,  -3.6177,  14.8737,  -4.1031,   4.4495,  -8.8732,\n",
      "         -11.0367,  -9.4374,  -0.2687]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 16.273439383761918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.4904, -12.4275,  -1.4092,  -9.2033,   8.0415,  -4.4330, -10.0044,\n",
      "          -8.7431,  -8.6091,  15.0468]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 32.490441930795654\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.1473,  -3.1301,  -2.0009,   5.3211, -11.4395,  -4.0660,  -2.2194,\n",
      "          -8.2343,   0.3808,  12.6075]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 13.147341714703355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.5527, -15.1396,  -0.8461,  -9.9532,   4.6199,  -2.9114, -12.7579,\n",
      "          -5.2401,   5.9786,  17.0582]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 20.5527062532677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 33.6151, -25.6393,  -1.4719,   2.2422,   0.6472,   5.5527, -11.6858,\n",
      "         -16.2182,   7.2132,   6.0747]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 33.61505503856885\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.5483,  -5.3327,  -2.8006,  -4.7123,   0.4153,  -4.2968, -20.9809,\n",
      "         -20.3960,  -3.4104,  28.8149]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 32.548339957410484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[11.6273, -3.5518, -1.1420, -1.5050, -5.3233, -4.9897, -5.8187, -9.1169,\n",
      "          4.0958, 16.2677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.267689744011328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.2198,  -9.8489,  -1.5245,  -2.6061,  -2.2934, -13.7060, -19.9703,\n",
      "         -14.6169,   6.1854,  39.2836]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 39.28363008522624\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 51.1326, -35.5261,  -2.6526,  -1.9670,   3.6085,   3.0908, -12.7555,\n",
      "         -17.2251,   0.1726,  14.1864]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 51.13258784026244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.2107, -23.0386,  -1.2497,  -7.1260,   3.3442,  -0.6752, -12.3731,\n",
      "          -4.8877,  -0.7139,  15.0476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 32.21066195437896\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 7.0909,  1.6737, -1.1768, -1.5757, -4.2120, -3.2079, -1.3390, -0.1339,\n",
      "         -5.5556,  8.1437]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.14374383686014\n",
      "----------------------------------------------------\n",
      "output:  tensor([[11.5159, -1.6758, -2.3821,  1.9236, -5.2435, -8.0544, -4.6220, -5.8219,\n",
      "         -4.1561, 18.0791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 18.079115496631733\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.8557,  -4.2025,  -1.5220,   6.6360,  -1.6619,   3.8134,  -3.7595,\n",
      "         -11.8571,   4.0063,   0.3146]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 7.855656433819725\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.1446,  -9.6502,  -1.8949,  -5.0850,  -6.1316,  -8.6640, -10.6428,\n",
      "         -11.0453,  -5.0735,  27.7846]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 31.144619255112005\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.7720,  -2.2395,  -1.7326,  -4.1332,   1.5094, -13.6754, -16.1833,\n",
      "          -9.4042,  -2.7586,  33.8102]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.8102128090447\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.0635,  -9.1315,  -2.1730,  -2.3362,   3.7964,  -1.6194, -14.3280,\n",
      "          -8.6884, -10.8986,  15.9963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 30.06353498985684\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.7164, -18.9773,  -2.2191,   2.0673,  -0.2917,  -3.3048,  -6.6399,\n",
      "         -19.2572,   6.3412,  15.9381]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 27.716352218870277\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.5546,  -4.9406,  -1.1872,  -7.7215,   2.8182,  -6.4791, -18.9251,\n",
      "         -10.0038,  -5.5324,  23.6899]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 29.554615134742754\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.9993, -18.7954,  -1.6911,  -4.4093,   6.6263,  -2.8809, -16.1414,\n",
      "         -17.3930,   3.1359,  22.8085]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 29.999273054787196\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.7546, -16.1823,  -0.9677,  -8.1035,   2.9939,  -3.1260, -13.1442,\n",
      "          -7.0967,   6.6294,  17.6158]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 22.754561225500908\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.4830, -14.4216,  -1.6050,   2.6467,   1.7671,  14.3237, -10.4449,\n",
      "         -12.8006,   0.6989,  -3.5441]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 24.483003235594822\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.7571, -16.3808,  -2.4398,  -4.4246,  -0.7563,  -2.1137, -12.8177,\n",
      "         -21.4121,  -4.7881,  26.8989]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 38.75707553734863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.8936,  -2.1356,  -1.4874, -16.4356,  -0.1222, -14.7552, -17.3572,\n",
      "          -6.4108,  -4.9045,  39.6467]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 39.64665743252525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.9411, -1.5932, -2.3577,  1.8448, -3.2549, -5.9845, -3.9697, -5.9575,\n",
      "         -5.4438, 13.4738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.473841752640487\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.3269,  0.9827, -1.6679, -0.0518, -5.4258, -5.8134, -2.9452, -2.0015,\n",
      "         -5.9777, 13.2008]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.200757351265064\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 42.0669, -30.7471,  -1.9567,  -9.3919,   7.6936,  -7.6618, -10.4586,\n",
      "         -16.0978,   1.8700,  26.0387]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 42.06688779085875\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.2700,  2.1486, -1.4362, -1.1504, -6.1769, -3.6615,  0.8800, -1.8382,\n",
      "         -6.6519,  8.4849]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 9.270001326965012\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 35.0872, -13.2869,  -2.0112,  -3.9050,   3.6911,  -5.8736, -19.7384,\n",
      "         -22.7619,   2.2103,  27.1612]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 35.08722273232924\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 6.7570,  3.8807, -1.3560, -1.6129, -1.1620, -4.5777, -9.7136, -6.8887,\n",
      "         -3.5669, 18.0428]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.04280822464941\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.7853, -10.0387,  -1.1055,  -9.1116,   0.5627,  -7.1289, -15.8689,\n",
      "          -8.2724,   1.7361,  27.5345]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.534459174962503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 41.9929, -20.6721,  -2.6376,  -3.9397,   3.3214,  -4.3189,  -9.4235,\n",
      "         -21.2332,  -3.9127,  23.0805]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 41.99287644863028\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.9910,  -5.4125,  -1.5228,  -5.2227,  -1.1023, -10.3487, -17.7061,\n",
      "         -12.0113,   4.0618,  31.9100]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.909950512485036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 7.8903,  5.4245, -1.1455, -5.1961, -5.8057, -2.8829,  0.2930,  1.1213,\n",
      "         -7.8331,  8.0428]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.042819472976785\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 37.1642, -27.2015,  -1.8737,  -2.5739,   3.3661,  -2.7964, -17.3999,\n",
      "         -10.0700,   1.5425,  20.0007]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 37.16417947735893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.4966,  -2.2227,  -0.9864,  -6.4513,   2.0860, -11.7304,  -3.9198,\n",
      "          -0.1220,  -1.3106,  18.3230]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.32304610473102\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.6227, -2.4538, -2.3022,  2.6762, -6.5283, -6.7320, -5.1752, -6.6013,\n",
      "         -3.7928, 17.8316]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.831567186995645\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.3822, -10.1334,  -1.9366,  -1.8328,  -0.9769,  10.1194,  -3.3615,\n",
      "         -14.5398,  -3.5832,  -0.5130]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 28.382193291960746\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.6674,  -8.5413,  -2.2092,   1.2700,  -8.3589,  -6.3313,  -8.1711,\n",
      "         -12.3268,  -6.7831,  21.2988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 30.667363098333936\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.8033,  -5.3189,  -1.2513,  -1.5866,   3.7841,  -4.0839,  -8.4558,\n",
      "         -11.0945,  -4.0265,  12.0281]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 20.8033279869826\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.1448,  -6.4302,  -1.4111,  -7.8235,  -1.2685,  -6.2755, -14.7392,\n",
      "         -14.0475,   4.3537,  25.3205]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 25.320533002441927\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.9270,   7.4543,  -1.4293,  -4.3810,  -5.2786,  -7.6929, -11.4787,\n",
      "          -4.9148,  -7.4055,  24.6039]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 24.60388025130066\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.6992,  -7.7653,  -1.0465,  -9.9378,   0.4106,  -7.5735, -16.1490,\n",
      "         -11.7355,   0.7859,  25.9970]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 27.69916603155685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.3691,  -3.1132,  -1.7577,  -0.8699,   5.8148, -14.4425, -15.8797,\n",
      "          -7.1489,  -4.6575,  29.9312]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.93120968616684\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.9346,  -7.1909,  -2.5903,  -0.5166,   1.8620,   0.7432, -13.4149,\n",
      "          -9.4968, -11.5128,  12.7877]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 29.934619427602584\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.3991,   0.7161,  -1.7123,  -2.0702,  -3.5481,  -6.7934, -17.1776,\n",
      "         -10.4736,  -5.8216,  28.4375]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.437528790928305\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.1181, -10.9283,  -0.5366, -13.5886,   3.8184,   0.3371,  -7.6113,\n",
      "           2.1170,   1.2649,   7.2421]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 19.118131036000904\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.9762,  -4.7990,  -1.4171,   4.6820,  -2.2209,   3.0797,  -1.6637,\n",
      "         -13.4846,   2.7628,   1.8967]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 11.976181971495128\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.1920,  -3.4881,  -0.9422,  -6.7534,   5.0410,  -9.1442, -15.5317,\n",
      "          -6.3100,  -3.0613,  21.4291]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.429136491137246\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.9134, -11.7760,  -1.2649, -14.5014,   2.7060, -10.3808, -22.7438,\n",
      "         -13.5683,   3.5705,  41.5552]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 41.55518499114796\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.4783,  -3.6313,  -1.1291,  -4.6768,  -3.2273, -12.5394, -16.0043,\n",
      "         -12.7188,   4.1858,  31.5781]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 31.578121537987002\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.9893, -1.2519, -1.7814,  0.3057, -1.6767, -5.6208, -2.4602, -2.0371,\n",
      "         -5.0667, 10.0379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.03792579905093\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.6221,  -3.9506,  -1.1926,  -4.8078,   3.7230, -10.8039, -16.4385,\n",
      "         -11.0888,   0.8045,  26.0961]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 26.09606487827414\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.4294,   1.0801,  -3.1435,   2.1723,  -1.9364,  -5.4275, -10.5992,\n",
      "         -17.8204,  -6.1330,  21.3396]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 21.33964420184517\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 40.3087, -23.7038,  -1.9314,  -5.5651,   0.6016,   3.1059, -16.2124,\n",
      "         -13.0809,   3.4620,  13.2928]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 40.30874938967228\n",
      "----------------------------------------------------\n",
      "output:  tensor([[11.3102, -8.0165, -0.7375, -6.3802,  0.6219, -6.3190, -8.5587, -7.0169,\n",
      "          4.3147, 21.0411]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.041137322956047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.1025,  -4.7359,  -2.1372,  -3.1125,   3.3953,  -5.1566, -15.1712,\n",
      "         -15.7971,  -0.0935,  24.6382]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.63822661649913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.9221,  -0.4234,  -0.6100,  -4.5688,  -2.3019,  -5.3717, -13.5389,\n",
      "          -6.0653,  -1.2449,  18.9813]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.98126774217897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.0547,  -5.8643,  -2.0060,  -5.7870,   4.6329,  -6.0887, -19.4019,\n",
      "         -15.3504,  -7.3017,  27.5050]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 30.054683833344313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2509,   2.1472,  -1.4412,  -3.5232,   2.7118, -13.0974, -16.9256,\n",
      "         -10.7371,  -1.0825,  32.1584]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 32.1584396709769\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.6599, -16.2275,  -0.4659, -13.8555,   7.7491,  -2.7598, -12.4230,\n",
      "          -3.9446,   2.9940,  14.1863]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 26.659917679660218\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.3947,  -3.6917,  -1.3470,   0.5755,   7.5144,   6.5686,  -8.4353,\n",
      "         -12.2026,  -5.9143,  -0.6242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 18.394684206224163\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.4861,  -2.0907,  -1.6867,  -6.1708,   6.9204,  -1.2781, -20.7726,\n",
      "         -15.2625, -11.9950,  25.5823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 27.48610862523953\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.1481,  -7.8227,  -1.4775,   0.7427,   1.6817, -12.5917, -16.1738,\n",
      "         -12.0055,   3.2801,  30.5010]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.50101441731542\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.7971,  -8.4475,  -3.1657,  -7.8077,  -2.9607,  -9.2628, -19.8438,\n",
      "         -27.0342,   8.6904,  38.1178]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 38.1178486442117\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.6031,  -6.6756,  -1.7323,   1.7286,  -3.4250,  -5.7140,  -6.4657,\n",
      "         -14.5983,   4.1591,  17.5750]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 17.575018972021958\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 36.3169, -11.1082,  -2.5205,  -2.7207,  -8.4533,  -0.9858, -10.4471,\n",
      "         -13.1249,  -7.2593,  20.8711]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 36.31685293160667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.0470, -7.9097, -1.0840, -0.0609, -0.7684, -7.9290, -5.8788, -3.6724,\n",
      "          0.9026, 17.6783]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 17.678322681466355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.3332,  2.7461, -1.9341, -1.0151, -6.0453, -6.6168, -3.9625, -1.9507,\n",
      "         -7.0008, 15.8986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.89855553777328\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.1737,   1.4470,  -2.6758,   5.0133,  -7.4372,   6.8711,  -7.1461,\n",
      "         -10.4026,  -2.4379,   1.1449]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 16.173704612403267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.6474,  -8.4653,  -1.4854,  -7.9039,   1.4750, -12.0326, -17.6962,\n",
      "          -5.3775,   2.5053,  32.6822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 32.682163703279876\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.7777,   8.7398,  -2.2082,  -5.0956, -10.8466,  -5.3850,  -1.0613,\n",
      "          -0.4619, -13.6082,  15.1483]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 15.148270391001832\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.1794,  -5.5807,  -1.4177,  -2.9143,   0.8615,  -8.4203, -16.8544,\n",
      "         -15.5215,   5.5754,  29.8758]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 29.875835913366508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 7.7374,  6.7714, -1.8565, -2.5852,  5.3335, -9.1175, -8.1865, -5.2307,\n",
      "         -9.6271, 16.5919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 16.59185425556244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[10.5703, -1.0535, -1.9508, -0.0107, -2.1077, -5.6615, -0.7487, -3.9738,\n",
      "         -5.1000,  9.5858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 10.570312004320355\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.4871,  -9.8362,  -1.7394,   1.0283,   5.0938,   0.4920, -14.6941,\n",
      "         -15.9401,  -3.7303,  13.0825]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 26.487084186512334\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 7.9569,  0.9907, -1.5982,  0.3995, -2.3464, -4.7016, -0.8435, -1.8169,\n",
      "         -5.7509,  7.4842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 7.956891900579947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.3764,   3.8913,  -2.8866,  -9.6290,   9.2323, -11.8165, -11.6280,\n",
      "          -7.5403, -11.3283,  26.4735]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.473535149094783\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 37.1705, -24.6946,  -1.9155,  -7.7255,   4.5612,  -8.8991,  -9.5488,\n",
      "          -8.9095,  -3.3939,  24.0923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 37.17046899940251\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.3117,   4.3203,  -1.7320,  -0.7744, -10.9144,  -7.1172,  -2.8042,\n",
      "          -8.5254,  -5.0232,  19.7402]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.74022380189065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.6932,  -7.3309,  -2.3947,  -3.0751,  -4.1421,  -1.4554, -10.2390,\n",
      "         -10.7307,  -8.2653,  19.3228]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 28.693230772313782\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 39.3488, -18.1213,  -2.4846,   4.8895,   5.6634,   5.0310, -17.5500,\n",
      "         -17.8431,  -5.4853,   7.0903]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 39.34882729810833\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.5169, -0.6170, -1.7159,  0.4127, -3.7733, -4.8515, -4.1354, -5.2725,\n",
      "         -3.2860, 13.4316]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 13.43160629806552\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.3676, -4.3205, -1.4701, -2.1075,  2.7256, -4.0784, -1.9756, -6.2635,\n",
      "         -0.8390, 10.3313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 10.331299396535783\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.8011,   2.2976,  -1.6499,  -1.3901,   4.2963, -10.4854, -16.1277,\n",
      "         -15.1078,   2.8242,  24.5611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 24.561107027161626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 21.6458,  -3.6192,  -1.2594,  -8.9208,   4.1288,  -5.8984, -21.6623,\n",
      "          -9.9172,  -0.9613,  26.9796]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.97964314525158\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 21.2404,  -8.2348,  -2.5431,  -4.9595,  -0.0511,  -6.8221, -11.6483,\n",
      "         -16.4276,   3.2030,  26.0610]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.060964141414598\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.9898,   1.2217,  -1.3547,  -2.1095,  -1.5873,  -9.6109, -17.7302,\n",
      "          -8.1701,  -1.3932,  30.7753]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 30.775326295631857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 33.0532,  -7.7330,  -1.7497, -10.4491,   0.2716,  -3.0553,  -7.6149,\n",
      "          -8.1448,  -5.8574,  13.1468]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 33.05317265405979\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.5059, -1.6486, -1.4186,  0.1173, -7.3225, -1.5545,  0.5343, -7.9793,\n",
      "         -2.0639, 10.2340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 12.505925233455116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 36.9315, -16.8134,  -1.3753,  -7.7419,  -5.6688,  -4.1609,  -9.7149,\n",
      "         -12.9839,   1.3258,  21.1020]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 36.93148503355485\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.2162,  -3.4452,  -2.1665,   2.7739,  -3.1661, -15.3716, -22.2497,\n",
      "         -14.5928,  -0.4957,  40.5716]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 40.57164766477121\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 43.8893, -25.3325,  -2.1074, -10.6153,  -3.3151,  -3.9357, -12.6465,\n",
      "         -15.2155,   2.9693,  27.2696]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  9\n",
      "activation[0] = 43.889315088875385\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 28.5576,  -9.3397,  -2.3781,  -8.3859,  -7.3399,  -8.9155, -15.4749,\n",
      "          -9.8822,  -2.4608,  35.7500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 35.74996883891273\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 31.4914, -15.0308,  -1.6797,  -7.0144,  -0.9336,  -6.3419, -12.2539,\n",
      "         -15.6355,   3.4875,  24.7482]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 31.49137354008652\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 33.5804, -14.7325,  -1.4405,  -8.0751,   1.7791,  -0.1497, -15.2862,\n",
      "         -13.4746,  -5.1729,  23.5172]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 33.580377326883244\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.8604,  -8.0359,  -2.4765,   4.3003,  -9.0844,  -4.4962,  -9.5743,\n",
      "         -20.3568,   1.7594,  20.6832]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 27.860438504865705\n",
      "----------------------------------------------------\n",
      "output:  tensor([[13.7833, -7.7618, -0.9883, -1.2834,  1.3841,  5.4718, -3.0380, -3.6563,\n",
      "         -1.3357, -1.5893]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 13.78331295663425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.7948,  -0.7215,  -1.2877,  -7.6232,   3.9830,  -9.5695, -15.2045,\n",
      "          -7.5417,  -2.2002,  21.6229]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.62286032062036\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.6271, -11.5476,  -0.7853,  -7.1342,   0.8334,  -1.3781,  -9.3617,\n",
      "         -13.9315,   7.5935,  18.1374]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 18.627075951663933\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 29.1876,  -9.6479,  -1.0968,  -6.6450,  -2.9916,  -7.5996, -17.4902,\n",
      "         -13.6844,   2.4909,  28.0998]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  4\n",
      "activation[0] = 29.18756278388068\n",
      "----------------------------------------------------\n",
      "output:  tensor([[17.4134, -5.9698, -1.6083, -8.5794,  0.0248, -8.5641, -9.9897,  0.0382,\n",
      "         -6.5606, 24.0745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 24.07448606141945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 38.0345, -26.3640,  -1.6184,  -9.3092,   7.0290,  -7.0446, -10.6262,\n",
      "         -10.1099,  -2.3788,  23.4297]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 38.0345341537381\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.9392,  -5.9927,  -2.0794,   1.6322,  -4.8011, -10.4094, -11.6031,\n",
      "         -10.7930,  -0.8635,  26.7895]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 26.789527925040424\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 24.0814,  -8.4772,  -2.3407,  -1.2991,  -7.3106,  -5.8543,  -8.2612,\n",
      "         -11.5470,  -0.8562,  21.8358]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 24.08138331658983\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.4182,  -3.7993,  -1.4918,   1.3554,   3.9502,   6.9008,  -7.5756,\n",
      "         -13.0142,  -1.4798,   3.6902]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 11.418174356028022\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.1005,  -5.2989,  -2.6093,   5.4145,   0.7017,   7.5875, -13.7346,\n",
      "         -19.7140,  -0.2410,   2.1525]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 26.100474567531784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.0113,  -6.3829,  -1.4121, -11.7581,  -3.3785,  -5.5975,  -8.2867,\n",
      "          -1.9584,  -2.9586,  22.2611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 22.261115365343166\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.1807,  -7.4440,  -2.5190,   2.4126,   2.1705,   1.4305, -19.6779,\n",
      "         -22.8746,  -1.4616,  21.7151]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 26.180688026584257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.7016e+01,  4.4017e+00, -2.2919e+00, -9.1189e-04, -7.0678e+00,\n",
      "         -3.2862e+00, -1.0409e+01, -1.4008e+01, -3.2199e+00,  1.9126e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 19.125710792773443\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 44.5956, -32.1231,  -1.8364,   3.2114,  -0.6930,   4.8845, -11.6028,\n",
      "         -17.0881,   5.4622,   6.3988]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 44.59559342724616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.4688,   1.9062,  -1.3567,  -1.1887,   0.7634,   0.4965, -12.2840,\n",
      "          -5.2218,  -6.8343,   6.2028]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 17.46882784378677\n",
      "----------------------------------------------------\n",
      "output:  tensor([[25.2108, -9.1401, -1.5701, -4.4812, -6.4460, -1.3934, -4.7055, -8.2790,\n",
      "         -5.1203, 16.3016]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 25.2107671728047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 57.8670, -44.8539,  -1.8764,   4.0520,  -1.5979,   7.4471, -11.3476,\n",
      "         -21.3482,   5.0394,   8.1963]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 57.86700504382839\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 30.7846,  -8.3724,  -2.2105,  -5.4390,  -0.9055,  -9.3575, -21.6092,\n",
      "         -22.2870,   3.9625,  35.4662]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 35.46623361541494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 64.3846, -41.6380,  -3.1415,  -2.5829,   2.5403,   6.1188, -15.0346,\n",
      "         -25.3792,   1.1682,  15.5606]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 64.38462525654484\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 46.2877, -35.0266,  -1.7928,   5.3764,  -0.1976,   8.4039, -11.5868,\n",
      "         -20.6483,   4.8079,   4.8985]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 46.287686988881426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.7894,   6.0548,  -2.1898,   1.6489, -10.7767,  -1.0829,  -7.9036,\n",
      "          -8.6483, -10.3333,  12.0386]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 20.789438249977508\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 40.5689, -19.3964,  -2.0503,  -6.4421,  -1.5999,  -4.4089,  -9.9151,\n",
      "          -6.9276,  -6.1824,  17.0477]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 40.56888953213444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 22.2010,  -5.5664,  -2.7237, -12.5030,   1.5746,  -9.2893, -12.5549,\n",
      "          -3.4822, -10.1738,  32.2587]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 32.25867906819583\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 27.6882,  -1.9071,  -2.6795,  -2.6411,   1.2394,  -5.0794, -21.2553,\n",
      "         -22.5546,   0.0645,  26.5979]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 27.688230981704315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.3658,  -2.6562,  -1.9554,  -1.0405,  -9.4837,   1.2006,  -3.6281,\n",
      "         -12.5556,   2.0827,  10.2495]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 18.365765591821948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.4773,  0.0791, -1.8097,  1.1472, -3.5904, -4.9180, -2.9256, -4.4541,\n",
      "         -4.1320, 10.8118]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.811798008559023\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 36.9308, -22.8118,  -2.4109,  -4.3984,   0.0896,  -4.3103, -13.4797,\n",
      "         -22.3680,   3.6582,  28.8981]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 36.93076227814071\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 32.5656, -19.8517,  -0.7332, -13.6346,   5.4131,   0.1468, -11.5306,\n",
      "          -0.0991,   0.9667,   8.6232]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  7\n",
      "activation[0] = 32.56562244146438\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [19]: loss = 20.951, accuracy = 19.92\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3104, -0.0329, -0.4580,  0.0823, -0.0431, -0.5426,  0.8818,\n",
      "        -0.5433,  0.4552], dtype=torch.float64, requires_grad=True)\n",
      "weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "biases: Parameter containing:\n",
      "tensor([-0.0086,  0.3104, -0.0329, -0.4580,  0.0823, -0.0431, -0.5426,  0.8818,\n",
      "        -0.5433,  0.4552], dtype=torch.float64, requires_grad=True)\n",
      "output:  tensor([[ -4.7951,   2.3121,  -2.1041,  -1.3580,  -0.9615, -10.3022, -18.6223,\n",
      "           8.2687,  -1.8895,  28.7962]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 28.79622809210452\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.8732, -2.0714, -2.5959,  1.9890, -6.7134, -7.4781, -3.4690,  0.4667,\n",
      "         -4.0842, 17.8675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 17.86747102046771\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.5986,  -3.9530,  -1.3747,  -4.7396,   1.4298,  -5.4592, -16.5587,\n",
      "          18.1976,  -1.9536,  22.3771]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 22.37709406491814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.6227, -25.4154,  -1.5356,  -8.6294,   3.5712,  -5.9588,  -9.3930,\n",
      "          16.5794,  -3.1522,  20.2024]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 20.20238620958147\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.3691,   0.9055,  -3.0033,   3.9610,  -9.1463,   1.7239, -11.3514,\n",
      "           3.5923,  -0.8315,  12.0953]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 12.09529904443893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.5984, -11.8614,  -1.4829,  -4.6436,   2.0922, -12.4749, -20.7649,\n",
      "          10.8958,   3.5237,  36.6815]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 36.681472630274065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.7243, -35.3740,  -1.9351,   5.2283,  -0.1712,   7.5982, -11.3968,\n",
      "           5.8151,   7.0073,   4.7668]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 19.72431045401221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.6596, -15.1553,  -1.7174,  -5.8212,   9.4401,  -4.5081,  -5.4062,\n",
      "           6.7409,  -3.9990,  14.1480]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.148007859736522\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.8030,  1.3767, -1.7945, -1.0263, -5.3988, -6.1277, -4.5828,  3.5940,\n",
      "         -5.6741, 16.2515]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.251503141117755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.9250,  -8.9013,  -1.3806,  -9.9940,   0.9682,  -5.2500, -15.7534,\n",
      "          21.3172,  -0.2731,  24.7344]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.734443491832728\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.0425,   0.1266,  -1.3749,  -1.1050,   1.2814, -12.1040, -18.1465,\n",
      "          -0.2125,   0.6582,  29.8726]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.872552104234124\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-27.3918, -17.5337,  -0.6933, -13.2856,   4.8908,   1.5829,  -7.2553,\n",
      "          54.3956,   2.0482,   4.7527]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 54.39556104217916\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.8044, -16.8646,  -2.1051,  -1.6510,  -2.5311, -11.6930, -13.5336,\n",
      "          10.1316,   2.7291,  33.9007]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 33.90072309380492\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.0388,  -8.9521,  -1.2215,  -6.5216,   0.1464,  -5.0540, -13.8884,\n",
      "          19.6394,   3.0274,  20.7002]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.700210333449597\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.1469,   4.7515,  -2.9859,   7.1220,  -7.2415,   3.0030, -10.1730,\n",
      "          -1.8952,  -3.5747,   3.0029]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 8.146877171590841\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.1279, -24.4309,  -1.6131,  -9.2814,  -2.3968,  -1.5075, -11.5357,\n",
      "          22.4228,   4.0196,  24.3738]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 24.373759989791907\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0341,   8.8276,  -1.7953,  -7.8066,  -0.7537,  -7.7063, -11.9066,\n",
      "           8.2243, -12.4060,  21.5411]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.541088682107045\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0504,  -9.4696,  -2.4590,   2.7080,   2.1904,   0.9782, -13.3926,\n",
      "           5.1266,  -2.7047,  13.6456]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.64555578420239\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.0838, -24.5480,  -2.3700,   0.1675,   1.4976,  -4.8469,  -1.0654,\n",
      "          -2.9165,   2.7476,  19.7198]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 19.71978911199566\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.7177,   4.5280,  -1.7700,  -3.1539,   5.4369,  -8.5056, -17.1911,\n",
      "          11.3110,  -6.2904,  23.2152]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 23.21520993296135\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0691,   4.2353,  -2.0066,  -3.3049,  -6.2057,  -5.1703,  -0.8066,\n",
      "           7.5716, -11.0189,  12.3413]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.341311954094996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9429,  -5.5815,  -1.5735,  -0.3526,   8.6539,   3.2230, -17.9693,\n",
      "           9.9897,  -7.7640,  12.8193]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 12.819296396478295\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.0091, -23.1350,  -2.3855,   0.1815,  -5.2543,  -0.4117,  -2.3717,\n",
      "          -2.9307,   2.1302,  17.8749]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 18.0090758748224\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.8289, -12.4893,  -1.9713,  -4.8761,  -3.9965, -11.1793, -12.6031,\n",
      "           1.1952,   7.4112,  31.9674]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 31.96743256915613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -8.2222, -14.1851,  -2.1996, -11.5913,   1.0782, -15.8257, -10.3598,\n",
      "          22.1536,   4.6876,  35.0282]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 35.02819012318025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.1479, -29.8950,  -1.9707,   2.8549,   0.4992,   5.8847, -16.6278,\n",
      "          10.7826,   5.6903,   9.7500]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 13.147884256449755\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.6468, -10.2750,  -1.6836,  -0.6682,   2.9370, -13.5143, -12.6966,\n",
      "           5.8858,  -0.7393,  28.9187]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 28.918733336031956\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.1612,   3.6833,  -2.5608,   0.1167,   8.1692,  -1.7232, -19.4777,\n",
      "           8.4363,  -5.5361,  13.6659]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.665918093132335\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.6772, -42.8133,  -1.5549,  -3.8299,   2.9963,   3.7166, -16.3962,\n",
      "          19.3308,   8.1299,  15.9180]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 19.33075632025221\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-24.7649, -12.5024,  -0.6081, -12.0169,   6.6203,  -2.7811, -11.5148,\n",
      "          44.7963,   3.2573,  11.2003]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 44.79627996492872\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.5632,   0.2654,  -2.4448,  -1.4250,   1.4917, -13.6753, -20.8122,\n",
      "           3.5049,  -6.6135,  37.8704]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 37.870381102317545\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.6758, -10.1479,  -1.2294,  -9.5775,   2.5672,  -8.4438, -17.8654,\n",
      "          30.7710,   1.5186,  27.3733]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  9\n",
      "activation[7] = 30.77103936432913\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.9342,  -4.3940,  -1.6874,  -2.3209,   1.0369,  -9.2268, -18.9201,\n",
      "          10.0064,  -0.5012,  27.7664]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.766397848458787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.3313, -12.7801,  -1.0260,  -7.8699,   0.5037, -11.0977, -17.9663,\n",
      "          19.2718,   6.3657,  32.5158]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 32.515831507867496\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-2.3159,  5.8590, -1.8534,  3.1447, -1.1335, -1.4267, -9.8507,  3.4075,\n",
      "         -3.7761,  7.7638]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 7.763759839333996\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-11.5289, -12.6941,  -1.3086,  -7.8686,   0.7148, -11.3540, -15.6334,\n",
      "          25.5152,   5.4672,  29.2196]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.219636593975537\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.4334, -0.2496, -0.8169,  0.4624, -1.0046, -2.6458, -1.8129,  2.2534,\n",
      "         -3.1070,  5.2481]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 5.248092557944814\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.1019, -18.4910,  -1.5110,  -7.8651,  -2.1881,  -5.0456, -12.8909,\n",
      "          19.3759,   6.1444,  27.3498]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.349777541641863\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.5277,  -0.9285,  -1.2911,  -3.0173,  -1.8842,  -6.3771, -14.1184,\n",
      "          -2.1375,  -0.4290,  26.9046]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 26.904611180387015\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 4.0934e+00,  4.6008e-03, -1.8344e+00, -5.0224e-01, -4.8190e+00,\n",
      "         -5.5067e+00, -6.2612e-01,  5.1988e+00, -7.3100e+00,  1.1055e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 11.055190357138974\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.5394,  -3.2517,  -1.6956, -14.7034,   6.7522, -14.2493, -11.6429,\n",
      "          24.8902,  -7.6331,  27.4327]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 27.432739860547613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.8492, -20.3971,  -2.2244,  -6.0277,   4.7530,  -6.1292,  -9.6925,\n",
      "          11.5667,  -7.4294,  18.2911]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.291112692013073\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.4667, -38.7937,  -2.0010,   5.1746,   1.5422,  11.9834,  -9.2454,\n",
      "           9.5569,   4.5654,  -0.2734]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 18.46672864205377\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.1366, -15.2114,  -1.1687,  -6.6527,   2.7838,  -9.6026, -18.4190,\n",
      "          19.1619,   5.7738,  30.3218]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 30.3218010271938\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.7709,  -0.0929,  -2.7293,  -0.1872,  -5.2751,   5.1404,  -3.6851,\n",
      "           0.2327, -13.3095,   3.8262]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 15.770900688969444\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.0536,  -8.1770,  -1.6696,  -6.6922,  -0.1884,  -6.3674, -14.9368,\n",
      "          18.4591,  -3.0850,  21.3052]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 21.305196682435955\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.5464, -2.1615, -1.4520,  1.0088, -4.5372, -3.8620, -2.2440, -6.0924,\n",
      "         -2.6672, 13.7138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.713848586954962\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.4244, -20.7840,  -2.6128,   0.0335,   0.2293,   8.0927, -18.2536,\n",
      "          12.0058,   7.6446,  10.4382]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 12.005788834369596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.6526,  -1.7903,  -1.5909,  -1.5537,   2.9678, -11.0903, -19.5716,\n",
      "           5.0080,  -5.4278,  32.3642]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 32.36423773765748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.6352,   8.7127,  -1.7621,  -4.7329,  -5.2722,  -2.7770,  -2.7249,\n",
      "           7.6220, -10.9836,   7.7372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.712713013632934\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.2543, -5.6146, -1.4162,  0.8178, -9.6471, -1.4514,  1.5528,  2.5554,\n",
      "         -2.9295,  7.4569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 9.254339880525267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.5994, -14.2139,  -2.7767,  -1.9258,  -1.9123,  -4.2528,  -9.8158,\n",
      "          -3.8802,  -1.2929,  23.1808]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 23.180825670357322\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.2463,  -3.3852,  -1.3156,  -2.9345,  -2.2761,  -6.5525, -15.0722,\n",
      "          -5.5190,   1.9569,  29.9366]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 29.936602275210944\n",
      "----------------------------------------------------\n",
      "output:  tensor([[10.0196, -1.8300, -3.6955, 11.8810,  1.0265,  8.3687, -9.3964, -3.4052,\n",
      "         -9.2015, -3.1015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.881000770852216\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.8583, -6.2631, -1.7475,  0.8615, -4.2215, -3.2435,  0.8296,  1.8960,\n",
      "         -2.5379,  9.5983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 9.598333013542813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.8952, -18.5005,  -1.9425,   0.3380,  -0.1620, -11.7183, -13.8729,\n",
      "           2.5675,   7.0803,  32.4111]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 32.411059469549734\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.3502,  1.7790, -0.7868, -2.9460, -1.8866, -0.2816,  0.9013,  3.8407,\n",
      "         -4.7332,  1.7500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 3.840742085526313\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.7141,   4.6024,  -2.5480,  -2.1034,  -0.6788,  -7.7397,  -5.6754,\n",
      "          11.5471, -15.7386,  16.3512]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 16.351165801192693\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.8463, -25.9337,  -0.7638,  -3.5301,  -0.6012,  -5.6075,  -2.8929,\n",
      "          15.6671,   4.5858,  14.9998]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 15.667098643881076\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.2910, -17.8127,  -1.8578,  -5.0198,   0.4852,   1.9529,  -0.2181,\n",
      "           4.4603,  -4.5486,  10.0448]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 14.291006957208534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.7194,   5.3341,  -1.8795,  -3.5633,  -5.9621,  -4.5891,   0.0495,\n",
      "           6.7905, -11.1341,  10.3657]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.365651077162392\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.4143,  -3.3715,  -1.6973, -17.9252,   7.0582,  -8.3154, -10.3594,\n",
      "          18.1637,  -6.8988,  25.8356]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 25.83558927171193\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 25.1568, -45.4259,  -2.3154,   7.7108,  -1.1433,  12.4570, -11.5287,\n",
      "           9.7212,   3.6804,   2.9705]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 25.15683347667342\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.3051, -12.5282,  -2.2201,  -6.0393,   4.0668,  -3.4283, -14.4440,\n",
      "          -2.0638,  -7.0543,  26.9914]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 26.991376367825282\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-13.5711,  -0.9763,  -0.7659,  -7.7604,   1.2149,  -0.8801,  -5.8449,\n",
      "          22.6203,   0.4844,   5.8547]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 22.620324275506118\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.3535, -23.4142,  -2.0775,  -6.9642,  -1.9606,  -9.5429,  -9.6323,\n",
      "           3.3137,   3.1908,  36.9755]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 36.97552666787712\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.8616, -15.3318,  -2.4573,   0.5386,   0.7401,  -5.9145,  -6.3933,\n",
      "          -6.0969,   1.6353,  22.3925]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 22.39252917684024\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.8487, -29.6883,  -2.5587,   6.3943,   1.0495,  12.4244,  -9.4769,\n",
      "           1.1249,   1.2587,   2.3601]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 18.848653591967572\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.7880, -0.4959, -1.1652, -6.8234,  6.6512, -8.4001, -5.3643,  3.3796,\n",
      "         -5.0361, 16.2119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 16.211939727809316\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.6380,  19.5742,  -1.8321,  -7.9653,  -7.7774,   1.0211, -10.7051,\n",
      "           8.0005, -15.2569,   9.6242]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.57418599158991\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.7028,  -8.2509,  -1.6035,   0.9400,   0.7586,   2.1230, -10.1887,\n",
      "          -0.8459,  -0.6414,   8.4673]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 10.702810476844594\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.0565,  -3.0333,  -3.1216,  -2.8206,  -4.0028,  -0.1833,  -6.4989,\n",
      "          12.9952, -15.9281,  13.3388]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 13.338766652135197\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.4593,   8.3678,  -1.9110,  -9.2044,   0.8425, -14.6407, -23.6423,\n",
      "          10.8096,  -7.6406,  41.4551]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 41.455143099998004\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.8001,  -2.1263,  -3.9360,  12.1208,   1.6505,   3.9760, -12.7779,\n",
      "          -5.4055,  -7.3674,   4.2420]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.120834952296427\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.9728, -18.9844,  -3.7820,   2.0537,  -3.8479,   1.3481,  -9.6220,\n",
      "           3.2719,  -9.5309,  20.1834]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.183363440659633\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.2797,  -4.8618,  -2.4149,  -7.2303,  15.3245, -12.5680,  -8.5840,\n",
      "           4.4696,  -8.2859,  19.9422]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.942227155226767\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.0814,   5.5172,  -2.4476,  -7.3723,   1.5799,  -5.4881,  -4.6780,\n",
      "          14.1748, -14.7310,  14.0595]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.1748208573758\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.0217,  11.7935,  -1.7656,  -6.4973,  -3.0568,  -6.0513,  -4.3720,\n",
      "          14.0095, -16.2055,  12.1221]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 14.009474734956182\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.8368,  0.2378, -1.2989,  0.5110, -2.5363, -2.7167, -2.7510,  1.9229,\n",
      "         -2.7395,  8.4676]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.467550299624701\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.1099,   4.5577,  -2.7039,  -0.8999, -12.0936,  -1.5258,  -4.6375,\n",
      "           0.5909, -13.4026,  18.2211]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.22109762590967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.6777,  3.4307, -1.7390, -2.3510, -3.0216, -4.7139, -0.9408,  6.7060,\n",
      "         -8.5389,  8.9675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.967489578006326\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.2154,   2.9470,  -1.7852, -16.2681,   2.9790,  -4.8939,  -8.1034,\n",
      "          14.4533, -11.2879,  25.0458]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 25.045816256191323\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-6.4821,  4.2947, -1.3349, -7.5244, -6.1956, -7.6636, -8.3809, 15.3402,\n",
      "         -4.1929, 21.9166]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.91663186419803\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.0974,   0.9539,  -3.5856,   0.3248,  -2.7359,  -0.4058, -14.6959,\n",
      "          -0.2838, -17.4762,  23.5540]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.554031487081538\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.4824, -25.1750,  -2.3057,   7.0563,   1.2503,   8.6650, -11.5082,\n",
      "           8.2194,   2.3722,  -0.2377]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 12.48241820927527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.3427,  -6.2894,  -1.5654, -12.2623,   7.5727,  -8.7172, -12.7177,\n",
      "           8.7210, -11.7154,  29.8239]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 29.82386615209434\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 4.6542,  1.3803, -1.6978, -1.1302, -4.9024, -4.1816, -2.3984,  4.1780,\n",
      "         -6.6540, 10.4816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.48164946401183\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.5603, -28.4453,  -3.0982,   8.3950,   0.9508,  11.3128,  -6.0300,\n",
      "           9.9973,  -2.7353,   1.6149]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  0\n",
      "activation[5] = 11.312790005708656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-5.1809, -2.0404, -0.2177, -5.7499,  0.7039, -2.5773, -5.3765, 14.1641,\n",
      "         -1.5492,  8.3598]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 14.164077426167111\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.6549,  12.1691,  -1.4607,  -7.9157,  -7.1022,  -0.1266,  -4.0272,\n",
      "           7.1775, -11.3110,   7.7081]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.169060112398947\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -5.1222,  -2.8879,  -1.4430,  -7.8332,  -2.9416,  -9.5268, -16.8806,\n",
      "          10.3388,   4.2744,  32.8238]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 32.82376600012795\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.9944, -13.5108,  -3.6129,   3.9865,  -6.8492,   2.9554, -10.3356,\n",
      "           3.7312,   5.0882,  12.5311]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 12.531140964030948\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.9027,  -0.2667,  -2.2367,   1.5988,   2.6377,   1.9277, -18.7158,\n",
      "           2.9672,   0.6640,   9.3772]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 9.377237010159986\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.7843,  -0.9201,  -3.7569,  12.0093,   0.1308,   3.8931, -14.4383,\n",
      "          -6.2717,  -5.8565,   5.0072]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 12.009325742488898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.4376, -13.7823,  -1.4527,   1.5144,  -3.6323,   1.0506,  -1.1138,\n",
      "           4.2033,  -0.7244,   6.0907]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  1\n",
      "activation[0] = 8.437580535375632\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.3962,  -5.9920,  -2.2702,  -6.3795,   6.7454, -15.3483, -11.1090,\n",
      "           2.0509,  -3.1638,  33.5189]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 33.51887884846804\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.8847,  2.2504, -1.8131, -1.5494, -3.2226, -4.5425, -0.2209,  3.9659,\n",
      "         -7.2362,  8.1315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.131498605067673\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.2693,   9.4727,  -1.8347,  -5.6561,  -2.3553,  -6.5070,  -2.6540,\n",
      "          13.6461, -14.6770,  11.1964]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 13.646138378790315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.3132, -10.3654,  -2.0819,  -1.0234,   3.6056,   4.8817, -12.2969,\n",
      "           2.1591,   3.2175,   7.7924]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 7.79237124466982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[15.4601, -9.2182, -2.7085, -0.9974, -2.8257,  0.4850, -5.8598, -2.1017,\n",
      "         -7.2261, 16.4739]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 16.47387906547207\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.8715, -9.4448, -1.5541,  3.0209, -5.8408, -6.2058, -8.9800,  2.1832,\n",
      "          3.1513, 20.5191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 20.519116911775626\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.9026e-02, -1.4201e+01, -2.4764e+00, -7.3189e+00,  4.5567e+00,\n",
      "         -7.5253e+00, -6.9087e+00,  8.7011e+00,  3.6207e+00,  2.1756e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.755708004493933\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.8132,  -0.8839,  -3.2959,   8.1614,  -5.9282,   1.6639, -15.2614,\n",
      "         -10.7133,   0.8685,  13.2545]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.254488949682692\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.6108,  -1.4881,  -3.0264,   2.5638,  -0.8335,   3.6857,  -7.3038,\n",
      "          -3.2551, -11.3329,   8.0698]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 12.610822351640348\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.1780,  -2.0570,  -2.8403,   1.7731,  -1.9377,   5.0753, -14.3136,\n",
      "           2.4910,   0.2892,   9.9265]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 9.926467424291138\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.2102,  -2.7247,  -2.9274,  11.7322,  -0.7349,   2.9443,  -9.8064,\n",
      "         -17.9748,  -4.0896,  10.5923]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 13.210183374649748\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.5828, -3.3953, -2.2604,  1.6138, -3.4156, -5.9234, -5.9682,  3.0377,\n",
      "         -2.4884, 16.7746]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 16.774564878465426\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.9656e+00,  1.5272e+00, -1.3646e+00, -2.3620e+00, -1.4331e+00,\n",
      "         -1.3032e+00,  4.9366e-03,  5.2404e+00, -7.0141e+00,  2.8336e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 5.240444815233195\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.7645,  8.2748, -1.0784, -5.3288, -3.5913, -0.0357, -1.7405,  5.7783,\n",
      "         -9.1239,  4.0333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.274825965646682\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.7145,   0.0598,  -1.4426,  -8.3454,   6.1007, -13.9224, -14.9798,\n",
      "           2.9157,  -6.4922,  33.0113]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.01129123543459\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.1136, -11.1025,  -1.8832,   7.7252,  -1.4160,   1.6277,  -8.0427,\n",
      "         -14.7245,   9.3720,   9.6168]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 9.616759258707596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.2154,  -4.8267,  -1.8940,  -4.7663,   1.9367, -14.8807, -18.4650,\n",
      "           2.9364,  -4.5470,  37.8845]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 37.88448232043945\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.1173, -2.8823, -1.1925, -1.0383, -2.7689, -1.6413, -0.4947,  1.6617,\n",
      "         -3.1646,  6.3191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 6.319128421865208\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.1856,  -7.6926,  -1.7134,  -6.9341,   4.9863, -11.9321,  -6.0769,\n",
      "           9.8518,  -0.5370,  21.4894]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 21.48941450875092\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.9169,  9.1929, -1.1382, -6.2457, -5.2795, -3.9891, -1.7761,  6.4971,\n",
      "         -8.7999, 10.1958]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 10.195766819961742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.1493,  7.4622, -1.1466, -5.4729, -2.4326, -1.5760, -3.1513,  6.4923,\n",
      "         -7.8155,  4.0466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 7.4621542184470835\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.4259,  2.1292, -1.6854, -3.5990, -9.6214, -2.5898,  1.8361, -0.9727,\n",
      "         -5.8160, 12.9407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 12.940655643278898\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.4511, -21.3812,  -2.9016,   3.4852,   1.6809,   5.8802, -10.1285,\n",
      "           4.3074,   0.4991,   9.6581]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 10.451075430534726\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.4778,  10.1090,  -2.6255,   2.9985, -10.0429,  -2.0454, -10.1922,\n",
      "           0.8840,  -9.6408,  13.7255]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 13.725508073176469\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.3671, -10.2413,  -2.0310, -12.6272,   5.3535, -13.8127, -12.2793,\n",
      "           5.6922,  -6.2280,  37.6391]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 37.6391498497897\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -9.5977, -14.9660,  -1.1777,  -4.5038,   0.9867,  -3.9718,  -3.1766,\n",
      "          23.3800,   7.1050,   7.0162]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 23.379988618502363\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 20.8805, -39.1372,  -3.4405,   9.9599,   0.7501,   9.6881, -15.2281,\n",
      "           9.6090,  -0.5089,   8.3016]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 20.880465153494114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.7203,  4.5550, -1.3421, -1.8116, -4.1539, -3.3762, -3.9219,  3.1186,\n",
      "         -2.7657, 11.2704]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 11.270351508293317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.6559,   5.2186,  -2.9952,   1.1684,  -5.6241,   0.3548,  -7.3030,\n",
      "           9.1039, -18.3537,  11.8950]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 11.894959005384047\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.9387,   6.3969,  -3.5182,   1.8351,  -4.0368,  -4.9551, -12.8819,\n",
      "          -0.4309,  -8.2650,  19.0785]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.07852133928577\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.7319,  -6.3100,  -1.8217, -16.1658,   7.9963,  -9.5802, -14.7027,\n",
      "          14.0539, -10.7178,  31.5434]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 31.543412844632932\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.7840, -14.9288,  -2.1862,  -0.8050,   4.2455,   3.1843,  -8.5001,\n",
      "           2.4344,  -6.7857,   8.5584]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 15.783966958617857\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.2218, -7.5580, -1.8540, -7.5892,  6.4683, -9.0735, -6.4756,  9.1290,\n",
      "         -1.9108, 18.4562]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.456156267481525\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.7809,   0.9598,  -1.8337,  -4.2627,   2.0590,  -4.9977, -14.4234,\n",
      "          -5.0098,  -3.4143,  22.0622]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.06223805996813\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.2739, 11.8149, -1.1390, -6.1165, -5.0322, -0.4241, -5.3994,  7.1611,\n",
      "         -9.8857,  5.2353]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 11.814946122314206\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.8915, -25.2339,  -1.1990,   5.3442,   1.6056,   9.1041,  -7.2780,\n",
      "           7.2875,   2.8095,  -2.9567]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 10.891462156231405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.3767,  -3.7754,  -1.6633, -15.4904,  11.9464,  -8.7470,  -6.5397,\n",
      "          18.9262,  -7.2157,  17.2723]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 18.926210210060635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[18.0795, -6.0753, -4.0335,  7.7668, -5.2004,  3.7072, -9.9671, -6.4545,\n",
      "         -8.7688, 10.8701]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 18.07952226844259\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.8296, -19.9253,  -3.1669,   4.7825,  -4.0486,  -0.9153,  -7.3048,\n",
      "          -3.7893,   0.1879,  17.0779]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 17.829627558758045\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.3593,  3.4312, -0.7253, -2.7366, -4.4174, -0.0976,  0.7204,  3.5589,\n",
      "         -4.8656,  2.7053]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 3.558927924483622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.0597, -2.7186, -1.6420, -6.1037, -3.3324, -3.9871, -9.8778,  0.5447,\n",
      "         -5.3260, 20.2920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.29197787487113\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-1.1375e+01, -3.2184e+00, -1.0622e+00, -1.4080e+01, -4.5977e-01,\n",
      "          1.7090e-01, -1.3774e+01,  2.5246e+01, -3.4718e-03,  1.9454e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 25.246419646691578\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.7681,  -4.9194,  -3.7639,   5.6390,  -0.5682,  -0.0736, -14.1816,\n",
      "          -1.9142,  -9.2978,  19.2766]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 19.276576438348087\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.9678,  -7.0041,  -2.4116,   0.4375,   4.5653, -11.6019, -16.9386,\n",
      "          -1.0305,  -0.8919,  31.9872]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 31.987209100289256\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.4761, -14.9502,  -1.7151,   0.3468,  -3.8619,  -3.0333,   2.0676,\n",
      "          -4.7339,   0.7258,  14.6735]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 14.673506497760249\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.2060,  5.4965, -1.1193, -5.4850, -3.2741,  0.2107, -0.0788,  6.6162,\n",
      "         -7.9976,  2.5804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  1\n",
      "activation[7] = 6.616163177931281\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.0266,   1.2125,  -2.9177,  -2.5856,  -1.0852,   6.0346, -11.8050,\n",
      "          -4.6315, -11.5311,  15.3518]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 15.351804433486846\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0579,  10.3409,  -1.5253,  -5.9754,  -7.8988,  -1.0664,  -2.8095,\n",
      "           7.5194, -10.5127,   7.8970]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 10.340918373987257\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.8073, -40.8020,  -2.7812,   6.0444,   4.1342,  12.1370,  -8.6628,\n",
      "           8.7560,   1.0918,   2.3295]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 19.807258004377065\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.5388e+00, -3.0326e+00, -1.1338e+00, -1.3458e+00,  2.9769e+00,\n",
      "         -8.5561e+00, -1.8793e+01,  1.1546e+00,  1.7817e-02,  2.7570e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 27.56961960546616\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.8181,  -3.2486,  -3.5195,   7.1825,   0.4686,   2.6564, -15.5182,\n",
      "          -5.2335,  -9.0704,  12.0022]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 14.818126111516007\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.2213, -24.5033,  -1.8516,  -0.7543,   5.6154,   7.6999, -15.3101,\n",
      "           1.9625,   6.8456,   6.7757]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 14.221293795116656\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.6974,   0.6291,  -3.5721,  11.9028,  -1.7273,   0.1972, -12.6563,\n",
      "          -5.5808,  -7.1339,   6.9947]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 11.902757956178672\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.6366, -1.1682, -1.7127,  0.7361, -5.1556, -6.2167, -0.4878,  3.6749,\n",
      "         -5.4621, 12.0775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.077510130376819\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.8238, -15.4937,  -3.4583,   0.0312,  -5.0612,   3.5359, -10.5976,\n",
      "           8.4129,  -1.4644,  15.0549]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 15.054947818698393\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.1949,   3.0117,  -1.6972,  -5.5593,  -2.3269, -11.1835, -14.6214,\n",
      "           9.6309,  -6.4581,  29.1680]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 29.168022773014194\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.0012e+01, -3.7077e+01, -3.2029e+00,  8.3692e+00, -2.6249e-02,\n",
      "          1.3850e+01, -7.4406e+00,  3.4674e+00,  1.5304e+00,  2.4523e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 20.012155192827365\n",
      "----------------------------------------------------\n",
      "output:  tensor([[10.3263,  0.9855, -1.6273, -5.3436, -3.8778, -0.7576, -8.3393,  3.1250,\n",
      "         -9.0807, 14.8614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 14.86141119665787\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.9273, -19.2420,  -2.2884, -10.4478,  -2.9505,  -8.4690, -17.1332,\n",
      "           7.3479,  -2.4440,  43.9341]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 43.93410784135419\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.9197, -23.0512,  -2.7149,  -6.0078,  -6.0049,   1.2764,  -8.0969,\n",
      "           9.5169,  -4.6944,  23.2286]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 23.228628480507503\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 21.1890, -46.3282,  -2.9661,   7.4312,  -4.0586,   4.3414, -11.7725,\n",
      "          13.7429,   5.4795,  14.2380]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 21.189013625596356\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.4328,  0.7702, -1.0502, -1.1277, -0.9242, -2.1561, -1.3957,  1.9588,\n",
      "         -3.9854,  5.2918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 5.291819569707747\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.3380, -9.4159, -1.8578,  0.7090, -9.0371, -4.5630,  5.1333, -3.3567,\n",
      "         -0.0866, 15.2392]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.239222246956858\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.4406,   4.2480,  -2.1824,  -6.7807,  -7.6630, -10.5611, -11.3093,\n",
      "          11.1776,  -6.5627,  28.5640]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.564044356077623\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.7371,  12.7280,  -1.3288,  -6.7983,  -6.9857,   0.3256,  -3.3304,\n",
      "           7.7013, -10.9666,   5.7722]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 12.728049454639116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.1420,  -2.1113,  -1.5247,   1.3083,  -1.6775,  -8.2978, -11.2754,\n",
      "           1.3343,   1.6217,  21.1956]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 21.195562213928568\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-0.0747, -7.6414, -1.9669, -3.7429,  3.8278, -9.2118, -5.3295,  7.8288,\n",
      "         -1.7517, 18.3301]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.330114438431742\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.7693, -15.5102,  -2.4255,   4.7009,  -4.6577,  -0.5102,   4.2999,\n",
      "          -7.4920,   0.4653,   8.4714]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 13.769336226833033\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.6690,   9.3995,  -2.4642,  -4.4594,   4.0026,  -8.5658,  -6.2242,\n",
      "          13.7648, -12.7865,  10.3756]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 13.764841090867051\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.4126,  -8.8371,  -2.2863,   1.0125,   0.6207,   4.8676, -13.2661,\n",
      "          -4.5526,   2.6792,  12.7372]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 12.737186625235145\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.1854,  -2.7880,  -3.3416,  -0.6540,   4.1508,  -4.6935, -18.2906,\n",
      "           5.1041, -13.6365,  27.6060]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 27.606001813980264\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.4569,   3.5620,  -2.5931,  -1.9015,  -3.5111,  -5.6483,  -5.6731,\n",
      "           0.4645, -10.0607,  17.2822]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 17.282207092723965\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2572,   0.3559,  -4.4193,  15.8656,  -1.6308,   3.2024,  -9.2861,\n",
      "           0.0598, -15.4098,   1.3356]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  3 Label:  3\n",
      "activation[3] = 15.865551479794263\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -3.7878,   6.0651,  -2.1021,  -1.4838,  -2.8668, -12.8116, -17.7372,\n",
      "           9.1078,  -5.5660,  31.0737]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 31.073749128989057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.7421,  -3.5908,  -2.2824,  -3.2810,  13.6971, -11.6181,  -9.9015,\n",
      "           4.3194,  -9.7469,  19.9427]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 19.942739774612242\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 18.0979,  -2.5789,  -4.5278,  -6.2842,   2.2133,   1.8679, -13.9384,\n",
      "           5.2134, -23.6439,  24.0682]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.068220283250625\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -4.2916,  -4.7281,  -1.7021, -11.8802,   5.4617,  -4.4097,  -6.2619,\n",
      "          16.6186,  -3.1376,  14.3471]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 16.618582715079285\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.8537,  -3.6563,  -2.9361,   8.5548, -10.8240,  -2.5561,  -7.5164,\n",
      "          -1.7917,  -2.4879,  13.2784]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 13.278406303123164\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.3400,   6.9286,  -2.2210,  -0.2405, -18.4293,  -2.4633,  -0.1378,\n",
      "          -1.2959,  -8.6615,  15.6651]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.665090408270046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -0.6015,   5.2819,  -2.0294,  -0.7520,   5.9052,  -9.6396, -11.4719,\n",
      "           4.9549,  -9.7826,  18.0816]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 18.081576472814085\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 15.0071, -17.1755,  -1.9920,   2.4855,  -5.4963,   0.1159,   4.6163,\n",
      "          -5.9137,  -0.5439,   9.6206]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 15.00708214493498\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 17.1616, -21.0612,  -2.3417,   2.8859,   4.0100,   0.5951,  -8.6107,\n",
      "           0.3251,  -1.9971,  10.9710]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  6\n",
      "activation[0] = 17.16161347570838\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.1424, -11.0925,  -3.2402,   5.2875,   0.7697,   0.2945, -14.0995,\n",
      "          -7.2030,   0.4351,  18.2823]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 18.282288630665967\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 7.7869, -5.2189, -1.7289,  2.9170, -5.0836,  0.2757, -2.3224, -6.9048,\n",
      "          1.9796,  9.2638]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 9.263760664667613\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.6417,  -4.1211,  -3.0092,  -0.3042,  -2.3095,   2.4453, -15.2460,\n",
      "         -12.1075,  -3.9951,  23.8196]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 23.819620185453893\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.4083,  -3.9364,  -2.2821, -14.8345,  10.7685, -15.4844, -13.7782,\n",
      "          14.8379,  -7.3624,  33.9445]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 33.94450607396596\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.7217, -30.0109,  -1.6272,  -0.8873,  -6.3411,  -4.5205,  -5.9547,\n",
      "           2.1156,   9.3240,  25.5168]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 25.51684522568106\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.3160,  -6.6368,  -1.0670,  -3.1824,   2.6352,  -7.5400, -13.2687,\n",
      "          -0.8505,   4.8551,  23.3476]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.34758561172717\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.5067,  -4.5517,  -1.7569,  -5.7253,   8.1245, -12.4500,  -6.0564,\n",
      "           5.4294,  -6.3559,  21.6708]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 21.67080569634436\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.2412, -16.4266,  -1.9755,  -5.3271,   6.9017,   7.5032, -15.2889,\n",
      "           3.1537,   1.9806,  11.7148]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 11.714832527441667\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -7.4490, -17.0703,  -1.6869,  -4.7278,   2.8605,  -8.6514,  -6.8621,\n",
      "          18.2390,  10.7960,  15.9493]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 18.238956500615483\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.7149,   3.6427,  -2.5759,   2.2158, -11.0993,  -4.9407, -12.9449,\n",
      "          -8.7939,   1.1886,  22.5053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.50525884885662\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.4956,  21.8289,  -1.8545,  -9.0125,  -6.5809,   0.7549, -13.6467,\n",
      "           6.9177, -15.7094,  12.0252]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 21.828932543700635\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -2.7575, -18.2004,  -1.6703,  -2.8459,   3.0016,   0.5347, -12.0285,\n",
      "          27.1318,  -0.8887,   8.5611]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 27.131782251658027\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 19.0157, -36.7290,  -3.0742,  10.0802,   0.3239,  15.0667,  -7.8150,\n",
      "           7.7264,  -2.4278,  -0.9930]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 19.015655767825315\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.4853,  2.6805, -1.8649, -0.3175, -3.1433, -6.0141, -4.0614,  2.0527,\n",
      "         -5.2572, 12.9104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 12.91043603464835\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.9897,  -6.0807,  -2.7944,   1.3617,   3.1919,  10.5089, -14.8017,\n",
      "          -8.4481,  -6.0199,   8.9604]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 13.989685248999685\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.8615, -12.8605,  -3.0611,   3.3083,   2.9223,  -1.7874, -18.8681,\n",
      "          -2.3580,  -6.0813,  25.8902]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 25.89022753667819\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.4746,   0.9646,  -1.9535, -10.2670,   4.1026,  -8.1504,  -2.4119,\n",
      "          18.6047,  -6.6676,  12.5369]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 18.604747075255617\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.0948, -0.7709, -1.4469, -0.4457, -2.2879, -4.0573, -1.8505,  3.7302,\n",
      "         -5.3724,  8.9693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.969335448278715\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.2204,  -7.5913,  -2.1455, -11.3448,   6.7100,  -7.0561,  -8.3382,\n",
      "           9.3797,  -7.6471,  23.5328]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 23.53279720460695\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.1358, -15.2752,  -2.6090,   5.5157,  -0.0589,   1.4962, -14.3660,\n",
      "         -13.4724,   8.7502,  20.3673]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 20.367305061104048\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.0471e-02,  1.4767e+01, -1.4899e+00, -7.4005e+00, -9.2176e-01,\n",
      "         -1.6312e+00, -4.9702e+00,  1.1539e+01, -1.5646e+01,  6.1483e+00]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  5\n",
      "activation[1] = 14.767406785120267\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.7107, -21.4886,  -1.2237,  -6.7813,  -3.1617,  -6.5185, -13.9433,\n",
      "          25.2282,   7.5315,  28.4872]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 28.487231360835317\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.6405, -13.9526,  -1.5698, -11.7096,   3.7598,  -2.8318,  -0.6544,\n",
      "           7.5638,  -4.9724,  15.9801]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 15.980103185076247\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -6.9477, -12.7223,  -1.0616,  -7.0880,   1.2509,  -2.0865,  -6.4477,\n",
      "          20.2282,   2.0279,  14.0384]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  4\n",
      "activation[7] = 20.228211996082653\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.2642,   9.2904,  -2.5977, -10.9376,  -6.6296,  -0.5284,  -5.9278,\n",
      "          19.0204, -18.7585,  15.2752]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  2\n",
      "activation[7] = 19.020430098914815\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.5415, -11.5580,  -2.8454,   8.9119,   0.1763,  10.7187,  -9.9315,\n",
      "         -10.2245,   3.1597,  -0.1114]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  5\n",
      "activation[0] = 12.541515463051816\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.8533, -11.2487,  -3.8812,   5.8483,  -0.7095,  -3.4435, -12.9891,\n",
      "          -3.2506,  -9.6150,  27.3237]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 27.323657333190063\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.5877, -11.3945,  -0.3175,  -3.8800,   2.1603,  -1.3103,  -4.2778,\n",
      "          14.8484,   0.4263,   3.8578]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  7\n",
      "activation[7] = 14.848379544808534\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.3230,  -7.3012,  -2.2435,  -8.0303,  14.4059, -11.5666,  -7.1595,\n",
      "           6.0366,  -8.8485,  22.1152]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 22.11515416255154\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.3144, -22.2143,  -2.3557,   0.1848,  -5.7342,  -2.5405,   1.1577,\n",
      "          -3.6137,   2.3901,  18.5663]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 18.56634328195433\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.8810, -16.5658,  -2.1071,  -3.4316,  -1.2529,   0.5664,  -6.6380,\n",
      "           5.8046,  -6.7437,  17.5150]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 17.515029642773086\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.2195, -23.2882,  -1.9377,  -9.8430,   1.1035,   1.9398,  -5.5214,\n",
      "          21.8889,  -8.4611,  14.9854]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 21.88893645340481\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.9143,  19.2709,  -1.7380,  -9.8132,  -0.7423,  -2.6689, -13.6674,\n",
      "           8.6277, -15.2579,  12.2599]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 19.270879678737185\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 26.8013, -46.1352,  -2.6849,  10.5026,   1.1019,  16.5775, -12.4647,\n",
      "           6.8364,   2.2823,  -1.4131]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 26.801257647711555\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.2218,  22.5109,  -1.9395,  -8.7177,  -7.5771,   0.4320, -12.9089,\n",
      "           7.5633, -16.4736,  12.0487]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 22.510909907536576\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 21.4875,   0.7481,  -3.1792,   4.1138, -10.3630,   2.3163, -14.0327,\n",
      "           1.8709, -13.4955,  10.6102]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 21.487510895703114\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  2.3613,  -7.1979,  -2.3382,  -3.5084,   7.6221, -15.4479,  -9.9498,\n",
      "           1.9453,  -3.2878,  30.6722]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.672227483934982\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.2787, -2.1269, -1.2118,  2.4891, -3.2135, -1.0452, -3.7434, -1.2504,\n",
      "          0.6516,  7.6524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 7.652448875092494\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  8.1202,   5.7558,  -2.5398,  -6.5249,  -4.1126,   0.1219,  -3.3355,\n",
      "          12.5199, -21.3352,  11.5554]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 12.5198589138761\n",
      "----------------------------------------------------\n",
      "output:  tensor([[10.5974, -7.3312, -3.0320,  2.0952, -6.6428,  7.7328, -8.8482, -2.2159,\n",
      "          1.5848,  7.0468]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  3\n",
      "activation[0] = 10.597374372364367\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.3642,   5.8617,  -1.3968,  -7.6825,  -0.4124,  -2.4662,  -0.6524,\n",
      "          12.4871, -11.7948,   4.7677]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 12.487097309958447\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 5.9051,  0.3525, -1.8821, -1.1971, -8.8631, -4.9800, -4.5003, -1.0280,\n",
      "         -0.6893, 18.0380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  0\n",
      "activation[9] = 18.038007383722622\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.9190, -33.7605,  -3.0659,   9.3098,  -2.5892,   8.2390,  -4.9599,\n",
      "           9.1597,  -2.8563,   6.6593]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 14.918985712573438\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.3419, -14.1999,  -2.5104,  -8.8389,   1.8135,  -2.6143, -12.0098,\n",
      "          22.1709,  -5.1525,  18.2677]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  6\n",
      "activation[7] = 22.170860060499425\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.3199, -12.6558,  -1.8766,   0.4397,   4.5092,  -8.0363,  -6.3062,\n",
      "           0.5722,   2.5891,  17.6545]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 17.654467813440142\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 8.7616,  1.2081, -2.9518,  6.5539, -4.7484, -3.9625, -8.8171,  1.0190,\n",
      "         -7.8876, 11.3725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 11.372482439728527\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 13.8027,  -1.2361,  -3.3130,  -1.8993,  -1.3622,   0.3435, -14.1575,\n",
      "          -0.3065, -16.1867,  24.2921]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 24.292127246545988\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-4.1724,  3.0010, -1.8447, -0.8454, -7.2586, -2.7140, -9.7234,  8.7927,\n",
      "         -2.6742, 17.0051]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 17.005099633839713\n",
      "----------------------------------------------------\n",
      "output:  tensor([[-5.8962, -9.3836, -2.0146, -7.5464,  6.4019, -9.9536, -6.9017, 16.9017,\n",
      "          1.1843, 18.1581]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 18.158082041912706\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.3685,  3.3470, -1.4907, -2.3519, -1.7476, -5.1158, -1.9036,  5.8230,\n",
      "         -7.2159,  8.7535]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  1\n",
      "activation[9] = 8.75350168944528\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.1024, -18.5123,  -2.0086,   3.6142,   4.5013, -11.6807, -11.9972,\n",
      "          -5.9558,  10.5539,  27.5069]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 27.50689013052981\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ -1.0999,   1.4985,  -1.8023,   1.7145,   0.9945,   6.5096, -12.2118,\n",
      "           6.3753,  -1.8772,  -0.1483]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  5 Label:  3\n",
      "activation[5] = 6.509623262334543\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.9995, -20.0662,  -1.9307,  -9.6016,  -2.7843,  -4.8740, -11.6434,\n",
      "           6.5118,   2.0289,  34.8312]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 34.831224913106894\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.0468,   5.1766,  -1.7922,   1.0368, -13.2750,   2.1700,  -6.0195,\n",
      "           2.7937,  -8.1502,   6.2973]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 12.046813679919849\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 1.0085e+01, -6.9277e+00, -2.8784e+00, -9.7140e-01, -1.1305e+01,\n",
      "          1.6229e-03, -2.2831e+00,  1.1231e+01, -8.0546e+00,  1.1572e+01]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 11.5722838293025\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.2492, -27.2220,  -2.9124,   7.0542,  -0.7296,   9.1033, -11.0272,\n",
      "          11.8594,  -0.6653,   6.5355]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  0\n",
      "activation[7] = 11.85935542637693\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.9806,  -0.4617,  -3.6723,   7.1864,   1.1725,   0.2025, -16.5719,\n",
      "          -7.0869,  -9.6585,  18.0659]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 18.06593589665821\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  7.9884,   0.9086,  -1.6595,   2.6692, -11.2289,  -6.4074,   1.7154,\n",
      "          -3.7468,  -4.7979,  15.8223]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 15.822277159021722\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.6570, -4.7892, -2.3835, -8.1991, -2.1347,  0.3186, -2.7350,  8.6225,\n",
      "         -9.9518, 13.3399]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  6\n",
      "activation[9] = 13.33986526453116\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  0.1251,  -9.5222,  -1.3277,  -5.4505,   0.3381, -13.7209,  -8.8240,\n",
      "          10.2773,  -0.5218,  28.6615]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  7\n",
      "activation[9] = 28.661458757654557\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  3.2519,  -9.0084,  -2.4861,  -0.6356,   7.6654, -14.5369, -11.9140,\n",
      "          -1.1579,  -1.3805,  30.2975]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 30.29754464479405\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.7678,   5.6452,  -2.7540,   4.4167,  -1.5335,  -1.5005, -16.4009,\n",
      "          -1.8948,  -1.6530,  14.0569]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  3\n",
      "activation[9] = 14.056905982626189\n",
      "----------------------------------------------------\n",
      "output:  tensor([[12.3396, -9.9931, -3.4744,  1.8930, -9.0211,  8.0565, -6.1377,  5.5341,\n",
      "         -2.8811,  4.8756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  2\n",
      "activation[0] = 12.33957247216346\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 10.5548,  -5.4438,  -2.7031,   1.5805,  -1.8568,  -4.8311, -10.8247,\n",
      "           0.8269,  -7.3341,  20.6769]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 20.676866936162284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0382,   3.7970,  -2.4967, -12.8757,  14.2656,  -6.4625, -17.7133,\n",
      "          10.3307, -16.4853,  23.8809]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 23.88089721520344\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  9.0013, -28.1775,  -1.1314,  -4.0582,  -3.8968,   3.4383, -10.8798,\n",
      "          11.3731,   5.0218,  20.0774]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  9\n",
      "activation[9] = 20.077403500372284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  4.0520,  26.3400,  -1.9873,  -8.0556,  -8.1643,   0.8937, -15.2945,\n",
      "           7.2850, -19.0779,  13.1825]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 26.34004905909465\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 14.2572, -27.5207,  -2.0291,   0.3135,   5.0314,  10.1980, -16.1701,\n",
      "          10.7782,  -1.8802,   8.1527]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 14.257240477431608\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.3499,  11.6099,  -2.5620,  -2.3763,  -2.1753,  -5.4766,  -8.6581,\n",
      "          11.2063, -20.4573,  14.2293]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  5\n",
      "activation[9] = 14.229345379554784\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 9.2184,  1.8053, -1.7045, -1.9490, -9.1019, -7.5890, -5.6155,  1.8475,\n",
      "         -8.4646, 21.6520]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 21.651996632079175\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  1.6566,  -4.1318,  -2.4003,   0.6711,   6.5690, -13.9676, -18.1403,\n",
      "           6.9002,  -6.0513,  29.5699]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 29.56992423445284\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 3.3441,  5.8402, -1.3964, -1.8000, -6.7358, -1.1712, -9.3429, -2.2856,\n",
      "         -0.4277, 14.1262]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 14.12622922098929\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 11.6505, -12.9544,  -3.0150,  -7.4245, -10.6804,  -1.1475,  -1.7437,\n",
      "           6.8077,  -0.1232,  19.4053]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  2\n",
      "activation[9] = 19.40528069892445\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 2.6898,  8.5207, -1.3622, -6.3768, -2.9436, -1.5664, -2.7897,  6.4322,\n",
      "         -8.4017,  5.2737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  1 Label:  1\n",
      "activation[1] = 8.520685153641057\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 23.7587, -37.8138,  -3.1256,   8.0436,  -1.2377,  11.3756,  -8.4777,\n",
      "           8.1047,  -4.6229,   5.4204]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  0\n",
      "activation[0] = 23.758675000395918\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 12.2407,   6.8183,  -2.9218, -14.4240,  -1.1215,   2.5109, -10.3340,\n",
      "           6.5812, -22.2545,  22.5838]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  8\n",
      "activation[9] = 22.583785499715745\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  5.9953, -15.2311,  -2.0939,  -0.4251,   0.0675,  -7.7459,  -3.3428,\n",
      "          -5.2598,   8.1027,  20.6942]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 20.69418999256247\n",
      "----------------------------------------------------\n",
      "output:  tensor([[  6.0120,  -4.6838,  -2.5118,   2.8828,  -4.6384, -14.6483, -16.8600,\n",
      "           1.9283,  -0.3931,  33.1868]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  9 Label:  4\n",
      "activation[9] = 33.18683152127046\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 16.1558,  -1.5520,  -3.0245,   0.1659,   3.3847,   3.9094, -10.8721,\n",
      "          -7.3898, -14.4000,  12.8431]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Pred:  0 Label:  8\n",
      "activation[0] = 16.155789720368286\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "batch [20]: loss = 12.175, accuracy = 26.95\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([-0.4910,  0.3104, -0.0329, -0.4580,  0.0823, -0.0431, -0.5426,  0.8818,\n",
      "        -0.0433,  0.4377], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "net = LinLayer()\n",
    "weights = net.lin.weight\n",
    "print(\"initial weights: {}\".format(weights))\n",
    "biases = net.lin.bias\n",
    "print(\"initial biases: {}\".format(biases))\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "it = iter(mnist_dl) \n",
    "\n",
    "for batch in range(20):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    print(\"weights: {}\".format(weights))\n",
    "    print(\"biases: {}\".format(biases))\n",
    "    for i in range(256):\n",
    "        net.zero_grad()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # print the current weights and biases\n",
    "        weights = net.lin.weight\n",
    "        biases = net.lin.bias\n",
    "        image, label = next(it)\n",
    "        output = net(image.to(torch.float64))\n",
    "        print(\"output: \", output)\n",
    "        pred = torch.argmax(output).numpy()\n",
    "        if(pred == label[0].numpy()):\n",
    "            correct += 1\n",
    "        print(\"Pred: \", pred, \"Label: \", label[0].numpy())\n",
    "        print(\"activation[{}] = {}\".format(pred, output[0][pred]))\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        # print(\"backward weights: {}\".format(weights))\n",
    "        # print(\"backward biases: {}\".format(biases))\n",
    "        running_loss += loss.item()\n",
    "        # print(\"Loss: \", loss.item())\n",
    "        # print(\"Correct: \", correct)\n",
    "        # print(\"Accuracy: {} %\".format(100*correct/256))\n",
    "        if i % 256 == 255:    # print every 256 mini-batches\n",
    "            print(\"----------------------------------------------------\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "            print('batch [%d]: loss = %.3f, accuracy = %.2f' % (batch + 1, running_loss / 256, 100*correct/256))\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            print(\"----------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "    optimizer.step()\n",
    "    # print the updated weights and biases\n",
    "    weights = net.lin.weight\n",
    "    biases = net.lin.bias\n",
    "    print(\"updated weights: {}\".format(weights))\n",
    "    print(\"updated biases: {}\".format(biases))\n",
    "    # # print(\"acc = \", (correct/256) * 100)\n",
    "        # # print(torch.argmax(output).numpy())\n",
    "        # optimizer.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1598, -0.0484,  0.0685,  0.4418,  0.0252, -0.2573,  0.2446, -0.1718,\n",
       "          0.2287,  0.0333]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_grads.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0801,  0.0895,  0.1006,  0.1462,  0.0964, -0.9273,  0.1200,  0.0791,\n",
       "         0.1181,  0.0972])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s_images.astype(np.float16)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "initial biases: Parameter containing:\n",
      "tensor([ 0.0298, -0.0277,  0.0149,  0.0131,  0.0262,  0.0057, -0.0165,  0.0169,\n",
      "         0.0078,  0.0310], dtype=torch.float64, requires_grad=True)\n",
      "----------------------------------------------------\n",
      "output:  tensor([[ 0.0534,  0.1614,  0.2875,  0.0104,  0.2178, -0.2916, -0.0588,  0.4338,\n",
      "          0.1176,  0.0230]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Pred:  7 Label:  5\n",
      "activation[7] = 0.4337690970363521\n",
      "----------------------------------------------------\n",
      "updated weights: Parameter containing:\n",
      "tensor([[-3.1560e-02, -3.1221e-02, -2.6887e-02,  ..., -2.4941e-05,\n",
      "          1.3176e-02,  3.4670e-02],\n",
      "        [ 2.9437e-02,  4.8206e-04,  2.0457e-02,  ...,  2.2568e-02,\n",
      "         -2.5558e-02,  1.1166e-02],\n",
      "        [ 1.1707e-02, -1.9986e-02, -8.9901e-03,  ...,  1.7762e-02,\n",
      "          1.6051e-02, -6.3088e-03],\n",
      "        ...,\n",
      "        [ 9.1818e-03, -2.7026e-02, -1.9310e-02,  ..., -2.9743e-02,\n",
      "          2.2434e-02, -1.3787e-02],\n",
      "        [-6.9841e-03, -2.1756e-02, -2.8993e-02,  ...,  2.2575e-02,\n",
      "         -4.3033e-03, -1.8470e-02],\n",
      "        [ 2.4284e-02,  2.0369e-02, -6.6877e-03,  ...,  3.1235e-02,\n",
      "          1.8621e-03,  2.9635e-02]], dtype=torch.float64, requires_grad=True)\n",
      "updated biases: Parameter containing:\n",
      "tensor([ 0.0298, -0.0277,  0.0149,  0.0131,  0.0262,  0.0057, -0.0165,  0.0169,\n",
      "         0.0078,  0.0310], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# single step of training \n",
    "torch.manual_seed(42)\n",
    "\n",
    "net = LinLayer()\n",
    "weights = net.lin.weight\n",
    "print(\"initial weights: {}\".format(weights))\n",
    "biases = net.lin.bias\n",
    "print(\"initial biases: {}\".format(biases))\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "it = iter(mnist_dl) \n",
    "\n",
    "for i in range(1):\n",
    "    net.zero_grad()\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # print the current weights and biases\n",
    "    weights = net.lin.weight\n",
    "    biases = net.lin.bias\n",
    "    image, label = next(it)\n",
    "    output = net(image.to(torch.float64))\n",
    "    print(\"output: \", output)\n",
    "    pred = torch.argmax(output).numpy()\n",
    "    if(pred == label[0].numpy()):\n",
    "        correct += 1\n",
    "    print(\"Pred: \", pred, \"Label: \", label[0].numpy())\n",
    "    print(\"activation[{}] = {}\".format(pred, output[0][pred]))\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    # print(\"backward weights: {}\".format(weights))\n",
    "    # print(\"backward biases: {}\".format(biases))\n",
    "    running_loss += loss.item()\n",
    "    # print(\"Loss: \", loss.item())\n",
    "    # print(\"Correct: \", correct)\n",
    "    # print(\"Accuracy: {} %\".format(100*correct/256))\n",
    "    if i % 256 == 255:    # print every 256 mini-batches\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print('batch [%d]: loss = %.3f, accuracy = %.2f' % (batch + 1, running_loss / 256, 100*correct/256))\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "optimizer.step()\n",
    "# print the updated weights and biases\n",
    "u_weights = net.lin.weight\n",
    "u_biases = net.lin.bias\n",
    "print(\"updated weights: {}\".format(u_weights))\n",
    "print(\"updated biases: {}\".format(u_biases))\n",
    "# # print(\"acc = \", (correct/256) * 100)\n",
    "    # # print(torch.argmax(output).numpy())\n",
    "    # optimizer.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "            'IN_CH1': 28,\n",
    "            'IN_CH2': 28,\n",
    "            'OUT_CH': 10,\n",
    "            'DATASET_SIZE': 5,\n",
    "            'INPUT': s_images,\n",
    "            'LABELS': s_labels,\n",
    "            'WEIGHTS': weights.detach(),\n",
    "            'BIASES': biases.detach(),\n",
    "            'WEIGHT GRADIENTS': weight_grads,\n",
    "            'BIAS GRADIENTS': bias_grads,\n",
    "            'prec': 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mnist_header_file('mnist', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "weights.flatten()[0]\n",
    "print(type(s_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1598, -0.0484,  0.0685,  0.4418,  0.0252, -0.2573,  0.2446, -0.1718,\n",
      "          0.2287,  0.0333]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0801, 0.0895, 0.1006, 0.1462, 0.0964, 0.0727, 0.1200, 0.0791, 0.1181,\n",
       "         0.0972]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)\n",
    "sm = nn.Softmax(dim=1)\n",
    "sm(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4418, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 152,  153,  154, ..., 7737, 7738, 7739]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(weight_grads.flatten() != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0057)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_grads.flatten()[153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0801,  0.0895,  0.1006,  0.1462,  0.0964, -0.9273,  0.1200,  0.0791,\n",
       "         0.1181,  0.0972])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycparser as pyc\n",
    "from pyclibrary import CParser\n",
    "\n",
    "\n",
    "parser = CParser('/home/msc22f11/snitch/sw/applications/data/data_full_mnist.h')\n",
    "\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.defs['variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02730494923889637,\n",
       " 0.029643140733242035,\n",
       " -0.008366874419152737,\n",
       " 0.032807547599077225,\n",
       " -0.007825127802789211,\n",
       " 0.007206810638308525,\n",
       " -0.01738768070936203,\n",
       " 0.020974380895495415,\n",
       " 0.03148367628455162,\n",
       " -0.026201006025075912,\n",
       " 0.03104272112250328,\n",
       " 0.006684260908514261,\n",
       " 0.02638603188097477,\n",
       " 0.004836806561797857,\n",
       " 0.017221003770828247,\n",
       " -0.005042536184191704,\n",
       " 0.027531638741493225,\n",
       " 0.005278890021145344,\n",
       " -0.016672855243086815,\n",
       " 0.009103511460125446,\n",
       " -0.01645488105714321,\n",
       " -0.004188316408544779,\n",
       " -0.014505655504763126,\n",
       " 0.023691821843385696,\n",
       " -0.028191793709993362,\n",
       " -0.016464656218886375,\n",
       " -0.01008481252938509,\n",
       " -0.021474016830325127,\n",
       " 0.0033708258997648954,\n",
       " -0.03527425602078438,\n",
       " 0.032253898680210114,\n",
       " -0.03033815324306488,\n",
       " 0.027572408318519592,\n",
       " 0.005943541415035725,\n",
       " -0.011596591211855412,\n",
       " 0.022069642320275307,\n",
       " 0.005566099192947149,\n",
       " 0.028855836018919945,\n",
       " 0.0039042746648192406,\n",
       " -0.011263328604400158,\n",
       " 0.009595845825970173,\n",
       " -0.009684979915618896,\n",
       " 0.015030627138912678,\n",
       " 0.0318865068256855,\n",
       " 0.020644985139369965,\n",
       " -0.015613305382430553,\n",
       " 0.020616596564650536,\n",
       " 0.006390222813934088,\n",
       " 0.018136966973543167,\n",
       " -0.02176803909242153,\n",
       " -0.035353876650333405,\n",
       " -0.013798590749502182,\n",
       " -0.027393674477934837,\n",
       " 0.02930496074259281,\n",
       " 0.010286834090948105,\n",
       " 0.014793341048061848,\n",
       " 0.011295042000710964,\n",
       " -0.0006212847656570375,\n",
       " 0.02795029617846012,\n",
       " -0.0253754872828722,\n",
       " 0.002248704433441162,\n",
       " -0.024376435205340385,\n",
       " 0.01101257186383009,\n",
       " -0.012299368157982826,\n",
       " 0.010943438857793808,\n",
       " -0.007440767250955105,\n",
       " 0.02962113916873932,\n",
       " -0.021167926490306854,\n",
       " -0.021299930289387703,\n",
       " -0.021301215514540672,\n",
       " 0.032122958451509476,\n",
       " 0.011901826597750187,\n",
       " 0.034366097301244736,\n",
       " -0.029474154114723206,\n",
       " -0.03542415052652359,\n",
       " -0.027941564098000526,\n",
       " -0.024024611338973045,\n",
       " 0.014465720392763615,\n",
       " 0.012788424268364906,\n",
       " 0.02967587299644947,\n",
       " -0.018443763256072998,\n",
       " -0.02434685081243515,\n",
       " 0.018949219956994057,\n",
       " -0.014435875229537487,\n",
       " 0.021675851196050644,\n",
       " -0.008475023321807384,\n",
       " 0.02043021284043789,\n",
       " -0.02774885855615139,\n",
       " -0.018023205921053886,\n",
       " 0.010888445191085339,\n",
       " 0.007550269830971956,\n",
       " -0.009105670265853405,\n",
       " 0.021288195624947548,\n",
       " 0.024278901517391205,\n",
       " -0.025899048894643784,\n",
       " -0.019066721200942993,\n",
       " 0.032702215015888214,\n",
       " -0.012051161378622055,\n",
       " -0.012661299668252468,\n",
       " -0.034556951373815536,\n",
       " -0.020452508702874184,\n",
       " 0.008921559900045395,\n",
       " -0.0047140419483184814,\n",
       " -0.025924500077962875,\n",
       " 0.0008377390913665295,\n",
       " -0.024395769461989403,\n",
       " -0.030299881473183632,\n",
       " -0.01966652274131775,\n",
       " -0.03125757724046707,\n",
       " -0.022740645334124565,\n",
       " 0.03570031747221947,\n",
       " 0.006745534483343363,\n",
       " 0.011005704291164875,\n",
       " -0.03331015631556511,\n",
       " -0.023456208407878876,\n",
       " -0.011887708678841591,\n",
       " 0.0055846828036010265,\n",
       " -0.03142576292157173,\n",
       " -0.015388322994112968,\n",
       " -0.021381022408604622,\n",
       " 9.897351992549375e-05,\n",
       " -0.013289401307702065,\n",
       " -0.0024748488795012236,\n",
       " -0.024201061576604843,\n",
       " -0.02451411448419094,\n",
       " -0.02083577960729599,\n",
       " -0.012224908918142319,\n",
       " -0.02818860486149788,\n",
       " 0.02994535304605961,\n",
       " -0.0070880018174648285,\n",
       " 0.030728455632925034,\n",
       " 0.011127931997179985,\n",
       " -0.03024275042116642,\n",
       " 0.024715544655919075,\n",
       " -0.009826600551605225,\n",
       " -0.013690216466784477,\n",
       " -0.029645375907421112,\n",
       " -0.035505738109350204,\n",
       " 0.010218237526714802,\n",
       " -0.007801567204296589,\n",
       " 0.013904397375881672,\n",
       " -0.029309410601854324,\n",
       " 0.026515327394008636,\n",
       " -0.026216205209493637,\n",
       " -0.006166905630379915,\n",
       " 0.007459632121026516,\n",
       " 0.018437564373016357,\n",
       " 0.028832513839006424,\n",
       " 0.03253426030278206,\n",
       " -0.028318649157881737,\n",
       " 0.00898811686784029,\n",
       " -0.01536164153367281,\n",
       " -0.003913743421435356,\n",
       " -0.026731790974736214,\n",
       " 0.03253066539764404,\n",
       " -0.02621251903474331,\n",
       " 0.019087545573711395,\n",
       " 0.012551414780318737,\n",
       " 0.01160557009279728,\n",
       " -0.019308794289827347,\n",
       " 0.032462555915117264,\n",
       " 0.007848229259252548,\n",
       " 0.00459428783506155,\n",
       " -0.03147338703274727,\n",
       " 0.014992446638643742,\n",
       " -0.005357878748327494,\n",
       " -0.016361583024263382,\n",
       " 0.030676664784550667,\n",
       " 0.007962456904351711,\n",
       " -0.019759872928261757,\n",
       " -0.018076390027999878,\n",
       " -0.0017055614152923226,\n",
       " 0.019941475242376328,\n",
       " -0.009126207791268826,\n",
       " -0.02037767507135868,\n",
       " -0.01223010290414095,\n",
       " -0.026681246235966682,\n",
       " 0.012736874632537365,\n",
       " 0.027644295245409012,\n",
       " -0.033622872084379196,\n",
       " 0.008294668048620224,\n",
       " 0.018449706956744194,\n",
       " 0.0064760493114590645,\n",
       " -0.012718738056719303,\n",
       " 0.0186407919973135,\n",
       " 0.018768329173326492,\n",
       " 0.013354544527828693,\n",
       " -0.006275764666497707,\n",
       " -0.009457188658416271,\n",
       " 0.003820747369900346,\n",
       " -0.006309075281023979,\n",
       " -0.010642895475029945,\n",
       " 0.02282881923019886,\n",
       " 0.030692841857671738,\n",
       " -0.0035356199368834496,\n",
       " -0.007996316999197006,\n",
       " 0.0005211532115936279,\n",
       " -0.002132437191903591,\n",
       " 0.008586117997765541,\n",
       " 0.010008344426751137,\n",
       " -0.03243774175643921,\n",
       " -0.013179919682443142,\n",
       " 0.030076052993535995,\n",
       " 0.013912678696215153,\n",
       " -0.001776341930963099,\n",
       " -0.021532349288463593,\n",
       " -0.021850181743502617,\n",
       " -0.03199167549610138,\n",
       " -0.011641515418887138,\n",
       " 0.012060863897204399,\n",
       " 0.022772202268242836,\n",
       " 0.016489190980792046,\n",
       " -0.031569432467222214,\n",
       " -0.0214772317558527,\n",
       " -0.005636309273540974,\n",
       " 0.03454820066690445,\n",
       " 0.005166339222341776,\n",
       " -0.009248955175280571,\n",
       " 0.014775545336306095,\n",
       " -0.013602913357317448,\n",
       " -0.023116273805499077,\n",
       " 0.026067402213811874,\n",
       " -0.0162393506616354,\n",
       " -0.007159527391195297,\n",
       " -0.03552872687578201,\n",
       " 0.023902524262666702,\n",
       " 0.027058381587266922,\n",
       " 0.013016006909310818,\n",
       " -0.024902651086449623,\n",
       " -0.03524785488843918,\n",
       " -0.029006393626332283,\n",
       " 0.026632152497768402,\n",
       " 0.017146635800600052,\n",
       " 0.03005373105406761,\n",
       " 0.018709639087319374,\n",
       " 0.009039006195962429,\n",
       " -0.0003497387806419283,\n",
       " -0.02716093137860298,\n",
       " -0.03059900738298893,\n",
       " -0.03340531140565872,\n",
       " 0.014620070345699787,\n",
       " -0.017534572631120682,\n",
       " -0.007187592331320047,\n",
       " -0.02055376023054123,\n",
       " -0.006507984362542629,\n",
       " -0.025136960670351982,\n",
       " -0.023336274549365044,\n",
       " 0.0118468152359128,\n",
       " -0.010614157654345036,\n",
       " 0.022047972306609154,\n",
       " -0.011457456275820732,\n",
       " -0.02619883045554161,\n",
       " -0.0063013904727995396,\n",
       " -0.01731240749359131,\n",
       " -0.010926485992968082,\n",
       " -0.03399984538555145,\n",
       " 0.01998182013630867,\n",
       " -0.024864448234438896,\n",
       " 0.01795063354074955,\n",
       " 0.01620658114552498,\n",
       " 0.02551545575261116,\n",
       " -0.027394717559218407,\n",
       " 0.02568560093641281,\n",
       " -0.016883987933397293,\n",
       " 0.013252471573650837,\n",
       " 0.03353981301188469,\n",
       " -0.0050368523225188255,\n",
       " -0.0002761951764114201,\n",
       " -0.008222520351409912,\n",
       " -0.02982087805867195,\n",
       " 0.017139388248324394,\n",
       " -0.03545420989394188,\n",
       " 0.022171426564455032,\n",
       " 0.026722325012087822,\n",
       " 0.03377522900700569,\n",
       " -0.00842426996678114,\n",
       " -0.029344355687499046,\n",
       " 0.008029652759432793,\n",
       " 0.019729547202587128,\n",
       " -0.035546742379665375,\n",
       " -0.00810655951499939,\n",
       " -0.02140912599861622,\n",
       " -0.003123705042526126,\n",
       " -0.017579054459929466,\n",
       " -0.014598842710256577,\n",
       " -0.011337817646563053,\n",
       " -0.033939432352781296,\n",
       " 0.029303841292858124,\n",
       " 0.029940402135252953,\n",
       " -0.005602466408163309,\n",
       " -0.0040672169998288155,\n",
       " -0.014575712382793427,\n",
       " -0.032252244651317596,\n",
       " -0.0347551591694355,\n",
       " 0.013273516669869423,\n",
       " -0.019608791917562485,\n",
       " -0.022959893569350243,\n",
       " -0.0027865427546203136,\n",
       " -0.011893255636096,\n",
       " -0.011554313823580742,\n",
       " 0.0011475427309051156,\n",
       " -0.0075754439458251,\n",
       " -0.012296873144805431,\n",
       " -0.01710021123290062,\n",
       " -0.029065266251564026,\n",
       " 0.029946686699986458,\n",
       " -0.01429239846765995,\n",
       " 0.009463553316891193,\n",
       " -0.01239163987338543,\n",
       " 0.0029021885711699724,\n",
       " 0.03329644724726677,\n",
       " 0.016454381868243217,\n",
       " -0.030949989333748817,\n",
       " 0.01417510025203228,\n",
       " 0.033901531249284744,\n",
       " 0.009395834058523178,\n",
       " 0.023943740874528885,\n",
       " 0.035210270434617996,\n",
       " -0.005472464486956596,\n",
       " 0.007412659469991922,\n",
       " -0.02482268400490284,\n",
       " -0.007359896786510944,\n",
       " 0.026449421420693398,\n",
       " 0.01830878108739853,\n",
       " -0.022599609568715096,\n",
       " -0.028638752177357674,\n",
       " -0.024405846372246742,\n",
       " -0.035245634615421295,\n",
       " -0.02755853720009327,\n",
       " -0.008832050487399101,\n",
       " 0.02410275675356388,\n",
       " 0.005977937486022711,\n",
       " -0.027164481580257416,\n",
       " -0.028650855645537376,\n",
       " 0.01776697486639023,\n",
       " -0.026565762236714363,\n",
       " -0.004397409502416849,\n",
       " 0.017132360488176346,\n",
       " -0.016529003158211708,\n",
       " -0.003894282504916191,\n",
       " -0.003108731471002102,\n",
       " -0.008449405431747437,\n",
       " -0.018108291551470757,\n",
       " -0.031837087124586105,\n",
       " -0.02886989340186119,\n",
       " -0.019123632460832596,\n",
       " 0.03449420630931854,\n",
       " -0.017250526696443558,\n",
       " -0.023983143270015717,\n",
       " 0.008656936697661877,\n",
       " 0.00984322652220726,\n",
       " 0.019568204879760742,\n",
       " 0.027147158980369568,\n",
       " 0.019888363778591156,\n",
       " -0.03541075065732002,\n",
       " 0.003167450660839677,\n",
       " 0.021634038537740707,\n",
       " -0.0033009096514433622,\n",
       " -0.021045686677098274,\n",
       " 0.03404785320162773,\n",
       " -0.01335813757032156,\n",
       " -0.020333733409643173,\n",
       " -0.03219839558005333,\n",
       " 0.0015952971298247576,\n",
       " 0.015826184302568436,\n",
       " 0.007905815728008747,\n",
       " 0.007062491029500961,\n",
       " -0.02708526700735092,\n",
       " -0.03335311636328697,\n",
       " 0.0006289056618697941,\n",
       " 0.03256550431251526,\n",
       " 0.020604334771633148,\n",
       " -0.020794082432985306,\n",
       " -0.004636019468307495,\n",
       " -0.026327986270189285,\n",
       " -0.017229408025741577,\n",
       " 0.006467798259109259,\n",
       " 0.019447803497314453,\n",
       " 0.029584618285298347,\n",
       " -0.032789506018161774,\n",
       " 0.023879116401076317,\n",
       " -0.025189004838466644,\n",
       " 0.013373831287026405,\n",
       " 0.030223047360777855,\n",
       " 0.0005015134811401367,\n",
       " 0.03249318152666092,\n",
       " -0.03043041191995144,\n",
       " -0.013641400262713432,\n",
       " 0.020830461755394936,\n",
       " -0.007780995219945908,\n",
       " -0.007310722954571247,\n",
       " -0.014885418117046356,\n",
       " 0.024618078023195267,\n",
       " 0.017517972737550735,\n",
       " 0.011444645933806896,\n",
       " -0.020070131868124008,\n",
       " -0.028991058468818665,\n",
       " 0.0038628792390227318,\n",
       " 0.01058138720691204,\n",
       " -0.01648971065878868,\n",
       " -0.009992774575948715,\n",
       " 0.024120276793837547,\n",
       " 0.0028449895326048136,\n",
       " 0.0016113690799102187,\n",
       " -0.008789305575191975,\n",
       " -0.032342489808797836,\n",
       " -0.03358062356710434,\n",
       " -0.01707196794450283,\n",
       " -0.018154336139559746,\n",
       " 0.011126914992928505,\n",
       " -0.010396813042461872,\n",
       " -0.013972219079732895,\n",
       " 0.034051068127155304,\n",
       " 0.012440103106200695,\n",
       " 0.025460798293352127,\n",
       " -0.017289740964770317,\n",
       " -0.014588100835680962,\n",
       " 0.013126445934176445,\n",
       " -0.023795541375875473,\n",
       " -0.02334657497704029,\n",
       " -0.0017249883385375142,\n",
       " -0.013062882237136364,\n",
       " -0.026773501187562943,\n",
       " 0.021184248849749565,\n",
       " 0.028720103204250336,\n",
       " 0.005793691147118807,\n",
       " -0.006218331400305033,\n",
       " -0.03308118134737015,\n",
       " -0.013008526526391506,\n",
       " 0.009092343971133232,\n",
       " 0.016840390861034393,\n",
       " -0.00451491167768836,\n",
       " -0.01411974523216486,\n",
       " 0.019900931045413017,\n",
       " -0.028442848473787308,\n",
       " 0.022572072222828865,\n",
       " -0.013855529949069023,\n",
       " 0.0005466214497573674,\n",
       " -0.0070577096194028854,\n",
       " 0.004329962655901909,\n",
       " -0.010792801156640053,\n",
       " 0.025968821719288826,\n",
       " -0.000928470108192414,\n",
       " 0.02787855453789234,\n",
       " 0.03433858975768089,\n",
       " -0.017399678006768227,\n",
       " -0.02605389803647995,\n",
       " 0.028653644025325775,\n",
       " 0.02798621356487274,\n",
       " -0.027269547805190086,\n",
       " -0.0027608319651335478,\n",
       " -0.035218797624111176,\n",
       " -0.029235683381557465,\n",
       " 0.006897947750985622,\n",
       " 0.009501236490905285,\n",
       " 0.0075707524083554745,\n",
       " -0.009720168076455593,\n",
       " 0.03294920548796654,\n",
       " 0.005106355529278517,\n",
       " -0.021074457094073296,\n",
       " -0.0020219215657562017,\n",
       " 0.008576614782214165,\n",
       " 0.012506881728768349,\n",
       " -0.02525288797914982,\n",
       " 0.013385343365371227,\n",
       " -0.018245775252580643,\n",
       " -0.029676442965865135,\n",
       " -0.019507408142089844,\n",
       " 0.034443192183971405,\n",
       " 0.030530637130141258,\n",
       " 0.031981587409973145,\n",
       " 0.020964687690138817,\n",
       " 0.026980342343449593,\n",
       " -0.004780347924679518,\n",
       " -0.01965099573135376,\n",
       " 0.017844878137111664,\n",
       " -0.018506526947021484,\n",
       " -0.024102352559566498,\n",
       " -0.011404787190258503,\n",
       " 0.007494973484426737,\n",
       " 0.018385594710707664,\n",
       " -0.013871751725673676,\n",
       " -0.021020226180553436,\n",
       " 0.004817609675228596,\n",
       " -0.021051187068223953,\n",
       " -0.023252194747328758,\n",
       " 0.018616139888763428,\n",
       " -0.005999450571835041,\n",
       " 0.03263517841696739,\n",
       " 0.03474223613739014,\n",
       " 0.01068234071135521,\n",
       " 0.012291346676647663,\n",
       " 0.008224419318139553,\n",
       " 0.0005593172390945256,\n",
       " -0.002597587648779154,\n",
       " 0.0004908613045699894,\n",
       " 0.013336599804461002,\n",
       " 0.03320610150694847,\n",
       " -0.009255682118237019,\n",
       " -0.015096993185579777,\n",
       " -0.008648744784295559,\n",
       " -0.017254438251256943,\n",
       " 0.006072810851037502,\n",
       " 0.02665887214243412,\n",
       " 0.027927765622735023,\n",
       " 0.01639734022319317,\n",
       " -0.026283269748091698,\n",
       " -0.019168028607964516,\n",
       " -0.007846836932003498,\n",
       " -0.006583005655556917,\n",
       " 0.002937419107183814,\n",
       " -0.03278469666838646,\n",
       " 0.011115883477032185,\n",
       " -0.027245434001088142,\n",
       " -0.0225980244576931,\n",
       " -0.029692234471440315,\n",
       " 0.03111856058239937,\n",
       " -0.033819280564785004,\n",
       " 0.02694167196750641,\n",
       " -0.0012006036704406142,\n",
       " -0.004153528716415167,\n",
       " 0.022338518872857094,\n",
       " -0.0033009862527251244,\n",
       " 0.022398361936211586,\n",
       " 0.02582196332514286,\n",
       " -0.03100750409066677,\n",
       " 0.013742285780608654,\n",
       " 0.006742107216268778,\n",
       " 0.007678990252315998,\n",
       " 0.005213980562984943,\n",
       " 0.009768962860107422,\n",
       " -0.01718095876276493,\n",
       " -0.004569326527416706,\n",
       " 0.03393285721540451,\n",
       " 0.023994626477360725,\n",
       " -0.0013417304726317525,\n",
       " -0.03359039127826691,\n",
       " 0.001565277692861855,\n",
       " -0.024320485070347786,\n",
       " 0.029042556881904602,\n",
       " -0.021681692451238632,\n",
       " -0.00257862894795835,\n",
       " -0.007926523685455322,\n",
       " 0.006355494726449251,\n",
       " 0.03360813111066818,\n",
       " 0.0033935438841581345,\n",
       " 0.02068443037569523,\n",
       " 0.027722202241420746,\n",
       " 0.02883254364132881,\n",
       " -0.01233398076146841,\n",
       " -0.007987737655639648,\n",
       " 0.01721206307411194,\n",
       " -0.009745274670422077,\n",
       " 0.016723714768886566,\n",
       " -0.0078024184331297874,\n",
       " -0.02422329969704151,\n",
       " 0.014537262730300426,\n",
       " 0.005475644953548908,\n",
       " 0.01592315547168255,\n",
       " 0.03548164665699005,\n",
       " 0.024383319541811943,\n",
       " 0.03385647013783455,\n",
       " 0.0019115295726805925,\n",
       " -0.0307218786329031,\n",
       " -0.02505454607307911,\n",
       " -0.02218477800488472,\n",
       " -0.031473156064748764,\n",
       " -0.017901698127388954,\n",
       " -0.032877422869205475,\n",
       " -0.032950546592473984,\n",
       " -0.02134123630821705,\n",
       " -0.03520835563540459,\n",
       " -0.021921874955296516,\n",
       " 0.013618167489767075,\n",
       " 0.02978760190308094,\n",
       " -0.010623672977089882,\n",
       " -0.010388527996838093,\n",
       " 0.019069761037826538,\n",
       " -0.0176203902810812,\n",
       " -0.0168868787586689,\n",
       " 0.0220046266913414,\n",
       " -0.031117917969822884,\n",
       " 0.00436695571988821,\n",
       " 0.0315493568778038,\n",
       " 0.006124517880380154,\n",
       " 0.009712278842926025,\n",
       " -0.020799685269594193,\n",
       " -0.0004927346017211676,\n",
       " 0.0019637304358184338,\n",
       " 0.00876551028341055,\n",
       " 0.013876643031835556,\n",
       " 0.031033137813210487,\n",
       " -0.02726069651544094,\n",
       " 0.0010705463355407119,\n",
       " -0.017844153568148613,\n",
       " -0.028252283111214638,\n",
       " -0.0028599160723388195,\n",
       " -0.03143703192472458,\n",
       " 0.024924973025918007,\n",
       " 0.004136243369430304,\n",
       " -0.01924850419163704,\n",
       " 0.018663538619875908,\n",
       " -0.03380100056529045,\n",
       " -0.013814258389174938,\n",
       " -0.006957812234759331,\n",
       " -0.03034822642803192,\n",
       " -0.022710299119353294,\n",
       " -0.0058292364701628685,\n",
       " 0.02709873765707016,\n",
       " 0.03448765352368355,\n",
       " 0.02272365801036358,\n",
       " -0.021325858309864998,\n",
       " -0.023365043103694916,\n",
       " 0.031167615205049515,\n",
       " 0.012632766738533974,\n",
       " 0.0009488463983871043,\n",
       " 0.004833289887756109,\n",
       " -0.02870345674455166,\n",
       " -0.011924480088055134,\n",
       " 0.03437922149896622,\n",
       " -0.00880829431116581,\n",
       " -0.001791575225070119,\n",
       " -0.02965468354523182,\n",
       " -0.019978826865553856,\n",
       " -0.0007292713853530586,\n",
       " -0.02218426577746868,\n",
       " -0.004428914748132229,\n",
       " 0.014534257352352142,\n",
       " -0.03493490442633629,\n",
       " 0.010607575066387653,\n",
       " -0.02361457794904709,\n",
       " -0.017430394887924194,\n",
       " 0.013711061328649521,\n",
       " 0.028397152200341225,\n",
       " -0.009761023335158825,\n",
       " -0.014663182199001312,\n",
       " -0.0322941392660141,\n",
       " -0.01841634511947632,\n",
       " -0.03127275034785271,\n",
       " -0.008173947222530842,\n",
       " 0.00728769414126873,\n",
       " -0.033459849655628204,\n",
       " 0.031182626262307167,\n",
       " 0.022406818345189095,\n",
       " -0.034962352365255356,\n",
       " -0.017058322206139565,\n",
       " 0.011648399755358696,\n",
       " -0.00733784306794405,\n",
       " -0.0038920175284147263,\n",
       " -0.01612555980682373,\n",
       " 0.028686413541436195,\n",
       " -0.019964223727583885,\n",
       " 0.029617030173540115,\n",
       " 0.0023043667897582054,\n",
       " 0.0071793501265347,\n",
       " 0.027861852198839188,\n",
       " -0.00588448578491807,\n",
       " -0.02033369056880474,\n",
       " -0.005776222329586744,\n",
       " 0.02896619401872158,\n",
       " -0.0264995489269495,\n",
       " 0.008106444962322712,\n",
       " -0.03509969636797905,\n",
       " 0.0187250766903162,\n",
       " 0.013195277191698551,\n",
       " 0.001514009083621204,\n",
       " 0.01532832719385624,\n",
       " 4.0169274143408984e-05,\n",
       " 0.01976260170340538,\n",
       " -0.02827216126024723,\n",
       " -0.005244732368737459,\n",
       " 0.015843380242586136,\n",
       " 0.03556488826870918,\n",
       " 0.018192552030086517,\n",
       " -0.025970514863729477,\n",
       " 0.027467746287584305,\n",
       " -0.007964223623275757,\n",
       " -0.007625516504049301,\n",
       " -0.03246106207370758,\n",
       " -0.005621940363198519,\n",
       " 0.02526167221367359,\n",
       " 0.004980172496289015,\n",
       " -0.020801927894353867,\n",
       " 0.01099328976124525,\n",
       " -0.011451585218310356,\n",
       " 0.032606929540634155,\n",
       " -0.030998380854725838,\n",
       " -0.01128126960247755,\n",
       " -0.03448477014899254,\n",
       " -0.014065364375710487,\n",
       " 0.011258845217525959,\n",
       " 0.03437909483909607,\n",
       " 0.005998083855956793,\n",
       " 0.035012803971767426,\n",
       " 0.006987576372921467,\n",
       " 0.020626286044716835,\n",
       " 0.02863079495728016,\n",
       " 0.02985440567135811,\n",
       " -0.019990134984254837,\n",
       " 0.03283535689115524,\n",
       " 0.021634481847286224,\n",
       " -0.016699250787496567,\n",
       " -0.0170429777354002,\n",
       " -0.029955223202705383,\n",
       " 0.00896918773651123,\n",
       " -0.028948189690709114,\n",
       " 0.01508659590035677,\n",
       " 0.011278489604592323,\n",
       " -0.03102865070104599,\n",
       " 0.009732174687087536,\n",
       " -0.002904662163928151,\n",
       " 0.016314920037984848,\n",
       " 0.020492486655712128,\n",
       " -0.035505183041095734,\n",
       " 0.032753534615039825,\n",
       " 0.02995150163769722,\n",
       " 0.014210131019353867,\n",
       " -0.032641466706991196,\n",
       " -0.01275788526982069,\n",
       " -0.010350316762924194,\n",
       " -0.00917849875986576,\n",
       " 0.020140111446380615,\n",
       " 0.012984664179384708,\n",
       " 0.028292112052440643,\n",
       " -0.013375828042626381,\n",
       " 0.012019277550280094,\n",
       " 0.012706969864666462,\n",
       " -0.029735388234257698,\n",
       " -0.034643568098545074,\n",
       " -0.01853175275027752,\n",
       " 0.024448132142424583,\n",
       " -0.03362356126308441,\n",
       " -0.03108692355453968,\n",
       " 0.020007163286209106,\n",
       " 0.01926889270544052,\n",
       " 0.029371168464422226,\n",
       " -0.026962097734212875,\n",
       " -0.0261392779648304,\n",
       " 0.018320953473448753,\n",
       " 0.03105822391808033,\n",
       " 0.021369244903326035,\n",
       " 0.005594717804342508,\n",
       " 0.011770525947213173,\n",
       " 0.033897385001182556,\n",
       " -0.023043012246489525,\n",
       " -0.016214707866311073,\n",
       " 0.02498096413910389,\n",
       " -0.024437131360173225,\n",
       " -0.01969330757856369,\n",
       " 0.026071110740303993,\n",
       " 0.011268646456301212,\n",
       " 0.011538216844201088,\n",
       " -0.015137158334255219,\n",
       " -0.0004928751150146127,\n",
       " 0.03268688544631004,\n",
       " -0.021436432376503944,\n",
       " 0.00028079323237761855,\n",
       " 0.01698569767177105,\n",
       " -0.024655582383275032,\n",
       " 0.034684889018535614,\n",
       " -0.017843235284090042,\n",
       " -0.0085762869566679,\n",
       " -0.009663224220275879,\n",
       " -0.023273533210158348,\n",
       " -0.035045165568590164,\n",
       " 0.02013755775988102,\n",
       " 0.0094883618876338,\n",
       " -0.03345002979040146,\n",
       " -0.022986672818660736,\n",
       " 0.03529886156320572,\n",
       " 0.01365125272423029,\n",
       " 0.014330166392028332,\n",
       " -0.021367790177464485,\n",
       " -0.015657003968954086,\n",
       " -0.005391219165176153,\n",
       " -0.006531426217406988,\n",
       " -0.0244731567800045,\n",
       " 0.002942319493740797,\n",
       " 0.0035495716147124767,\n",
       " -0.004522179253399372,\n",
       " 0.004951136652380228,\n",
       " -0.014155380427837372,\n",
       " 0.009294710122048855,\n",
       " 0.013469301164150238,\n",
       " -0.018812108784914017,\n",
       " -0.03541354089975357,\n",
       " 0.018694086000323296,\n",
       " 0.008519168943166733,\n",
       " -0.018163856118917465,\n",
       " 0.034417927265167236,\n",
       " -0.01615171507000923,\n",
       " 0.024133814498782158,\n",
       " 0.018118876963853836,\n",
       " -0.02994314767420292,\n",
       " 0.023033620789647102,\n",
       " -0.03283832222223282,\n",
       " -0.01978623867034912,\n",
       " -0.005954104010015726,\n",
       " -0.02407309040427208,\n",
       " 0.03488963842391968,\n",
       " -0.007163559086620808,\n",
       " 0.014185348525643349,\n",
       " -0.03188971430063248,\n",
       " 0.020559515804052353,\n",
       " -0.011099419556558132,\n",
       " -0.027166832238435745,\n",
       " 0.005222248379141092,\n",
       " 0.01730220764875412,\n",
       " 0.03090704046189785,\n",
       " -0.021814024075865746,\n",
       " -0.017575154080986977,\n",
       " 0.006866531912237406,\n",
       " 0.00968790054321289,\n",
       " 0.0137311527505517,\n",
       " 0.019602686166763306,\n",
       " -0.00809834711253643,\n",
       " 0.019841773435473442,\n",
       " 0.026331843808293343,\n",
       " -0.009329340420663357,\n",
       " 0.025409188121557236,\n",
       " 0.01744926907122135,\n",
       " 0.0315018855035305,\n",
       " -0.02029549703001976,\n",
       " -0.01763603650033474,\n",
       " -0.010326390154659748,\n",
       " 0.0018116534920409322,\n",
       " 0.021435679867863655,\n",
       " -0.020387953147292137,\n",
       " 0.017880499362945557,\n",
       " -0.012799335643649101,\n",
       " 0.021575333550572395,\n",
       " -0.0016956159379333258,\n",
       " -0.03128882125020027,\n",
       " -0.019651640206575394,\n",
       " -0.02584828808903694,\n",
       " 0.017712946981191635,\n",
       " -0.023948151618242264,\n",
       " -0.0029756512958556414,\n",
       " 0.007705565541982651,\n",
       " -0.01958552561700344,\n",
       " 0.010302501730620861,\n",
       " -0.03487226366996765,\n",
       " -0.025553874671459198,\n",
       " -0.032361552119255066,\n",
       " -0.010802763514220715,\n",
       " -0.013010622002184391,\n",
       " 0.005114048719406128,\n",
       " -0.006604088470339775,\n",
       " 0.016788644716143608,\n",
       " 0.0327426940202713,\n",
       " 0.01281396858394146,\n",
       " -0.014070268720388412,\n",
       " -0.03344234451651573,\n",
       " 0.012935783714056015,\n",
       " -0.017694925889372826,\n",
       " 0.018174154683947563,\n",
       " 0.023874463513493538,\n",
       " 0.01377573236823082,\n",
       " 0.033511098474264145,\n",
       " 0.03392130136489868,\n",
       " 0.0075621395371854305,\n",
       " -0.026022741571068764,\n",
       " 0.03190862014889717,\n",
       " -0.016946278512477875,\n",
       " -0.016869772225618362,\n",
       " 0.029884953051805496,\n",
       " 0.027671799063682556,\n",
       " 0.010791119188070297,\n",
       " 0.002238708082586527,\n",
       " -0.030041640624403954,\n",
       " -0.0037072899285703897,\n",
       " 0.034254513680934906,\n",
       " 0.009094958193600178,\n",
       " 0.0030577864963561296,\n",
       " -0.0074161081574857235,\n",
       " -0.01245651114732027,\n",
       " 0.021286526694893837,\n",
       " 0.002202447038143873,\n",
       " 0.023234793916344643,\n",
       " -0.006321379449218512,\n",
       " 0.015603900887072086,\n",
       " 0.014741783030331135,\n",
       " 0.005695147439837456,\n",
       " 0.022441895678639412,\n",
       " 0.02238021232187748,\n",
       " 0.03310440480709076,\n",
       " 0.027456285431981087,\n",
       " -0.0091320239007473,\n",
       " -0.030236437916755676,\n",
       " 0.006529195234179497,\n",
       " -0.0003117237938567996,\n",
       " -0.009315192699432373,\n",
       " -0.0059805260971188545,\n",
       " 0.0016797441057860851,\n",
       " 0.02605821006000042,\n",
       " 0.011133615858852863,\n",
       " -0.012681940570473671,\n",
       " -0.01468660682439804,\n",
       " -0.008843976072967052,\n",
       " -0.013803678564727306,\n",
       " 0.03211510181427002,\n",
       " 0.018915904685854912,\n",
       " 0.03224913403391838,\n",
       " 0.00011405775148887187,\n",
       " 0.007202532142400742,\n",
       " 0.012384453788399696,\n",
       " -0.033805470913648605,\n",
       " 0.0031891637481749058,\n",
       " -0.002388928784057498,\n",
       " -0.02002335898578167,\n",
       " -0.02771240659058094,\n",
       " 0.0316169448196888,\n",
       " 0.029038073495030403,\n",
       " 0.016552453860640526,\n",
       " 0.034080348908901215,\n",
       " -0.014493138529360294,\n",
       " -0.006168668158352375,\n",
       " 0.013522093184292316,\n",
       " -0.005900949705392122,\n",
       " -0.00700838677585125,\n",
       " -0.029520053416490555,\n",
       " 0.009595045819878578,\n",
       " -0.021583115682005882,\n",
       " 0.001298793824389577,\n",
       " 0.034820556640625,\n",
       " -0.010993404313921928,\n",
       " -0.011256848461925983,\n",
       " 0.02154688909649849,\n",
       " -0.013130473904311657,\n",
       " -0.003067050827667117,\n",
       " 0.033347804099321365,\n",
       " -0.014641920104622841,\n",
       " -0.025550367310643196,\n",
       " -0.019987277686595917,\n",
       " -0.009901630692183971,\n",
       " -0.01694638468325138,\n",
       " -0.01853327825665474,\n",
       " 0.01442658994346857,\n",
       " 0.006069204770028591,\n",
       " -0.011430771090090275,\n",
       " -0.027746835723519325,\n",
       " -0.011244995519518852,\n",
       " -0.015072827227413654,\n",
       " -0.011622105725109577,\n",
       " -0.032218679785728455,\n",
       " 0.0076938956044614315,\n",
       " -0.02624012902379036,\n",
       " -0.027814257889986038,\n",
       " -0.029179757460951805,\n",
       " 0.014906560070812702,\n",
       " -0.021500954404473305,\n",
       " -0.014741102233529091,\n",
       " 0.02799431048333645,\n",
       " 0.018963009119033813,\n",
       " 0.020478257909417152,\n",
       " -0.033910948783159256,\n",
       " -0.025610707700252533,\n",
       " -0.013482537120580673,\n",
       " 0.029503487050533295,\n",
       " 0.003653586143627763,\n",
       " -0.026710612699389458,\n",
       " 0.00022363664174918085,\n",
       " -0.027738245204091072,\n",
       " -0.007824975065886974,\n",
       " -0.009820538572967052,\n",
       " 0.03091648779809475,\n",
       " 0.01106202695518732,\n",
       " -0.006227540317922831,\n",
       " 0.006033169571310282,\n",
       " -0.010309483855962753,\n",
       " 0.014032156206667423,\n",
       " 0.014127280563116074,\n",
       " 0.009590933099389076,\n",
       " -0.01392060611397028,\n",
       " 0.03046967089176178,\n",
       " -0.005156069993972778,\n",
       " -0.013904167339205742,\n",
       " 0.022368360310792923,\n",
       " 0.0291091687977314,\n",
       " 0.03554142266511917,\n",
       " 0.010580655187368393,\n",
       " -0.012174781411886215,\n",
       " 0.018139000982046127,\n",
       " 0.030641233548521996,\n",
       " -0.03502979129552841,\n",
       " -0.004424533806741238,\n",
       " -0.02435591071844101,\n",
       " 0.006655706092715263,\n",
       " 0.014770887792110443,\n",
       " -0.0073781399987638,\n",
       " -0.0029877552296966314,\n",
       " 0.016075385734438896,\n",
       " -0.006002490408718586,\n",
       " -0.029992125928401947,\n",
       " 0.028576286509633064,\n",
       " -0.017975518479943275,\n",
       " -0.00392351858317852,\n",
       " 0.003368799341842532,\n",
       " -0.002146316459402442,\n",
       " -0.03359593078494072,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.defs['variables']['mini_mnist_weights_dram'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine FP8 from F32\n",
    "\n",
    "Special values:\n",
    "1. exponent and fractional part all zeros --> zero\n",
    "1. exponent all ones and fractional all zeros --> INF\n",
    "1. exponent all ones and fractional non-zero --> NaN\n",
    "\n",
    "FP8 format:  | 5 bit exponent | 2 bit mantissa | <br/>\n",
    "FP8ALT format: | 4 bit exponent | 3 bit mantissa | <br/>\n",
    "\n",
    "Example below is for FP8 format. TODO: Discuss with GIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary equivalent of -0.009314311668276787: 10111100000110001001101100001110\n",
      "\n",
      "Sign     ( 1 bit ) = 1\n",
      "Exponent ( 8 bits) = 01111000\n",
      "Mantissa (23 bits) = 00110001001101100001110\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def floatToBinary32(value):\n",
    "    return ''.join(f'{c:0>8b}' for c in struct.pack('!f', value))\n",
    "\n",
    "# float to binary\n",
    "fl0 = biases.detach().numpy()[0]\n",
    "binstr = floatToBinary32(fl0)\n",
    "print(f'Binary equivalent of {fl0}: {binstr}')\n",
    "\n",
    "print(f'\\nSign     ( 1 bit ) = {binstr[0]}\\nExponent ( 8 bits) = {binstr[1:9]}\\nMantissa (23 bits) = {binstr[9:]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate exponent bias of an FP32\n",
    "exp_bias_fp32 = 2 ** (8 - 1) - 1\n",
    "exp_bias_fp32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate unbiased exponent\n",
    "exponent_fp32 = int('01111000', 2) - exp_bias_fp32\n",
    "exponent_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate exponent bias of an FP8\n",
    "exp_bias_fp8 = 2 ** (5 - 1) - 1\n",
    "exp_bias_fp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the new exponent in the new FP format\n",
    "# minimum exponent: E_min = b'00001 - b'01111 = -14 \n",
    "# maximum exponent: E_max = b'01111 - b'00000 = 15\n",
    "exp_8 = exponent_fp32 + exp_bias_fp8\n",
    "exp_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the binary representation of the new exponent\n",
    "exp_8_bin = \"{0:b}\".format(exp_8)\n",
    "exp_8_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: check this with GIM\n",
    "# determine the new mantissa in the new FP format\n",
    "man_8_bin = binstr[9:11]\n",
    "man_8_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1100000'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 sign it + 5 exponent bits + 2 mantissa bits\n",
    "fp_8 = binstr[0] + exp_8_bin + man_8_bin\n",
    "fp_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('msc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ecad0643b88c81fa0e19ea49e906f3e8e46360fe82f2ddcb2e85abcf6121e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
